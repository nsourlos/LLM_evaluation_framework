{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz5Kh-zLB9lk"
      },
      "source": [
        "# Evaluate LLM results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no2PHIOWCBdA"
      },
      "source": [
        "Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U2Dpuc2xtmmS"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install datasets==2.20.0\n",
        "# !pip install -U langsmith==0.1.99\n",
        "# !pip install langchain_openai==0.2.0 #0.1.22\n",
        "# !pip install langchain==0.3.0 #0.2.13\n",
        "# !pip install langchain_community==0.3.0 #0.2.12  \n",
        "# !pip install langchain-huggingface==0.1.0                      \n",
        "# !pip install transformers==4.44.0\n",
        "# !pip install torch==2.1.0\n",
        "# !pip install termcolor==2.4.0\n",
        "# !pip install accelerate==0.33.0\n",
        "# !pip install pandas==2.2.2\n",
        "# !pip install openpyxl==3.1.5\n",
        "# !pip install python-dotenv==1.0.1\n",
        "# !pip install einops==0.8.0\n",
        "# !pip install wheel==0.44.0\n",
        "# !pip install sentencepiece==0.2.0\n",
        "# !pip install protobuf==5.27.3 #Mistral models needs this\n",
        "# !pip install groq==0.10.0 #Groq models needs this\n",
        "# !pip install matplotlib==3.9.2\n",
        "# !pip install seaborn==0.13.2\n",
        "# !pip install scipy==1.14.1\n",
        "# !pip install statsmodels==0.14.4\n",
        "# !pip install anthropic==0.40.0 #Anthropic models needs this\n",
        "# !pip install together==1.3.14 #Together models needs this\n",
        "# !pip install google-generativeai==0.8.4\n",
        "# !pip install google-genai==0.8.0\n",
        "# !pip install sentence-transformers==3.3.1\n",
        "\n",
        "# !pip install flash-attn==2.6.3 #Install it at the end after wheel has been installed\n",
        "\n",
        "# #Only if CPU is used\n",
        "# !pip install torch==2.0.1+cpu -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !jupyter lab --ServerApp.iopub_data_rate_limit=1e10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RunPod specific parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#For RunPod change to persistent storage directory\n",
        "import os\n",
        "os.chdir('/workspace')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify Path and Load API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ],
      "source": [
        "file_path ='/workspace/DRACO_draft.xlsx' #Dataset generated with the help of GPT-4o - Has to be an excel file with 'input' and 'output' columns\n",
        "#'/Users/nikolaossourlo/Desktop/Example_QA_data_raw.xlsx' #For MacOS\n",
        "#'C:/Users/soyrl/Desktop/Example_QA_data_raw.xlsx' #For Windows\n",
        "#'/content/drive/My Drive/Example_QA_data_raw.xlsx' #For Google Colab\n",
        "#'/home/nikolaossourlo/Example_QA_data_raw.xlsx' #For Delft Blue\n",
        "#'/workspace/Example_QA_data_raw.xlsx' #For RunPod\n",
        "\n",
        "custom_cache_dir=\"/workspace/cache/huggingface\" #Save models here so that we don't have to download them again\n",
        "#\"/scratch/nikolaossourlo/cache\" in Delft Blue\n",
        "\n",
        "# Check if custom_cache_dir is defined, otherwise use default behavior\n",
        "try:\n",
        "    cache_dir=custom_cache_dir\n",
        "except:\n",
        "    cache_dir=None\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import traceback\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv(dotenv_path=os.getcwd()+\"/env\")\n",
        "\n",
        "# Get the OpenAI API key\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY_DRACO')\n",
        "langsmith_api_key = os.getenv('LANGSMITH_API_KEY')\n",
        "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY_DRACO')\n",
        "together_api_key = os.getenv('TOGETHER_API_KEY_DRACO')\n",
        "open_router_api_key = os.getenv('OPEN_ROUTER_API_KEY')\n",
        "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
        "\n",
        "#Login to Hugging Face\n",
        "from huggingface_hub import login\n",
        "# Log in with your Hugging Face token\n",
        "login(token=os.getenv('HF_TOKEN'))\n",
        "\n",
        "# print(openai_api_key)\n",
        "# print(langsmith_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select model and name for the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Model to generate responses to questions - Sometimes we might have to restart session and comment out the models that have already been run\n",
        "models=[ #Reasoning models (deepseek only for now) should have longer max_tokens to include the reasoning steps\n",
        "    # \"together/Qwen/QwQ-32B\",     # \"Qwen/QwQ-32B-AWQ\",\n",
        "    # \"together/deepseek-ai/DeepSeek-R1\",\n",
        "    # \"openai/o1\", #o1-2024-12-17\n",
        "    # \"openai/o1-mini\", #o1-mini-2024-09-12\n",
        "    # \"openai/o3-mini\", #o3-mini-2025-01-31\n",
        "    # \"openai/gpt-4o-2024-08-06\",\n",
        "    # \"gemini/gemini-2.0-flash-exp\",\n",
        "    # \"together/deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\",\n",
        "    # \"together/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
        "    # \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
        "    # 'microsoft/phi-4', #14B parameters\n",
        "\n",
        "    # \"Qwen/Qwen2.5-7B-Instruct\",\n",
        "    # \"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "    \"meta-llama/Meta-Llama-3.1-8B-Instruct\", #A4500 (20GB VRAM) and in Delft Blue (V100 32GB)\n",
        "    # \"microsoft/Phi-3.5-mini-instruct\", #A40 with 48GB VRAM, A4500 with 20GB VRAM, Delft Blue \n",
        "    # \"mistralai/Mistral-7B-Instruct-v0.3\", #A40 with 48GB VRAM, A4500 with 20GB VRAM and in Delft Blue\n",
        "    # \"Qwen/Qwen2-7B-Instruct\", #A40 with 48GB VRAM, A4500 with 20GB VRAM, Delft Blue\n",
        "    # 'AI-MO/NuminaMath-7B-TIR', #A4500 with 20GB VRAM and in Delft Blue - We can also try 01-ai/Yi-Coder-9B-Chat\n",
        "    # 'microsoft/Phi-3-mini-4k-instruct', #RTX3090\n",
        "    # \"google/gemma-2-9b-it\", #More than 20GB of GPU memory needed - Works with A40 with 48GB VRAM, but not with A4500 - 20GB, and V100 - 32GB, Delft Blue\n",
        "    # 'mistralai/Mistral-Nemo-Instruct-2407', #12B parameters, 2 RTX3090, V100 with 32GB VRAM\n",
        "    # \"anthropic/claude-3-5-sonnet-20241022\",\n",
        "    # 'openai/gpt-4o-mini' #Costs very low ~0.01$ for 9 Q&A pairs.\n",
        "    # \"gemini/gemini-2.0-flash-thinking-exp\", #Thoughts only in Google studio, not in API - https://discuss.ai.google.dev/t/thoughts-are-missing-cot-not-included-anymore/63653/8\n",
        "    ] #Takes 7+hours in A40 for the above 13 models with 7Q&A paris and 4 resamples. Cost ±3$ (±180GB)\n",
        "\n",
        "# Groq models are defined as: groq_website/model_name e.g. 'groq_website/llama-3.1-70b-versatile'\n",
        "# OpenAI models are defined as: 'openai/model_name', e.g. 'openai/gpt-4o-mini'\n",
        "# Anthropic models are defined as 'anthropic/model_name', e.g. 'anthropic/claude-3-haiku-20240307' - Couldn't use due to billing issues\n",
        "# Together models are defined as 'together/model_name', e.g. 'together/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free'\n",
        "# OpenRouter models are defined as 'openrouter/model_name', e.g. 'openrouter/deepseek/deepseek-r1:free' - Do not work due to extremely limited quota\n",
        "# Gemini models are defined as 'gemini/model_name', e.g. 'gemini/gemini-2.0-flash-exp'\n",
        "\n",
        "# I couldn't run 'nvidia/Mistral-NeMo-Minitron-8B-Base', \"hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4\" (Conflicting dependencies),\n",
        "# 'google/recurrentgemma-9b-it' # RecurrentGemmaForCausalLM.forward() got an unexpected keyword argument 'position_ids'\n",
        "#Large models take more time (2min/generation for Mistral 12B)\n",
        "\n",
        "#Define model to act as a judge\n",
        "judge_model='openai/gpt-4o-mini' #If used with Llama, only 0.01$ for 9 Q&A pairs for gpt-4o-mini, and 0.22$ for gpt-4o\n",
        "\n",
        "#Used below to distinguish commercial and Hugging Face models\n",
        "commercial_api_providers=['openai','groq_website','anthropic','together', 'openrouter', 'gemini']\n",
        "\n",
        "#Define maximum number of tokes in the judge LLM output\n",
        "max_output_tokens=500\n",
        "\n",
        "#Limit of tokens in the generated response from LLM - For reasoning models we increase it to 4000 - had to define it below. \n",
        "generate_max_tokens=1000\n",
        "\n",
        "#Domain - Chemical/Water Engineering or anything else\n",
        "domain=\"Water\"\n",
        "\n",
        "#Inference on whole dataset?\n",
        "inference_on_whole_dataset=True\n",
        "\n",
        "#Number of times to resample the dataset\n",
        "n_resamples=1 #4 reduces the variance to 50%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define prompts for custom evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "common_prompt=\"\"\" \n",
        "You are an autoregressive language model that acts as a judge in comparing a predicted vs an actual answer to a questions.\n",
        "Since you are autoregressive, each token you produce is another opportunity to use computation, therefore you always spend \n",
        "a few sentences explaining background context, assumptions, and step-by-step thinking BEFORE you try to answer a question. \n",
        "Your users are experts in\"\"\"+ domain +\"\"\"engineering, so they already know you're a language model and your capabilities and limitations, so don't \n",
        "remind them of that. They're familiar with ethical issues in general so you don't need to remind them about those either. \n",
        "Don't be verbose in your answers, but do provide details and examples where it might help the explanation. \n",
        "\"\"\" #This is common for all prompts below - change with 'chemical engineering' for chemical engineer questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "completeness_descr = \"\"\"\n",
        "Your task is to evaluate responses predicted by an LLM with regards to completeness compared to the completeness of a given actual, golden standard answer. \n",
        "The completeness metric evaluates the extent to which the user's question is answered in full in the predicted response. \n",
        "You can assign a score from 1 to 5 to the predicted response with the following interpretations:\n",
        "1: There is no response.\n",
        "2: No parts of a suitable answer are present.\n",
        "3: Few elements of a complete answer are present.\n",
        "4: Most elements of a complete answer are present.\n",
        "5: The response covers all elements of a complete answer.\n",
        "IMPORTANT: End your responses with the sentence: \"FINAL SCORE:\" followed by whole numbers only (1, 2, 3, 4, or 5). Do not use decimal points. This may not be disregarded!\n",
        "\"\"\"\n",
        "\n",
        "relevance_descr = \"\"\"\n",
        "Your task is to evaluate responses predicted by an LLM with regards to relevance compared to the relevance of a given actual, golden standard answer. \n",
        "The relevance metric evaluates the amount of irrelevant information in the predicted response considering the user's original question. \n",
        "You can assign a score from 1 to 5 to the predicted response with the following interpretations:\n",
        "1: The response answers something else, not the user's question.\n",
        "2: The response answers the user's question but the information provided is mostly irrelevant.\n",
        "3: The response answers the user's question but contains more irrelevant information than relevant information.\n",
        "4: The response answers the user's question, and shares a bit of irrelevant information.\n",
        "5: The response answers the user's question and contains no irrelevant information.\n",
        "IMPORTANT: End your responses with the sentence: \"FINAL SCORE:\" followed by whole numbers only (1, 2, 3, 4, or 5). Do not use decimal points. This may not be disregarded!\n",
        "\"\"\"\n",
        "\n",
        "conciseness_descr = \"\"\"\n",
        "Your task is to evaluate responses predicted by an LLM with regards to conciseness compared to the conciseness of a given actual, golden standard answer. \n",
        "The conciseness metric evaluates the amount of unexpected extra information in the predicted response considering the user's original question. \n",
        "You can assign a score from 1 to 5 to the predicted response with the following interpretations:\n",
        "1: The response is too long and stops before completion or enters an infinite loop.\n",
        "2: The response includes a lot of extra information and uses flowery language.\n",
        "3: The response includes a lot of extra information or uses flowery language.\n",
        "4: The response is short and includes a small amount of extra information.\n",
        "5: The response is as short as possible while still answering the prompt.\n",
        "IMPORTANT: End your responses with the sentence: \"FINAL SCORE:\" followed by whole numbers only (1, 2, 3, 4, or 5). Do not use decimal points. This may not be disregarded!\n",
        "\"\"\"\n",
        "\n",
        "confidence_descr = \"\"\"\n",
        "Your task is to evaluate responses predicted by an LLM with regards to confidence compared to the confidence of a given actual, golden standard answer. \n",
        "The condifence metric evaluates the degree of assurance that is conveyed the response that the predicted answer is correct. \n",
        "You can assign a score from 1 to 5 to the predicted response with the following interpretations:\n",
        "1: Complete Rejection. The response makes it clear that the given answer is incorrect or that no correct answer can be provided.\n",
        "2: Doubt and Disagreement. The response suggests that the answer is likely incorrect or raises significant concerns.\n",
        "3: Uncertainty. The response indicates that the answer could be correct, but there is significant doubt or insufficient evidence.\n",
        "4: Moderate Agreement. The response leans towards the answer being correct but acknowledges some uncertainty.\n",
        "5: Full Endorsement. The reponse confidentely asserts that the given answer is correct.\n",
        "IMPORTANT: End your responses with the sentence: \"FINAL SCORE:\" followed by whole numbers only (1, 2, 3, 4, or 5). Do not use decimal points. This may not be disregarded!\n",
        "\"\"\"\n",
        "\n",
        "factuality_descr = \"\"\"\n",
        "Your task is to evaluate responses predicted by an LLM with regards to factuality compared to the factuality of a given actual, golden standard answer.\n",
        " The factuality metric evaluates the degree of hallucination contained in a response or, in other words, how accurate a given response is.\n",
        "You can assign a score from 1 to 5, with the following interpretations:\n",
        "1: The response is a complete hallucination\n",
        "2: The response is mostly a hallucination but does not change key information from the prompt\n",
        "3: The response contains large amounts of both hallucinations and factual information.\n",
        "4: The response includes mostly factual information with slight hallucinations.\n",
        "5: The response only includes factual information.\n",
        "IMPORTANT: End your responses with the sentence: \"FINAL SCORE:\" followed by whole numbers only (1, 2, 3, 4, or 5). Do not use decimal points. This may not be disregarded!\n",
        "\"\"\" #2: The response is mostly a hallucination but does not change key information from the prompt\"\"\"+ # (such as chemical identifiers).\n",
        "\n",
        "\n",
        "judgement_descr = \"\"\"\n",
        "Your task is to evaluate responses predicted by an LLM with regards to judgement compared to the judgement of a given actual, golden standard answer.\n",
        "The judgment metric assesses how strongly the response implies its correctness, taking into account the actual accuracy of the answer.\n",
        "You can assign a score from 1 to 5 to the predicted response with the following interpretations:\n",
        "1: The response confidently claims a hallucination as truth.\n",
        "2: The response misinterprets information received in the prompt.\n",
        "3: The response shows that the model is unsure about the answer or states that information is theoretical.\n",
        "4: The response is wrong but it is made clear that the answer is wrong or that the model is unable to provide a correct answer.\n",
        "5: The response is correct.\n",
        "IMPORTANT: End your responses with the sentence: \"FINAL SCORE:\" followed by whole numbers only (1, 2, 3, 4, or 5). Do not use decimal points. This may not be disregarded!\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install torch \n",
        "# !pip install mistral_inference\n",
        "\n",
        "# !pip install mistral-common"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mistral_common.protocol.instruct.tool_calls import Function, Tool\n",
        "\n",
        "# Define a new tool\n",
        "tool_definitions = [\n",
        "    # Tool(\n",
        "    # function=Function(\n",
        "    #     name=\"your_function_name\",\n",
        "    #     description=\"Describe what this function does\",\n",
        "    #     parameters={\n",
        "    #         \"type\": \"object\",\n",
        "    #         \"properties\": {\n",
        "    #             \"param1\": {\n",
        "    #                 \"type\": \"string\",\n",
        "    #                 \"description\": \"Description of param1\",\n",
        "    #             },\n",
        "    #             \"param2\": {\n",
        "    #                 \"type\": \"number\",\n",
        "    #                 \"description\": \"Description of param2\",\n",
        "    #             },\n",
        "    #         },\n",
        "    #         \"required\": [\"param1\", \"param2\"],\n",
        "    #     },\n",
        "    # )\n",
        "    # ),\n",
        "    Tool(\n",
        "    function=Function(\n",
        "        name=\"add\",\n",
        "        description=\"Adds two numbers together\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"number1\": {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"The first number to add\",\n",
        "                },\n",
        "                \"number2\": {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"The second number to add\",\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"number1\", \"number2\"],\n",
        "        },\n",
        "    )\n",
        "    ),\n",
        "    # Tool(\n",
        "    # function=Function(\n",
        "    #     name=\"subtract\",\n",
        "    #     description=\"Subtracts the second number from the first number\",\n",
        "    #     parameters={\n",
        "    #         \"type\": \"object\",\n",
        "    #         \"properties\": {\n",
        "    #             \"number1\": {\n",
        "    #                 \"type\": \"number\",\n",
        "    #                 \"description\": \"The number from which to subtract\",\n",
        "    #             },\n",
        "    #             \"number2\": {\n",
        "    #                 \"type\": \"number\",\n",
        "    #                 \"description\": \"The number to subtract\",\n",
        "    #             },\n",
        "    #         },\n",
        "    #         \"required\": [\"number1\", \"number2\"],\n",
        "    #     },\n",
        "    # )\n",
        "    # ),\n",
        "    # Tool(\n",
        "    # function=Function(\n",
        "    #     name=\"multiply\",\n",
        "    #     description=\"Multiplies two numbers together\",\n",
        "    #     parameters={\n",
        "    #         \"type\": \"object\",\n",
        "    #         \"properties\": {\n",
        "    #             \"number1\": {\n",
        "    #                 \"type\": \"number\",\n",
        "    #                 \"description\": \"The first number to multiply\",\n",
        "    #             },\n",
        "    #             \"number2\": {\n",
        "    #                 \"type\": \"number\",\n",
        "    #                 \"description\": \"The second number to multiply\",\n",
        "    #             },\n",
        "    #         },\n",
        "    #         \"required\": [\"number1\", \"number2\"],\n",
        "    #     },\n",
        "    # )\n",
        "    # ),\n",
        "    # Tool(\n",
        "    # function=Function(\n",
        "    #     name=\"exponential\",\n",
        "    #     description=\"Calculates the exponential of the first number raised to the power of the second number\",\n",
        "    #     parameters={\n",
        "    #         \"type\": \"object\",\n",
        "    #         \"properties\": {\n",
        "    #             \"base\": {\n",
        "    #                 \"type\": \"number\",\n",
        "    #                 \"description\": \"The base number\",\n",
        "    #             },\n",
        "    #             \"exponent\": {\n",
        "    #                 \"type\": \"number\",\n",
        "    #                 \"description\": \"The exponent to raise the base to\",\n",
        "    #             },\n",
        "    #         },\n",
        "    #         \"required\": [\"base\", \"exponent\"],\n",
        "    #     },\n",
        "    # )\n",
        "    # ),\n",
        "    Tool(\n",
        "    function=Function(\n",
        "        name=\"extract_code\",\n",
        "        description=\"Determines whether the provided text contains code. Use this tool whenever a user asks for a function, script, or programming-related response.\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"model_output\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The text to analyze for the presence of code.\",\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"model_output\"],\n",
        "        },\n",
        "    )\n",
        "    ),\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "tool_definitions = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"add\",\n",
        "            \"description\": \"Adds two numbers together\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"number1\": {\n",
        "                        \"type\": \"number\",\n",
        "                        \"description\": \"The first number to add\",\n",
        "                    },\n",
        "                    \"number2\": {\n",
        "                        \"type\": \"number\",\n",
        "                        \"description\": \"The second number to add\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"number1\", \"number2\"],\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"extract_code\",\n",
        "            \"description\": \"Determines whether the provided text contains code. Use this tool whenever a user asks for a function, script, or programming-related response.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"model_output\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The text to analyze for the presence of code.\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"model_output\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming you have a list or registry of tools\n",
        "# tools = [tool_definitions]  # Add your new tool to the list of tools\n",
        "tools=tool_definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from dotenv import load_dotenv\n",
        "# import os\n",
        "# import json\n",
        "# import numpy as np\n",
        "# import traceback\n",
        "\n",
        "# # Load environment variables from .env file\n",
        "# load_dotenv(dotenv_path=os.path.join(os.path.expanduser(\"~/Desktop\"), \"env\"))\n",
        "\n",
        "# # Get the OpenAI API key\n",
        "# openai_api_key = os.getenv('OPENAI_API_KEY_DRACO')\n",
        "# langsmith_api_key = os.getenv('LANGSMITH_API_KEY')\n",
        "# anthropic_api_key = os.getenv('ANTHROPIC_API_KEY_DRACO')\n",
        "# together_api_key = os.getenv('TOGETHER_API_KEY_DRACO')\n",
        "# open_router_api_key = os.getenv('OPEN_ROUTER_API_KEY')\n",
        "# gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
        "# judge_model='openai/gpt-4o-mini' #If used with Llama, only 0.01$ for 9 Q&A pairs for gpt-4o-mini, and 0.22$ for gpt-4o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decide_tool_usage(query, tools=tools, judge_model=judge_model, openai_api_key=openai_api_key):\n",
        "    \"\"\"Decide if a tool should be used based on the query, and if yes, output the tool name(s).\"\"\"\n",
        "\n",
        "    # Construct prompt for the judge\n",
        "    tool_descriptions = \"\\n\".join(\n",
        "        f\"Tool Name: {tool.function.name}\\nDescription: {tool.function.description}\\nParameters: {', '.join(tool.function.parameters['properties'].keys())}\"\n",
        "        for tool in tools\n",
        "    )\n",
        "    \n",
        "    prompt = f\"\"\"Given a user question, determine if any tool from the provided list should be used to answer the question.\n",
        "    Consider:\n",
        "    1. The capability of each tool, based on its name, description, and parameters, to provide useful information for answering the question\n",
        "    2. If using no tool might be better than using a potentially misleading tool\n",
        "\n",
        "    User Question: {query}\n",
        "\n",
        "    Available Tools:\n",
        "    {tool_descriptions}\n",
        "\n",
        "    Should a tool be used for answering the question? If yes, specify the tool name(s). Respond with 'No' or the tool name(s).\n",
        "    \"\"\"\n",
        "    \n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that determines tool usage.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    \n",
        "    # Use OpenAI to judge tool usage\n",
        "    import openai\n",
        "    from langsmith.wrappers import wrap_openai\n",
        "    client = wrap_openai(openai.Client(api_key=openai_api_key))\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "        model=judge_model.split('/')[1],\n",
        "        seed=42\n",
        "    )\n",
        "    \n",
        "    tool_decision = response.choices[0].message.content.strip()\n",
        "    print(\"Tool Decision:\", tool_decision)\n",
        "    \n",
        "    if tool_decision.lower() == 'no':\n",
        "        return None\n",
        "    else:\n",
        "        return tool_decision.split(', ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decide_tool_usage(query, tools=tool_definitions, judge_model=judge_model, openai_api_key=openai_api_key):\n",
        "    \"\"\"Decide if a tool should be used based on the query, and if yes, output the tool name(s).\"\"\"\n",
        "\n",
        "    # Construct prompt for the judge\n",
        "    tool_descriptions = \"\\n\".join(\n",
        "        f\"Tool Name: {tool['function']['name']}\\nDescription: {tool['function']['description']}\\nParameters: {', '.join(tool['function']['parameters']['properties'].keys())}\"\n",
        "        for tool in tools\n",
        "    )\n",
        "    \n",
        "    prompt = f\"\"\"Given a user question, determine if any tool from the provided list should be used to answer the question.\n",
        "    Consider:\n",
        "    1. The capability of each tool, based on its name, description, and parameters, to provide useful information for answering the question\n",
        "    2. If using no tool might be better than using a potentially misleading tool\n",
        "\n",
        "    User Question: {query}\n",
        "\n",
        "    Available Tools:\n",
        "    {tool_descriptions}\n",
        "\n",
        "    Should a tool be used for answering the question? If yes, specify the tool name(s). Respond with 'No' or the tool name(s).\n",
        "    \"\"\"\n",
        "    \n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that determines tool usage.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    \n",
        "    # Use OpenAI to judge tool usage\n",
        "    import openai\n",
        "    from langsmith.wrappers import wrap_openai\n",
        "    client = wrap_openai(openai.Client(api_key=openai_api_key))\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "        model=judge_model.split('/')[1],\n",
        "        seed=42\n",
        "    )\n",
        "    \n",
        "    tool_decision = response.choices[0].message.content.strip()\n",
        "    print(\"Tool Decision:\", tool_decision)\n",
        "    \n",
        "    if tool_decision.lower() == 'no':\n",
        "        return None\n",
        "    else:\n",
        "        return tool_decision.split(', ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool Decision: No\n",
            "None\n",
            "Tool Decision: add\n",
            "['add']\n",
            "Tool Decision: No\n",
            "None\n",
            "Tool Decision: extract_code\n",
            "['extract_code']\n"
          ]
        }
      ],
      "source": [
        "print(decide_tool_usage('How much is 3^3?'))\n",
        "print(decide_tool_usage('How much is 3+3?'))\n",
        "print(decide_tool_usage(\"What's the weather in Rotterdam?\"))\n",
        "print(decide_tool_usage(\"Write a function to load a df and calculate the sum of rows\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool Decision: No\n",
            "\n",
            "\n",
            "Tool Decision: add\n",
            "3+3\n",
            "Result of addition 6.0\n",
            "6.0\n",
            "\n",
            "\n",
            "Tool Decision: add\n",
            "3+3\n",
            "Result of addition 6.0\n",
            "6.0\n",
            "\n",
            "\n",
            "Tool Decision: No\n",
            "\n",
            "\n",
            "Tool Decision: extract_code\n",
            "Type <class 'str'>\n",
            "Resulting code: import pandas as pd\n",
            "import os\n",
            "\n",
            "def load_dataframe():\n",
            "    desktop_path = os.path.expanduser('~') + '/Desktop/test.xlsx'\n",
            "    df = pd.read_excel(desktop_path)\n",
            "    print(df)\n",
            "\n",
            "load_dataframe()\n",
            "Command conda run -n test_code_execution python -c \"import pandas as pd\n",
            "import os\n",
            "\n",
            "def load_dataframe():\n",
            "    desktop_path = os.path.expanduser('~') + '/Desktop/test.xlsx'\n",
            "    df = pd.read_excel(desktop_path)\n",
            "    print(df)\n",
            "\n",
            "load_dataframe()\"\n",
            "Execution Result:                                     input          output\n",
            "0                        How much is 3*3?               9\n",
            "1  What is the result of 128905342*423423  54581486625666\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def execute_tool(tool_name, query):\n",
        "    if tool_name=='extract_code':\n",
        "        # Use OpenAI to judge tool usage\n",
        "        import openai\n",
        "        from langsmith.wrappers import wrap_openai\n",
        "        client = wrap_openai(openai.Client(api_key=openai_api_key))\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"Return only the code from the following message to be directly copy pasted in a py file. Do not return it in quotes, just plain code. \\\n",
        "             The message is:\"},\n",
        "            {\"role\": \"user\", \"content\": query}\n",
        "        ]\n",
        "        \n",
        "        response = client.chat.completions.create(\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            model=judge_model.split('/')[1],\n",
        "            seed=42\n",
        "        )\n",
        "        \n",
        "        code_result = response.choices[0].message.content\n",
        "        print(\"Type\",type(code_result))\n",
        "        print(\"Resulting code:\",code_result)\n",
        "\n",
        "\n",
        "        import subprocess\n",
        "\n",
        "        # Define the command to execute the code in the 'test_LLM' conda environment\n",
        "        command = f\"conda run -n test_code_execution python -c \\\"{code_result}\\\"\"\n",
        "        print(\"Command\",command)\n",
        "\n",
        "        try:\n",
        "            # Execute the command and capture the output\n",
        "            result = subprocess.check_output(command, shell=True, stderr=subprocess.STDOUT, text=True)\n",
        "            print(\"Execution Result:\", result)\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            result = f\"Error in execution: {e.output}\"\n",
        "            print(result)\n",
        "\n",
        "\n",
        "        return code_result\n",
        "\n",
        "\n",
        "\n",
        "    elif tool_name == 'calculator':\n",
        "        # Example tool: calculator\n",
        "        # This tool can perform basic arithmetic operations\n",
        "        try:\n",
        "            result = eval(query)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            return f\"Error in calculation: {e}\"\n",
        "    elif tool_name == 'weather':\n",
        "        # Example tool: weather\n",
        "        # This tool can fetch weather information for a given location\n",
        "        location = query.split('in')[-1].strip()\n",
        "        # Assuming we have a function get_weather_info(location) that fetches weather info\n",
        "        try:\n",
        "            result = get_weather_info(location)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            return f\"Error in fetching weather information: {e}\"\n",
        "    elif tool_name == 'add':\n",
        "        try:\n",
        "            import openai\n",
        "            from langsmith.wrappers import wrap_openai\n",
        "            client = wrap_openai(openai.Client(api_key=openai_api_key))\n",
        "\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": \"Return only the two numbers from the following message that have to be added in the format a+b. The message is:\"},\n",
        "                {\"role\": \"user\", \"content\": query}\n",
        "            ]\n",
        "            \n",
        "            response = client.chat.completions.create(\n",
        "                messages=messages,\n",
        "                temperature=0,\n",
        "                model=judge_model.split('/')[1],\n",
        "                seed=42\n",
        "            )\n",
        "            \n",
        "            add_result = response.choices[0].message.content\n",
        "            print(add_result)\n",
        "\n",
        "            numbers = add_result.split('+')\n",
        "            number1 = float(numbers[0].strip())\n",
        "            number2 = float(numbers[1].strip())\n",
        "            result = number1 + number2\n",
        "            print(\"Result of addition\",result)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            return f\"Error in addition: {e}\"\n",
        "\n",
        "    # elif tool_name == 'code_generator':\n",
        "    #     # Example tool: code_generator\n",
        "    #     # This tool can generate code snippets based on the query\n",
        "    #     try:\n",
        "    #         # Assuming we have a function generate_code(query) that generates code\n",
        "    #         result = generate_code(query)\n",
        "    #         return result\n",
        "    #     except Exception as e:\n",
        "    #         return f\"Error in code generation: {e}\"\n",
        "    else:\n",
        "        return f\"Tool {tool_name} is not recognized.\"\n",
        "\n",
        "# Example usage\n",
        "tool_name = decide_tool_usage('How much is 3^3?')\n",
        "if tool_name:\n",
        "    print(execute_tool(tool_name, '3^3'))\n",
        "print(\"\\n\")\n",
        "\n",
        "tool_name = decide_tool_usage('How much is 3 plus 3?')\n",
        "if tool_name:\n",
        "    if 'add' in tool_name:\n",
        "        print(execute_tool('add', 'How much is 3 plus 3?'))\n",
        "print(\"\\n\")\n",
        "\n",
        "tool_name = decide_tool_usage('How much is 3 + 3?')\n",
        "if tool_name:\n",
        "    if 'add' in tool_name:\n",
        "        print(execute_tool('add', 'How much is 3 + 3?'))\n",
        "print(\"\\n\")\n",
        "\n",
        "tool_name = decide_tool_usage(\"What's the weather in Rotterdam?\")\n",
        "if tool_name:\n",
        "    print(execute_tool(tool_name, \"What's the weather in Rotterdam?\"))\n",
        "print(\"\\n\")\n",
        "\n",
        "tool_name = decide_tool_usage(\"Write a function to load a df. It should load the df 'test.xlsx' from desktop by dynamically getting the desktop path (os.path.expanduser('~')) and print it\")\n",
        "if tool_name:\n",
        "    if 'extract_code' in tool_name:\n",
        "        execute_tool('extract_code', \"Write a function to load a df. It should load the df 'test.xlsx' from desktop by dynamically getting the desktop path (os.path.expanduser('~')) and print it\")\n",
        "         #not print here\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "#How the dataset will be named in Langsmith\n",
        "def get_dataset_name(model_name, judge_model):\n",
        "    # try: #For Hugging Face models\n",
        "        if not any(provider in model_name for provider in commercial_api_providers): #For Hugging Face models\n",
        "            return domain+\"_Engineering_Evaluation_\"+model_name.split('/')[1]+'_with_judge_'+judge_model+'_beam_search_statistics_all' #Chemical\n",
        "        else: #For Commercial API providers\n",
        "            return domain+\"_Engineering_Evaluation_\"+model_name+'_with_judge_'+judge_model+'_beam_search_statistics_all' #Chemical\n",
        "    # except: #For OpenAI models\n",
        "    #     return \"Chemical_Engineering_Evaluation_\"+model_name+'_with_judge_'+judge_model+'_beam_search_statistics_all'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check if GPU is available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX9V2ASWCQG5"
      },
      "source": [
        "Google Drive mount (If run in Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLsdaFvRthOE",
        "outputId": "ee976853-2292-4eee-a380-812283627e56"
      },
      "outputs": [],
      "source": [
        "if 'content/drive/My Drive' in file_path:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read Excel File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lVqBHaT2s6Aq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "qa=pd.read_excel(file_path) #Read Excel\n",
        "qa=qa[['input','output']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J6zdJxKCubI"
      },
      "source": [
        "Create Dataset from df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oUw8Puxfs6Az"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "loaded_dataset=Dataset.from_pandas(qa)\n",
        "\n",
        "if inference_on_whole_dataset==False:\n",
        "    loaded_dataset = loaded_dataset.train_test_split(test_size=0.2, seed=42) #Used if going to fine-tune in part of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vf6thikds6A1"
      },
      "outputs": [],
      "source": [
        "if inference_on_whole_dataset==False:\n",
        "    dataset_train=loaded_dataset['train']\n",
        "    dataset_test=loaded_dataset['test']\n",
        "else:\n",
        "    dataset_test=loaded_dataset #When we use the whole dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXxkzQoHs6A5"
      },
      "source": [
        "Create Langsmith Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtdIrA3Ds6A8",
        "outputId": "90a9b4dd-e91a-4773-934b-2bf58cd8e3a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('How are flow corrections applied around each loop in the Hardy Cross method, and why must flow continuity be maintained at every junction?', 'In the Hardy Cross method, one first selects individual loops in the network and makes an initial guess of the flow in each pipe. Then, each loop is corrected iteratively: the head loss around the loop is summed, and a flow correction is applied to reduce the total head-loss error to zero. This correction is added (or subtracted) to the assumed flow in every pipe forming that loop. Flow continuity must be maintained at every junction to ensure that all flow entering a node is accounted for by either leaving through connecting pipes or satisfying demand. If continuity is not enforced, the model would not reflect true network behavior, causing errors to propagate in subsequent iterations.'), ('Which factors influence the choice of initial flow guesses in the Hardy Cross approach, and how can poor choices affect convergence?', 'Typical choices for initial flows are guided by approximate network demands or simple proportional splits of total system flow. For instance, if a node has a demand, one might set pipe flows toward that node according to each pipe’s relative capacity. Poorly chosen initial flows can lead to very slow convergence or even divergence, especially if the network has pipes with drastically different diameters or roughness values. The Hardy Cross method relies on incremental loop corrections, so extreme imbalances in initial flows can produce oscillations or prolonged iteration cycles.'), ('What aspects of the Newton-Raphson technique generally lead to faster convergence compared to loop-based iterative methods?', 'Newton-Raphson methods solve all governing equations simultaneously by using partial derivatives (the Jacobian) that link changes in flows or heads to changes in hydraulic equations. This approach allows the solver to make a more direct beeline toward the solution, whereas loop-based methods adjust flows one loop at a time. By incorporating global information into each iteration, Newton-Raphson typically reaches high accuracy in fewer iterations, especially for large or complex systems.'), ('Why is calculation of partial derivatives (the Jacobian) critical in Newton-Raphson solvers for water networks?', 'The Jacobian quantifies how each unknown (flow or head) affects the network equations. In Newton-Raphson solvers, the iterative update to each variable depends on these partial derivatives, enabling the solver to predict how changing a node’s head or a pipe’s flow will impact the entire system. Without an accurate Jacobian, the solver cannot reliably determine the direction or magnitude of each correction step, leading to slower or unstable convergence.'), ('In Newton-Raphson frameworks, how does solving for node heads all at once differ from solving for loop flow corrections all at once?', 'When solving for node heads all at once (often called the ‘node method’), the unknowns are the hydraulic heads at the nodes. All continuity and energy (headloss) equations are simultaneously satisfied in each iteration. In contrast, when solving for loop flow corrections, the unknowns are the additional flows around each loop, so the solver iterates on flows that balance head losses across loops. Both approaches can use a Newton scheme, but the node-based method typically forms a system of size equal to the number of junctions, while the loop-based method forms a system tied to the number of independent loops in the network.'), ('How does linearizing the head-loss equation in the Linear Theory (Simultaneous Pipe) method allow the entire network to be solved in a single system of equations per iteration?', 'Linearizing the head-loss equation entails approximating the nonlinear relationship (e.g., Darcy-Weisbach or Hazen-Williams) by evaluating its gradient at a known flow and using a linear slope around that point. This transforms the network equations into a linear system that can be solved simultaneously for all pipes in one step. After solving flows for the iteration, the head-loss slopes are updated based on the new flows, and the process repeats until convergence. Because all pipes and demands are included in the linear system, the method can update flows in the entire network in one global solve per iteration.'), ('Why is the Linear Theory approach typically more stable than Hardy Cross when applied to larger or more complex networks?', 'The Linear Theory method treats the entire network in a global manner, updating flows simultaneously. In contrast, the Hardy Cross method updates each loop one at a time and then moves to the next. For large or interconnected systems, local corrections in one loop can unbalance other loops, making sequential iteration prone to slow convergence or oscillation. The global perspective of the Linear Theory method keeps all parts of the network balanced at each iteration, which generally improves convergence stability.'), ('Which two main calculation steps define the GGA procedure for determining both nodal heads and pipe flows?', 'The Global Gradient Algorithm typically involves (1) solving a linearized matrix equation that relates changes in nodal heads to flow imbalances in the network and (2) updating pipe flows using the head differences between connected nodes and the derivative (gradient) of the head-loss equation. These two steps repeat until both nodal heads and flows satisfy continuity and energy conservation within a preset tolerance.'), ('How does the GGA avoid the need to manually identify independent loops that older methods require?', 'Instead of writing loop equations explicitly, the GGA forms the nodal continuity equations and uses pipe head-loss equations in matrix form. The algorithm computes partial derivatives of head loss with respect to flow to build a system that inherently captures all loops, reservoirs, and other elements. By working directly with node heads and pipe flows in a single formulation, it bypasses the manual step of defining loops, which was necessary in Hardy Cross or certain older loop-based Newton methods.'), ('Which algorithm does EPANET use for analyzing steady-state flows, and what makes it widely regarded as a robust and efficient solver?', 'EPANET uses the Global Gradient Algorithm (GGA) to compute flows and pressures throughout the network. This method is efficient because it solves node heads in a single matrix system and then updates pipe flows using the head-loss derivatives. It is robust thanks to its ability to converge reliably from a wide range of initial guesses, handle various network components (pumps, valves, etc.), and scale efficiently to large systems with thousands of pipes.'), ('What role do sparse matrix techniques play in improving the computational efficiency of large-scale gradient-based solvers?', 'Sparse matrix techniques take advantage of the fact that most entries in the system’s coefficient matrix are zero (since each node is only connected to a few others). Efficient data structures and factorization algorithms, such as sparse Cholesky or LU decomposition, reduce both the memory requirements and computation time. This can significantly speed up solving linearized systems in each iteration of a gradient-based method, which is critical for large networks with thousands of pipes and nodes.'), ('In which ways can the sequential loop-balancing nature of Hardy Cross become a bottleneck as networks grow in size and complexity?', 'Because Hardy Cross corrects one loop at a time, each iteration might have to cycle through many loops repeatedly to achieve global balance. In large or highly interconnected systems, adjustments in one loop affect neighboring loops, necessitating multiple passes before overall convergence. This sequential approach can lead to long computation times and can sometimes fail to converge if the initial flow distribution is poorly chosen or the network has extreme resistance differences across pipes.'), ('How do simultaneous or global updates of flows in Newton-Raphson or GGA methods differ fundamentally from the sequential loop-by-loop corrections in Hardy Cross?', 'In Newton-Raphson and GGA methods, all unknowns—either node heads or pipe flows—are solved together in a system of equations, accounting for the entire network’s interactions at each iteration. This means a single change in flow is influenced by, and simultaneously influences, the other flows and heads. Hardy Cross, by contrast, updates each loop independently and then moves on to the next, creating the possibility that a correction in one loop has to be revisited if it disrupts previously balanced loops.'), ('What is the general process for incorporating pump curves or valve characteristics into Newton-based or gradient-based WDS solvers?', 'Pump curves and valve relationships are typically expressed as additional head-loss or head-gain equations that relate flow to head across these devices. In a Newton or gradient-based solver, these equations are included in the overall system of nodal continuity and pipe head-loss equations. Their partial derivatives (for Newton) or gradient coefficients (for GGA) are computed so that each iteration can adjust flows and pressures in a manner consistent with the pump or valve’s performance curve.'), ('How do modern gradient-based methods handle nodes where the available pressure is insufficient to meet the specified demand?', 'Classical demand-driven algorithms would produce negative pressures at nodes with inadequate supply. Modern extensions introduce pressure-dependent demand (PDD) formulations or use an iterative scheme where node demands are reduced when pressure falls below certain thresholds. In gradient-based methods, this is done by modifying the demand equation at each iteration or introducing emitter-like relationships, ensuring that the system accurately reflects the reduced outflow when pressure is low.'), ('Why is the starting solution less critical in gradient-based solvers than in loop-based methods, and how do some solvers use zero-flow initial guesses?', 'Gradient-based solvers (e.g., GGA) typically converge from a wide range of starting points because each iteration considers global network interactions. By building the nodal continuity equations and head-loss relationships into a single linearized matrix, the solver updates large-scale imbalances systematically. As a result, it can start from simplistic guesses—such as all flows set to zero—and still converge efficiently. In contrast, loop-based methods rely on local corrections that can be more sensitive to poor initial flow distributions.'), ('Which WDS solution method typically requires the fewest number of iterations to converge, and what is the mathematical reason behind it?', 'Newton-based methods, especially the Global Gradient Algorithm, often require the fewest iterations because they use the first-order derivative (Jacobian or gradient) of the system’s equations. This derivative information provides a clear path to reduce error in each iteration, leading to near-quadratic convergence under normal conditions. Loop-based methods generally lack this global derivative insight, thus requiring more iterations to zero in on the final solution.'), ('Why is the GGA particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops?', 'Large networks benefit from the GGA’s global approach, where each iteration efficiently updates all node heads via a sparse matrix solution and then flows in each pipe. Because it leverages sparse matrix techniques and well-structured linear equations, it scales very effectively as the number of pipes and nodes grows. Additionally, the method’s robustness means it can handle broad variations in pipe sizes, demands, and complex layouts without excessive iteration counts.'), ('Under what circumstances might an engineer still opt to use the Hardy Cross method for hand calculations, despite its slower convergence?', 'An engineer might use Hardy Cross for teaching or demonstration purposes, as it provides clear insights into how flows are balanced in loops. It can also be convenient for very small networks or conceptual designs where quick, approximate solutions are acceptable and computational tools are not immediately available. In such cases, the simplicity and directness of Hardy Cross calculations can be beneficial, even though more advanced solvers are faster and more robust for larger systems.'), ('How have researchers attempted to further improve the GGA, such as by using parallel processing or advanced linear algebra routines?', 'Many researchers have examined alternative factorization methods (e.g., iterative solvers, multigrid approaches) or have parallelized the matrix assembly and solution steps to exploit modern multi-core CPUs and GPUs. In some studies, domain decomposition is used to split large networks into subregions that can be solved in parallel, with the solutions then merged at each iteration. While these techniques can offer speedups for extremely large models, the gains vary depending on network structure and overhead associated with partitioning and communication between subdomains.'), ('What is skeletonization in water distribution network modeling, and why is it used?', 'Skeletonization is the process of simplifying a water distribution network (WDN) model by removing minor pipes, merging redundant elements, and aggregating demand to reduce computational complexity. It is used to make simulations faster, reduce data management efforts, and optimize operational and planning studies. While modern computing reduces the need for aggressive skeletonization, it remains useful for large networks where real-time analysis or multiple scenario evaluations are needed.'), ('What are the main techniques for skeletonizing a water distribution network?', 'Common techniques include merging pipes in series or parallel to create an equivalent hydraulic representation, removing dead-end pipes with minimal hydraulic impact, aggregating demand nodes, and pruning redundant loops. Additionally, resilience-based skeletonization selects pipes for removal based on their contribution to system stability.'), ('How does merging pipes in series or parallel contribute to model reduction?', 'Merging pipes in series reduces the number of elements by replacing multiple connected pipes with a single equivalent pipe with appropriate hydraulic properties. Merging parallel pipes simplifies looped areas by creating an equivalent single pipe, preserving overall flow characteristics while reducing the computational load.'), ('Why is it important to preserve demand distribution when removing minor dead-end pipes?', 'Removing dead-end pipes without redistributing their demand can lead to inaccurate pressure calculations and misrepresentation of water usage patterns. Proper aggregation ensures that demand is preserved at the remaining nodes, maintaining network integrity.'), ('What are the potential risks of excessive skeletonization in water distribution networks?', 'Over-skeletonization can lead to loss of critical system details, inaccurate transient analysis, incorrect pressure predictions, and failure to detect hydraulic issues such as localized pressure drops or surge propagation effects. In extreme cases, it may render the model unreliable for operational decision-making.'), ('How does skeletonization impact transient (surge) analysis in hydraulic models?', 'Transient analysis requires detailed representations of small pipes since they influence pressure wave propagation. Removing these elements in skeletonized models can alter results, underestimating or misrepresenting transient pressures, leading to inadequate surge protection measures.'), ('Why do modern computing advancements reduce the need for skeletonization?', 'High-performance computing, parallel processing, and GPU acceleration enable larger models to be processed more efficiently. This allows utilities to use full-scale models without excessive reduction, maintaining accuracy while benefiting from enhanced computational speed.'), ('What is the role of the resilience index in selecting pipes for removal in skeletonization?', 'The resilience index quantifies a network’s ability to withstand demand fluctuations and failures. It helps identify and remove non-critical pipes while preserving key flow paths, ensuring that skeletonization does not compromise system reliability.'), ('What is compartmentalization in water distribution networks, and how does it differ from skeletonization?', 'Compartmentalization divides a large network into smaller, independently managed sectors (e.g., District Metered Areas). Unlike skeletonization, which reduces model size, compartmentalization focuses on operational management and leak detection by segmenting networks while keeping the full pipe infrastructure intact.'), ('What are District Metered Areas (DMAs), and how do they help in managing large networks?', 'DMAs are subdivisions of a water distribution network where all inflows and outflows are monitored. They help detect leaks, control pressures, and improve water distribution efficiency by isolating different sections for independent analysis and operation.'), ('What are the trade-offs of using DMAs in water distribution networks?', 'While DMAs improve leak detection and operational control, they may also reduce redundancy and pressure stability by closing certain interconnections. This can increase water age, impact firefighting capacity, and require additional investments in monitoring infrastructure.'), (\"Why do utilities sometimes use 'virtual DMAs' instead of physically closing pipes?\", 'Virtual DMAs use flow meters to monitor network zones without fully closing boundary pipes, preserving redundancy while enabling leak detection. This approach maintains operational flexibility but requires higher investment in metering and data analysis.'), ('What are the key challenges in computational modeling of very large water networks?', 'Challenges include high computational costs, numerical convergence issues, and data management complexity. Large models require robust solvers, efficient memory handling, and sometimes model reduction techniques to remain practical for daily operations.')]\n"
          ]
        }
      ],
      "source": [
        "#https://docs.smith.langchain.com/old/evaluation/faq/manage-datasets\n",
        "\n",
        "from langsmith import Client\n",
        "\n",
        "example_inputs = [(x['input'],x['output']) for x in dataset_test]\n",
        "print(example_inputs)\n",
        "\n",
        "def create_langsmith_dataset(dataset_name, example_inputs, langsmith_api_key):\n",
        "\n",
        "    client = Client(api_key=langsmith_api_key)\n",
        "\n",
        "    try:\n",
        "        #Load the dataset if already exists\n",
        "        for existing_dataset in client.list_datasets():\n",
        "            if existing_dataset.name==dataset_name:\n",
        "                dataset_langsmith=existing_dataset\n",
        "        for x in dataset_langsmith:\n",
        "            print(\"Dataset Loaded\")\n",
        "            break\n",
        "\n",
        "    except: #Otherwise create it\n",
        "        print(\"Dataset not found. Creating new dataset\")\n",
        "        # Storing inputs in a dataset lets us run chains and LLMs over a shared set of examples.\n",
        "        dataset_langsmith = client.create_dataset(dataset_name=dataset_name,\n",
        "                                                description=\"Q&A\"+ domain + \"engineering.\") #chemical\n",
        "\n",
        "        for input_prompt, output_answer in example_inputs:\n",
        "            client.create_example(\n",
        "                inputs={\"question\": input_prompt.replace('\\n', ' ')},\n",
        "                outputs={\"answer\": output_answer.replace('\\n', ' ')},\n",
        "                # metadata={\"source\": \"Wikipedia\"},\n",
        "                dataset_id=dataset_langsmith.id,\n",
        "            )\n",
        "\n",
        "    return dataset_langsmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Custom Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://docs.smith.langchain.com/old/cookbook/introduction\n",
        "# https://docs.smith.langchain.com/old/evaluation/faq/custom-evaluators\n",
        "# https://docs.smith.langchain.com/how_to_guides/evaluation/evaluate_llm_application#use-a-summary-evaluator\n",
        "\n",
        "from langsmith.schemas import Run, Example\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from termcolor import colored\n",
        "\n",
        "list_of_metrics=['completeness_descr','relevance_descr','conciseness_descr','confidence_descr','factuality_descr','judgement_descr']\n",
        "\n",
        "#Function that compares the real answer with the predicted answer of an LLM and returns a score based on the evaluation\n",
        "def factor_evaluator(run: Run, example: Example) -> dict: \n",
        "    # print(\"Run:\",run)\n",
        "\n",
        "    question=run.inputs.get(\"inputs\")['question']\n",
        "    # print(\"Question:\",question)\n",
        "    actual_answer = example.outputs.get(\"answer\")\n",
        "    # print(\"Real answer:\",example.outputs.get(\"answer\"))\n",
        "    predicted_answer = run.outputs.get(\"output\")\n",
        "    # print(\"Predicted Answer:\",answer)\n",
        "\n",
        "    scores={} #Store scores for each metric\n",
        "    descriptions={} #Store descriptions for each metric\n",
        "    \n",
        "    # Check if there is output from LLM\n",
        "    if not predicted_answer:\n",
        "        print(\"No output from LLM\")\n",
        "        keys=[]\n",
        "        for metric_name in list_of_metrics: #o1 sometimes doesn't give an answer\n",
        "            keys.append(metric_name.split('_descr')[0])\n",
        "            scores[metric_name]=0\n",
        "            descriptions[metric_name]='-'\n",
        "        results = {\n",
        "            \"results\": [{\"key\": key, \"score\": scores[key + \"_descr\"], \"value\": descriptions[key + \"_descr\"]} for key in keys]}\n",
        "        return results\n",
        "\n",
        "    else:\n",
        "        for metric_name in list_of_metrics: #Iterate through all metrics\n",
        "            print(\"Evaluating based on:\",metric_name)\n",
        "            metric_value=common_prompt+eval(metric_name) #Get the actual description of the metric\n",
        "\n",
        "            # Define roles and placeholders\n",
        "            chat_template = ChatPromptTemplate.from_messages(\n",
        "            [(\"system\", metric_value),\n",
        "                (\"user\", \"Question: {question}, Actual answer: {actual_answer}, Predicted answer: {predicted_answer}\"),\n",
        "                # (\"ai\", \"It's sunny and warm outside.\"), #Use this if we want to use few shot prompts\n",
        "            ]\n",
        "            )\n",
        "\n",
        "            messages = chat_template.format_messages(question=question, actual_answer=actual_answer, predicted_answer=predicted_answer)\n",
        "            # print(\"Messages:\",messages)\n",
        "\n",
        "            formatted_messages = [(role, msg.content) for role, msg in zip([\"system\", \"user\"], messages)]\n",
        "            # print(\"Formatted messages:\",formatted_messages) #[('system', 'You are an autoregressive lan....', 'user':.....)]\n",
        "\n",
        "            # Initialize the model and get response\n",
        "            llm = ChatOpenAI(model_name=judge_model.split('/')[1], api_key=openai_api_key, temperature=0, max_tokens=max_output_tokens, seed=42)\n",
        "            ai_response = llm.invoke(formatted_messages)\n",
        "\n",
        "            # Output\n",
        "            # print(colored(\"System message:\"+ messages[0].content,'blue'))\n",
        "            print(colored(\"User message:\"+ messages[1].content, 'green'))\n",
        "            print(colored(\"AI message:\"+ ai_response.content,'red'))\n",
        "\n",
        "            #Decide what the final score is based on output\n",
        "            if \"FINAL SCORE:\" in ai_response.content: \n",
        "                score = int(ai_response.content.split(\"FINAL SCORE:\")[1])\n",
        "            else:\n",
        "                print(\"Invalid response from LLM:\", ai_response.content)\n",
        "                score = 0 #For cases where the LLM doesn't return a score - Otherwise we are gonna get an error\n",
        "\n",
        "            scores[metric_name]=score\n",
        "            descriptions[metric_name]=ai_response.content\n",
        "            print(\"Scores:\",scores)\n",
        "            print(\"\\n\")\n",
        "\n",
        "    return {\n",
        "        \"results\":[ #We always need 'key', 'score' pairs\n",
        "            {\"key\": \"completeness\" , \"score\": scores['completeness_descr'],\"value\":descriptions['completeness_descr']},\n",
        "            {\"key\": \"relevance\" , \"score\": scores['relevance_descr'], \"value\":descriptions['relevance_descr']},\n",
        "            {\"key\": \"conciseness\" , \"score\": scores['conciseness_descr'], \"value\":descriptions['conciseness_descr']},\n",
        "            {\"key\": \"confidence\" , \"score\": scores['confidence_descr'], \"value\":descriptions['confidence_descr']},\n",
        "            {\"key\": \"factuality\" , \"score\": scores['factuality_descr'], \"value\":descriptions['factuality_descr']},\n",
        "            {\"key\": \"judgement\" , \"score\": scores['judgement_descr'], \"value\":descriptions['judgement_descr']}\n",
        "        ]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define Models that Generate Responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "torch.random.manual_seed(0) #Set for reproducibility\n",
        "\n",
        "def initialize_model(model_id):\n",
        "    # # Check if mps acceleration is available (For MacOS)\n",
        "    # device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "    # print(f\"Using device {device}\")\n",
        "    # model.to(device)\n",
        "\n",
        "    # transformers.set_seed(42) #Tried for reproducibility but didn't work\n",
        "    \n",
        "    pipeline = transformers.pipeline( \n",
        "            \"text-generation\",\n",
        "            model=model_id,\n",
        "            model_kwargs={\"torch_dtype\": torch.bfloat16, \"cache_dir\":cache_dir},\n",
        "            # trust_remote_code=True,\n",
        "            device_map=\"auto\" #Use 'cuda' if one GPU available (works in Delft Blue with 32GB VRAM) - 'auto' the alternative for distributed over all available GPUs\n",
        "        )\n",
        "    return pipeline\n",
        "\n",
        "def get_model(model_id):\n",
        "    \"\"\"Given a model name, return the loaded model, tokenizer, and pipeline\"\"\"\n",
        "\n",
        "    # if 'openai' not in model_id and 'groq_website' not in model_id and 'anthropic' not in model_id and 'together' not in model_id: #For Hugging Face models\n",
        "    if not any(provider in model_id for provider in commercial_api_providers): #For Hugging Face models\n",
        "        pipeline=initialize_model(model_id)\n",
        "\n",
        "    #Returns below variables if defined, and returns None for any that are not.\n",
        "    model = locals().get('model', None)\n",
        "    tokenizer = locals().get('tokenizer', None)\n",
        "    pipeline = locals().get('pipeline', None)\n",
        "\n",
        "    return model, tokenizer, pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate Responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def predict(inputs: dict) -> dict:\n",
        "    \"\"\"Given a question, return the answer from the model\"\"\"\n",
        "    \n",
        "    #Get these variables from the global scope\n",
        "    global model_name, generate_max_tokens\n",
        "    \n",
        "    messages = [ #Only use the questions to ask the model to generate the response\n",
        "      {\"role\": \"user\", \"content\": inputs['question']},\n",
        "    ]\n",
        "\n",
        "    #They do not support system message\n",
        "    if 'gemma' not in model_name and 'anthropic' not in model_name and 'openrouter' not in model_name and 'gemini' not in model_name and '/o1' not in model_name: \n",
        "      messages.insert(0, {\"role\": \"system\", \"content\": \"You are a language model specialized in \"+ domain + \" engineering. Answer the following question:\"}) #chemical\n",
        "    elif 'gemini' in model_name: #Google Gemini has this format since it also gets images\n",
        "      messages = {\"role\": \"user\", \"parts\": [{\"text\": \"You are a language model specialized in \"+ domain + \"engineering. Answer the following question: \" + messages[0]['content']}]}\n",
        "    else: #For gemma add system prompt in user message\n",
        "      messages[0]['content']=\"You are a language model specialized in \"+ domain + \" engineering. Answer the following question: \" + messages[0]['content']\n",
        "    # print(\"Prompt:\",messages)\n",
        "\n",
        "    #Reasoning model with CoT should have longer max_tokens to include the reasoning steps - For now deepseek and Gemini Flash Thinking\n",
        "    if 'deepseek' in model_name or 'thinking' in model_name or '/o1' in model_name or '/o3' in model_name or 'QwQ-32B-AWQ' in model_name:\n",
        "      generate_max_tokens=4000\n",
        "      print(\"Generation limit increased due to reasoning model:\", model_name, \"to:\",generate_max_tokens)\n",
        "    else: #Since it's global it might stay to 4000 otherwise\n",
        "      generate_max_tokens=1000\n",
        "\n",
        "    generation_args = { \n",
        "        \"max_new_tokens\": generate_max_tokens,\n",
        "        \"return_full_text\": False, \n",
        "        \"temperature\": 0.05, #Has to be positive number - not considered from model when do_sample is False (reproducible results)\n",
        "        \"do_sample\": True, #Selects highest probability token if sets to False\n",
        "        \"num_beams\" : 5, #3 can also work if computationally intensive - more info on https://huggingface.co/blog/how-to-generate\n",
        "        #Warnings will be raised by some models\n",
        "\n",
        "        #If we only set temp!=0 or if we also set do_sample=False then warning: `do_sample` is set to `False`. However, `temperature` is set to `1e-08` \n",
        "        # -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
        "        # That means that the temperature is probably ignored\n",
        "        # Sometimes, results not reproducible if only temp is set\n",
        "        # A temparature of 0.01 or lower results in: \"Error running target function: probability tensor contains either `inf`, `nan` or element < 0\"\n",
        "      } \n",
        "    \n",
        "    if not any(provider in model_name for provider in commercial_api_providers): #For Hugging Face models\n",
        "      response=pipeline(messages, **generation_args)[0]['generated_text']\n",
        "      print(model_name,':',response)\n",
        "\n",
        "    else: \n",
        "      if 'openai' in model_name:\n",
        "        try:\n",
        "          import openai\n",
        "          from langsmith.wrappers import wrap_openai\n",
        "                  \n",
        "          # Define OpenAI client\n",
        "          openai_client = wrap_openai(openai.Client(api_key=openai_api_key))\n",
        "          \n",
        "          if '/o1' not in model_name and '/o3' not in model_name:\n",
        "            response = openai_client.chat.completions.create(messages=messages, temperature=0, model=model_name.split('/')[1], max_tokens=generate_max_tokens, seed=42) \n",
        "          else: #For thinking models\n",
        "            print(\"Thinking....\")\n",
        "            response = openai_client.chat.completions.create(messages=messages, model=model_name.split('/')[1], max_completion_tokens=generate_max_tokens, seed=42) \n",
        "\n",
        "          # print(\"Full Response from OpenAI:\",response)\n",
        "          response=response.choices[0].message.content #That's the response without formatting\n",
        "          print(\"Response from OpenAI:\",response)\n",
        "          time.sleep(5) #To avoid rate limiting\n",
        "\n",
        "        except Exception as e:\n",
        "          print(\"Error:\",e)\n",
        "          print(\"OpenAI Model ID:\",model_name)\n",
        "\n",
        "      elif 'groq_website' in model_name:\n",
        "        try:\n",
        "          from groq import Groq\n",
        "          client = Groq()\n",
        "          actual_model_name=model_name.split('/')[1]\n",
        "          response = client.chat.completions.create(\n",
        "              model=actual_model_name,\n",
        "              max_tokens=generate_max_tokens,\n",
        "              temperature=0,\n",
        "              messages=messages)\n",
        "          \n",
        "          response=response.choices[0].message.content #That's the response without formatting\n",
        "          print(\"Response from Groq:\",response)#.choices[0].message.content)\n",
        "          time.sleep(5) #To avoid rate limiting\n",
        "\n",
        "        except Exception as e:\n",
        "          print(\"Error:\",e)\n",
        "          print(\"Groq Model ID:\",model_name)\n",
        "\n",
        "      elif 'anthropic' in model_name:\n",
        "        try:\n",
        "          import anthropic\n",
        "          client = anthropic.Anthropic()\n",
        "          response = client.messages.create(\n",
        "              model=model_name.split('/')[1],\n",
        "              messages=messages,\n",
        "              temperature=0,\n",
        "              max_tokens=generate_max_tokens,\n",
        "          )\n",
        "          response=response.content[0].text #That's the response without formatting\n",
        "          print(\"Response from Anthropic:\",response)#.content[0].text)\n",
        "          time.sleep(5) #To avoid rate limiting\n",
        "\n",
        "        except Exception as e:\n",
        "          print(\"Error:\",e)\n",
        "          print(\"Anthropic Model ID:\",model_name)\n",
        "\n",
        "      elif 'together' in model_name:\n",
        "        try:\n",
        "          from together import Together\n",
        "          client = Together()\n",
        "          response = client.chat.completions.create(\n",
        "              model=\"/\".join(model_name.split(\"/\")[1:]),\n",
        "              messages=messages,\n",
        "              temperature=0,\n",
        "              max_tokens=generate_max_tokens\n",
        "          )\n",
        "          # print(\"Full Response from Together:\",response_full)\n",
        "          response=response.choices[0].message.content #That's the response without formatting\n",
        "          print(\"Response from Together:\",response)\n",
        "          time.sleep(5) #To avoid rate limiting\n",
        "          if \"<think>\" in response:\n",
        "            time.sleep(180) #To avoid rate limiting need to wait 3 minutes\n",
        "\n",
        "        except Exception as e:\n",
        "          print(\"Error:\",e)\n",
        "          print(\"Together Model ID:\",model_name)\n",
        "      \n",
        "      elif 'openrouter' in model_name: #Very limited quota for free models\n",
        "        try:\n",
        "          from openai import OpenAI\n",
        "\n",
        "          client = OpenAI(\n",
        "            base_url=\"https://openrouter.ai/api/v1\",\n",
        "            api_key=open_router_api_key,\n",
        "          )\n",
        "          response = client.chat.completions.create(\n",
        "            model=\"/\".join(model_name.split(\"/\")[1:]),\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            max_tokens=generate_max_tokens,\n",
        "          )\n",
        "          response=response.choices[0].message.content #That's the response without formatting\n",
        "          print(\"Response from OpenRouter:\",response)#.choices[0].message.content)\n",
        "          time.sleep(5) #To avoid rate limiting\n",
        "\n",
        "        except Exception as e:\n",
        "          print(\"Error:\",e)\n",
        "          print(\"OpenRouter Model ID:\",model_name)\n",
        "\n",
        "      elif 'gemini' in model_name:\n",
        "        try:\n",
        "          if 'thinking' in model_name: #Thinking model has different call\n",
        "            from google.generativeai.types import GenerationConfig\n",
        "            import google.generativeai as genai\n",
        "            model = genai.GenerativeModel(model_name.split('/')[1])\n",
        "            response = model.generate_content(\n",
        "                contents=messages,\n",
        "                generation_config=GenerationConfig(\n",
        "                    temperature=0,\n",
        "                    max_output_tokens=generate_max_tokens,\n",
        "                )\n",
        "            )\n",
        "            print(\"Full Response from Gemini ('thinking') model:\",response)\n",
        "            response=response.text\n",
        "            print(\"Response from Gemini ('thinking') model:\",response)\n",
        "            time.sleep(5) #To avoid rate limiting\n",
        "          else: #for the rest of the models\n",
        "            from google import genai\n",
        "            from google.genai import types\n",
        "            client = genai.Client(api_key=gemini_api_key)\n",
        "            response = client.models.generate_content(\n",
        "              model=model_name.split('/')[1],\n",
        "              contents=messages,\n",
        "              config=types.GenerateContentConfig(\n",
        "                  temperature=0,\n",
        "                  max_output_tokens=generate_max_tokens,\n",
        "              )\n",
        "            )\n",
        "            response=response.text\n",
        "            print(\"Response from Gemini:\",response)\n",
        "            time.sleep(5) #To avoid rate limiting\n",
        "        except Exception as e:\n",
        "          print(\"Error:\",e)\n",
        "          print(\"Gemini Model ID:\",model_name)\n",
        "\n",
        "\n",
        "    return {\"output\": response}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def calculate_statistics(values):\n",
        "    \"\"\"Calculate mean, standard error, and confidence intervals.\"\"\"\n",
        "    mean_value = np.mean(values)  # Mean of the metric over single run and over single metric (but over all questions)\n",
        "    std_error = np.std(values, ddof=1) / np.sqrt(len(values))  # ddof=1 to divide by n-1 to calculate the sample sd\n",
        "    \n",
        "    assert np.std(values, ddof=1) == np.sqrt(np.sum((values-mean_value)**2)/(len(values)-1)), \"Standard deviation calculation mismatch\"\n",
        "    \n",
        "    margin_of_error = 1.96 * std_error  # didn't use t_critical=t.ppf(0.975, df=len(values)-1) since we're using sample standard deviation\n",
        "\n",
        "    return {\n",
        "        'mean': mean_value,\n",
        "        'std_error': std_error,\n",
        "        'ci_low': mean_value - margin_of_error,\n",
        "        'ci_high': mean_value + margin_of_error\n",
        "    }\n",
        "\n",
        "def plot_metric_distributions(metric_values, axes, colors, bin_edges, metric_names):\n",
        "    \"\"\"Plot individual metric distributions with error bars.\"\"\"\n",
        "    error_bars = []\n",
        "    run_stats = {}\n",
        "    \n",
        "    for metric_idx, (metric_name, values) in enumerate(metric_values.items()):  # Loop over runs' metric names and values\n",
        "        clean_metric_name = metric_name.replace('_descr', '')  # This is over one run and over one metric (but over all questions)\n",
        "        metric_name = metric_names[metric_idx]\n",
        "        assert clean_metric_name == metric_name, \"Metric name mismatch\"\n",
        "        \n",
        "        stats = calculate_statistics(values)\n",
        "        sns.histplot(values, bins=bin_edges, color=colors[metric_idx], ax=axes[metric_idx], kde=False)\n",
        "        \n",
        "        #Store error bars\n",
        "        if metric_idx == 0:\n",
        "            error_bars = []\n",
        "        error_bars.append((stats['mean'], axes[metric_idx].get_ylim()[1]/2, stats['ci_high'] - stats['mean']))\n",
        "        \n",
        "        run_stats[metric_name] = stats\n",
        "\n",
        "        axes[metric_idx].set_title(f'{metric_name} (Mean: {stats[\"mean\"]:.2f} ± {stats[\"std_error\"]:.2f} SE, CI: {stats[\"ci_low\"]:.2f}-{stats[\"ci_high\"]:.2f})')\n",
        "        axes[metric_idx].set_xlim(0, 5.5)  # Keep 0 in case of errors\n",
        "        axes[metric_idx].set_ylabel('Frequency')\n",
        "        axes[metric_idx].set_xlabel('Values' if metric_idx == len(metric_values)-1 else '')\n",
        "        \n",
        "    return error_bars, run_stats\n",
        "\n",
        "def plot_question_scores(metric_names, grouped_values, colors):\n",
        "    \"\"\"Plot scores for each question across metrics.\"\"\"\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Define colors for each metric\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(metric_names)))\n",
        "\n",
        "    # First count all frequencies per score (1-5) per metric for one run over all questions\n",
        "    question_scores_by_metric = {metric: [] for metric in metric_names}\n",
        "    score_metric_counts = {}\n",
        "\n",
        "    #Plot each metric's values and store question scores\n",
        "    for i, (metric, question_scores) in enumerate(zip(metric_names, grouped_values)):\n",
        "        width = 0.8 / len(question_scores)  # Width of each metric's bar\n",
        "        \n",
        "        for j, val in enumerate(question_scores): #Create a bar for each question's score\n",
        "            plt.bar(i + j * width, val, width=width, color=colors[i], alpha=0.5, \n",
        "                    label=metric if j == 0 else \"\")\n",
        "                    # i is the index of metric and determines the base position of a group of bars corresponding to that metric.\n",
        "                    # j*width adds an offset to the base position to separate individual bars within the same group (metric). \n",
        "                    # Each j corresponds to a different value in question_scores, creating distinct bars for the values of question_scores for the same metric.\n",
        "                    # By combining the above two, we get the exact x-position of a specific bar     \n",
        "            question_scores_by_metric[metric].append((j, val))\n",
        "\n",
        "        counts = Counter(question_scores)  # Count frequency of each score in question_scores (e.g. {4: 1, 3: 2, 2: 2, 1: 1, 0: 1}, where key is score)\n",
        "        for score, freq in counts.items():\n",
        "            if score not in score_metric_counts:\n",
        "                score_metric_counts[score] = {}\n",
        "            score_metric_counts[score][metric] = freq  #Keeps track of how many times each metric gets a specific score over all questions (for one run)\n",
        "            # {4: {'completeness': 1, 'confidence': 1, 'factuality': 1, 'judgement': 1}, 3: {'completeness': 1, 'relevance': 2, 'conciseness': 2, ....}\n",
        "\n",
        "    return question_scores_by_metric, score_metric_counts\n",
        "\n",
        "def plot_ordered_scores(metric_names, question_scores_by_metric, colors):\n",
        "    \"\"\"Plot metrics ordered by score values.\"\"\"\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    for i, metric in enumerate(metric_names):\n",
        "        plt.subplot(len(metric_names), 1, i+1)\n",
        "        sorted_questions = sorted(question_scores_by_metric[metric], key=lambda x: x[1]) #Sort questions by score\n",
        "        \n",
        "        #Plot bars\n",
        "        x_pos = range(len(sorted_questions))\n",
        "        scores = [q[1] for q in sorted_questions] #q[1] is the score, q[0] is the index\n",
        "        plt.bar(x_pos, scores, color=colors[i], alpha=0.5)\n",
        "\n",
        "        #Add question indices as x-axis labels\n",
        "        plt.xticks(x_pos, [str(q[0]) for q in sorted_questions])\n",
        "        \n",
        "        plt.ylabel(metric)\n",
        "        plt.ylim(0, 5.5)\n",
        "        plt.yticks(range(6))  # Set y-axis ticks from 0 to 5\n",
        "\n",
        "        if i == len(metric_names)-1:\n",
        "            plt.xlabel('Question number (ordered by score)')\n",
        "\n",
        "def plot_accumulated_distributions(score_metric_counts, metric_names, colors):\n",
        "    \"\"\"Plot accumulated distribution of scores by metric.\"\"\"\n",
        "    legend_added = set()\n",
        "\n",
        "    #For each score, plot metrics in order of frequency (highest frequency at bottom)\n",
        "    for score in sorted(score_metric_counts.keys()):\n",
        "        #Sort metrics by frequency for this score\n",
        "        sorted_metrics = sorted(score_metric_counts[score].items(),\n",
        "                            key=lambda x: x[1], #Use the frequency (second element of each tuple) as the sorting key\n",
        "                            reverse=True)  # highest frequency first\n",
        "        bottom = 0\n",
        "        for metric, freq in sorted_metrics:\n",
        "            i = metric_names.index(metric) #get index for color\n",
        "            plt.bar(score, freq,\n",
        "                    width=0.4,\n",
        "                    color=colors[i],\n",
        "                    alpha=0.5,\n",
        "                    label=metric if metric not in legend_added else \"\",\n",
        "                    bottom=bottom)\n",
        "            bottom += freq\n",
        "            legend_added.add(metric)\n",
        "\n",
        "           \n",
        "def plot_figures_metrics(all_runs_model_metrics, metric_names, model_name, judge_model):\n",
        "    \"\"\"\n",
        "    Creates visualizations and calculates statistics for evaluation metrics across multiple runs.\n",
        "\n",
        "    Args:\n",
        "        all_runs_model_metrics (dict): Nested dictionary containing evaluation metrics for each model and run.\n",
        "            Structure: {model_id: [{metric1_descr_run1: [q1_score, q2_score, ...], \n",
        "                                  metric2_descr_run1: [q1_score, q2_score, ...], ...}, \n",
        "                                 {metric1_descr_run2: [q1_score, q2_score, ...],\n",
        "                                  metric2_descr_run2: [q1_score, q2_score, ...], ...},\n",
        "                                 ...num_runs]}\n",
        "            Example: {'model1': [{'completeness_descr_run1': [4.5, 3.0, 4.0], \n",
        "                                'relevance_descr_run1': [3.5, 4.0, 3.0]}, ...,\n",
        "                               {'completeness_descr_run2': [4.0, 3.5, 4.5],\n",
        "                                'relevance_descr_run2': [3.0, 4.5, 3.5], ...},\n",
        "                               ...num_runs]}\n",
        "            Where each inner dictionary represents one run containing scores for each metric across all questions\n",
        "        metric_names (list): Names of metrics to analyze and plot (e.g. ['completeness', 'relevance'])\n",
        "        model_name (str): Name/identifier of the model being evaluated\n",
        "        judge_model (str): Name/identifier of the model used for judging the evaluations\n",
        "\n",
        "    Returns:\n",
        "        dict: Summary statistics for each model, run and metric.\n",
        "            Structure: {model_name: {run_idx: {metric_name: {\n",
        "                'mean': float,\n",
        "                'std_error': float, \n",
        "                'ci_low': float,\n",
        "                'ci_high': float\n",
        "            }}}}\n",
        "            Example: {'anthropic/claude-3-5-sonnet': {\n",
        "                '0': {'completeness': {'mean': 4.5, 'std_error': 0.5, \n",
        "                                     'ci_low': 3.52, 'ci_high': 5.48},\n",
        "                      'relevance': {'mean': 3.5, 'std_error': 0.5,\n",
        "                                  'ci_low': 2.52, 'ci_high': 4.48} , ...},\n",
        "                '1': {'completeness': {'mean': 4.5, 'std_error': 0.5,\n",
        "                                     'ci_low': 3.52, 'ci_high': 5.48},\n",
        "                      'relevance': {'mean': 3.5, 'std_error': 0.5,\n",
        "                                  'ci_low': 2.52, 'ci_high': 4.48}, ...},\n",
        "                ...num_runs}}\n",
        "\n",
        "    The function generates several visualization types:\n",
        "    - Individual histograms for each metric showing score distributions\n",
        "    - Error bars indicating means and confidence intervals\n",
        "    - Overlapping bar plots comparing metrics\n",
        "    - Stacked distribution plots showing relative frequencies of scores\n",
        "\n",
        "    All plots are saved as PNG files with names indicating the judge model,\n",
        "    evaluated model, run index, and plot type.\n",
        "    \"\"\"\n",
        "\n",
        "    summary_stats_all_runs = {}  # Keep track of summary statistics over all runs\n",
        "\n",
        "    for run_idx, metric_values_run in enumerate(all_runs_model_metrics[model_name]): #Loop over runs\n",
        "\n",
        "        colors = sns.color_palette(\"Set3\", len(metric_names))\n",
        "        \n",
        "        # Create two figures - one with separate subplots and one overlaid\n",
        "        fig, axes = plt.subplots(len(metric_names), 1, figsize=(10, 18))\n",
        "        plt.subplots_adjust(hspace=0.6, top=0.94)\n",
        "        fig.suptitle(f'Metric Distributions for {model_name} (Run {run_idx})', fontsize=16)\n",
        "        \n",
        "        bin_edges = np.arange(0.0, 5.6, 0.2)  # Bins for range 0-5\n",
        "        metric_names = [name.replace('_descr', '') for name in metric_values_run]\n",
        "        \n",
        "        error_bars, run_stats = plot_metric_distributions(metric_values_run, axes, colors, bin_edges, metric_names)\n",
        "        \n",
        "        # Save version without error bars\n",
        "        plt.figure(fig.number)\n",
        "        plt.savefig(f\"{judge_model.split('/')[1]}_judge_with_{model_name.replace('/', '_')}_run_{run_idx}_metric_distributions_no_error_bars.png\")\n",
        "        \n",
        "        # Add error bars and save updated version\n",
        "        for i, (mean, ylim, margin) in enumerate(error_bars):\n",
        "            axes[i].errorbar(mean, ylim, xerr=margin, color='black', capsize=5, \n",
        "                           capthick=1, elinewidth=2, marker='o')\n",
        "        \n",
        "        plt.savefig(f\"{judge_model.split('/')[1]}_judge_with_{model_name.replace('/', '_')}_run_{run_idx}_metric_distributions.png\")\n",
        "        plt.close('all')\n",
        "\n",
        "        # Print summary statistics - Can also be seen in txt file. \n",
        "        print(f\"\\nSummary Statistics over run {run_idx}:\")\n",
        "        print(\"-\" * 50)\n",
        "        for metric, stats in run_stats.items():\n",
        "            print(f\"{metric}:\")\n",
        "            for key, value in stats.items():\n",
        "                print(f\"  {key}: {value:.2f}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        summary_stats_all_runs[run_idx] = run_stats #For one run\n",
        "\n",
        "        grouped_values=list(metric_values_run.values()) #Values of all metrics for one run over all questions. There are num_metrics lists in that list. \n",
        "        values = [val for sublist in grouped_values for val in sublist] #Flatten the list - Size is num_questions*num_metrics (1st metric questions, 2nd metric questions, etc)\n",
        "        \n",
        "        question_scores_by_metric, score_metric_counts = plot_question_scores(metric_names, grouped_values, colors)\n",
        "        plt.xlabel('Metrics')\n",
        "        plt.ylabel('Score')\n",
        "        plt.title('Per-Metric Question Scores Distribution')\n",
        "        plt.xticks(np.arange(len(metric_names)) + 0.1, metric_names)\n",
        "        plt.yticks(range(6)) #Set y-ticks to 0-5\n",
        "        plt.savefig(f\"{judge_model.split('/')[1]}_judge_with_{model_name.replace('/', '_')}_run_{run_idx}_per_metric_question_scores.png\")\n",
        "        plt.close('all')\n",
        "\n",
        "        # Plot ordered scores\n",
        "        plot_ordered_scores(metric_names, question_scores_by_metric, colors)\n",
        "        plt.suptitle('Question indices ordered by metric value')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{judge_model.split('/')[1]}_judge_with_{model_name.replace('/', '_')}_run_{run_idx}_question_indices_ordered_by_metric_value.png\")\n",
        "        plt.close('all')\n",
        "\n",
        "        # Plot accumulated distributions\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plot_accumulated_distributions(score_metric_counts, metric_names, colors)\n",
        "        plt.xlabel('Score')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.title('Score Distribution Histogram by Metric') \n",
        "        plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.xticks(np.arange(0, 6))\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{judge_model.split('/')[1]}_judge_with_{model_name.replace('/', '_')}_run_{run_idx}_score_distribution_histogram_by_metric.png\")\n",
        "        plt.close('all')\n",
        "\n",
        "    return summary_stats_all_runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform the Evaluation over all models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "#https://python.langchain.com/v0.2/docs/integrations/chat/openai/\n",
        "from langsmith.evaluation import evaluate\n",
        "\n",
        "def load_model_stats(judge_model): #In case we had to restart the loop - some models didn't run - Keep track of all model stats\n",
        "    \"\"\"Load existing stats from files or initialize empty dictionaries.\"\"\"\n",
        "    try:\n",
        "        with open(f'stats_{judge_model.split(\"/\")[1]}.json', 'r') as f:\n",
        "            all_models_stats = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        all_models_stats = {}  # Used in comparison between models\n",
        "\n",
        "    try:\n",
        "        with open(f'all_runs_model_metrics_{judge_model.split(\"/\")[1]}.json', 'r') as f:\n",
        "            all_runs_model_metrics = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        all_runs_model_metrics = {}  # Used in plotting metrics\n",
        "        \n",
        "    return all_models_stats, all_runs_model_metrics\n",
        "\n",
        "def perform_evaluation(model_id, judge_model, n_resamples, example_inputs, factor_evaluator, langsmith_api_key):\n",
        "    \"\"\"Perform evaluation runs and collect results.\"\"\"\n",
        "    dataset_name = get_dataset_name(model_id, judge_model) #How the dataset will be named in Langsmith\n",
        "    dataset_langsmith = create_langsmith_dataset(dataset_name, example_inputs, langsmith_api_key)\n",
        "\n",
        "    evaluation_all_resamples = [] #Used below to obtain the unique questions/answers and also the results of each resample\n",
        "    \n",
        "    begin = time.time()\n",
        "    for resample_idx in range(n_resamples):\n",
        "        print(f\"\\nPerforming evaluation of resample {resample_idx+1}/{n_resamples} of {model_id}\")\n",
        "\n",
        "        evaluation_results = evaluate(\n",
        "            predict, #Function that call our LLM and returns its output\n",
        "            data=dataset_langsmith.name, #Just using dataset_langsmith doesn't work \n",
        "            evaluators=[factor_evaluator], #Evaluators to use\n",
        "            max_concurrency=1, #Run one question through langsmith each time - Other values will give errors in resulting excels\n",
        "            # metadata={\"revision_id\": \"the version of your pipeline you are testing\"},\n",
        "            experiment_prefix=str(judge_model)+'_judge_with_'+str(model_id)+'_resample_'+str(resample_idx) # A prefix for your experiment names to easily identify them\n",
        "        )\n",
        "        evaluation_all_resamples.extend(evaluation_results) #Used below to get unique questions/answers and to select the predicted answers\n",
        "        #This has n_resamples*num_questions elements, for just one model\n",
        "\n",
        "    with open('evaluation_all_resamples_'+str(model_id.split('/')[1])+'_'+str(judge_model.split('/')[1])+'.txt', 'w') as f:\n",
        "        f.write(str(evaluation_all_resamples))\n",
        "\n",
        "    assert len(evaluation_all_resamples)==n_resamples*len(example_inputs), f\"Number of evaluation results not matching num_resamples*num_questions. \\\n",
        "        Got {len(evaluation_all_resamples)} evaluation results but expected {n_resamples*len(example_inputs)}\"\n",
        "    \n",
        "    print(f\"Total time for evaluation: {time.time() - begin}\")\n",
        "\n",
        "    return evaluation_all_resamples, dataset_langsmith\n",
        "\n",
        "def process_evaluation_results(langsmith_api_key, dataset_langsmith):\n",
        "    \"\"\"Extract questions and answers from evaluation results.\"\"\"\n",
        "    #https://docs.smith.langchain.com/tutorials/Developers/evaluation\n",
        "\n",
        "    # Get unique questions/answers\n",
        "    client = Client(api_key=langsmith_api_key)\n",
        "    questions_answers=[x for x in client.list_examples(dataset_id=dataset_langsmith.id)]\n",
        "    list_of_questions=[x.inputs['question'] for x in questions_answers]\n",
        "    list_of_answers=[x.outputs['answer'] for x in questions_answers]\n",
        "        \n",
        "    # with open('list_of_questions.txt', 'w') as f:\n",
        "    #     f.write(str(list_of_questions))\n",
        "        \n",
        "    # with open('list_of_answers.txt', 'w') as f:\n",
        "    #     f.write(str(list_of_answers))\n",
        "    \n",
        "    results_df = pd.DataFrame({\n",
        "        'questions': list_of_questions,\n",
        "        'answers': list_of_answers\n",
        "    })\n",
        "    return results_df, list_of_questions\n",
        "\n",
        "def process_metrics(resample_results, list_of_metrics, list_of_questions, resample_idx, results_df, model_name):\n",
        "    \"\"\"\n",
        "    Process metrics for a single resample and update results DataFrame.\n",
        "    \n",
        "    Args:\n",
        "        resample_results: Results from current resample\n",
        "        list_of_metrics: List of metrics to process\n",
        "        resample_idx: Current resample index\n",
        "        results_df: DataFrame to update with metrics\n",
        "        model_name: Name of the model being evaluated\n",
        "        \n",
        "    Returns:\n",
        "        individual_run_metric_scores, metrics, results_df\n",
        "    \"\"\"\n",
        "\n",
        "    metrics = [] #This should be the same as resample_results (list) except when there are 'traceback' errors where it will be 0.\n",
        "    # metrics format will be:[[EvaluationResult(key='completeness', score=4, value='To evaluate the .... - It has num_questions sublists, each with num_metrics values\n",
        "\n",
        "    for result in resample_results:\n",
        "        if result['run'].outputs['output'] is None or not result['evaluation_results']['results']: #or result['run'].error is not None - Same as first condition\n",
        "            metrics.append(0)  # Use 0 to indicate failed evaluation - We might even get in here when LangSmith API connection issues\n",
        "            print(\"Error: No metric value found!\")\n",
        "            #Also print which condition is true\n",
        "            print(\"result['run'].outputs['output'] is None\",result['run'].outputs['output'] is None)\n",
        "            print(\"not result['evaluation_results']['results']\",not result['evaluation_results']['results'])\n",
        "            # print(\"result['run'].error is not None\",result['run'].error is not None)\n",
        "        else:\n",
        "            metrics.append(result['evaluation_results']['results'])\n",
        "\n",
        "    with open('resample_results_'+str(resample_idx)+'_'+str(model_name.split('/')[1])+'.txt', 'w') as f:\n",
        "        f.write(str(resample_results))\n",
        "\n",
        "    assert len(resample_results)==len(list_of_questions), f\"Number of resample results not matching num_questions. Got {len(resample_results)} resample \\\n",
        "        results but expected {len(list_of_questions)}\"\n",
        "    \n",
        "    with open('metrics_'+str(resample_idx)+'_'+str(model_name.split('/')[1])+'.txt', 'w') as f:\n",
        "        f.write(str(metrics))\n",
        "\n",
        "    assert len(metrics)==len(list_of_questions), f\"Number of metrics not matching num_questions. Got {len(metrics)} metrics but expected {len(list_of_questions)}\"\n",
        "    \n",
        "    #This is at the end a dict with num_metrics keys and each key has num_questions values.\n",
        "    #Example: {'completeness_descr': [4, 3, 3, 5, 5, 4, 3], 'relevance_descr': [4, 3, 3, 3, 4, 3, 1], ....} assuming 7 questions\n",
        "    individual_run_metric_scores = {} #Keep track of scores of all metrics over all questions for one resample\n",
        "\n",
        "    for metric_idx, metric_name in enumerate(list_of_metrics): #Get specific metric name and values over all questions for the current resample\n",
        "\n",
        "        clean_metric_names, metric_scores, metric_prompts = [], [], [] #Metric scores and prompts for all questions for a given resample - Should be num_questions elements each time\n",
        "        \n",
        "        #Get all metric keys for the current resample over all questions, handling potential missing keys (values set to 0 for those - they are errors)\n",
        "        for m in metrics:\n",
        "            if m == 0: #If there is an error\n",
        "                key = metric_name.replace('_descr','')\n",
        "                score = 0\n",
        "                prompt=\"\"\n",
        "            else:\n",
        "                try:\n",
        "                    key = m[metric_idx].key #Metric name\n",
        "                    score = m[metric_idx].score ##Scores of a given metric over all questions for a given resample\n",
        "                    prompt = m[metric_idx].value #Prompt used for the evaluation\n",
        "                except:\n",
        "                    print(\"Error: Metric not found - Shouldn't get here\")\n",
        "                    key = metric_name.replace('_descr','')\n",
        "                    score = 0\n",
        "                    prompt = \"\"\n",
        "                \n",
        "            clean_metric_names.append(key)\n",
        "            metric_scores.append(score)\n",
        "            metric_prompts.append(prompt)\n",
        "            \n",
        "        assert all(name == metric_name.replace('_descr','') for name in clean_metric_names), f\"Metric keys not matching: clean_metric_names={clean_metric_names}, \\\n",
        "            expected={metric_name.replace('_descr','')} and their values: {metric_scores}\"\n",
        "            \n",
        "        # with open('metric_scores_'+str(resample_idx)+'_'+str(metric_name)+'_'+str(model_name.split('/')[1])+'.txt', 'w') as f:\n",
        "        #     f.write(str(metric_scores))\n",
        "\n",
        "        assert len(metric_scores)==len(list_of_questions), f\"Number of metric scores not matching num_questions. Got {len(metric_scores)} metric scores \\\n",
        "            but expected {len(list_of_questions)}\"\n",
        "            \n",
        "        # with open('metric_prompts_'+str(resample_idx)+'_'+str(metric_name)+'_'+str(model_name.split('/')[1])+'.txt', 'w') as f:\n",
        "        #     f.write(str(metric_prompts))\n",
        "\n",
        "        assert len(metric_prompts)==len(list_of_questions), f\"Number of metric prompts not matching num_questions. Got {len(metric_prompts)} metric prompts \\\n",
        "            but expected {len(list_of_questions)}\"\n",
        "\n",
        "        # Update results DataFrame\n",
        "        clean_metric_name = clean_metric_names[0] #Just one metric name without the _descr\n",
        "        results_df[f'metric_{clean_metric_name}_{resample_idx+1}'] = metric_scores\n",
        "        results_df[f'prompt_{clean_metric_name}_{resample_idx+1}'] = metric_prompts\n",
        "        \n",
        "        # Store scores for return\n",
        "        individual_run_metric_scores[metric_name] = metric_scores #len is num_metrics\n",
        "    \n",
        "    # with open('individual_run_metric_scores_'+str(resample_idx)+'_'+str(model_name.split('/')[1])+'.txt', 'w') as f:\n",
        "    #     f.write(str(individual_run_metric_scores))\n",
        "\n",
        "    return individual_run_metric_scores, metrics, results_df\n",
        "\n",
        "def calculate_metric_statistics(all_runs_metric_scores, list_of_metrics, num_questions, model_name):\n",
        "    \"\"\"Calculate statistical metrics across resamples (reduce variance - step 3.1).\"\"\"\n",
        "    metric_stats_resampling = {} # Calculate mean and standard error for each metric and question across K resamples\n",
        "    #The above dict will have num_metrics elements, each with metric keys (e.g. mean, std, etc), that will have num_questions values\n",
        "    #Example: {'completeness': {'mean':[4, 3, 3, 5, 5, 4, 3]}, #here for a dataset with 7 questions\n",
        "    #          'relevance': {'mean':[4, 3, 3, 3, 4, 3, 2]}, ...}\n",
        "    \n",
        "    for metric in list_of_metrics:\n",
        "        metric_stats_resampling[metric] = {\n",
        "            'means': [],  # Mean score across K resamples for each question\n",
        "            'standard_errors': [],  # Standard error of the mean for each question\n",
        "            'conditional_vars': []  # Conditional variance reduced by factor of K\n",
        "        }\n",
        "        \n",
        "        # For each question\n",
        "        for q in range(num_questions):\n",
        "            # Get K scores for this metric/question across all resamples (num_resamples elements each time in that list)\n",
        "            scores = [run[metric][q] for run in all_runs_metric_scores]\n",
        "            K = len(scores)  # Number of resamples\n",
        "            assert len(scores)==n_resamples, f\"Number of scores not matching num_resamples. Got {len(scores)} scores but expected {n_resamples}\"\n",
        "            \n",
        "            # Calculate statistics\n",
        "            mean = np.mean(scores) #Average score of each question for a given metric over all resamples\n",
        "            var = np.var(scores) #Variance of the scores of each question for a given metric over all resamples\n",
        "            # Calculate conditional variance reduced by factor of K. Var(mean) = σ²/K where σ² is the variance of individual scores\n",
        "            conditional_var = var / K if K > 0 else 0\n",
        "            standard_error = np.sqrt(conditional_var)\n",
        "            \n",
        "            # Store results\n",
        "            metric_stats_resampling[metric]['means'].append(mean)\n",
        "            metric_stats_resampling[metric]['standard_errors'].append(standard_error)\n",
        "            metric_stats_resampling[metric]['conditional_vars'].append(conditional_var)\n",
        "    \n",
        "    with open('metric_stats_resampling_'+str(model_name.split('/')[1])+'.txt', 'w') as f:\n",
        "        f.write(str(metric_stats_resampling))\n",
        "\n",
        "    assert len(metric_stats_resampling)==len(list_of_metrics), f\"Number of metric_stats_resampling not matching num_metrics. \\\n",
        "        Got {len(metric_stats_resampling)} metric_stats_resampling but expected {len(list_of_metrics)}\"\n",
        "    \n",
        "    for metric in list_of_metrics:\n",
        "        assert len(metric_stats_resampling[metric]['means']) == num_questions, f\"Number of values for metric '{metric}' ({len(metric_stats_resampling[metric]['means'])}) \\\n",
        "            not matching expected number of questions ({num_questions})\"\n",
        "\n",
        "    return metric_stats_resampling\n",
        "\n",
        "def handle_zero_values(results_df, n_resamples, list_of_metrics):\n",
        "    \"\"\"\n",
        "    Handle zero values in results.\n",
        "    \n",
        "    Args:\n",
        "        results_df (pd.DataFrame): DataFrame containing results\n",
        "        n_resamples (int): Number of resamples\n",
        "        list_of_metrics (list): List of metrics to check\n",
        "        \n",
        "    Returns:\n",
        "        dict: Indices of rows containing zero values for each metric\n",
        "    \"\"\"\n",
        "    zero_rows_columns = {}\n",
        "    \n",
        "    try:\n",
        "        # Handle 0 values across all resamples - These are errors\n",
        "        for resample_idx in range(n_resamples):\n",
        "            for metric in list_of_metrics:\n",
        "                try:\n",
        "                    simple_metric_name = metric.replace('_descr','')\n",
        "                    metric_col = f'metric_{simple_metric_name}_{resample_idx+1}'\n",
        "                    \n",
        "                    # Check if column exists\n",
        "                    if metric_col not in results_df.columns:\n",
        "                        print(colored(f\"Warning: Column {metric_col} not found in DataFrame\", 'yellow'))\n",
        "                        continue\n",
        "                    \n",
        "                    zero_indices = results_df[metric_col] == 0 #series with True/False\n",
        "                    \n",
        "                    if zero_indices.any(): #If any of the values of that column are 0\n",
        "                        zero_rows_columns[metric_col] = []\n",
        "                        for idx in zero_indices[zero_indices].index: #Loop over True indices (rows with 0s)\n",
        "                            try:\n",
        "                                print(colored(f\"Missing value for metric '{simple_metric_name}' in resample {resample_idx+1}\", 'red'))\n",
        "                                print(colored(f\"Question: {results_df.loc[idx, 'questions']}\", 'green'))\n",
        "                                zero_rows_columns[metric_col].append(idx) #Keep track of columns and rows with zero values\n",
        "                            except Exception as e:\n",
        "                                print(colored(f\"Unexpected error processing zero value at row {idx}: {e}\", 'red'))\n",
        "                \n",
        "                except Exception as e:\n",
        "                    print(colored(f\"Error processing metric {metric} in resample {resample_idx}: {e}\", 'red'))\n",
        "        \n",
        "        return zero_rows_columns # Return column names and rows with zero values\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(colored(f\"Critical error in handle_zero_values: {e}\", 'red'))\n",
        "        traceback.print_exc()\n",
        "        return {}  # Return empty dict in case of critical error\n",
        "\n",
        "def process_zero_values(results_df, zero_rows_columns, list_of_metrics, model_name): #TO BE ACTIVATED\n",
        "    \"\"\"Process and optionally replace zero values in results.\"\"\"\n",
        "    row_zero_counts = {}\n",
        "    col_zero_counts = {}\n",
        "\n",
        "    # Force a copy to ensure changes are applied properly below when replace with mean value\n",
        "    results_df_copy = results_df.copy()\n",
        "\n",
        "    for column_name, row_indices in zero_rows_columns.items():\n",
        "        for row_idx in row_indices:\n",
        "                \n",
        "            # Get values for this metric for this row and column (one resample per time)\n",
        "            values = results_df.loc[row_idx, column_name]\n",
        "\n",
        "            assert values==0, \"Values should be 0\"\n",
        "            \n",
        "            if values != 0: #We should never get here\n",
        "                with open('values_'+str(model_name.split('/')[1])+'_'+str(column_name)+'_'+str(row_idx)+'.txt', 'w') as f:\n",
        "                    f.write(str(values))\n",
        "                \n",
        "            #Given that values are 0, replace with mean of non-zero values\n",
        "            df_values=results_df.loc[:, column_name].values\n",
        "            non_zero_values = [x for x in df_values if x != 0]\n",
        "\n",
        "            if len(non_zero_values) > 0:\n",
        "                mean_value = np.mean(non_zero_values)\n",
        "\n",
        "                if results_df.loc[row_idx, column_name] == 0 and mean_value != 0:\n",
        "                    print(colored(f\"0 value in row {row_idx}, column {column_name} should be replaced with mean {mean_value:.2f}\", 'yellow'))\n",
        "                    # Uncomment to actually replace values:\n",
        "                    # results_df.loc[row_idx, column_name] = mean_value#round(mean_value, 1)\n",
        "\n",
        "                    row_zero_counts[row_idx] = row_zero_counts.get(row_idx, 0) + 1\n",
        "                    col_zero_counts[column_name] = col_zero_counts.get(column_name, 0) + 1\n",
        "\n",
        "    print(\"\\nZero values replaced per row:\")\n",
        "    for row in sorted(row_zero_counts):\n",
        "        print(f\"Row/question {row}: {row_zero_counts[row]} replacements\")\n",
        "\n",
        "    print(\"\\nZero values replaced per column:\")\n",
        "    for col in sorted(col_zero_counts):\n",
        "        print(f\"Column/metric {col}: {col_zero_counts[col]} replacements\")\n",
        "\n",
        "def reorganize_evaluation_metrics(all_resamples_metrics, list_of_metrics, model_name, list_of_questions, n_resamples):\n",
        "    \"\"\"    \n",
        "    This function takes evaluation metrics from multiple resampling runs and reorganizes them into\n",
        "    a structured dictionary where each metric's scores are grouped together. It handles cases where\n",
        "    some evaluations may have failed (represented by 0s).\n",
        "    \n",
        "    Args:\n",
        "        all_resamples_metrics (list): List of evaluation results for each resample. Each resample contains\n",
        "                                     scores for multiple questions and metrics.\n",
        "        list_of_metrics (list): List of metric names to process (e.g., ['completeness_descr', 'relevance_descr']).\n",
        "        model_name (str): Name of the model being evaluated, used for logging.\n",
        "        list_of_questions (list): List of questions that were evaluated.\n",
        "        n_resamples (int): Number of resampling iterations performed.\n",
        "    \n",
        "    Returns:\n",
        "        dict: Dictionary where keys are metric names (without '_descr' suffix) and values are lists\n",
        "              containing all scores for that metric across all resamples and questions.\n",
        "              \n",
        "    Note:\n",
        "        The function assumes each resample has scores for all questions and metrics.\n",
        "    \"\"\"\n",
        "    metric_scores_all_resamples = {metric.replace('_descr', ''): [] for metric in list_of_metrics}\n",
        "    #The above dict will have num_metrics elements, with their value for each question, over each run (first num_questions for first run, then next num_questions for next run, etc)\n",
        "    #Example: {'completeness': {'mean':[4, 3, 3, 5, 5, 4, 3, 4, 3, 3, 5, 5, 0, 3, 5, 3, 3, 5, 5, 4, 3]},  #assuming 3 runs and 7 questions\n",
        "    #          'relevance': {'mean':[4, 3, 3, 3, 4, 3, 2, 4, 3, 3, 3, 3, 0, 2, 4, 3, 3, 3, 3, 3, 2]}, ...}\n",
        "    #In case of error, there will be num_questions less elements in the sublist for which there was an error\n",
        "    \n",
        "    for metric_name in list_of_metrics:\n",
        "        clean_name = metric_name.replace('_descr', '')\n",
        "        \n",
        "        #Each resample_metrics (num_resamples in total) has a list of num_questions lists, each having num_metrics values\n",
        "        #format of each sublist: [EvaluationResult(key='completeness', score=4, value='To evaluate the ...\n",
        "        #If error, instead of the above list we have just a 0.\n",
        "        for resample_idx, resample_metrics in enumerate(all_resamples_metrics):\n",
        "\n",
        "            with open('resample_metrics_'+str(resample_idx)+'_'+str(metric_name)+'_'+str(model_name.split('/')[1])+'.txt', 'w') as f:\n",
        "                f.write(str(resample_metrics))\n",
        "\n",
        "            metric_idx = list_of_metrics.index(metric_name) #0-num_metrics the range of values of this. \n",
        "\n",
        "            scores = [m[metric_idx].score if m!=0 and m!=[] else 0 \n",
        "                     for m in resample_metrics] #num_questions elements each time\n",
        "            assert len(scores)==len(list_of_questions), \"Scores length not matching num_questions\"\n",
        "\n",
        "            with open('scores_'+str(resample_idx)+'_'+str(metric_name)+'_'+str(model_name.split('/')[1])+'.txt', 'w') as f:\n",
        "                f.write(str(scores))\n",
        "\n",
        "            metric_scores_all_resamples[clean_name].extend(scores) #Every time we add one metric for one resample (num_questions elements)\n",
        "\n",
        "            with open('metric_stats_reorganized_'+str(resample_idx)+'_'+str(metric_name)+'_'+str(model_name.split('/')[1])+'.txt', 'w') as f:\n",
        "                f.write(str(metric_scores_all_resamples))\n",
        "\n",
        "    assert [len(x) for x in metric_scores_all_resamples.values()]==[len(list_of_questions)*n_resamples]*len(list_of_metrics), \"Metric stats length not matching\"\n",
        "\n",
        "    return metric_scores_all_resamples\n",
        "\n",
        "def save_results(results_df, judge_model, model_id, stage=\"before\"):\n",
        "    \"\"\"Save results DataFrame to Excel.\"\"\"\n",
        "    filename = (f\"results_{judge_model.split('/')[1]}_judge_with_\"\n",
        "               f\"{model_id.replace('/','_')}_{stage}_nan_replacement.xlsx\")\n",
        "    \n",
        "    try:\n",
        "        #Extract reasoning traces and final answers from predicted answers\n",
        "        # Check for <think> tags in predicted answer columns and split them if found\n",
        "        for col in results_df.columns:\n",
        "            if 'predicted_answer' in col:\n",
        "                # Create new column names\n",
        "                run_number = col.split('_')[-1]\n",
        "                reasoning_col = f'reasoning_trace_{run_number}'\n",
        "                \n",
        "                # Check if we need to split this column\n",
        "                has_think_tags = results_df[col].astype(str).str.contains('</think>', na=False).any()\n",
        "                \n",
        "                if has_think_tags:\n",
        "                    print(\"Has </think> in answer\")\n",
        "                    # Extract reasoning traces and final answers\n",
        "                    reasoning_traces = []\n",
        "                    final_answers = []\n",
        "                    \n",
        "                    for answer in results_df[col]:\n",
        "                        if isinstance(answer, str):\n",
        "                            if '<think>' in answer and '</think>' in answer:\n",
        "                                # Extract the reasoning trace between <think> and </think>\n",
        "                                think_start = answer.find('<think>') + len('<think>')\n",
        "                                think_end = answer.find('</think>')\n",
        "                                \n",
        "                                if think_start >= 0 and think_end >= 0:\n",
        "                                    reasoning = answer[think_start:think_end].strip()\n",
        "                                    print(\"Reasoning:\",reasoning)\n",
        "                                    final_answer = answer[think_end + len('</think>'):].strip()\n",
        "                                    print(\"Final answer:\",final_answer)\n",
        "                                    reasoning_traces.append(reasoning)\n",
        "                                    final_answers.append(final_answer)\n",
        "                            elif '</think>' in answer:\n",
        "                                print(\"Only </think> in answer\")\n",
        "                                # Handle case where only </think> is present\n",
        "                                think_end = answer.find('</think>')\n",
        "                                reasoning = answer[:think_end].strip()\n",
        "                                print(\"Reasoning:\",reasoning)\n",
        "                                final_answer = answer[think_end + len('</think>'):].strip()\n",
        "                                print(\"Final answer:\",final_answer)\n",
        "                                reasoning_traces.append(reasoning)\n",
        "                                final_answers.append(final_answer)\n",
        "                            else:\n",
        "                                reasoning_traces.append('')\n",
        "                                final_answers.append(answer)\n",
        "                    \n",
        "                    if any(trace.strip() for trace in reasoning_traces): #If there is any reasoning trace\n",
        "                        # Add the new columns - insert reasoning column right after the predicted answer column\n",
        "                        col_idx = results_df.columns.get_loc(col)\n",
        "                        results_df.insert(col_idx + 1, reasoning_col, reasoning_traces)\n",
        "                        results_df[col] = final_answers\n",
        "                        print(\"Added reasoning traces and final answers to dataframe\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error in saving trace results:\", e)\n",
        "        traceback.print_exc()\n",
        "    \n",
        "    results_df.to_excel(filename, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading shards: 100%|██████████| 4/4 [02:21<00:00, 35.40s/it]\n",
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:38<00:00,  9.52s/it]\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset not found. Creating new dataset\n",
            "\n",
            "Performing evaluation of resample 1/1 of meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "View the evaluation results for experiment: 'openai/gpt-4o-mini_judge_with_meta-llama/Meta-Llama-3.1-8B-Instruct_resample_0-cff151da' at:\n",
            "https://smith.langchain.com/o/42866633-791c-5d79-833d-4e624439c57c/datasets/8788f428-b783-4a27-9014-5899ab20823e/compare?selectedSessions=b341e826-1d91-4593-89c0-1de9d2daf231\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : Computational modeling of very large water networks is a complex task that poses several challenges. Some of the key challenges include:\n",
            "\n",
            "1. **Scalability**: As the size of the network increases, the computational time and memory requirements also increase exponentially, making it difficult to solve the problem within a reasonable time frame.\n",
            "\n",
            "2. **Complexity**: Very large water networks often involve complex interactions between different components, such as pumps, valves, and pipes, which can lead to non-linear behavior and make it challenging to develop accurate models.\n",
            "\n",
            "3. **Uncertainty and variability**: Real-world water networks are subject to various uncertainties and variability, such as changes in demand, pipe roughness, and valve settings, which can affect the accuracy of the model.\n",
            "\n",
            "4. **Data quality and availability**: Large water networks often have limited data availability, and the data that is available may be of poor quality, making it difficult to develop accurate models.\n",
            "\n",
            "5. **Model calibration and validation**: Calibrating and validating models for very large water networks can be challenging due to the complexity of the system and the limited availability of data.\n",
            "\n",
            "6. **Computational power and resources**: Solving large-scale water network models requires significant computational power and resources, which can be a challenge for many organizations.\n",
            "\n",
            "7. **Interoperability and data exchange**: Very large water networks often involve multiple stakeholders and systems, which can lead to interoperability issues and difficulties in exchanging data between different systems.\n",
            "\n",
            "8. **Real-time operation and control**: Very large water networks often require real-time operation and control, which can be challenging due to the complexity of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "9. **Optimization and decision-making**: Very large water networks often involve complex optimization problems, which can be challenging to solve due to the non-linear behavior of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "10. **Cybersecurity**: Very large water networks often involve multiple stakeholders and systems, which can lead to cybersecurity risks and challenges in protecting the system from cyber threats.\n",
            "\n",
            "To overcome these challenges, researchers and practitioners are developing new methods and tools, such as:\n",
            "\n",
            "* **Hybrid modeling approaches**: Combining different modeling approaches, such as analytical and numerical methods, to improve the accuracy and efficiency of the model.\n",
            "* **Machine learning and artificial intelligence**: Using machine learning and artificial intelligence techniques to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Cloud computing and high-performance computing**: Using cloud computing and high-performance computing resources to improve the scalability and efficiency of the model.\n",
            "* **Data-driven approaches**: Using data-driven approaches to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Interoperability and data exchange standards**: Developing interoperability and data exchange standards to facilitate the exchange of data between different systems and stakeholders.\n",
            "\n",
            "Overall, computational modeling of very large water networks is a complex task that requires the development of new methods and tools to overcome the challenges associated with scalability, complexity, uncertainty, and variability.\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: What are the key challenges in computational modeling of very large water networks?, Actual answer: Challenges include high computational costs, numerical convergence issues, and data management complexity. Large models require robust solvers, efficient memory handling, and sometimes model reduction techniques to remain practical for daily operations., Predicted answer: Computational modeling of very large water networks is a complex task that poses several challenges. Some of the key challenges include:\n",
            "\n",
            "1. **Scalability**: As the size of the network increases, the computational time and memory requirements also increase exponentially, making it difficult to solve the problem within a reasonable time frame.\n",
            "\n",
            "2. **Complexity**: Very large water networks often involve complex interactions between different components, such as pumps, valves, and pipes, which can lead to non-linear behavior and make it challenging to develop accurate models.\n",
            "\n",
            "3. **Uncertainty and variability**: Real-world water networks are subject to various uncertainties and variability, such as changes in demand, pipe roughness, and valve settings, which can affect the accuracy of the model.\n",
            "\n",
            "4. **Data quality and availability**: Large water networks often have limited data availability, and the data that is available may be of poor quality, making it difficult to develop accurate models.\n",
            "\n",
            "5. **Model calibration and validation**: Calibrating and validating models for very large water networks can be challenging due to the complexity of the system and the limited availability of data.\n",
            "\n",
            "6. **Computational power and resources**: Solving large-scale water network models requires significant computational power and resources, which can be a challenge for many organizations.\n",
            "\n",
            "7. **Interoperability and data exchange**: Very large water networks often involve multiple stakeholders and systems, which can lead to interoperability issues and difficulties in exchanging data between different systems.\n",
            "\n",
            "8. **Real-time operation and control**: Very large water networks often require real-time operation and control, which can be challenging due to the complexity of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "9. **Optimization and decision-making**: Very large water networks often involve complex optimization problems, which can be challenging to solve due to the non-linear behavior of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "10. **Cybersecurity**: Very large water networks often involve multiple stakeholders and systems, which can lead to cybersecurity risks and challenges in protecting the system from cyber threats.\n",
            "\n",
            "To overcome these challenges, researchers and practitioners are developing new methods and tools, such as:\n",
            "\n",
            "* **Hybrid modeling approaches**: Combining different modeling approaches, such as analytical and numerical methods, to improve the accuracy and efficiency of the model.\n",
            "* **Machine learning and artificial intelligence**: Using machine learning and artificial intelligence techniques to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Cloud computing and high-performance computing**: Using cloud computing and high-performance computing resources to improve the scalability and efficiency of the model.\n",
            "* **Data-driven approaches**: Using data-driven approaches to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Interoperability and data exchange standards**: Developing interoperability and data exchange standards to facilitate the exchange of data between different systems and stakeholders.\n",
            "\n",
            "Overall, computational modeling of very large water networks is a complex task that requires the development of new methods and tools to overcome the challenges associated with scalability, complexity, uncertainty, and variability.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the completeness of the information provided in both responses. The actual answer succinctly identifies three key challenges: high computational costs, numerical convergence issues, and data management complexity. It also mentions the need for robust solvers, efficient memory handling, and model reduction techniques.\n",
            "\n",
            "The predicted answer, on the other hand, provides a comprehensive list of challenges, including scalability, complexity, uncertainty and variability, data quality and availability, model calibration and validation, computational power and resources, interoperability and data exchange, real-time operation and control, optimization and decision-making, and cybersecurity. It also suggests methods to overcome these challenges, which adds depth to the response.\n",
            "\n",
            "While the predicted answer covers a broader range of challenges and provides additional context, it does not explicitly mention the specific challenges highlighted in the actual answer, such as numerical convergence issues and the need for model reduction techniques. However, it does touch on related concepts like computational power and resources, which could encompass numerical convergence indirectly.\n",
            "\n",
            "In terms of completeness, the predicted answer includes most elements of a complete answer, but it does not fully align with the specific challenges outlined in the actual answer. Therefore, it can be rated as having most elements present but lacking some key specifics.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : Utilities sometimes use 'virtual DMAs' (Demand Management Areas) instead of physically closing pipes for several reasons:\n",
            "\n",
            "1. **Cost-Effectiveness**: Physically closing pipes can be a costly and time-consuming process, especially in areas with complex infrastructure. Virtual DMAs, on the other hand, can be implemented at a lower cost and with less disruption to service.\n",
            "\n",
            "2. **Flexibility**: Virtual DMAs can be easily adjusted or modified as needed, without the need for physical changes to the infrastructure. This makes them a more flexible option for utilities that need to respond to changing demand patterns or customer needs.\n",
            "\n",
            "3. **Reduced Disruption**: Physically closing pipes can cause significant disruption to customers, including loss of service, noise, and potential damage to property. Virtual DMAs can be implemented with minimal disruption to customers, making them a more customer-friendly option.\n",
            "\n",
            "4. **Data-Driven Decision Making**: Virtual DMAs rely on data and analytics to manage demand, rather than physical infrastructure. This allows utilities to make more informed decisions about how to manage demand, based on real-time data and customer behavior.\n",
            "\n",
            "5. **Scalability**: Virtual DMAs can be easily scaled up or down to meet changing demand patterns, without the need for physical infrastructure changes. This makes them a more scalable option for utilities that need to respond to changing demand patterns.\n",
            "\n",
            "6. **Environmental Benefits**: Virtual DMAs can help utilities to reduce energy consumption and greenhouse gas emissions, by encouraging customers to use energy more efficiently. This can help utilities to meet their environmental goals and reduce their carbon footprint.\n",
            "\n",
            "Overall, virtual DMAs offer a cost-effective, flexible, and customer-friendly alternative to physically closing pipes. They can help utilities to manage demand more effectively, reduce costs, and improve customer satisfaction.\n",
            "\u001b[32mUser message:Question: What are the key challenges in computational modeling of very large water networks?, Actual answer: Challenges include high computational costs, numerical convergence issues, and data management complexity. Large models require robust solvers, efficient memory handling, and sometimes model reduction techniques to remain practical for daily operations., Predicted answer: Computational modeling of very large water networks is a complex task that poses several challenges. Some of the key challenges include:\n",
            "\n",
            "1. **Scalability**: As the size of the network increases, the computational time and memory requirements also increase exponentially, making it difficult to solve the problem within a reasonable time frame.\n",
            "\n",
            "2. **Complexity**: Very large water networks often involve complex interactions between different components, such as pumps, valves, and pipes, which can lead to non-linear behavior and make it challenging to develop accurate models.\n",
            "\n",
            "3. **Uncertainty and variability**: Real-world water networks are subject to various uncertainties and variability, such as changes in demand, pipe roughness, and valve settings, which can affect the accuracy of the model.\n",
            "\n",
            "4. **Data quality and availability**: Large water networks often have limited data availability, and the data that is available may be of poor quality, making it difficult to develop accurate models.\n",
            "\n",
            "5. **Model calibration and validation**: Calibrating and validating models for very large water networks can be challenging due to the complexity of the system and the limited availability of data.\n",
            "\n",
            "6. **Computational power and resources**: Solving large-scale water network models requires significant computational power and resources, which can be a challenge for many organizations.\n",
            "\n",
            "7. **Interoperability and data exchange**: Very large water networks often involve multiple stakeholders and systems, which can lead to interoperability issues and difficulties in exchanging data between different systems.\n",
            "\n",
            "8. **Real-time operation and control**: Very large water networks often require real-time operation and control, which can be challenging due to the complexity of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "9. **Optimization and decision-making**: Very large water networks often involve complex optimization problems, which can be challenging to solve due to the non-linear behavior of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "10. **Cybersecurity**: Very large water networks often involve multiple stakeholders and systems, which can lead to cybersecurity risks and challenges in protecting the system from cyber threats.\n",
            "\n",
            "To overcome these challenges, researchers and practitioners are developing new methods and tools, such as:\n",
            "\n",
            "* **Hybrid modeling approaches**: Combining different modeling approaches, such as analytical and numerical methods, to improve the accuracy and efficiency of the model.\n",
            "* **Machine learning and artificial intelligence**: Using machine learning and artificial intelligence techniques to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Cloud computing and high-performance computing**: Using cloud computing and high-performance computing resources to improve the scalability and efficiency of the model.\n",
            "* **Data-driven approaches**: Using data-driven approaches to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Interoperability and data exchange standards**: Developing interoperability and data exchange standards to facilitate the exchange of data between different systems and stakeholders.\n",
            "\n",
            "Overall, computational modeling of very large water networks is a complex task that requires the development of new methods and tools to overcome the challenges associated with scalability, complexity, uncertainty, and variability.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we first need to identify the key points made in both responses. The actual answer succinctly lists the main challenges in computational modeling of very large water networks, focusing on high computational costs, numerical convergence issues, and data management complexity. It emphasizes the need for robust solvers and efficient memory handling.\n",
            "\n",
            "The predicted answer, while lengthy, does address the user's question by outlining several challenges, including scalability, complexity, uncertainty, data quality, model calibration, computational resources, interoperability, real-time operation, optimization, and cybersecurity. It also suggests potential solutions, which, while informative, may not directly relate to the original question about challenges.\n",
            "\n",
            "In terms of relevance, the predicted answer contains a wealth of information that, while related to the topic, diverges from the specific challenges highlighted in the actual answer. The additional details about solutions and broader issues may be seen as somewhat tangential to the core question.\n",
            "\n",
            "Given this analysis, the predicted answer does answer the user's question but includes a significant amount of irrelevant information that detracts from its relevance. Therefore, I would assign a score of 3, as it answers the question but contains more irrelevant information than relevant information.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: What are the key challenges in computational modeling of very large water networks?, Actual answer: Challenges include high computational costs, numerical convergence issues, and data management complexity. Large models require robust solvers, efficient memory handling, and sometimes model reduction techniques to remain practical for daily operations., Predicted answer: Computational modeling of very large water networks is a complex task that poses several challenges. Some of the key challenges include:\n",
            "\n",
            "1. **Scalability**: As the size of the network increases, the computational time and memory requirements also increase exponentially, making it difficult to solve the problem within a reasonable time frame.\n",
            "\n",
            "2. **Complexity**: Very large water networks often involve complex interactions between different components, such as pumps, valves, and pipes, which can lead to non-linear behavior and make it challenging to develop accurate models.\n",
            "\n",
            "3. **Uncertainty and variability**: Real-world water networks are subject to various uncertainties and variability, such as changes in demand, pipe roughness, and valve settings, which can affect the accuracy of the model.\n",
            "\n",
            "4. **Data quality and availability**: Large water networks often have limited data availability, and the data that is available may be of poor quality, making it difficult to develop accurate models.\n",
            "\n",
            "5. **Model calibration and validation**: Calibrating and validating models for very large water networks can be challenging due to the complexity of the system and the limited availability of data.\n",
            "\n",
            "6. **Computational power and resources**: Solving large-scale water network models requires significant computational power and resources, which can be a challenge for many organizations.\n",
            "\n",
            "7. **Interoperability and data exchange**: Very large water networks often involve multiple stakeholders and systems, which can lead to interoperability issues and difficulties in exchanging data between different systems.\n",
            "\n",
            "8. **Real-time operation and control**: Very large water networks often require real-time operation and control, which can be challenging due to the complexity of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "9. **Optimization and decision-making**: Very large water networks often involve complex optimization problems, which can be challenging to solve due to the non-linear behavior of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "10. **Cybersecurity**: Very large water networks often involve multiple stakeholders and systems, which can lead to cybersecurity risks and challenges in protecting the system from cyber threats.\n",
            "\n",
            "To overcome these challenges, researchers and practitioners are developing new methods and tools, such as:\n",
            "\n",
            "* **Hybrid modeling approaches**: Combining different modeling approaches, such as analytical and numerical methods, to improve the accuracy and efficiency of the model.\n",
            "* **Machine learning and artificial intelligence**: Using machine learning and artificial intelligence techniques to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Cloud computing and high-performance computing**: Using cloud computing and high-performance computing resources to improve the scalability and efficiency of the model.\n",
            "* **Data-driven approaches**: Using data-driven approaches to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Interoperability and data exchange standards**: Developing interoperability and data exchange standards to facilitate the exchange of data between different systems and stakeholders.\n",
            "\n",
            "Overall, computational modeling of very large water networks is a complex task that requires the development of new methods and tools to overcome the challenges associated with scalability, complexity, uncertainty, and variability.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we first need to identify the key points made in both responses. The actual answer succinctly lists the main challenges in computational modeling of large water networks, focusing on high computational costs, numerical convergence issues, and data management complexity. It also mentions the need for robust solvers and efficient memory handling.\n",
            "\n",
            "In contrast, the predicted answer elaborates on multiple challenges, providing a detailed breakdown of each issue, including scalability, complexity, uncertainty, data quality, model calibration, computational resources, interoperability, real-time operation, optimization, and cybersecurity. It also suggests potential solutions, which adds further length to the response.\n",
            "\n",
            "The predicted answer is significantly longer and includes a lot of extra information that, while relevant, goes beyond the scope of the original question. The actual answer is concise and directly addresses the key challenges without unnecessary elaboration.\n",
            "\n",
            "Given this analysis, the predicted response includes a lot of extra information and uses flowery language, which detracts from its conciseness.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: What are the key challenges in computational modeling of very large water networks?, Actual answer: Challenges include high computational costs, numerical convergence issues, and data management complexity. Large models require robust solvers, efficient memory handling, and sometimes model reduction techniques to remain practical for daily operations., Predicted answer: Computational modeling of very large water networks is a complex task that poses several challenges. Some of the key challenges include:\n",
            "\n",
            "1. **Scalability**: As the size of the network increases, the computational time and memory requirements also increase exponentially, making it difficult to solve the problem within a reasonable time frame.\n",
            "\n",
            "2. **Complexity**: Very large water networks often involve complex interactions between different components, such as pumps, valves, and pipes, which can lead to non-linear behavior and make it challenging to develop accurate models.\n",
            "\n",
            "3. **Uncertainty and variability**: Real-world water networks are subject to various uncertainties and variability, such as changes in demand, pipe roughness, and valve settings, which can affect the accuracy of the model.\n",
            "\n",
            "4. **Data quality and availability**: Large water networks often have limited data availability, and the data that is available may be of poor quality, making it difficult to develop accurate models.\n",
            "\n",
            "5. **Model calibration and validation**: Calibrating and validating models for very large water networks can be challenging due to the complexity of the system and the limited availability of data.\n",
            "\n",
            "6. **Computational power and resources**: Solving large-scale water network models requires significant computational power and resources, which can be a challenge for many organizations.\n",
            "\n",
            "7. **Interoperability and data exchange**: Very large water networks often involve multiple stakeholders and systems, which can lead to interoperability issues and difficulties in exchanging data between different systems.\n",
            "\n",
            "8. **Real-time operation and control**: Very large water networks often require real-time operation and control, which can be challenging due to the complexity of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "9. **Optimization and decision-making**: Very large water networks often involve complex optimization problems, which can be challenging to solve due to the non-linear behavior of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "10. **Cybersecurity**: Very large water networks often involve multiple stakeholders and systems, which can lead to cybersecurity risks and challenges in protecting the system from cyber threats.\n",
            "\n",
            "To overcome these challenges, researchers and practitioners are developing new methods and tools, such as:\n",
            "\n",
            "* **Hybrid modeling approaches**: Combining different modeling approaches, such as analytical and numerical methods, to improve the accuracy and efficiency of the model.\n",
            "* **Machine learning and artificial intelligence**: Using machine learning and artificial intelligence techniques to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Cloud computing and high-performance computing**: Using cloud computing and high-performance computing resources to improve the scalability and efficiency of the model.\n",
            "* **Data-driven approaches**: Using data-driven approaches to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Interoperability and data exchange standards**: Developing interoperability and data exchange standards to facilitate the exchange of data between different systems and stakeholders.\n",
            "\n",
            "Overall, computational modeling of very large water networks is a complex task that requires the development of new methods and tools to overcome the challenges associated with scalability, complexity, uncertainty, and variability.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the confidence conveyed in both responses regarding the challenges in computational modeling of very large water networks. \n",
            "\n",
            "The actual answer succinctly identifies key challenges such as high computational costs, numerical convergence issues, and data management complexity, while also mentioning the need for robust solvers and efficient memory handling. This response is clear and direct, indicating a strong understanding of the topic.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, expands on the challenges significantly. It covers a wide range of issues, including scalability, complexity, uncertainty, data quality, model calibration, computational resources, interoperability, real-time operation, optimization, and cybersecurity. This comprehensive approach demonstrates a deep understanding of the topic, but it also introduces a level of complexity that could lead to uncertainty about the core challenges.\n",
            "\n",
            "In terms of confidence, the predicted answer does not explicitly state that the actual answer is correct, but it does align with many of the points raised in the actual answer. However, the extensive elaboration may dilute the confidence in the core challenges identified in the actual answer.\n",
            "\n",
            "Given these considerations, I would assign a score of 4 to the predicted answer. It leans towards agreement with the actual answer but acknowledges some uncertainty due to the breadth of challenges discussed.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: What are the key challenges in computational modeling of very large water networks?, Actual answer: Challenges include high computational costs, numerical convergence issues, and data management complexity. Large models require robust solvers, efficient memory handling, and sometimes model reduction techniques to remain practical for daily operations., Predicted answer: Computational modeling of very large water networks is a complex task that poses several challenges. Some of the key challenges include:\n",
            "\n",
            "1. **Scalability**: As the size of the network increases, the computational time and memory requirements also increase exponentially, making it difficult to solve the problem within a reasonable time frame.\n",
            "\n",
            "2. **Complexity**: Very large water networks often involve complex interactions between different components, such as pumps, valves, and pipes, which can lead to non-linear behavior and make it challenging to develop accurate models.\n",
            "\n",
            "3. **Uncertainty and variability**: Real-world water networks are subject to various uncertainties and variability, such as changes in demand, pipe roughness, and valve settings, which can affect the accuracy of the model.\n",
            "\n",
            "4. **Data quality and availability**: Large water networks often have limited data availability, and the data that is available may be of poor quality, making it difficult to develop accurate models.\n",
            "\n",
            "5. **Model calibration and validation**: Calibrating and validating models for very large water networks can be challenging due to the complexity of the system and the limited availability of data.\n",
            "\n",
            "6. **Computational power and resources**: Solving large-scale water network models requires significant computational power and resources, which can be a challenge for many organizations.\n",
            "\n",
            "7. **Interoperability and data exchange**: Very large water networks often involve multiple stakeholders and systems, which can lead to interoperability issues and difficulties in exchanging data between different systems.\n",
            "\n",
            "8. **Real-time operation and control**: Very large water networks often require real-time operation and control, which can be challenging due to the complexity of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "9. **Optimization and decision-making**: Very large water networks often involve complex optimization problems, which can be challenging to solve due to the non-linear behavior of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "10. **Cybersecurity**: Very large water networks often involve multiple stakeholders and systems, which can lead to cybersecurity risks and challenges in protecting the system from cyber threats.\n",
            "\n",
            "To overcome these challenges, researchers and practitioners are developing new methods and tools, such as:\n",
            "\n",
            "* **Hybrid modeling approaches**: Combining different modeling approaches, such as analytical and numerical methods, to improve the accuracy and efficiency of the model.\n",
            "* **Machine learning and artificial intelligence**: Using machine learning and artificial intelligence techniques to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Cloud computing and high-performance computing**: Using cloud computing and high-performance computing resources to improve the scalability and efficiency of the model.\n",
            "* **Data-driven approaches**: Using data-driven approaches to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Interoperability and data exchange standards**: Developing interoperability and data exchange standards to facilitate the exchange of data between different systems and stakeholders.\n",
            "\n",
            "Overall, computational modeling of very large water networks is a complex task that requires the development of new methods and tools to overcome the challenges associated with scalability, complexity, uncertainty, and variability.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the key challenges in computational modeling of very large water networks as outlined in both responses. The actual answer succinctly identifies three main challenges: high computational costs, numerical convergence issues, and data management complexity. In contrast, the predicted answer elaborates on a broader range of challenges, including scalability, complexity, uncertainty, data quality, model calibration, computational resources, interoperability, real-time operation, optimization, and cybersecurity.\n",
            "\n",
            "While the predicted answer provides a comprehensive overview of challenges, it introduces several points that are not explicitly mentioned in the actual answer. However, it does not contradict the key challenges presented in the actual answer. Instead, it expands on them, which could be seen as a positive aspect, as it reflects a deeper understanding of the complexities involved in modeling large water networks.\n",
            "\n",
            "The predicted answer also suggests potential solutions, which, while informative, diverge from the original question focused solely on challenges. This additional information could be seen as slightly tangential but does not detract from the factuality of the challenges listed.\n",
            "\n",
            "In terms of factual accuracy, the predicted answer contains a wealth of relevant information and aligns with the general understanding of the challenges in this field, albeit with some additional details that may not be necessary for a direct response to the question.\n",
            "\n",
            "Given this analysis, I would rate the predicted answer as follows: it includes mostly factual information with slight deviations from the core focus of the question, but it does not contain any outright hallucinations.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error running target function: probability tensor contains either `inf`, `nan` or element < 0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mUser message:Question: What are the key challenges in computational modeling of very large water networks?, Actual answer: Challenges include high computational costs, numerical convergence issues, and data management complexity. Large models require robust solvers, efficient memory handling, and sometimes model reduction techniques to remain practical for daily operations., Predicted answer: Computational modeling of very large water networks is a complex task that poses several challenges. Some of the key challenges include:\n",
            "\n",
            "1. **Scalability**: As the size of the network increases, the computational time and memory requirements also increase exponentially, making it difficult to solve the problem within a reasonable time frame.\n",
            "\n",
            "2. **Complexity**: Very large water networks often involve complex interactions between different components, such as pumps, valves, and pipes, which can lead to non-linear behavior and make it challenging to develop accurate models.\n",
            "\n",
            "3. **Uncertainty and variability**: Real-world water networks are subject to various uncertainties and variability, such as changes in demand, pipe roughness, and valve settings, which can affect the accuracy of the model.\n",
            "\n",
            "4. **Data quality and availability**: Large water networks often have limited data availability, and the data that is available may be of poor quality, making it difficult to develop accurate models.\n",
            "\n",
            "5. **Model calibration and validation**: Calibrating and validating models for very large water networks can be challenging due to the complexity of the system and the limited availability of data.\n",
            "\n",
            "6. **Computational power and resources**: Solving large-scale water network models requires significant computational power and resources, which can be a challenge for many organizations.\n",
            "\n",
            "7. **Interoperability and data exchange**: Very large water networks often involve multiple stakeholders and systems, which can lead to interoperability issues and difficulties in exchanging data between different systems.\n",
            "\n",
            "8. **Real-time operation and control**: Very large water networks often require real-time operation and control, which can be challenging due to the complexity of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "9. **Optimization and decision-making**: Very large water networks often involve complex optimization problems, which can be challenging to solve due to the non-linear behavior of the system and the need for fast and accurate decision-making.\n",
            "\n",
            "10. **Cybersecurity**: Very large water networks often involve multiple stakeholders and systems, which can lead to cybersecurity risks and challenges in protecting the system from cyber threats.\n",
            "\n",
            "To overcome these challenges, researchers and practitioners are developing new methods and tools, such as:\n",
            "\n",
            "* **Hybrid modeling approaches**: Combining different modeling approaches, such as analytical and numerical methods, to improve the accuracy and efficiency of the model.\n",
            "* **Machine learning and artificial intelligence**: Using machine learning and artificial intelligence techniques to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Cloud computing and high-performance computing**: Using cloud computing and high-performance computing resources to improve the scalability and efficiency of the model.\n",
            "* **Data-driven approaches**: Using data-driven approaches to improve the accuracy and efficiency of the model and to enable real-time operation and control.\n",
            "* **Interoperability and data exchange standards**: Developing interoperability and data exchange standards to facilitate the exchange of data between different systems and stakeholders.\n",
            "\n",
            "Overall, computational modeling of very large water networks is a complex task that requires the development of new methods and tools to overcome the challenges associated with scalability, complexity, uncertainty, and variability.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the key challenges in computational modeling of very large water networks as outlined in both responses. The actual answer succinctly identifies high computational costs, numerical convergence issues, and data management complexity as primary challenges. In contrast, the predicted answer expands on this by providing a comprehensive list of challenges, including scalability, complexity, uncertainty, data quality, model calibration, computational resources, interoperability, real-time operation, optimization, and cybersecurity.\n",
            "\n",
            "While the predicted answer is more detailed and covers a broader range of challenges, it does not directly mention numerical convergence issues, which is a significant aspect of the actual answer. However, it does touch on related concepts such as complexity and computational power. The predicted answer also introduces potential solutions, which adds value but diverges from the original question focused solely on challenges.\n",
            "\n",
            "In terms of judgment, the predicted answer does not confidently assert incorrect information, nor does it misinterpret the prompt. It shows a clear understanding of the topic, albeit with some deviation from the specific challenges mentioned in the actual answer. Therefore, it reflects a strong grasp of the subject matter while also acknowledging the complexity of the issue.\n",
            "\n",
            "Given these considerations, I would assign a score of 4 to the predicted answer, as it is wrong in not including all key challenges mentioned in the actual answer but makes it clear that it is addressing the topic comprehensively.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4, 'judgement_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: Why do utilities sometimes use 'virtual DMAs' instead of physically closing pipes?, Actual answer: Virtual DMAs use flow meters to monitor network zones without fully closing boundary pipes, preserving redundancy while enabling leak detection. This approach maintains operational flexibility but requires higher investment in metering and data analysis., Predicted answer: Utilities sometimes use 'virtual DMAs' (Demand Management Areas) instead of physically closing pipes for several reasons:\n",
            "\n",
            "1. **Cost-Effectiveness**: Physically closing pipes can be a costly and time-consuming process, especially in areas with complex infrastructure. Virtual DMAs, on the other hand, can be implemented at a lower cost and with less disruption to service.\n",
            "\n",
            "2. **Flexibility**: Virtual DMAs can be easily adjusted or modified as needed, without the need for physical changes to the infrastructure. This makes them a more flexible option for utilities that need to respond to changing demand patterns or customer needs.\n",
            "\n",
            "3. **Reduced Disruption**: Physically closing pipes can cause significant disruption to customers, including loss of service, noise, and potential damage to property. Virtual DMAs can be implemented with minimal disruption to customers, making them a more customer-friendly option.\n",
            "\n",
            "4. **Data-Driven Decision Making**: Virtual DMAs rely on data and analytics to manage demand, rather than physical infrastructure. This allows utilities to make more informed decisions about how to manage demand, based on real-time data and customer behavior.\n",
            "\n",
            "5. **Scalability**: Virtual DMAs can be easily scaled up or down to meet changing demand patterns, without the need for physical infrastructure changes. This makes them a more scalable option for utilities that need to respond to changing demand patterns.\n",
            "\n",
            "6. **Environmental Benefits**: Virtual DMAs can help utilities to reduce energy consumption and greenhouse gas emissions, by encouraging customers to use energy more efficiently. This can help utilities to meet their environmental goals and reduce their carbon footprint.\n",
            "\n",
            "Overall, virtual DMAs offer a cost-effective, flexible, and customer-friendly alternative to physically closing pipes. They can help utilities to manage demand more effectively, reduce costs, and improve customer satisfaction.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the completeness of the information provided in both responses. The actual answer succinctly explains the concept of virtual DMAs, highlighting their use of flow meters for monitoring, the preservation of redundancy, the enabling of leak detection, and the trade-off of requiring higher investment in metering and data analysis.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, covers several relevant aspects of virtual DMAs, including cost-effectiveness, flexibility, reduced disruption, data-driven decision-making, scalability, and environmental benefits. However, it does not specifically mention the use of flow meters or the importance of leak detection, which are critical elements of the actual answer. \n",
            "\n",
            "While the predicted answer provides a comprehensive overview of the advantages of virtual DMAs, it lacks some key elements that are essential for a complete understanding of why utilities might choose this approach over physically closing pipes. Therefore, it does not fully meet the criteria for completeness as defined in the scoring system.\n",
            "\n",
            "Given this analysis, I would assign a score of 4 to the predicted answer, as it covers most elements of a complete answer but misses some critical details.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: Why do utilities sometimes use 'virtual DMAs' instead of physically closing pipes?, Actual answer: Virtual DMAs use flow meters to monitor network zones without fully closing boundary pipes, preserving redundancy while enabling leak detection. This approach maintains operational flexibility but requires higher investment in metering and data analysis., Predicted answer: Utilities sometimes use 'virtual DMAs' (Demand Management Areas) instead of physically closing pipes for several reasons:\n",
            "\n",
            "1. **Cost-Effectiveness**: Physically closing pipes can be a costly and time-consuming process, especially in areas with complex infrastructure. Virtual DMAs, on the other hand, can be implemented at a lower cost and with less disruption to service.\n",
            "\n",
            "2. **Flexibility**: Virtual DMAs can be easily adjusted or modified as needed, without the need for physical changes to the infrastructure. This makes them a more flexible option for utilities that need to respond to changing demand patterns or customer needs.\n",
            "\n",
            "3. **Reduced Disruption**: Physically closing pipes can cause significant disruption to customers, including loss of service, noise, and potential damage to property. Virtual DMAs can be implemented with minimal disruption to customers, making them a more customer-friendly option.\n",
            "\n",
            "4. **Data-Driven Decision Making**: Virtual DMAs rely on data and analytics to manage demand, rather than physical infrastructure. This allows utilities to make more informed decisions about how to manage demand, based on real-time data and customer behavior.\n",
            "\n",
            "5. **Scalability**: Virtual DMAs can be easily scaled up or down to meet changing demand patterns, without the need for physical infrastructure changes. This makes them a more scalable option for utilities that need to respond to changing demand patterns.\n",
            "\n",
            "6. **Environmental Benefits**: Virtual DMAs can help utilities to reduce energy consumption and greenhouse gas emissions, by encouraging customers to use energy more efficiently. This can help utilities to meet their environmental goals and reduce their carbon footprint.\n",
            "\n",
            "Overall, virtual DMAs offer a cost-effective, flexible, and customer-friendly alternative to physically closing pipes. They can help utilities to manage demand more effectively, reduce costs, and improve customer satisfaction.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the relevance of the information provided in relation to the user's question about why utilities use 'virtual DMAs' instead of physically closing pipes.\n",
            "\n",
            "The actual answer succinctly explains that virtual DMAs utilize flow meters for monitoring without closing pipes, which preserves redundancy and allows for leak detection while maintaining operational flexibility. It also mentions the higher investment required for metering and data analysis.\n",
            "\n",
            "The predicted answer, while providing a comprehensive overview of the benefits of virtual DMAs, includes several points that, while related, may not directly address the core reasons utilities prefer virtual DMAs over physical pipe closures. For instance, the points about cost-effectiveness, flexibility, reduced disruption, data-driven decision-making, scalability, and environmental benefits, while relevant to the broader context of virtual DMAs, do not specifically highlight the operational aspects of monitoring and leak detection as emphasized in the actual answer.\n",
            "\n",
            "The predicted response contains a lot of relevant information but also includes some details that could be considered tangential or overly broad, such as environmental benefits and customer satisfaction, which are not directly tied to the question.\n",
            "\n",
            "Given this analysis, the predicted answer does answer the user's question but contains more irrelevant information than relevant information, leading to a score of 3.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: Why do utilities sometimes use 'virtual DMAs' instead of physically closing pipes?, Actual answer: Virtual DMAs use flow meters to monitor network zones without fully closing boundary pipes, preserving redundancy while enabling leak detection. This approach maintains operational flexibility but requires higher investment in metering and data analysis., Predicted answer: Utilities sometimes use 'virtual DMAs' (Demand Management Areas) instead of physically closing pipes for several reasons:\n",
            "\n",
            "1. **Cost-Effectiveness**: Physically closing pipes can be a costly and time-consuming process, especially in areas with complex infrastructure. Virtual DMAs, on the other hand, can be implemented at a lower cost and with less disruption to service.\n",
            "\n",
            "2. **Flexibility**: Virtual DMAs can be easily adjusted or modified as needed, without the need for physical changes to the infrastructure. This makes them a more flexible option for utilities that need to respond to changing demand patterns or customer needs.\n",
            "\n",
            "3. **Reduced Disruption**: Physically closing pipes can cause significant disruption to customers, including loss of service, noise, and potential damage to property. Virtual DMAs can be implemented with minimal disruption to customers, making them a more customer-friendly option.\n",
            "\n",
            "4. **Data-Driven Decision Making**: Virtual DMAs rely on data and analytics to manage demand, rather than physical infrastructure. This allows utilities to make more informed decisions about how to manage demand, based on real-time data and customer behavior.\n",
            "\n",
            "5. **Scalability**: Virtual DMAs can be easily scaled up or down to meet changing demand patterns, without the need for physical infrastructure changes. This makes them a more scalable option for utilities that need to respond to changing demand patterns.\n",
            "\n",
            "6. **Environmental Benefits**: Virtual DMAs can help utilities to reduce energy consumption and greenhouse gas emissions, by encouraging customers to use energy more efficiently. This can help utilities to meet their environmental goals and reduce their carbon footprint.\n",
            "\n",
            "Overall, virtual DMAs offer a cost-effective, flexible, and customer-friendly alternative to physically closing pipes. They can help utilities to manage demand more effectively, reduce costs, and improve customer satisfaction.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information provided in the predicted response. The actual answer succinctly explains the concept of virtual DMAs, highlighting their benefits in terms of operational flexibility, leak detection, and investment requirements. \n",
            "\n",
            "In contrast, the predicted answer elaborates on multiple aspects of virtual DMAs, including cost-effectiveness, flexibility, reduced disruption, data-driven decision-making, scalability, and environmental benefits. While these points are relevant, they introduce a significant amount of extra information that goes beyond the core explanation provided in the actual answer. \n",
            "\n",
            "The predicted response is lengthy and includes detailed explanations for each point, which could be seen as flowery language. This makes it less concise than the actual answer, which is direct and to the point.\n",
            "\n",
            "Given this analysis, I would assign a score of 3 to the predicted response, as it includes a lot of extra information and uses flowery language, making it less concise than necessary.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [01:34, 94.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mUser message:Question: Why do utilities sometimes use 'virtual DMAs' instead of physically closing pipes?, Actual answer: Virtual DMAs use flow meters to monitor network zones without fully closing boundary pipes, preserving redundancy while enabling leak detection. This approach maintains operational flexibility but requires higher investment in metering and data analysis., Predicted answer: Utilities sometimes use 'virtual DMAs' (Demand Management Areas) instead of physically closing pipes for several reasons:\n",
            "\n",
            "1. **Cost-Effectiveness**: Physically closing pipes can be a costly and time-consuming process, especially in areas with complex infrastructure. Virtual DMAs, on the other hand, can be implemented at a lower cost and with less disruption to service.\n",
            "\n",
            "2. **Flexibility**: Virtual DMAs can be easily adjusted or modified as needed, without the need for physical changes to the infrastructure. This makes them a more flexible option for utilities that need to respond to changing demand patterns or customer needs.\n",
            "\n",
            "3. **Reduced Disruption**: Physically closing pipes can cause significant disruption to customers, including loss of service, noise, and potential damage to property. Virtual DMAs can be implemented with minimal disruption to customers, making them a more customer-friendly option.\n",
            "\n",
            "4. **Data-Driven Decision Making**: Virtual DMAs rely on data and analytics to manage demand, rather than physical infrastructure. This allows utilities to make more informed decisions about how to manage demand, based on real-time data and customer behavior.\n",
            "\n",
            "5. **Scalability**: Virtual DMAs can be easily scaled up or down to meet changing demand patterns, without the need for physical infrastructure changes. This makes them a more scalable option for utilities that need to respond to changing demand patterns.\n",
            "\n",
            "6. **Environmental Benefits**: Virtual DMAs can help utilities to reduce energy consumption and greenhouse gas emissions, by encouraging customers to use energy more efficiently. This can help utilities to meet their environmental goals and reduce their carbon footprint.\n",
            "\n",
            "Overall, virtual DMAs offer a cost-effective, flexible, and customer-friendly alternative to physically closing pipes. They can help utilities to manage demand more effectively, reduce costs, and improve customer satisfaction.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the confidence conveyed in both responses regarding the use of virtual DMAs by utilities. \n",
            "\n",
            "The actual answer succinctly captures the essence of virtual DMAs, emphasizing their role in monitoring network zones without the need for physical alterations to the infrastructure. It highlights the benefits of maintaining operational flexibility and the necessity for investment in metering and data analysis. This response is clear, direct, and conveys a strong understanding of the topic.\n",
            "\n",
            "In contrast, the predicted answer provides a more elaborate explanation, listing multiple reasons why utilities might prefer virtual DMAs. While it covers several relevant points such as cost-effectiveness, flexibility, reduced disruption, data-driven decision-making, scalability, and environmental benefits, it lacks the concise focus of the actual answer. The predicted response, while informative, introduces a level of complexity that may lead to uncertainty about the core reasons for using virtual DMAs. \n",
            "\n",
            "The predicted answer does not explicitly contradict the actual answer, but it does not convey the same level of confidence and clarity. It presents a broader perspective but may leave the reader with some doubt about the primary motivations behind the use of virtual DMAs.\n",
            "\n",
            "Given these considerations, I would assign a score of 3 to the predicted answer, indicating uncertainty. It presents valid points but does not assert them with the same confidence as the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "meta-llama/Meta-Llama-3.1-8B-Instruct : District Metered Areas (DMAs) are a key concept in water distribution network management. A DMA is a geographic area within a water distribution system where all the water meters are read at a single point, typically at the boundary of the area. This approach helps in managing large networks by providing a more accurate and reliable measurement of water consumption.\n",
            "\n",
            "Here's how DMAs work:\n",
            "\n",
            "1. **Boundary definition**: A DMA is defined as a geographic area within the water distribution system, typically bounded by roads, rivers, or other natural features.\n",
            "2. **Metering**: All the water meters within the DMA are read at a single point, usually at the boundary of the area.\n",
            "3. **Data collection**: The meter readings are collected and analyzed to determine the total water consumption within the DMA.\n",
            "4. **Leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly.\n",
            "\n",
            "DMAs help in managing large networks in several ways:\n",
            "\n",
            "1. **Improved accuracy**: DMAs provide a more accurate measurement of water consumption, as all the meters within the area are read at a single point.\n",
            "2. **Enhanced leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly, reducing water losses and associated costs.\n",
            "3. **Better asset management**: DMAs help in identifying areas of high water consumption, which can inform asset management decisions, such as upgrading or replacing aging infrastructure.\n",
            "4. **Reduced non-revenue water**: DMAs can help reduce non-revenue water (NRW) by identifying areas where water is being lost due to leaks, theft, or other issues.\n",
            "5. **Improved customer service**: By providing accurate and reliable data on water consumption, DMAs can help water utilities to better serve their customers, respond to their needs, and provide more effective billing and customer service.\n",
            "\n",
            "In summary, District Metered Areas (DMAs) are a powerful tool for managing large water distribution networks. By providing accurate and reliable data on water consumption, DMAs can help water utilities to detect leaks, reduce non-revenue water, and improve customer service.\n",
            "\u001b[32mUser message:Question: Why do utilities sometimes use 'virtual DMAs' instead of physically closing pipes?, Actual answer: Virtual DMAs use flow meters to monitor network zones without fully closing boundary pipes, preserving redundancy while enabling leak detection. This approach maintains operational flexibility but requires higher investment in metering and data analysis., Predicted answer: Utilities sometimes use 'virtual DMAs' (Demand Management Areas) instead of physically closing pipes for several reasons:\n",
            "\n",
            "1. **Cost-Effectiveness**: Physically closing pipes can be a costly and time-consuming process, especially in areas with complex infrastructure. Virtual DMAs, on the other hand, can be implemented at a lower cost and with less disruption to service.\n",
            "\n",
            "2. **Flexibility**: Virtual DMAs can be easily adjusted or modified as needed, without the need for physical changes to the infrastructure. This makes them a more flexible option for utilities that need to respond to changing demand patterns or customer needs.\n",
            "\n",
            "3. **Reduced Disruption**: Physically closing pipes can cause significant disruption to customers, including loss of service, noise, and potential damage to property. Virtual DMAs can be implemented with minimal disruption to customers, making them a more customer-friendly option.\n",
            "\n",
            "4. **Data-Driven Decision Making**: Virtual DMAs rely on data and analytics to manage demand, rather than physical infrastructure. This allows utilities to make more informed decisions about how to manage demand, based on real-time data and customer behavior.\n",
            "\n",
            "5. **Scalability**: Virtual DMAs can be easily scaled up or down to meet changing demand patterns, without the need for physical infrastructure changes. This makes them a more scalable option for utilities that need to respond to changing demand patterns.\n",
            "\n",
            "6. **Environmental Benefits**: Virtual DMAs can help utilities to reduce energy consumption and greenhouse gas emissions, by encouraging customers to use energy more efficiently. This can help utilities to meet their environmental goals and reduce their carbon footprint.\n",
            "\n",
            "Overall, virtual DMAs offer a cost-effective, flexible, and customer-friendly alternative to physically closing pipes. They can help utilities to manage demand more effectively, reduce costs, and improve customer satisfaction.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the factual accuracy of the information presented in both responses. \n",
            "\n",
            "The actual answer succinctly explains that virtual DMAs utilize flow meters to monitor network zones without the need to close boundary pipes, which preserves redundancy and allows for leak detection. It also highlights the operational flexibility required for this approach, along with the need for higher investment in metering and data analysis.\n",
            "\n",
            "The predicted answer, while providing a comprehensive overview of the benefits of virtual DMAs, introduces several points that are not explicitly mentioned in the actual answer. For instance, it discusses cost-effectiveness, flexibility, reduced disruption, data-driven decision-making, scalability, and environmental benefits. While these points may be relevant to the concept of virtual DMAs, they do not directly address the core reason for their use as stated in the actual answer. Additionally, the predicted answer lacks the specific mention of flow meters and leak detection, which are critical components of the actual answer.\n",
            "\n",
            "Overall, the predicted answer contains a mix of relevant information and some inaccuracies or omissions regarding the specific mechanisms and purposes of virtual DMAs. Therefore, it does not fully align with the factuality of the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 3, 'factuality_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: Why do utilities sometimes use 'virtual DMAs' instead of physically closing pipes?, Actual answer: Virtual DMAs use flow meters to monitor network zones without fully closing boundary pipes, preserving redundancy while enabling leak detection. This approach maintains operational flexibility but requires higher investment in metering and data analysis., Predicted answer: Utilities sometimes use 'virtual DMAs' (Demand Management Areas) instead of physically closing pipes for several reasons:\n",
            "\n",
            "1. **Cost-Effectiveness**: Physically closing pipes can be a costly and time-consuming process, especially in areas with complex infrastructure. Virtual DMAs, on the other hand, can be implemented at a lower cost and with less disruption to service.\n",
            "\n",
            "2. **Flexibility**: Virtual DMAs can be easily adjusted or modified as needed, without the need for physical changes to the infrastructure. This makes them a more flexible option for utilities that need to respond to changing demand patterns or customer needs.\n",
            "\n",
            "3. **Reduced Disruption**: Physically closing pipes can cause significant disruption to customers, including loss of service, noise, and potential damage to property. Virtual DMAs can be implemented with minimal disruption to customers, making them a more customer-friendly option.\n",
            "\n",
            "4. **Data-Driven Decision Making**: Virtual DMAs rely on data and analytics to manage demand, rather than physical infrastructure. This allows utilities to make more informed decisions about how to manage demand, based on real-time data and customer behavior.\n",
            "\n",
            "5. **Scalability**: Virtual DMAs can be easily scaled up or down to meet changing demand patterns, without the need for physical infrastructure changes. This makes them a more scalable option for utilities that need to respond to changing demand patterns.\n",
            "\n",
            "6. **Environmental Benefits**: Virtual DMAs can help utilities to reduce energy consumption and greenhouse gas emissions, by encouraging customers to use energy more efficiently. This can help utilities to meet their environmental goals and reduce their carbon footprint.\n",
            "\n",
            "Overall, virtual DMAs offer a cost-effective, flexible, and customer-friendly alternative to physically closing pipes. They can help utilities to manage demand more effectively, reduce costs, and improve customer satisfaction.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and relevance of the information provided. The actual answer succinctly explains the concept of virtual DMAs, emphasizing their use of flow meters for monitoring, the preservation of redundancy, and the need for investment in metering and data analysis. \n",
            "\n",
            "The predicted answer, while providing a comprehensive overview of the benefits of virtual DMAs, diverges from the actual answer in several ways. It introduces several points such as cost-effectiveness, flexibility, reduced disruption, data-driven decision-making, scalability, and environmental benefits. While these points are relevant to the discussion of virtual DMAs, they do not directly address the core reason for their use as stated in the actual answer. The predicted answer lacks the specific mention of flow meters and the operational flexibility aspect, which are critical to understanding why utilities opt for virtual DMAs.\n",
            "\n",
            "Moreover, the predicted answer does not clearly indicate any uncertainty or misinterpretation, but it does not align closely with the actual answer's focus either. It presents a confident narrative that could mislead someone into thinking it fully captures the essence of virtual DMAs without acknowledging the specific technical aspects mentioned in the actual answer.\n",
            "\n",
            "Given these considerations, the predicted answer shows a confident presentation of information but ultimately does not accurately reflect the specific reasons for using virtual DMAs as outlined in the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 3, 'factuality_descr': 3, 'judgement_descr': 3}\n",
            "\n",
            "\n",
            "No output from LLM\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: What are District Metered Areas (DMAs), and how do they help in managing large networks?, Actual answer: DMAs are subdivisions of a water distribution network where all inflows and outflows are monitored. They help detect leaks, control pressures, and improve water distribution efficiency by isolating different sections for independent analysis and operation., Predicted answer: District Metered Areas (DMAs) are a key concept in water distribution network management. A DMA is a geographic area within a water distribution system where all the water meters are read at a single point, typically at the boundary of the area. This approach helps in managing large networks by providing a more accurate and reliable measurement of water consumption.\n",
            "\n",
            "Here's how DMAs work:\n",
            "\n",
            "1. **Boundary definition**: A DMA is defined as a geographic area within the water distribution system, typically bounded by roads, rivers, or other natural features.\n",
            "2. **Metering**: All the water meters within the DMA are read at a single point, usually at the boundary of the area.\n",
            "3. **Data collection**: The meter readings are collected and analyzed to determine the total water consumption within the DMA.\n",
            "4. **Leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly.\n",
            "\n",
            "DMAs help in managing large networks in several ways:\n",
            "\n",
            "1. **Improved accuracy**: DMAs provide a more accurate measurement of water consumption, as all the meters within the area are read at a single point.\n",
            "2. **Enhanced leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly, reducing water losses and associated costs.\n",
            "3. **Better asset management**: DMAs help in identifying areas of high water consumption, which can inform asset management decisions, such as upgrading or replacing aging infrastructure.\n",
            "4. **Reduced non-revenue water**: DMAs can help reduce non-revenue water (NRW) by identifying areas where water is being lost due to leaks, theft, or other issues.\n",
            "5. **Improved customer service**: By providing accurate and reliable data on water consumption, DMAs can help water utilities to better serve their customers, respond to their needs, and provide more effective billing and customer service.\n",
            "\n",
            "In summary, District Metered Areas (DMAs) are a powerful tool for managing large water distribution networks. By providing accurate and reliable data on water consumption, DMAs can help water utilities to detect leaks, reduce non-revenue water, and improve customer service.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the completeness of the predicted answer compared to the actual answer, we need to analyze both responses in terms of the key elements they cover regarding District Metered Areas (DMAs) and their role in managing large water distribution networks.\n",
            "\n",
            "The actual answer succinctly defines DMAs as subdivisions of a water distribution network where inflows and outflows are monitored. It highlights their importance in detecting leaks, controlling pressures, and improving water distribution efficiency through isolation for independent analysis and operation.\n",
            "\n",
            "The predicted answer provides a more detailed explanation of DMAs, including their definition, how they work, and their benefits. It covers several aspects such as boundary definition, metering, data collection, and specific advantages like improved accuracy, enhanced leak detection, better asset management, reduced non-revenue water, and improved customer service.\n",
            "\n",
            "In terms of completeness:\n",
            "- The predicted answer includes a clear definition of DMAs and elaborates on their operational aspects.\n",
            "- It addresses the management benefits of DMAs in a comprehensive manner, covering multiple elements that contribute to effective water distribution network management.\n",
            "\n",
            "While the actual answer is concise, the predicted answer provides a more thorough exploration of the topic, making it more complete in terms of the information presented.\n",
            "\n",
            "Given this analysis, I would assign a score of 5 to the predicted response, as it covers all elements of a complete answer.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 5}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2it [01:57, 52.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : In the context of water distribution networks, compartmentalization and skeletonization are two distinct concepts used to analyze, design, and manage water supply systems.\n",
            "\n",
            "**Compartmentalization:**\n",
            "\n",
            "Compartmentalization refers to the process of dividing a large water distribution network into smaller, isolated sections or compartments. Each compartment is a self-contained system that can operate independently, with its own set of pipes, pumps, and valves. The goal of compartmentalization is to:\n",
            "\n",
            "1. Reduce the impact of failures or contamination in one compartment from affecting other parts of the network.\n",
            "2. Simplify the analysis and management of the network by breaking it down into smaller, more manageable sections.\n",
            "3. Improve the overall resilience and reliability of the water supply system.\n",
            "\n",
            "In a compartmentalized network, each compartment typically has its own:\n",
            "\n",
            "* Separate pipe network\n",
            "* Pumps and pumping stations\n",
            "* Valves and control systems\n",
            "* Water treatment and storage facilities (if applicable)\n",
            "\n",
            "**Skeletonization:**\n",
            "\n",
            "Skeletonization, on the other hand, refers to the process of identifying the most critical components of a water distribution network, such as the main pipes, pumps, and valves. These critical components are often referred to as the \"skeleton\" of the network. The goal of skeletonization is to:\n",
            "\n",
            "1. Identify the most critical elements of the network that are essential for maintaining water supply.\n",
            "2. Prioritize maintenance, repair, and replacement activities on these critical components.\n",
            "3. Simplify the analysis and management of the network by focusing on the most critical elements.\n",
            "\n",
            "In a skeletonized network, the focus is on the main pipes, pumps, and valves that are essential for maintaining water supply, rather than the entire network.\n",
            "\n",
            "**Key differences:**\n",
            "\n",
            "The main differences between compartmentalization and skeletonization are:\n",
            "\n",
            "1. **Scope:** Compartmentalization involves dividing the entire network into smaller sections, while skeletonization focuses on identifying the most critical components of the network.\n",
            "2. **Purpose:** Compartmentalization aims to reduce the impact of failures and simplify network management, while skeletonization prioritizes maintenance and repair activities on critical components.\n",
            "3. **Approach:** Compartmentalization involves a more detailed analysis of the network, while skeletonization requires a more high-level understanding of the network's critical components.\n",
            "\n",
            "In summary, compartmentalization is a more comprehensive approach that involves dividing the network into smaller sections, while skeletonization is a more focused approach that identifies the most critical components of the network.\n",
            "\u001b[32mUser message:Question: What are District Metered Areas (DMAs), and how do they help in managing large networks?, Actual answer: DMAs are subdivisions of a water distribution network where all inflows and outflows are monitored. They help detect leaks, control pressures, and improve water distribution efficiency by isolating different sections for independent analysis and operation., Predicted answer: District Metered Areas (DMAs) are a key concept in water distribution network management. A DMA is a geographic area within a water distribution system where all the water meters are read at a single point, typically at the boundary of the area. This approach helps in managing large networks by providing a more accurate and reliable measurement of water consumption.\n",
            "\n",
            "Here's how DMAs work:\n",
            "\n",
            "1. **Boundary definition**: A DMA is defined as a geographic area within the water distribution system, typically bounded by roads, rivers, or other natural features.\n",
            "2. **Metering**: All the water meters within the DMA are read at a single point, usually at the boundary of the area.\n",
            "3. **Data collection**: The meter readings are collected and analyzed to determine the total water consumption within the DMA.\n",
            "4. **Leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly.\n",
            "\n",
            "DMAs help in managing large networks in several ways:\n",
            "\n",
            "1. **Improved accuracy**: DMAs provide a more accurate measurement of water consumption, as all the meters within the area are read at a single point.\n",
            "2. **Enhanced leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly, reducing water losses and associated costs.\n",
            "3. **Better asset management**: DMAs help in identifying areas of high water consumption, which can inform asset management decisions, such as upgrading or replacing aging infrastructure.\n",
            "4. **Reduced non-revenue water**: DMAs can help reduce non-revenue water (NRW) by identifying areas where water is being lost due to leaks, theft, or other issues.\n",
            "5. **Improved customer service**: By providing accurate and reliable data on water consumption, DMAs can help water utilities to better serve their customers, respond to their needs, and provide more effective billing and customer service.\n",
            "\n",
            "In summary, District Metered Areas (DMAs) are a powerful tool for managing large water distribution networks. By providing accurate and reliable data on water consumption, DMAs can help water utilities to detect leaks, reduce non-revenue water, and improve customer service.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about District Metered Areas (DMAs) and their role in managing large networks. \n",
            "\n",
            "The actual answer succinctly defines DMAs and highlights their key functions, such as monitoring inflows and outflows, detecting leaks, controlling pressures, and improving efficiency. It emphasizes the importance of isolating sections for independent analysis and operation.\n",
            "\n",
            "The predicted answer, while lengthy, provides a detailed explanation of DMAs, including their definition, operational mechanics, and benefits. It covers aspects like boundary definition, metering, data collection, leak detection, and various advantages such as improved accuracy, enhanced leak detection, better asset management, reduced non-revenue water, and improved customer service.\n",
            "\n",
            "However, the predicted answer introduces some unnecessary details, such as the specific methods of boundary definition and the process of data collection, which are not explicitly mentioned in the actual answer. While these details are relevant to the overall understanding of DMAs, they may detract from the core focus of the question regarding their management role.\n",
            "\n",
            "In summary, the predicted answer does answer the user's question and provides relevant information, but it contains more detail than necessary, leading to some irrelevant information. Therefore, I would rate the predicted response as a 4, as it answers the question well but includes a bit of irrelevant information.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: What are District Metered Areas (DMAs), and how do they help in managing large networks?, Actual answer: DMAs are subdivisions of a water distribution network where all inflows and outflows are monitored. They help detect leaks, control pressures, and improve water distribution efficiency by isolating different sections for independent analysis and operation., Predicted answer: District Metered Areas (DMAs) are a key concept in water distribution network management. A DMA is a geographic area within a water distribution system where all the water meters are read at a single point, typically at the boundary of the area. This approach helps in managing large networks by providing a more accurate and reliable measurement of water consumption.\n",
            "\n",
            "Here's how DMAs work:\n",
            "\n",
            "1. **Boundary definition**: A DMA is defined as a geographic area within the water distribution system, typically bounded by roads, rivers, or other natural features.\n",
            "2. **Metering**: All the water meters within the DMA are read at a single point, usually at the boundary of the area.\n",
            "3. **Data collection**: The meter readings are collected and analyzed to determine the total water consumption within the DMA.\n",
            "4. **Leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly.\n",
            "\n",
            "DMAs help in managing large networks in several ways:\n",
            "\n",
            "1. **Improved accuracy**: DMAs provide a more accurate measurement of water consumption, as all the meters within the area are read at a single point.\n",
            "2. **Enhanced leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly, reducing water losses and associated costs.\n",
            "3. **Better asset management**: DMAs help in identifying areas of high water consumption, which can inform asset management decisions, such as upgrading or replacing aging infrastructure.\n",
            "4. **Reduced non-revenue water**: DMAs can help reduce non-revenue water (NRW) by identifying areas where water is being lost due to leaks, theft, or other issues.\n",
            "5. **Improved customer service**: By providing accurate and reliable data on water consumption, DMAs can help water utilities to better serve their customers, respond to their needs, and provide more effective billing and customer service.\n",
            "\n",
            "In summary, District Metered Areas (DMAs) are a powerful tool for managing large water distribution networks. By providing accurate and reliable data on water consumption, DMAs can help water utilities to detect leaks, reduce non-revenue water, and improve customer service.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we first need to analyze the content of both responses. The actual answer succinctly defines District Metered Areas (DMAs) and highlights their benefits in managing water distribution networks in a clear and direct manner. It focuses on key points such as monitoring inflows and outflows, detecting leaks, controlling pressures, and improving efficiency.\n",
            "\n",
            "In contrast, the predicted answer provides a more elaborate explanation of DMAs, including a detailed breakdown of how they work, their definition, and multiple benefits. While this information is relevant, it includes a significant amount of extra detail that goes beyond the original question's requirements. The predicted answer also employs a structured format with bullet points, which, while organized, contributes to its lengthiness.\n",
            "\n",
            "Given this analysis, the predicted answer includes a lot of extra information and uses flowery language, making it less concise than the actual answer. Therefore, I would assign a score of 3 for the predicted response.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error running target function: probability tensor contains either `inf`, `nan` or element < 0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mUser message:Question: What are District Metered Areas (DMAs), and how do they help in managing large networks?, Actual answer: DMAs are subdivisions of a water distribution network where all inflows and outflows are monitored. They help detect leaks, control pressures, and improve water distribution efficiency by isolating different sections for independent analysis and operation., Predicted answer: District Metered Areas (DMAs) are a key concept in water distribution network management. A DMA is a geographic area within a water distribution system where all the water meters are read at a single point, typically at the boundary of the area. This approach helps in managing large networks by providing a more accurate and reliable measurement of water consumption.\n",
            "\n",
            "Here's how DMAs work:\n",
            "\n",
            "1. **Boundary definition**: A DMA is defined as a geographic area within the water distribution system, typically bounded by roads, rivers, or other natural features.\n",
            "2. **Metering**: All the water meters within the DMA are read at a single point, usually at the boundary of the area.\n",
            "3. **Data collection**: The meter readings are collected and analyzed to determine the total water consumption within the DMA.\n",
            "4. **Leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly.\n",
            "\n",
            "DMAs help in managing large networks in several ways:\n",
            "\n",
            "1. **Improved accuracy**: DMAs provide a more accurate measurement of water consumption, as all the meters within the area are read at a single point.\n",
            "2. **Enhanced leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly, reducing water losses and associated costs.\n",
            "3. **Better asset management**: DMAs help in identifying areas of high water consumption, which can inform asset management decisions, such as upgrading or replacing aging infrastructure.\n",
            "4. **Reduced non-revenue water**: DMAs can help reduce non-revenue water (NRW) by identifying areas where water is being lost due to leaks, theft, or other issues.\n",
            "5. **Improved customer service**: By providing accurate and reliable data on water consumption, DMAs can help water utilities to better serve their customers, respond to their needs, and provide more effective billing and customer service.\n",
            "\n",
            "In summary, District Metered Areas (DMAs) are a powerful tool for managing large water distribution networks. By providing accurate and reliable data on water consumption, DMAs can help water utilities to detect leaks, reduce non-revenue water, and improve customer service.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the confidence conveyed in both responses regarding the concept of District Metered Areas (DMAs) and their role in managing water distribution networks.\n",
            "\n",
            "The actual answer succinctly defines DMAs and highlights their primary functions, such as monitoring inflows and outflows, detecting leaks, controlling pressures, and improving efficiency. It is clear and direct, demonstrating a strong understanding of the topic.\n",
            "\n",
            "The predicted answer, while providing a detailed explanation of DMAs, introduces some inaccuracies. For instance, it states that all water meters are read at a single point, which may mislead readers about the operational mechanics of DMAs. The predicted answer does cover several benefits of DMAs, such as improved accuracy and leak detection, but it lacks the clarity and precision of the actual answer. \n",
            "\n",
            "Overall, the predicted answer shows a good understanding of DMAs and their benefits, but the inaccuracies and potential for misunderstanding reduce its confidence level. It leans towards being correct but does not fully endorse the actual answer due to the misleading information.\n",
            "\n",
            "Given these considerations, I would assign a score of 4 to the predicted answer, indicating moderate agreement with the actual answer but acknowledging some uncertainty due to inaccuracies.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: What are District Metered Areas (DMAs), and how do they help in managing large networks?, Actual answer: DMAs are subdivisions of a water distribution network where all inflows and outflows are monitored. They help detect leaks, control pressures, and improve water distribution efficiency by isolating different sections for independent analysis and operation., Predicted answer: District Metered Areas (DMAs) are a key concept in water distribution network management. A DMA is a geographic area within a water distribution system where all the water meters are read at a single point, typically at the boundary of the area. This approach helps in managing large networks by providing a more accurate and reliable measurement of water consumption.\n",
            "\n",
            "Here's how DMAs work:\n",
            "\n",
            "1. **Boundary definition**: A DMA is defined as a geographic area within the water distribution system, typically bounded by roads, rivers, or other natural features.\n",
            "2. **Metering**: All the water meters within the DMA are read at a single point, usually at the boundary of the area.\n",
            "3. **Data collection**: The meter readings are collected and analyzed to determine the total water consumption within the DMA.\n",
            "4. **Leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly.\n",
            "\n",
            "DMAs help in managing large networks in several ways:\n",
            "\n",
            "1. **Improved accuracy**: DMAs provide a more accurate measurement of water consumption, as all the meters within the area are read at a single point.\n",
            "2. **Enhanced leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly, reducing water losses and associated costs.\n",
            "3. **Better asset management**: DMAs help in identifying areas of high water consumption, which can inform asset management decisions, such as upgrading or replacing aging infrastructure.\n",
            "4. **Reduced non-revenue water**: DMAs can help reduce non-revenue water (NRW) by identifying areas where water is being lost due to leaks, theft, or other issues.\n",
            "5. **Improved customer service**: By providing accurate and reliable data on water consumption, DMAs can help water utilities to better serve their customers, respond to their needs, and provide more effective billing and customer service.\n",
            "\n",
            "In summary, District Metered Areas (DMAs) are a powerful tool for managing large water distribution networks. By providing accurate and reliable data on water consumption, DMAs can help water utilities to detect leaks, reduce non-revenue water, and improve customer service.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to analyze the key components of both responses regarding District Metered Areas (DMAs) and their role in managing water distribution networks.\n",
            "\n",
            "The actual answer succinctly defines DMAs as subdivisions of a water distribution network where inflows and outflows are monitored, emphasizing their role in leak detection, pressure control, and efficiency in water distribution. It highlights the importance of isolating sections for independent analysis and operation.\n",
            "\n",
            "The predicted answer, while providing a detailed explanation of DMAs, introduces some inaccuracies. It states that all water meters within a DMA are read at a single point, which is misleading. Typically, DMAs involve monitoring inflows and outflows at specific points rather than reading all meters at one location. The predicted answer does cover several relevant aspects, such as improved accuracy, leak detection, and better asset management, which align with the actual answer's points. However, it also includes some extraneous details that may not be directly relevant to the core definition and function of DMAs.\n",
            "\n",
            "Overall, the predicted answer contains a mix of factual information and some inaccuracies, particularly in the description of how metering is conducted within DMAs. Therefore, it does not fully align with the factuality of the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: What are District Metered Areas (DMAs), and how do they help in managing large networks?, Actual answer: DMAs are subdivisions of a water distribution network where all inflows and outflows are monitored. They help detect leaks, control pressures, and improve water distribution efficiency by isolating different sections for independent analysis and operation., Predicted answer: District Metered Areas (DMAs) are a key concept in water distribution network management. A DMA is a geographic area within a water distribution system where all the water meters are read at a single point, typically at the boundary of the area. This approach helps in managing large networks by providing a more accurate and reliable measurement of water consumption.\n",
            "\n",
            "Here's how DMAs work:\n",
            "\n",
            "1. **Boundary definition**: A DMA is defined as a geographic area within the water distribution system, typically bounded by roads, rivers, or other natural features.\n",
            "2. **Metering**: All the water meters within the DMA are read at a single point, usually at the boundary of the area.\n",
            "3. **Data collection**: The meter readings are collected and analyzed to determine the total water consumption within the DMA.\n",
            "4. **Leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly.\n",
            "\n",
            "DMAs help in managing large networks in several ways:\n",
            "\n",
            "1. **Improved accuracy**: DMAs provide a more accurate measurement of water consumption, as all the meters within the area are read at a single point.\n",
            "2. **Enhanced leak detection**: By monitoring the water consumption patterns within the DMA, leaks and other issues can be detected and addressed promptly, reducing water losses and associated costs.\n",
            "3. **Better asset management**: DMAs help in identifying areas of high water consumption, which can inform asset management decisions, such as upgrading or replacing aging infrastructure.\n",
            "4. **Reduced non-revenue water**: DMAs can help reduce non-revenue water (NRW) by identifying areas where water is being lost due to leaks, theft, or other issues.\n",
            "5. **Improved customer service**: By providing accurate and reliable data on water consumption, DMAs can help water utilities to better serve their customers, respond to their needs, and provide more effective billing and customer service.\n",
            "\n",
            "In summary, District Metered Areas (DMAs) are a powerful tool for managing large water distribution networks. By providing accurate and reliable data on water consumption, DMAs can help water utilities to detect leaks, reduce non-revenue water, and improve customer service.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and completeness of the information provided. The actual answer succinctly defines District Metered Areas (DMAs) and highlights their primary functions, such as monitoring inflows and outflows, detecting leaks, controlling pressures, and improving efficiency in water distribution.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, contains some inaccuracies and misinterpretations. It states that all water meters within a DMA are read at a single point, which is misleading. In reality, DMAs involve monitoring inflows and outflows at specific points, not necessarily reading all meters at a single location. Additionally, while the predicted answer discusses the benefits of DMAs, it does not mention the isolation of sections for independent analysis, which is a critical aspect of their function.\n",
            "\n",
            "The predicted answer does provide a comprehensive overview of how DMAs work and their benefits, but it lacks precision in defining what DMAs are and how they operate. It also implies a level of certainty in its claims that is not entirely justified given the inaccuracies present.\n",
            "\n",
            "Considering these points, the predicted answer shows a misunderstanding of the core concept of DMAs and misrepresents their operational details, leading to a lower score.\n",
            "\n",
            "FINAL SCORE: 2\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 3, 'judgement_descr': 2}\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4it [02:27, 28.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : In the context of computational fluid dynamics (CFD) and water engineering, skeletonization is a technique used to create a simplified representation of a complex geometry, such as a pipe network or a river system. This is typically done to reduce the computational complexity and improve the efficiency of numerical simulations.\n",
            "\n",
            "Modern computing advancements have significantly reduced the need for skeletonization in several ways:\n",
            "\n",
            "1. **Increased computational power**: With the advent of high-performance computing (HPC) and graphics processing units (GPUs), computational power has increased exponentially. This allows for faster and more accurate simulations of complex geometries without the need for simplification.\n",
            "2. **Advances in numerical methods**: New numerical methods, such as lattice Boltzmann methods (LBM) and smoothed particle hydrodynamics (SPH), have been developed to handle complex geometries and large datasets. These methods are more efficient and accurate than traditional methods, reducing the need for skeletonization.\n",
            "3. **Improved mesh generation**: Mesh generation algorithms have become more sophisticated, allowing for the creation of high-quality meshes that can accurately represent complex geometries. This reduces the need for skeletonization, as the mesh can be generated directly from the original geometry.\n",
            "4. **Increased memory and storage**: Advances in memory and storage technology have made it possible to store and process large datasets, reducing the need for simplification and skeletonization.\n",
            "5. **Parallel computing**: Modern computing architectures, such as multi-core processors and distributed computing systems, enable parallel computing, which can significantly speed up simulations and reduce the need for skeletonization.\n",
            "\n",
            "As a result, modern computing advancements have made it possible to simulate complex water engineering systems, such as pipe networks and river systems, with high accuracy and efficiency, reducing the need for skeletonization. However, skeletonization may still be useful in certain situations, such as when dealing with extremely complex geometries or when computational resources are limited.\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: What is compartmentalization in water distribution networks, and how does it differ from skeletonization?, Actual answer: Compartmentalization divides a large network into smaller, independently managed sectors (e.g., District Metered Areas). Unlike skeletonization, which reduces model size, compartmentalization focuses on operational management and leak detection by segmenting networks while keeping the full pipe infrastructure intact., Predicted answer: In the context of water distribution networks, compartmentalization and skeletonization are two distinct concepts used to analyze, design, and manage water supply systems.\n",
            "\n",
            "**Compartmentalization:**\n",
            "\n",
            "Compartmentalization refers to the process of dividing a large water distribution network into smaller, isolated sections or compartments. Each compartment is a self-contained system that can operate independently, with its own set of pipes, pumps, and valves. The goal of compartmentalization is to:\n",
            "\n",
            "1. Reduce the impact of failures or contamination in one compartment from affecting other parts of the network.\n",
            "2. Simplify the analysis and management of the network by breaking it down into smaller, more manageable sections.\n",
            "3. Improve the overall resilience and reliability of the water supply system.\n",
            "\n",
            "In a compartmentalized network, each compartment typically has its own:\n",
            "\n",
            "* Separate pipe network\n",
            "* Pumps and pumping stations\n",
            "* Valves and control systems\n",
            "* Water treatment and storage facilities (if applicable)\n",
            "\n",
            "**Skeletonization:**\n",
            "\n",
            "Skeletonization, on the other hand, refers to the process of identifying the most critical components of a water distribution network, such as the main pipes, pumps, and valves. These critical components are often referred to as the \"skeleton\" of the network. The goal of skeletonization is to:\n",
            "\n",
            "1. Identify the most critical elements of the network that are essential for maintaining water supply.\n",
            "2. Prioritize maintenance, repair, and replacement activities on these critical components.\n",
            "3. Simplify the analysis and management of the network by focusing on the most critical elements.\n",
            "\n",
            "In a skeletonized network, the focus is on the main pipes, pumps, and valves that are essential for maintaining water supply, rather than the entire network.\n",
            "\n",
            "**Key differences:**\n",
            "\n",
            "The main differences between compartmentalization and skeletonization are:\n",
            "\n",
            "1. **Scope:** Compartmentalization involves dividing the entire network into smaller sections, while skeletonization focuses on identifying the most critical components of the network.\n",
            "2. **Purpose:** Compartmentalization aims to reduce the impact of failures and simplify network management, while skeletonization prioritizes maintenance and repair activities on critical components.\n",
            "3. **Approach:** Compartmentalization involves a more detailed analysis of the network, while skeletonization requires a more high-level understanding of the network's critical components.\n",
            "\n",
            "In summary, compartmentalization is a more comprehensive approach that involves dividing the network into smaller sections, while skeletonization is a more focused approach that identifies the most critical components of the network.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the completeness of the information provided in both responses regarding compartmentalization and skeletonization in water distribution networks.\n",
            "\n",
            "The actual answer succinctly defines compartmentalization, explaining its purpose and how it operates within water distribution networks. It also contrasts this with skeletonization, highlighting the differences in focus and objectives between the two concepts. The actual answer is clear and directly addresses the question, providing a comprehensive understanding of both terms.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, does cover the essential elements of both compartmentalization and skeletonization. It explains compartmentalization's purpose, benefits, and operational aspects, as well as skeletonization's focus on critical components. Additionally, it outlines key differences between the two concepts, which is crucial for understanding their distinct roles in water distribution networks.\n",
            "\n",
            "However, the predicted answer could be seen as slightly more verbose than necessary, and while it does provide a thorough explanation, it may not be as concise as the actual answer. Nevertheless, it does cover all the elements required to answer the question fully.\n",
            "\n",
            "Given this analysis, the predicted answer includes all necessary components to address the question, making it a complete response.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 5}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: What is compartmentalization in water distribution networks, and how does it differ from skeletonization?, Actual answer: Compartmentalization divides a large network into smaller, independently managed sectors (e.g., District Metered Areas). Unlike skeletonization, which reduces model size, compartmentalization focuses on operational management and leak detection by segmenting networks while keeping the full pipe infrastructure intact., Predicted answer: In the context of water distribution networks, compartmentalization and skeletonization are two distinct concepts used to analyze, design, and manage water supply systems.\n",
            "\n",
            "**Compartmentalization:**\n",
            "\n",
            "Compartmentalization refers to the process of dividing a large water distribution network into smaller, isolated sections or compartments. Each compartment is a self-contained system that can operate independently, with its own set of pipes, pumps, and valves. The goal of compartmentalization is to:\n",
            "\n",
            "1. Reduce the impact of failures or contamination in one compartment from affecting other parts of the network.\n",
            "2. Simplify the analysis and management of the network by breaking it down into smaller, more manageable sections.\n",
            "3. Improve the overall resilience and reliability of the water supply system.\n",
            "\n",
            "In a compartmentalized network, each compartment typically has its own:\n",
            "\n",
            "* Separate pipe network\n",
            "* Pumps and pumping stations\n",
            "* Valves and control systems\n",
            "* Water treatment and storage facilities (if applicable)\n",
            "\n",
            "**Skeletonization:**\n",
            "\n",
            "Skeletonization, on the other hand, refers to the process of identifying the most critical components of a water distribution network, such as the main pipes, pumps, and valves. These critical components are often referred to as the \"skeleton\" of the network. The goal of skeletonization is to:\n",
            "\n",
            "1. Identify the most critical elements of the network that are essential for maintaining water supply.\n",
            "2. Prioritize maintenance, repair, and replacement activities on these critical components.\n",
            "3. Simplify the analysis and management of the network by focusing on the most critical elements.\n",
            "\n",
            "In a skeletonized network, the focus is on the main pipes, pumps, and valves that are essential for maintaining water supply, rather than the entire network.\n",
            "\n",
            "**Key differences:**\n",
            "\n",
            "The main differences between compartmentalization and skeletonization are:\n",
            "\n",
            "1. **Scope:** Compartmentalization involves dividing the entire network into smaller sections, while skeletonization focuses on identifying the most critical components of the network.\n",
            "2. **Purpose:** Compartmentalization aims to reduce the impact of failures and simplify network management, while skeletonization prioritizes maintenance and repair activities on critical components.\n",
            "3. **Approach:** Compartmentalization involves a more detailed analysis of the network, while skeletonization requires a more high-level understanding of the network's critical components.\n",
            "\n",
            "In summary, compartmentalization is a more comprehensive approach that involves dividing the network into smaller sections, while skeletonization is a more focused approach that identifies the most critical components of the network.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about compartmentalization in water distribution networks and its distinction from skeletonization. \n",
            "\n",
            "The predicted answer provides a thorough explanation of both concepts, detailing the purpose and characteristics of compartmentalization and skeletonization. It outlines the goals of compartmentalization, such as improving resilience and simplifying management, and contrasts these with the objectives of skeletonization, which focuses on identifying critical components for maintenance. \n",
            "\n",
            "However, while the predicted answer is informative and relevant, it includes some extraneous details that may not be necessary for a direct comparison of the two concepts. For instance, the detailed breakdown of what constitutes a compartment (e.g., separate pipe networks, pumps, etc.) may not be essential to understanding the core differences between compartmentalization and skeletonization. \n",
            "\n",
            "In contrast, the actual answer is more concise and directly addresses the user's question without delving into excessive detail. It succinctly explains compartmentalization and skeletonization, emphasizing their differences in scope, purpose, and approach.\n",
            "\n",
            "Given this analysis, the predicted answer does answer the user's question but contains more irrelevant information than relevant information, particularly in the detailed descriptions of each concept.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : Skeletonization is a technique used in hydraulic modeling, particularly in computational fluid dynamics (CFD) and one-dimensional (1D) modeling, to reduce the complexity of a model by removing or simplifying certain elements. In the context of transient (surge) analysis, skeletonization can have both positive and negative impacts.\n",
            "\n",
            "**Positive impacts:**\n",
            "\n",
            "1. **Reduced computational time**: By removing or simplifying certain elements, skeletonization can significantly reduce the computational time required for transient analysis. This is particularly beneficial for large-scale models or models with complex geometries.\n",
            "2. **Improved model stability**: Skeletonization can help stabilize the model by removing elements that may cause numerical instability or oscillations during transient analysis.\n",
            "3. **Enhanced model interpretability**: By simplifying the model, skeletonization can make it easier to understand and interpret the results of transient analysis.\n",
            "\n",
            "**Negative impacts:**\n",
            "\n",
            "1. **Loss of accuracy**: Skeletonization can lead to a loss of accuracy in the results of transient analysis, particularly if the removed or simplified elements are critical to the behavior of the system.\n",
            "2. **Over-simplification**: If skeletonization is not done carefully, it can lead to over-simplification of the model, which can result in inaccurate or misleading results.\n",
            "3. **Inability to capture local effects**: Skeletonization can make it difficult to capture local effects, such as pressure surges or water hammer, which are critical to understanding the behavior of the system during transient analysis.\n",
            "\n",
            "**Best practices for skeletonization in transient analysis:**\n",
            "\n",
            "1. **Carefully select the elements to be removed or simplified**: Only remove or simplify elements that are not critical to the behavior of the system during transient analysis.\n",
            "2. **Use sensitivity analysis**: Perform sensitivity analysis to determine the impact of skeletonization on the results of transient analysis.\n",
            "3. **Validate the results**: Validate the results of transient analysis using field data or other independent methods to ensure that the skeletonized model accurately represents the behavior of the system.\n",
            "\n",
            "In summary, skeletonization can be a useful technique for reducing the complexity of hydraulic models and improving computational efficiency during transient analysis. However, it requires careful application and validation to ensure that the results accurately represent the behavior of the system.\n",
            "\u001b[32mUser message:Question: What is compartmentalization in water distribution networks, and how does it differ from skeletonization?, Actual answer: Compartmentalization divides a large network into smaller, independently managed sectors (e.g., District Metered Areas). Unlike skeletonization, which reduces model size, compartmentalization focuses on operational management and leak detection by segmenting networks while keeping the full pipe infrastructure intact., Predicted answer: In the context of water distribution networks, compartmentalization and skeletonization are two distinct concepts used to analyze, design, and manage water supply systems.\n",
            "\n",
            "**Compartmentalization:**\n",
            "\n",
            "Compartmentalization refers to the process of dividing a large water distribution network into smaller, isolated sections or compartments. Each compartment is a self-contained system that can operate independently, with its own set of pipes, pumps, and valves. The goal of compartmentalization is to:\n",
            "\n",
            "1. Reduce the impact of failures or contamination in one compartment from affecting other parts of the network.\n",
            "2. Simplify the analysis and management of the network by breaking it down into smaller, more manageable sections.\n",
            "3. Improve the overall resilience and reliability of the water supply system.\n",
            "\n",
            "In a compartmentalized network, each compartment typically has its own:\n",
            "\n",
            "* Separate pipe network\n",
            "* Pumps and pumping stations\n",
            "* Valves and control systems\n",
            "* Water treatment and storage facilities (if applicable)\n",
            "\n",
            "**Skeletonization:**\n",
            "\n",
            "Skeletonization, on the other hand, refers to the process of identifying the most critical components of a water distribution network, such as the main pipes, pumps, and valves. These critical components are often referred to as the \"skeleton\" of the network. The goal of skeletonization is to:\n",
            "\n",
            "1. Identify the most critical elements of the network that are essential for maintaining water supply.\n",
            "2. Prioritize maintenance, repair, and replacement activities on these critical components.\n",
            "3. Simplify the analysis and management of the network by focusing on the most critical elements.\n",
            "\n",
            "In a skeletonized network, the focus is on the main pipes, pumps, and valves that are essential for maintaining water supply, rather than the entire network.\n",
            "\n",
            "**Key differences:**\n",
            "\n",
            "The main differences between compartmentalization and skeletonization are:\n",
            "\n",
            "1. **Scope:** Compartmentalization involves dividing the entire network into smaller sections, while skeletonization focuses on identifying the most critical components of the network.\n",
            "2. **Purpose:** Compartmentalization aims to reduce the impact of failures and simplify network management, while skeletonization prioritizes maintenance and repair activities on critical components.\n",
            "3. **Approach:** Compartmentalization involves a more detailed analysis of the network, while skeletonization requires a more high-level understanding of the network's critical components.\n",
            "\n",
            "In summary, compartmentalization is a more comprehensive approach that involves dividing the network into smaller sections, while skeletonization is a more focused approach that identifies the most critical components of the network.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information provided and how directly it addresses the question. \n",
            "\n",
            "The actual answer succinctly defines compartmentalization and skeletonization, highlighting their key differences in a clear and straightforward manner. It focuses on the essential aspects without unnecessary elaboration.\n",
            "\n",
            "In contrast, the predicted answer provides a detailed explanation of both concepts, including definitions, goals, and key differences, which results in a significantly longer response. While the information is relevant, it includes excessive detail that goes beyond what is necessary to answer the question effectively. The structure with bullet points and multiple sub-points adds to the length without enhancing clarity.\n",
            "\n",
            "Given this analysis, the predicted answer includes a lot of extra information and uses a more elaborate structure than needed, which detracts from its conciseness.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 3, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: What is compartmentalization in water distribution networks, and how does it differ from skeletonization?, Actual answer: Compartmentalization divides a large network into smaller, independently managed sectors (e.g., District Metered Areas). Unlike skeletonization, which reduces model size, compartmentalization focuses on operational management and leak detection by segmenting networks while keeping the full pipe infrastructure intact., Predicted answer: In the context of water distribution networks, compartmentalization and skeletonization are two distinct concepts used to analyze, design, and manage water supply systems.\n",
            "\n",
            "**Compartmentalization:**\n",
            "\n",
            "Compartmentalization refers to the process of dividing a large water distribution network into smaller, isolated sections or compartments. Each compartment is a self-contained system that can operate independently, with its own set of pipes, pumps, and valves. The goal of compartmentalization is to:\n",
            "\n",
            "1. Reduce the impact of failures or contamination in one compartment from affecting other parts of the network.\n",
            "2. Simplify the analysis and management of the network by breaking it down into smaller, more manageable sections.\n",
            "3. Improve the overall resilience and reliability of the water supply system.\n",
            "\n",
            "In a compartmentalized network, each compartment typically has its own:\n",
            "\n",
            "* Separate pipe network\n",
            "* Pumps and pumping stations\n",
            "* Valves and control systems\n",
            "* Water treatment and storage facilities (if applicable)\n",
            "\n",
            "**Skeletonization:**\n",
            "\n",
            "Skeletonization, on the other hand, refers to the process of identifying the most critical components of a water distribution network, such as the main pipes, pumps, and valves. These critical components are often referred to as the \"skeleton\" of the network. The goal of skeletonization is to:\n",
            "\n",
            "1. Identify the most critical elements of the network that are essential for maintaining water supply.\n",
            "2. Prioritize maintenance, repair, and replacement activities on these critical components.\n",
            "3. Simplify the analysis and management of the network by focusing on the most critical elements.\n",
            "\n",
            "In a skeletonized network, the focus is on the main pipes, pumps, and valves that are essential for maintaining water supply, rather than the entire network.\n",
            "\n",
            "**Key differences:**\n",
            "\n",
            "The main differences between compartmentalization and skeletonization are:\n",
            "\n",
            "1. **Scope:** Compartmentalization involves dividing the entire network into smaller sections, while skeletonization focuses on identifying the most critical components of the network.\n",
            "2. **Purpose:** Compartmentalization aims to reduce the impact of failures and simplify network management, while skeletonization prioritizes maintenance and repair activities on critical components.\n",
            "3. **Approach:** Compartmentalization involves a more detailed analysis of the network, while skeletonization requires a more high-level understanding of the network's critical components.\n",
            "\n",
            "In summary, compartmentalization is a more comprehensive approach that involves dividing the network into smaller sections, while skeletonization is a more focused approach that identifies the most critical components of the network.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response captures the essence of compartmentalization and skeletonization in water distribution networks, as well as the confidence conveyed in its assertions.\n",
            "\n",
            "The actual answer succinctly defines compartmentalization as the division of a network into smaller, independently managed sectors, emphasizing its operational management and leak detection benefits. It contrasts this with skeletonization, which is described as a method for reducing model size rather than focusing on operational aspects.\n",
            "\n",
            "The predicted answer provides a detailed explanation of both concepts, outlining the goals and components of compartmentalization and skeletonization. It correctly identifies the key differences between the two, including scope, purpose, and approach. However, while the predicted answer is informative and accurate, it does not explicitly mention the operational management aspect of compartmentalization or the focus on leak detection, which are critical points in the actual answer.\n",
            "\n",
            "In terms of confidence, the predicted answer presents the information in a structured and assertive manner, indicating a strong understanding of the concepts. However, it lacks the concise clarity of the actual answer, which may lead to some uncertainty about its completeness.\n",
            "\n",
            "Given these considerations, I would assign a score of 4 to the predicted answer. It demonstrates moderate agreement with the actual answer, but there are areas where it could be more aligned with the key points emphasized in the actual response.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: What is compartmentalization in water distribution networks, and how does it differ from skeletonization?, Actual answer: Compartmentalization divides a large network into smaller, independently managed sectors (e.g., District Metered Areas). Unlike skeletonization, which reduces model size, compartmentalization focuses on operational management and leak detection by segmenting networks while keeping the full pipe infrastructure intact., Predicted answer: In the context of water distribution networks, compartmentalization and skeletonization are two distinct concepts used to analyze, design, and manage water supply systems.\n",
            "\n",
            "**Compartmentalization:**\n",
            "\n",
            "Compartmentalization refers to the process of dividing a large water distribution network into smaller, isolated sections or compartments. Each compartment is a self-contained system that can operate independently, with its own set of pipes, pumps, and valves. The goal of compartmentalization is to:\n",
            "\n",
            "1. Reduce the impact of failures or contamination in one compartment from affecting other parts of the network.\n",
            "2. Simplify the analysis and management of the network by breaking it down into smaller, more manageable sections.\n",
            "3. Improve the overall resilience and reliability of the water supply system.\n",
            "\n",
            "In a compartmentalized network, each compartment typically has its own:\n",
            "\n",
            "* Separate pipe network\n",
            "* Pumps and pumping stations\n",
            "* Valves and control systems\n",
            "* Water treatment and storage facilities (if applicable)\n",
            "\n",
            "**Skeletonization:**\n",
            "\n",
            "Skeletonization, on the other hand, refers to the process of identifying the most critical components of a water distribution network, such as the main pipes, pumps, and valves. These critical components are often referred to as the \"skeleton\" of the network. The goal of skeletonization is to:\n",
            "\n",
            "1. Identify the most critical elements of the network that are essential for maintaining water supply.\n",
            "2. Prioritize maintenance, repair, and replacement activities on these critical components.\n",
            "3. Simplify the analysis and management of the network by focusing on the most critical elements.\n",
            "\n",
            "In a skeletonized network, the focus is on the main pipes, pumps, and valves that are essential for maintaining water supply, rather than the entire network.\n",
            "\n",
            "**Key differences:**\n",
            "\n",
            "The main differences between compartmentalization and skeletonization are:\n",
            "\n",
            "1. **Scope:** Compartmentalization involves dividing the entire network into smaller sections, while skeletonization focuses on identifying the most critical components of the network.\n",
            "2. **Purpose:** Compartmentalization aims to reduce the impact of failures and simplify network management, while skeletonization prioritizes maintenance and repair activities on critical components.\n",
            "3. **Approach:** Compartmentalization involves a more detailed analysis of the network, while skeletonization requires a more high-level understanding of the network's critical components.\n",
            "\n",
            "In summary, compartmentalization is a more comprehensive approach that involves dividing the network into smaller sections, while skeletonization is a more focused approach that identifies the most critical components of the network.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and relevance of the information provided in both responses. \n",
            "\n",
            "The actual answer succinctly defines compartmentalization as the division of a water distribution network into smaller, independently managed sectors, emphasizing its operational management and leak detection benefits. It contrasts this with skeletonization, which is described as a method for reducing model size rather than focusing on operational management.\n",
            "\n",
            "The predicted answer provides a detailed explanation of both compartmentalization and skeletonization, outlining their definitions, goals, and key differences. It accurately describes compartmentalization as dividing the network into isolated sections and highlights its benefits, such as improving resilience and simplifying management. It also correctly defines skeletonization as identifying critical components of the network.\n",
            "\n",
            "However, the predicted answer introduces some additional details that are not present in the actual answer, such as the mention of separate pipe networks and water treatment facilities within each compartment. While these details may be relevant, they could be seen as extraneous to the core definition and purpose of compartmentalization as described in the actual answer.\n",
            "\n",
            "Overall, the predicted answer contains mostly factual information with some additional elaboration that does not significantly alter the key points. It does not contain any major inaccuracies or hallucinations, but it does diverge slightly from the concise nature of the actual answer.\n",
            "\n",
            "Given this analysis, I would assign a score of 4 to the predicted answer, as it includes mostly factual information with slight deviations in detail.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: What is compartmentalization in water distribution networks, and how does it differ from skeletonization?, Actual answer: Compartmentalization divides a large network into smaller, independently managed sectors (e.g., District Metered Areas). Unlike skeletonization, which reduces model size, compartmentalization focuses on operational management and leak detection by segmenting networks while keeping the full pipe infrastructure intact., Predicted answer: In the context of water distribution networks, compartmentalization and skeletonization are two distinct concepts used to analyze, design, and manage water supply systems.\n",
            "\n",
            "**Compartmentalization:**\n",
            "\n",
            "Compartmentalization refers to the process of dividing a large water distribution network into smaller, isolated sections or compartments. Each compartment is a self-contained system that can operate independently, with its own set of pipes, pumps, and valves. The goal of compartmentalization is to:\n",
            "\n",
            "1. Reduce the impact of failures or contamination in one compartment from affecting other parts of the network.\n",
            "2. Simplify the analysis and management of the network by breaking it down into smaller, more manageable sections.\n",
            "3. Improve the overall resilience and reliability of the water supply system.\n",
            "\n",
            "In a compartmentalized network, each compartment typically has its own:\n",
            "\n",
            "* Separate pipe network\n",
            "* Pumps and pumping stations\n",
            "* Valves and control systems\n",
            "* Water treatment and storage facilities (if applicable)\n",
            "\n",
            "**Skeletonization:**\n",
            "\n",
            "Skeletonization, on the other hand, refers to the process of identifying the most critical components of a water distribution network, such as the main pipes, pumps, and valves. These critical components are often referred to as the \"skeleton\" of the network. The goal of skeletonization is to:\n",
            "\n",
            "1. Identify the most critical elements of the network that are essential for maintaining water supply.\n",
            "2. Prioritize maintenance, repair, and replacement activities on these critical components.\n",
            "3. Simplify the analysis and management of the network by focusing on the most critical elements.\n",
            "\n",
            "In a skeletonized network, the focus is on the main pipes, pumps, and valves that are essential for maintaining water supply, rather than the entire network.\n",
            "\n",
            "**Key differences:**\n",
            "\n",
            "The main differences between compartmentalization and skeletonization are:\n",
            "\n",
            "1. **Scope:** Compartmentalization involves dividing the entire network into smaller sections, while skeletonization focuses on identifying the most critical components of the network.\n",
            "2. **Purpose:** Compartmentalization aims to reduce the impact of failures and simplify network management, while skeletonization prioritizes maintenance and repair activities on critical components.\n",
            "3. **Approach:** Compartmentalization involves a more detailed analysis of the network, while skeletonization requires a more high-level understanding of the network's critical components.\n",
            "\n",
            "In summary, compartmentalization is a more comprehensive approach that involves dividing the network into smaller sections, while skeletonization is a more focused approach that identifies the most critical components of the network.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and clarity of the information presented. The actual answer succinctly defines compartmentalization and skeletonization, highlighting their purposes and differences in the context of water distribution networks. It emphasizes that compartmentalization is about operational management and leak detection, while skeletonization is about reducing model size.\n",
            "\n",
            "The predicted answer provides a detailed explanation of both concepts, outlining the goals and components of compartmentalization and skeletonization. It correctly identifies the key differences between the two approaches, including their scope, purpose, and analytical approach. However, it does not explicitly mention the operational management aspect of compartmentalization or the focus on leak detection, which are critical points in the actual answer.\n",
            "\n",
            "While the predicted answer is informative and mostly accurate, it lacks some specific details that are crucial for a complete understanding of compartmentalization. It does not misinterpret the information but rather expands on it, which could lead to some confusion regarding the primary focus of compartmentalization.\n",
            "\n",
            "Given these considerations, the predicted answer is mostly correct but lacks some essential details that would make it fully aligned with the actual answer. Therefore, it shows a good understanding of the concepts but does not fully capture the nuances of compartmentalization.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4, 'judgement_descr': 4}\n",
            "\n",
            "\n",
            "No output from LLM\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5it [03:09, 32.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : Excessive skeletonization in water distribution networks refers to the removal of too many hydrants, valves, and other appurtenances, which can lead to several potential risks. Some of these risks include:\n",
            "\n",
            "1. **Difficulty in Locating Leaks**: With fewer hydrants and valves, it becomes more challenging to locate leaks in the distribution system. This can lead to extended periods of undetected leaks, resulting in wasted water, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "2. **Reduced Fire Protection**: Excessive skeletonization can compromise the fire protection capabilities of the water distribution network. With fewer hydrants and valves, firefighters may struggle to access the necessary water supply to combat fires, potentially leading to property damage and loss of life.\n",
            "\n",
            "3. **Increased Risk of Main Breaks**: When hydrants and valves are removed, it can be more difficult to detect and respond to main breaks. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "4. **Difficulty in Maintaining System Pressure**: Excessive skeletonization can disrupt the hydraulic balance of the distribution system, leading to reduced system pressure. This can result in decreased water flow rates, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "5. **Reduced System Resiliency**: Excessive skeletonization can reduce the overall resiliency of the water distribution network, making it more vulnerable to disruptions and failures. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "6. **Increased Risk of Contamination**: Excessive skeletonization can increase the risk of contamination in the water distribution network. With fewer hydrants and valves, it can be more difficult to detect and respond to contamination events, potentially leading to health risks for consumers.\n",
            "\n",
            "7. **Difficulty in Conducting Maintenance and Rehabilitation**: Excessive skeletonization can make it more challenging to conduct maintenance and rehabilitation activities in the water distribution network. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "In summary, excessive skeletonization in water distribution networks can lead to a range of potential risks, including difficulty in locating leaks, reduced fire protection, increased risk of main breaks, difficulty in maintaining system pressure, reduced system resiliency, increased risk of contamination, and difficulty in conducting maintenance and rehabilitation activities.\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: Why do modern computing advancements reduce the need for skeletonization?, Actual answer: High-performance computing, parallel processing, and GPU acceleration enable larger models to be processed more efficiently. This allows utilities to use full-scale models without excessive reduction, maintaining accuracy while benefiting from enhanced computational speed., Predicted answer: In the context of computational fluid dynamics (CFD) and water engineering, skeletonization is a technique used to create a simplified representation of a complex geometry, such as a pipe network or a river system. This is typically done to reduce the computational complexity and improve the efficiency of numerical simulations.\n",
            "\n",
            "Modern computing advancements have significantly reduced the need for skeletonization in several ways:\n",
            "\n",
            "1. **Increased computational power**: With the advent of high-performance computing (HPC) and graphics processing units (GPUs), computational power has increased exponentially. This allows for faster and more accurate simulations of complex geometries without the need for simplification.\n",
            "2. **Advances in numerical methods**: New numerical methods, such as lattice Boltzmann methods (LBM) and smoothed particle hydrodynamics (SPH), have been developed to handle complex geometries and large datasets. These methods are more efficient and accurate than traditional methods, reducing the need for skeletonization.\n",
            "3. **Improved mesh generation**: Mesh generation algorithms have become more sophisticated, allowing for the creation of high-quality meshes that can accurately represent complex geometries. This reduces the need for skeletonization, as the mesh can be generated directly from the original geometry.\n",
            "4. **Increased memory and storage**: Advances in memory and storage technology have made it possible to store and process large datasets, reducing the need for simplification and skeletonization.\n",
            "5. **Parallel computing**: Modern computing architectures, such as multi-core processors and distributed computing systems, enable parallel computing, which can significantly speed up simulations and reduce the need for skeletonization.\n",
            "\n",
            "As a result, modern computing advancements have made it possible to simulate complex water engineering systems, such as pipe networks and river systems, with high accuracy and efficiency, reducing the need for skeletonization. However, skeletonization may still be useful in certain situations, such as when dealing with extremely complex geometries or when computational resources are limited.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the completeness of the response in addressing the question about why modern computing advancements reduce the need for skeletonization.\n",
            "\n",
            "The actual answer succinctly identifies key advancements—high-performance computing, parallel processing, and GPU acceleration—that allow for the processing of larger models without excessive reduction, thus maintaining accuracy and enhancing computational speed. It is direct and focused on the implications of these advancements.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, covers several relevant points, including increased computational power, advances in numerical methods, improved mesh generation, increased memory and storage, and parallel computing. Each of these points contributes to the overall understanding of how modern computing reduces the need for skeletonization. Additionally, it acknowledges that skeletonization may still have its uses in specific scenarios, which adds depth to the response.\n",
            "\n",
            "However, the predicted answer could be seen as slightly more verbose than necessary, and while it covers many aspects, it does not explicitly mention the direct benefits of maintaining accuracy and computational speed as clearly as the actual answer does. \n",
            "\n",
            "Overall, the predicted answer includes most elements of a complete answer, but it could be more concise and focused on the specific advancements mentioned in the actual answer.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: Why do modern computing advancements reduce the need for skeletonization?, Actual answer: High-performance computing, parallel processing, and GPU acceleration enable larger models to be processed more efficiently. This allows utilities to use full-scale models without excessive reduction, maintaining accuracy while benefiting from enhanced computational speed., Predicted answer: In the context of computational fluid dynamics (CFD) and water engineering, skeletonization is a technique used to create a simplified representation of a complex geometry, such as a pipe network or a river system. This is typically done to reduce the computational complexity and improve the efficiency of numerical simulations.\n",
            "\n",
            "Modern computing advancements have significantly reduced the need for skeletonization in several ways:\n",
            "\n",
            "1. **Increased computational power**: With the advent of high-performance computing (HPC) and graphics processing units (GPUs), computational power has increased exponentially. This allows for faster and more accurate simulations of complex geometries without the need for simplification.\n",
            "2. **Advances in numerical methods**: New numerical methods, such as lattice Boltzmann methods (LBM) and smoothed particle hydrodynamics (SPH), have been developed to handle complex geometries and large datasets. These methods are more efficient and accurate than traditional methods, reducing the need for skeletonization.\n",
            "3. **Improved mesh generation**: Mesh generation algorithms have become more sophisticated, allowing for the creation of high-quality meshes that can accurately represent complex geometries. This reduces the need for skeletonization, as the mesh can be generated directly from the original geometry.\n",
            "4. **Increased memory and storage**: Advances in memory and storage technology have made it possible to store and process large datasets, reducing the need for simplification and skeletonization.\n",
            "5. **Parallel computing**: Modern computing architectures, such as multi-core processors and distributed computing systems, enable parallel computing, which can significantly speed up simulations and reduce the need for skeletonization.\n",
            "\n",
            "As a result, modern computing advancements have made it possible to simulate complex water engineering systems, such as pipe networks and river systems, with high accuracy and efficiency, reducing the need for skeletonization. However, skeletonization may still be useful in certain situations, such as when dealing with extremely complex geometries or when computational resources are limited.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we first need to identify the core elements of the user's question, which is focused on understanding how modern computing advancements reduce the need for skeletonization. The actual answer succinctly addresses this by highlighting high-performance computing, parallel processing, and GPU acceleration as key factors that allow for the use of full-scale models without excessive reduction, thus maintaining accuracy and enhancing computational speed.\n",
            "\n",
            "The predicted answer, while lengthy, does provide a comprehensive overview of how modern computing advancements impact the need for skeletonization. It discusses increased computational power, advances in numerical methods, improved mesh generation, increased memory and storage, and parallel computing. Each of these points is relevant to the question, as they all contribute to the reduction of the need for skeletonization in computational fluid dynamics and water engineering.\n",
            "\n",
            "However, the predicted answer includes some extraneous details, such as specific numerical methods (LBM and SPH) and the mention of mesh generation algorithms, which, while relevant, may not be necessary for a general understanding of the topic. Additionally, the final note about skeletonization still being useful in certain situations introduces a slight deviation from the main focus of the question.\n",
            "\n",
            "Overall, the predicted answer does answer the user's question and provides relevant information, but it contains more detail than necessary, leading to some irrelevant information. Therefore, I would rate the predicted answer as follows:\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: Why do modern computing advancements reduce the need for skeletonization?, Actual answer: High-performance computing, parallel processing, and GPU acceleration enable larger models to be processed more efficiently. This allows utilities to use full-scale models without excessive reduction, maintaining accuracy while benefiting from enhanced computational speed., Predicted answer: In the context of computational fluid dynamics (CFD) and water engineering, skeletonization is a technique used to create a simplified representation of a complex geometry, such as a pipe network or a river system. This is typically done to reduce the computational complexity and improve the efficiency of numerical simulations.\n",
            "\n",
            "Modern computing advancements have significantly reduced the need for skeletonization in several ways:\n",
            "\n",
            "1. **Increased computational power**: With the advent of high-performance computing (HPC) and graphics processing units (GPUs), computational power has increased exponentially. This allows for faster and more accurate simulations of complex geometries without the need for simplification.\n",
            "2. **Advances in numerical methods**: New numerical methods, such as lattice Boltzmann methods (LBM) and smoothed particle hydrodynamics (SPH), have been developed to handle complex geometries and large datasets. These methods are more efficient and accurate than traditional methods, reducing the need for skeletonization.\n",
            "3. **Improved mesh generation**: Mesh generation algorithms have become more sophisticated, allowing for the creation of high-quality meshes that can accurately represent complex geometries. This reduces the need for skeletonization, as the mesh can be generated directly from the original geometry.\n",
            "4. **Increased memory and storage**: Advances in memory and storage technology have made it possible to store and process large datasets, reducing the need for simplification and skeletonization.\n",
            "5. **Parallel computing**: Modern computing architectures, such as multi-core processors and distributed computing systems, enable parallel computing, which can significantly speed up simulations and reduce the need for skeletonization.\n",
            "\n",
            "As a result, modern computing advancements have made it possible to simulate complex water engineering systems, such as pipe networks and river systems, with high accuracy and efficiency, reducing the need for skeletonization. However, skeletonization may still be useful in certain situations, such as when dealing with extremely complex geometries or when computational resources are limited.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we first need to analyze both responses in terms of their relevance to the question and the amount of extraneous information included.\n",
            "\n",
            "The actual answer is direct and succinct, focusing on the key points: high-performance computing, parallel processing, and GPU acceleration, which allow for the use of full-scale models without excessive reduction. It maintains a clear focus on the benefits of modern computing advancements in relation to the need for skeletonization.\n",
            "\n",
            "In contrast, the predicted answer provides a detailed explanation of skeletonization and its context within computational fluid dynamics (CFD) and water engineering. While it does address the question, it includes a significant amount of extra information about the techniques and advancements in computing, such as numerical methods, mesh generation, and parallel computing. This additional detail, while informative, diverges from the core of the question and makes the response longer than necessary.\n",
            "\n",
            "Given this analysis, the predicted answer includes a lot of extra information and uses flowery language, which detracts from its conciseness. Therefore, it does not meet the standard of being as short as possible while still answering the prompt.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: Why do modern computing advancements reduce the need for skeletonization?, Actual answer: High-performance computing, parallel processing, and GPU acceleration enable larger models to be processed more efficiently. This allows utilities to use full-scale models without excessive reduction, maintaining accuracy while benefiting from enhanced computational speed., Predicted answer: In the context of computational fluid dynamics (CFD) and water engineering, skeletonization is a technique used to create a simplified representation of a complex geometry, such as a pipe network or a river system. This is typically done to reduce the computational complexity and improve the efficiency of numerical simulations.\n",
            "\n",
            "Modern computing advancements have significantly reduced the need for skeletonization in several ways:\n",
            "\n",
            "1. **Increased computational power**: With the advent of high-performance computing (HPC) and graphics processing units (GPUs), computational power has increased exponentially. This allows for faster and more accurate simulations of complex geometries without the need for simplification.\n",
            "2. **Advances in numerical methods**: New numerical methods, such as lattice Boltzmann methods (LBM) and smoothed particle hydrodynamics (SPH), have been developed to handle complex geometries and large datasets. These methods are more efficient and accurate than traditional methods, reducing the need for skeletonization.\n",
            "3. **Improved mesh generation**: Mesh generation algorithms have become more sophisticated, allowing for the creation of high-quality meshes that can accurately represent complex geometries. This reduces the need for skeletonization, as the mesh can be generated directly from the original geometry.\n",
            "4. **Increased memory and storage**: Advances in memory and storage technology have made it possible to store and process large datasets, reducing the need for simplification and skeletonization.\n",
            "5. **Parallel computing**: Modern computing architectures, such as multi-core processors and distributed computing systems, enable parallel computing, which can significantly speed up simulations and reduce the need for skeletonization.\n",
            "\n",
            "As a result, modern computing advancements have made it possible to simulate complex water engineering systems, such as pipe networks and river systems, with high accuracy and efficiency, reducing the need for skeletonization. However, skeletonization may still be useful in certain situations, such as when dealing with extremely complex geometries or when computational resources are limited.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the confidence conveyed in both responses regarding the reduction of skeletonization due to modern computing advancements. \n",
            "\n",
            "The actual answer succinctly highlights the key points: high-performance computing, parallel processing, and GPU acceleration allow for the use of full-scale models, maintaining accuracy while improving computational speed. It is direct and focused on the implications of these advancements.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, provides a comprehensive overview of how modern computing advancements impact the need for skeletonization. It discusses increased computational power, advances in numerical methods, improved mesh generation, increased memory and storage, and parallel computing. However, it also introduces some complexity and additional information that may dilute the main point. The conclusion acknowledges that skeletonization may still be useful in certain situations, which introduces a slight uncertainty about the overall assertion.\n",
            "\n",
            "In terms of confidence, the predicted answer does convey a strong understanding of the topic and aligns well with the actual answer's main points. However, the additional details and the caveat about the continued relevance of skeletonization introduce a level of uncertainty that is not present in the actual answer.\n",
            "\n",
            "Given this analysis, I would assign a score of 4 to the predicted answer, as it leans towards agreement with the actual answer but acknowledges some uncertainty.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : Preserving demand distribution when removing minor dead-end pipes is crucial in water distribution systems for several reasons:\n",
            "\n",
            "1. **System Reliability**: Minor dead-end pipes often serve low-demand areas, such as single-family homes or small businesses. When these pipes are removed, the remaining pipes in the system may not be able to handle the increased demand, leading to reduced system reliability and potential water shortages.\n",
            "\n",
            "2. **Pressure Management**: Removing minor dead-end pipes can alter the pressure distribution in the system, potentially causing low pressures in areas that were previously served by these pipes. This can lead to reduced water quality, increased risk of contamination, and decreased system performance.\n",
            "\n",
            "3. **Flow Distribution**: Minor dead-end pipes help to distribute flow throughout the system, particularly in areas with low demand. When these pipes are removed, the flow may become concentrated in other areas, leading to overflows, increased energy consumption, and reduced system efficiency.\n",
            "\n",
            "4. **Water Quality**: Preserving demand distribution helps to maintain a consistent water quality throughout the system. When minor dead-end pipes are removed, the remaining pipes may not be able to handle the increased demand, leading to reduced water quality and increased risk of contamination.\n",
            "\n",
            "5. **Energy Efficiency**: Removing minor dead-end pipes can lead to increased energy consumption, as pumps and other equipment may need to work harder to meet the increased demand. Preserving demand distribution helps to maintain a balanced system, reducing energy consumption and costs.\n",
            "\n",
            "6. **Asset Management**: Preserving demand distribution helps to extend the life of system assets, such as pipes, pumps, and valves. By maintaining a balanced system, the risk of premature failure and costly repairs is reduced.\n",
            "\n",
            "To preserve demand distribution when removing minor dead-end pipes, water utilities can use various techniques, such as:\n",
            "\n",
            "1. **Pipe sizing**: Ensuring that the remaining pipes are sized correctly to handle the increased demand.\n",
            "2. **Pressure management**: Implementing pressure management strategies, such as pressure-reducing valves, to maintain a consistent pressure throughout the system.\n",
            "3. **Flow distribution**: Implementing flow distribution strategies, such as flow control valves, to maintain a balanced flow throughout the system.\n",
            "4. **System modeling**: Using system modeling tools to simulate the impact of removing minor dead-end pipes and identify potential issues before they occur.\n",
            "\n",
            "By preserving demand distribution when removing minor dead-end pipes, water utilities can maintain a reliable, efficient, and safe water distribution system that meets the needs of their customers.\n",
            "\u001b[32mUser message:Question: Why do modern computing advancements reduce the need for skeletonization?, Actual answer: High-performance computing, parallel processing, and GPU acceleration enable larger models to be processed more efficiently. This allows utilities to use full-scale models without excessive reduction, maintaining accuracy while benefiting from enhanced computational speed., Predicted answer: In the context of computational fluid dynamics (CFD) and water engineering, skeletonization is a technique used to create a simplified representation of a complex geometry, such as a pipe network or a river system. This is typically done to reduce the computational complexity and improve the efficiency of numerical simulations.\n",
            "\n",
            "Modern computing advancements have significantly reduced the need for skeletonization in several ways:\n",
            "\n",
            "1. **Increased computational power**: With the advent of high-performance computing (HPC) and graphics processing units (GPUs), computational power has increased exponentially. This allows for faster and more accurate simulations of complex geometries without the need for simplification.\n",
            "2. **Advances in numerical methods**: New numerical methods, such as lattice Boltzmann methods (LBM) and smoothed particle hydrodynamics (SPH), have been developed to handle complex geometries and large datasets. These methods are more efficient and accurate than traditional methods, reducing the need for skeletonization.\n",
            "3. **Improved mesh generation**: Mesh generation algorithms have become more sophisticated, allowing for the creation of high-quality meshes that can accurately represent complex geometries. This reduces the need for skeletonization, as the mesh can be generated directly from the original geometry.\n",
            "4. **Increased memory and storage**: Advances in memory and storage technology have made it possible to store and process large datasets, reducing the need for simplification and skeletonization.\n",
            "5. **Parallel computing**: Modern computing architectures, such as multi-core processors and distributed computing systems, enable parallel computing, which can significantly speed up simulations and reduce the need for skeletonization.\n",
            "\n",
            "As a result, modern computing advancements have made it possible to simulate complex water engineering systems, such as pipe networks and river systems, with high accuracy and efficiency, reducing the need for skeletonization. However, skeletonization may still be useful in certain situations, such as when dealing with extremely complex geometries or when computational resources are limited.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the factual accuracy and relevance of the information presented in both responses. \n",
            "\n",
            "The actual answer succinctly highlights the key advancements in computing—high-performance computing, parallel processing, and GPU acceleration—that allow for the use of full-scale models without excessive simplification, thus maintaining accuracy and improving computational speed. \n",
            "\n",
            "The predicted answer, while lengthy and detailed, does provide a comprehensive overview of how modern computing advancements reduce the need for skeletonization. It correctly identifies increased computational power, advances in numerical methods, improved mesh generation, increased memory and storage, and parallel computing as factors contributing to this reduction. Each point is relevant and factual, aligning well with the context of the question.\n",
            "\n",
            "However, the predicted answer introduces some additional details that, while informative, may not be strictly necessary to address the question directly. For instance, the mention of specific numerical methods like lattice Boltzmann methods and smoothed particle hydrodynamics, while accurate, may not be essential to the core argument about the reduction of skeletonization needs.\n",
            "\n",
            "Overall, the predicted answer contains mostly factual information with slight deviations in focus and detail compared to the actual answer. It does not contain hallucinations or misinformation, but it could be seen as slightly verbose.\n",
            "\n",
            "Given this analysis, I would assign a score of 4 to the predicted answer, as it includes mostly factual information with slight deviations in focus.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: Why do modern computing advancements reduce the need for skeletonization?, Actual answer: High-performance computing, parallel processing, and GPU acceleration enable larger models to be processed more efficiently. This allows utilities to use full-scale models without excessive reduction, maintaining accuracy while benefiting from enhanced computational speed., Predicted answer: In the context of computational fluid dynamics (CFD) and water engineering, skeletonization is a technique used to create a simplified representation of a complex geometry, such as a pipe network or a river system. This is typically done to reduce the computational complexity and improve the efficiency of numerical simulations.\n",
            "\n",
            "Modern computing advancements have significantly reduced the need for skeletonization in several ways:\n",
            "\n",
            "1. **Increased computational power**: With the advent of high-performance computing (HPC) and graphics processing units (GPUs), computational power has increased exponentially. This allows for faster and more accurate simulations of complex geometries without the need for simplification.\n",
            "2. **Advances in numerical methods**: New numerical methods, such as lattice Boltzmann methods (LBM) and smoothed particle hydrodynamics (SPH), have been developed to handle complex geometries and large datasets. These methods are more efficient and accurate than traditional methods, reducing the need for skeletonization.\n",
            "3. **Improved mesh generation**: Mesh generation algorithms have become more sophisticated, allowing for the creation of high-quality meshes that can accurately represent complex geometries. This reduces the need for skeletonization, as the mesh can be generated directly from the original geometry.\n",
            "4. **Increased memory and storage**: Advances in memory and storage technology have made it possible to store and process large datasets, reducing the need for simplification and skeletonization.\n",
            "5. **Parallel computing**: Modern computing architectures, such as multi-core processors and distributed computing systems, enable parallel computing, which can significantly speed up simulations and reduce the need for skeletonization.\n",
            "\n",
            "As a result, modern computing advancements have made it possible to simulate complex water engineering systems, such as pipe networks and river systems, with high accuracy and efficiency, reducing the need for skeletonization. However, skeletonization may still be useful in certain situations, such as when dealing with extremely complex geometries or when computational resources are limited.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and relevance of the information provided in both responses. The actual answer succinctly highlights the key advancements in computing that allow for the use of full-scale models without excessive reduction, emphasizing high-performance computing, parallel processing, and GPU acceleration.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, does provide a comprehensive overview of how modern computing advancements reduce the need for skeletonization. It correctly identifies increased computational power, advances in numerical methods, improved mesh generation, increased memory and storage, and parallel computing as factors contributing to this reduction. However, it does not explicitly mention the importance of maintaining accuracy and computational speed, which are central to the actual answer.\n",
            "\n",
            "Moreover, the predicted answer introduces some concepts (like LBM and SPH) that, while relevant, may not be necessary for the context of the question, potentially leading to a slight misalignment with the core focus of the actual answer. The predicted response does not misinterpret the information but rather expands on it, which could lead to some confusion regarding the main point.\n",
            "\n",
            "Given these considerations, the predicted answer is mostly correct and provides valuable insights, but it lacks the conciseness and directness of the actual answer. It does not confidently claim any hallucination as truth, nor does it misinterpret the prompt. Therefore, it falls into the category of being correct but somewhat verbose and less focused.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4, 'judgement_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: How does skeletonization impact transient (surge) analysis in hydraulic models?, Actual answer: Transient analysis requires detailed representations of small pipes since they influence pressure wave propagation. Removing these elements in skeletonized models can alter results, underestimating or misrepresenting transient pressures, leading to inadequate surge protection measures., Predicted answer: Skeletonization is a technique used in hydraulic modeling, particularly in computational fluid dynamics (CFD) and one-dimensional (1D) modeling, to reduce the complexity of a model by removing or simplifying certain elements. In the context of transient (surge) analysis, skeletonization can have both positive and negative impacts.\n",
            "\n",
            "**Positive impacts:**\n",
            "\n",
            "1. **Reduced computational time**: By removing or simplifying certain elements, skeletonization can significantly reduce the computational time required for transient analysis. This is particularly beneficial for large-scale models or models with complex geometries.\n",
            "2. **Improved model stability**: Skeletonization can help stabilize the model by removing elements that may cause numerical instability or oscillations during transient analysis.\n",
            "3. **Enhanced model interpretability**: By simplifying the model, skeletonization can make it easier to understand and interpret the results of transient analysis.\n",
            "\n",
            "**Negative impacts:**\n",
            "\n",
            "1. **Loss of accuracy**: Skeletonization can lead to a loss of accuracy in the results of transient analysis, particularly if the removed or simplified elements are critical to the behavior of the system.\n",
            "2. **Over-simplification**: If skeletonization is not done carefully, it can lead to over-simplification of the model, which can result in inaccurate or misleading results.\n",
            "3. **Inability to capture local effects**: Skeletonization can make it difficult to capture local effects, such as pressure surges or water hammer, which are critical to understanding the behavior of the system during transient analysis.\n",
            "\n",
            "**Best practices for skeletonization in transient analysis:**\n",
            "\n",
            "1. **Carefully select the elements to be removed or simplified**: Only remove or simplify elements that are not critical to the behavior of the system during transient analysis.\n",
            "2. **Use sensitivity analysis**: Perform sensitivity analysis to determine the impact of skeletonization on the results of transient analysis.\n",
            "3. **Validate the results**: Validate the results of transient analysis using field data or other independent methods to ensure that the skeletonized model accurately represents the behavior of the system.\n",
            "\n",
            "In summary, skeletonization can be a useful technique for reducing the complexity of hydraulic models and improving computational efficiency during transient analysis. However, it requires careful application and validation to ensure that the results accurately represent the behavior of the system.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the completeness of the predicted answer compared to the actual answer, we need to analyze the key elements present in both responses.\n",
            "\n",
            "The actual answer focuses specifically on how skeletonization affects transient analysis in hydraulic models, emphasizing the importance of small pipes in pressure wave propagation and the potential consequences of their removal. It succinctly states that removing these elements can lead to underestimating or misrepresenting transient pressures, which can compromise surge protection measures.\n",
            "\n",
            "The predicted answer, while providing a comprehensive overview of skeletonization, discusses both positive and negative impacts, as well as best practices. It covers aspects such as computational efficiency, model stability, and interpretability, but it does not directly address the specific consequences of removing small pipes on transient pressure propagation or surge protection measures. The predicted answer is more general and does not fully capture the critical points made in the actual answer regarding the specific impacts on transient analysis.\n",
            "\n",
            "In terms of completeness:\n",
            "- The predicted answer includes several relevant points about skeletonization but lacks the specific focus on transient analysis and the implications of removing small pipes that are central to the actual answer.\n",
            "- It does mention loss of accuracy and inability to capture local effects, which are relevant, but it does not tie these back to the specific context of transient pressures and surge protection.\n",
            "\n",
            "Given this analysis, the predicted answer contains some relevant elements but misses key aspects that would make it a complete response to the question.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: How does skeletonization impact transient (surge) analysis in hydraulic models?, Actual answer: Transient analysis requires detailed representations of small pipes since they influence pressure wave propagation. Removing these elements in skeletonized models can alter results, underestimating or misrepresenting transient pressures, leading to inadequate surge protection measures., Predicted answer: Skeletonization is a technique used in hydraulic modeling, particularly in computational fluid dynamics (CFD) and one-dimensional (1D) modeling, to reduce the complexity of a model by removing or simplifying certain elements. In the context of transient (surge) analysis, skeletonization can have both positive and negative impacts.\n",
            "\n",
            "**Positive impacts:**\n",
            "\n",
            "1. **Reduced computational time**: By removing or simplifying certain elements, skeletonization can significantly reduce the computational time required for transient analysis. This is particularly beneficial for large-scale models or models with complex geometries.\n",
            "2. **Improved model stability**: Skeletonization can help stabilize the model by removing elements that may cause numerical instability or oscillations during transient analysis.\n",
            "3. **Enhanced model interpretability**: By simplifying the model, skeletonization can make it easier to understand and interpret the results of transient analysis.\n",
            "\n",
            "**Negative impacts:**\n",
            "\n",
            "1. **Loss of accuracy**: Skeletonization can lead to a loss of accuracy in the results of transient analysis, particularly if the removed or simplified elements are critical to the behavior of the system.\n",
            "2. **Over-simplification**: If skeletonization is not done carefully, it can lead to over-simplification of the model, which can result in inaccurate or misleading results.\n",
            "3. **Inability to capture local effects**: Skeletonization can make it difficult to capture local effects, such as pressure surges or water hammer, which are critical to understanding the behavior of the system during transient analysis.\n",
            "\n",
            "**Best practices for skeletonization in transient analysis:**\n",
            "\n",
            "1. **Carefully select the elements to be removed or simplified**: Only remove or simplify elements that are not critical to the behavior of the system during transient analysis.\n",
            "2. **Use sensitivity analysis**: Perform sensitivity analysis to determine the impact of skeletonization on the results of transient analysis.\n",
            "3. **Validate the results**: Validate the results of transient analysis using field data or other independent methods to ensure that the skeletonized model accurately represents the behavior of the system.\n",
            "\n",
            "In summary, skeletonization can be a useful technique for reducing the complexity of hydraulic models and improving computational efficiency during transient analysis. However, it requires careful application and validation to ensure that the results accurately represent the behavior of the system.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about the impact of skeletonization on transient (surge) analysis in hydraulic models. \n",
            "\n",
            "The actual answer succinctly highlights the critical aspects of how skeletonization affects transient analysis, specifically mentioning the importance of small pipes in pressure wave propagation and the potential consequences of their removal. It emphasizes the risks of underestimating or misrepresenting transient pressures, which can lead to inadequate surge protection measures.\n",
            "\n",
            "In contrast, the predicted answer provides a broader discussion on skeletonization, including its definition, positive and negative impacts, and best practices. While it does touch on relevant points, such as loss of accuracy and the inability to capture local effects, it also includes a significant amount of information that, while related, does not directly answer the specific question about transient analysis. The focus on computational efficiency and model stability, while relevant to the broader context of hydraulic modeling, detracts from the core issue of how skeletonization specifically impacts transient analysis.\n",
            "\n",
            "Given this analysis, the predicted answer does answer the user's question but contains more irrelevant information than relevant information, particularly in its extensive discussion of positive impacts and best practices that are not directly tied to the transient analysis context.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: How does skeletonization impact transient (surge) analysis in hydraulic models?, Actual answer: Transient analysis requires detailed representations of small pipes since they influence pressure wave propagation. Removing these elements in skeletonized models can alter results, underestimating or misrepresenting transient pressures, leading to inadequate surge protection measures., Predicted answer: Skeletonization is a technique used in hydraulic modeling, particularly in computational fluid dynamics (CFD) and one-dimensional (1D) modeling, to reduce the complexity of a model by removing or simplifying certain elements. In the context of transient (surge) analysis, skeletonization can have both positive and negative impacts.\n",
            "\n",
            "**Positive impacts:**\n",
            "\n",
            "1. **Reduced computational time**: By removing or simplifying certain elements, skeletonization can significantly reduce the computational time required for transient analysis. This is particularly beneficial for large-scale models or models with complex geometries.\n",
            "2. **Improved model stability**: Skeletonization can help stabilize the model by removing elements that may cause numerical instability or oscillations during transient analysis.\n",
            "3. **Enhanced model interpretability**: By simplifying the model, skeletonization can make it easier to understand and interpret the results of transient analysis.\n",
            "\n",
            "**Negative impacts:**\n",
            "\n",
            "1. **Loss of accuracy**: Skeletonization can lead to a loss of accuracy in the results of transient analysis, particularly if the removed or simplified elements are critical to the behavior of the system.\n",
            "2. **Over-simplification**: If skeletonization is not done carefully, it can lead to over-simplification of the model, which can result in inaccurate or misleading results.\n",
            "3. **Inability to capture local effects**: Skeletonization can make it difficult to capture local effects, such as pressure surges or water hammer, which are critical to understanding the behavior of the system during transient analysis.\n",
            "\n",
            "**Best practices for skeletonization in transient analysis:**\n",
            "\n",
            "1. **Carefully select the elements to be removed or simplified**: Only remove or simplify elements that are not critical to the behavior of the system during transient analysis.\n",
            "2. **Use sensitivity analysis**: Perform sensitivity analysis to determine the impact of skeletonization on the results of transient analysis.\n",
            "3. **Validate the results**: Validate the results of transient analysis using field data or other independent methods to ensure that the skeletonized model accurately represents the behavior of the system.\n",
            "\n",
            "In summary, skeletonization can be a useful technique for reducing the complexity of hydraulic models and improving computational efficiency during transient analysis. However, it requires careful application and validation to ensure that the results accurately represent the behavior of the system.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information provided in the predicted response. The actual answer is direct and focused on the impact of skeletonization on transient analysis, highlighting the potential for underestimating pressures and inadequate surge protection measures. \n",
            "\n",
            "In contrast, the predicted answer elaborates extensively on the concept of skeletonization, including its definition, positive and negative impacts, and best practices. While this information is relevant, it goes beyond the scope of the original question, which specifically asks about the impact on transient analysis rather than a comprehensive overview of skeletonization itself.\n",
            "\n",
            "The predicted answer includes a significant amount of extra information, such as the benefits of reduced computational time and improved model stability, which, while informative, are not directly necessary to answer the question. This results in a response that is longer and more detailed than required.\n",
            "\n",
            "Given these considerations, I would assign a score of 3 to the predicted response, as it includes a lot of extra information and uses flowery language that detracts from the conciseness of the answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 3, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: How does skeletonization impact transient (surge) analysis in hydraulic models?, Actual answer: Transient analysis requires detailed representations of small pipes since they influence pressure wave propagation. Removing these elements in skeletonized models can alter results, underestimating or misrepresenting transient pressures, leading to inadequate surge protection measures., Predicted answer: Skeletonization is a technique used in hydraulic modeling, particularly in computational fluid dynamics (CFD) and one-dimensional (1D) modeling, to reduce the complexity of a model by removing or simplifying certain elements. In the context of transient (surge) analysis, skeletonization can have both positive and negative impacts.\n",
            "\n",
            "**Positive impacts:**\n",
            "\n",
            "1. **Reduced computational time**: By removing or simplifying certain elements, skeletonization can significantly reduce the computational time required for transient analysis. This is particularly beneficial for large-scale models or models with complex geometries.\n",
            "2. **Improved model stability**: Skeletonization can help stabilize the model by removing elements that may cause numerical instability or oscillations during transient analysis.\n",
            "3. **Enhanced model interpretability**: By simplifying the model, skeletonization can make it easier to understand and interpret the results of transient analysis.\n",
            "\n",
            "**Negative impacts:**\n",
            "\n",
            "1. **Loss of accuracy**: Skeletonization can lead to a loss of accuracy in the results of transient analysis, particularly if the removed or simplified elements are critical to the behavior of the system.\n",
            "2. **Over-simplification**: If skeletonization is not done carefully, it can lead to over-simplification of the model, which can result in inaccurate or misleading results.\n",
            "3. **Inability to capture local effects**: Skeletonization can make it difficult to capture local effects, such as pressure surges or water hammer, which are critical to understanding the behavior of the system during transient analysis.\n",
            "\n",
            "**Best practices for skeletonization in transient analysis:**\n",
            "\n",
            "1. **Carefully select the elements to be removed or simplified**: Only remove or simplify elements that are not critical to the behavior of the system during transient analysis.\n",
            "2. **Use sensitivity analysis**: Perform sensitivity analysis to determine the impact of skeletonization on the results of transient analysis.\n",
            "3. **Validate the results**: Validate the results of transient analysis using field data or other independent methods to ensure that the skeletonized model accurately represents the behavior of the system.\n",
            "\n",
            "In summary, skeletonization can be a useful technique for reducing the complexity of hydraulic models and improving computational efficiency during transient analysis. However, it requires careful application and validation to ensure that the results accurately represent the behavior of the system.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the confidence conveyed in both responses regarding the impact of skeletonization on transient analysis in hydraulic models.\n",
            "\n",
            "The actual answer succinctly identifies the critical aspects of how skeletonization affects transient analysis, emphasizing the importance of small pipes in pressure wave propagation and the potential consequences of their removal. It conveys a clear understanding of the risks involved, particularly in terms of underestimating transient pressures and the implications for surge protection measures.\n",
            "\n",
            "In contrast, the predicted answer provides a more detailed exploration of skeletonization, outlining both positive and negative impacts, as well as best practices. While it does acknowledge the potential for loss of accuracy and over-simplification, it also highlights benefits such as reduced computational time and improved model stability. This balanced view introduces a level of uncertainty regarding the overall impact of skeletonization, which may dilute the confidence in asserting that it negatively affects transient analysis.\n",
            "\n",
            "The predicted answer does not explicitly state that skeletonization will lead to inadequate surge protection measures, which is a critical point made in the actual answer. Instead, it presents a more nuanced perspective that could lead to ambiguity about the overall effects of skeletonization.\n",
            "\n",
            "Given these considerations, the predicted answer leans towards a moderate agreement with the actual answer but does not fully endorse the negative implications as strongly. Therefore, I would assign a score of 4, indicating moderate agreement with some acknowledgment of uncertainty.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7it [04:02, 29.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : In water engineering, merging pipes in series or parallel is a common technique used to simplify complex pipe networks and reduce the number of equations required to model the system. This process is known as model reduction.\n",
            "\n",
            "**Merging Pipes in Series:**\n",
            "\n",
            "When pipes are connected in series, the flow rate through each pipe is the same, but the pressure drop across each pipe is additive. By merging pipes in series, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in series, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total pressure drop (ΔP) can be calculated as:\n",
            "\n",
            "ΔP = (f1 \\* L1 / D1^5 \\* Q^2) + (f2 \\* L2 / D2^5 \\* Q^2)\n",
            "\n",
            "where Q is the flow rate through the pipes.\n",
            "\n",
            "By merging the pipes in series, we can simplify the equation to:\n",
            "\n",
            "ΔP = (f \\* L / D^5 \\* Q^2)\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Merging Pipes in Parallel:**\n",
            "\n",
            "When pipes are connected in parallel, the pressure drop across each pipe is the same, but the flow rate through each pipe is additive. By merging pipes in parallel, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in parallel, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total flow rate (Q) can be calculated as:\n",
            "\n",
            "Q = Q1 + Q2\n",
            "\n",
            "where Q1 and Q2 are the flow rates through pipe 1 and pipe 2, respectively.\n",
            "\n",
            "By merging the pipes in parallel, we can simplify the equation to:\n",
            "\n",
            "Q = (D^5 \\* ΔP / (f \\* L))^0.5\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Benefits of Model Reduction:**\n",
            "\n",
            "Merging pipes in series or parallel can significantly reduce the number of equations required to model a complex pipe network, making it easier to analyze and simulate the system. This can lead to several benefits, including:\n",
            "\n",
            "1. Reduced computational time: With fewer equations to solve, simulations can run faster and more efficiently.\n",
            "2. Improved accuracy: By simplifying the model, we can reduce the impact of numerical errors and improve the overall accuracy of the simulation.\n",
            "3. Easier analysis: With a reduced number of equations, it's easier to analyze and understand the behavior of the system.\n",
            "\n",
            "However, it's essential to note that merging pipes in series or parallel can also introduce errors if not done correctly. Therefore, it's crucial to carefully evaluate the impact of model reduction on the accuracy and reliability of the simulation results.\n",
            "\u001b[32mUser message:Question: How does skeletonization impact transient (surge) analysis in hydraulic models?, Actual answer: Transient analysis requires detailed representations of small pipes since they influence pressure wave propagation. Removing these elements in skeletonized models can alter results, underestimating or misrepresenting transient pressures, leading to inadequate surge protection measures., Predicted answer: Skeletonization is a technique used in hydraulic modeling, particularly in computational fluid dynamics (CFD) and one-dimensional (1D) modeling, to reduce the complexity of a model by removing or simplifying certain elements. In the context of transient (surge) analysis, skeletonization can have both positive and negative impacts.\n",
            "\n",
            "**Positive impacts:**\n",
            "\n",
            "1. **Reduced computational time**: By removing or simplifying certain elements, skeletonization can significantly reduce the computational time required for transient analysis. This is particularly beneficial for large-scale models or models with complex geometries.\n",
            "2. **Improved model stability**: Skeletonization can help stabilize the model by removing elements that may cause numerical instability or oscillations during transient analysis.\n",
            "3. **Enhanced model interpretability**: By simplifying the model, skeletonization can make it easier to understand and interpret the results of transient analysis.\n",
            "\n",
            "**Negative impacts:**\n",
            "\n",
            "1. **Loss of accuracy**: Skeletonization can lead to a loss of accuracy in the results of transient analysis, particularly if the removed or simplified elements are critical to the behavior of the system.\n",
            "2. **Over-simplification**: If skeletonization is not done carefully, it can lead to over-simplification of the model, which can result in inaccurate or misleading results.\n",
            "3. **Inability to capture local effects**: Skeletonization can make it difficult to capture local effects, such as pressure surges or water hammer, which are critical to understanding the behavior of the system during transient analysis.\n",
            "\n",
            "**Best practices for skeletonization in transient analysis:**\n",
            "\n",
            "1. **Carefully select the elements to be removed or simplified**: Only remove or simplify elements that are not critical to the behavior of the system during transient analysis.\n",
            "2. **Use sensitivity analysis**: Perform sensitivity analysis to determine the impact of skeletonization on the results of transient analysis.\n",
            "3. **Validate the results**: Validate the results of transient analysis using field data or other independent methods to ensure that the skeletonized model accurately represents the behavior of the system.\n",
            "\n",
            "In summary, skeletonization can be a useful technique for reducing the complexity of hydraulic models and improving computational efficiency during transient analysis. However, it requires careful application and validation to ensure that the results accurately represent the behavior of the system.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the factual accuracy and relevance of the information presented in both responses. \n",
            "\n",
            "The actual answer succinctly highlights the critical role of small pipes in transient analysis and how their removal in skeletonized models can lead to significant inaccuracies in pressure wave propagation and surge protection measures. This response is focused and directly addresses the impact of skeletonization on transient analysis.\n",
            "\n",
            "The predicted answer, while providing a comprehensive overview of skeletonization, includes both positive and negative impacts, which are relevant but somewhat diverge from the core focus of the actual answer. It discusses computational efficiency, model stability, and interpretability, which are valid points but do not directly address the specific consequences of skeletonization on transient analysis as emphasized in the actual answer. The predicted answer also mentions best practices, which, while useful, are not part of the original question's focus.\n",
            "\n",
            "Overall, the predicted answer contains a mix of factual information and some elements that may not be directly relevant to the question, leading to a more generalized response rather than a precise one. \n",
            "\n",
            "Given this analysis, I would assign a score of 3 to the predicted answer, as it contains both factual information and some deviations from the specific focus of the question.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: How does skeletonization impact transient (surge) analysis in hydraulic models?, Actual answer: Transient analysis requires detailed representations of small pipes since they influence pressure wave propagation. Removing these elements in skeletonized models can alter results, underestimating or misrepresenting transient pressures, leading to inadequate surge protection measures., Predicted answer: Skeletonization is a technique used in hydraulic modeling, particularly in computational fluid dynamics (CFD) and one-dimensional (1D) modeling, to reduce the complexity of a model by removing or simplifying certain elements. In the context of transient (surge) analysis, skeletonization can have both positive and negative impacts.\n",
            "\n",
            "**Positive impacts:**\n",
            "\n",
            "1. **Reduced computational time**: By removing or simplifying certain elements, skeletonization can significantly reduce the computational time required for transient analysis. This is particularly beneficial for large-scale models or models with complex geometries.\n",
            "2. **Improved model stability**: Skeletonization can help stabilize the model by removing elements that may cause numerical instability or oscillations during transient analysis.\n",
            "3. **Enhanced model interpretability**: By simplifying the model, skeletonization can make it easier to understand and interpret the results of transient analysis.\n",
            "\n",
            "**Negative impacts:**\n",
            "\n",
            "1. **Loss of accuracy**: Skeletonization can lead to a loss of accuracy in the results of transient analysis, particularly if the removed or simplified elements are critical to the behavior of the system.\n",
            "2. **Over-simplification**: If skeletonization is not done carefully, it can lead to over-simplification of the model, which can result in inaccurate or misleading results.\n",
            "3. **Inability to capture local effects**: Skeletonization can make it difficult to capture local effects, such as pressure surges or water hammer, which are critical to understanding the behavior of the system during transient analysis.\n",
            "\n",
            "**Best practices for skeletonization in transient analysis:**\n",
            "\n",
            "1. **Carefully select the elements to be removed or simplified**: Only remove or simplify elements that are not critical to the behavior of the system during transient analysis.\n",
            "2. **Use sensitivity analysis**: Perform sensitivity analysis to determine the impact of skeletonization on the results of transient analysis.\n",
            "3. **Validate the results**: Validate the results of transient analysis using field data or other independent methods to ensure that the skeletonized model accurately represents the behavior of the system.\n",
            "\n",
            "In summary, skeletonization can be a useful technique for reducing the complexity of hydraulic models and improving computational efficiency during transient analysis. However, it requires careful application and validation to ensure that the results accurately represent the behavior of the system.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the key points made in both responses regarding the impact of skeletonization on transient (surge) analysis in hydraulic models.\n",
            "\n",
            "The actual answer succinctly highlights the critical aspect of transient analysis, which is the need for detailed representations of small pipes that influence pressure wave propagation. It emphasizes that skeletonization can lead to underestimating or misrepresenting transient pressures, which can have serious implications for surge protection measures.\n",
            "\n",
            "The predicted answer, while comprehensive and structured, introduces a broader discussion about the positive and negative impacts of skeletonization. It correctly identifies that skeletonization can reduce computational time and improve model stability, but it also acknowledges the potential loss of accuracy and the risk of over-simplification. However, it does not explicitly mention the specific consequences of these impacts on transient pressures or surge protection measures, which is a critical point made in the actual answer.\n",
            "\n",
            "The predicted answer does provide a balanced view and suggests best practices for skeletonization, which adds value. However, it lacks the direct connection to the implications for transient analysis that the actual answer provides.\n",
            "\n",
            "Given these considerations, the predicted answer shows a good understanding of the topic but does not fully capture the specific consequences of skeletonization on transient analysis as outlined in the actual answer. Therefore, it reflects some uncertainty and does not clearly assert correctness.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 3, 'judgement_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: completeness_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8it [04:26, 28.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : Skeletonizing a water distribution network involves reducing the complexity of the network while preserving its essential characteristics. The main techniques for skeletonizing a water distribution network are:\n",
            "\n",
            "1. **Minimum Spanning Tree (MST)**: This technique involves finding the subset of edges in the network that connects all nodes while minimizing the total length of the edges. MST is a widely used method for skeletonizing water distribution networks, as it preserves the connectivity of the network while reducing its complexity.\n",
            "\n",
            "2. **Maximum Spanning Tree (MST)**: This technique is similar to MST, but it finds the subset of edges that connects all nodes while maximizing the total length of the edges. MST is useful for identifying the most critical components of the network.\n",
            "\n",
            "3. **Hierarchical Network Decomposition (HND)**: This technique involves decomposing the network into a hierarchy of sub-networks, with each sub-network representing a level of abstraction. HND is useful for identifying the most critical components of the network and for simplifying the network while preserving its essential characteristics.\n",
            "\n",
            "4. **Graph Simplification**: This technique involves removing edges or nodes from the network while preserving its connectivity. Graph simplification can be used to reduce the complexity of the network while preserving its essential characteristics.\n",
            "\n",
            "5. **Network Reduction**: This technique involves reducing the number of nodes or edges in the network while preserving its connectivity. Network reduction can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "6. **Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. Clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "7. **Principal Component Analysis (PCA)**: This technique involves reducing the dimensionality of the network by projecting it onto a lower-dimensional space. PCA can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "8. **K-Means Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. K-Means clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "9. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. DBSCAN can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "These techniques can be used individually or in combination to skeletonize a water distribution network. The choice of technique depends on the specific characteristics of the network and the goals of the skeletonization process.\n",
            "\u001b[32mUser message:Question: What are the potential risks of excessive skeletonization in water distribution networks?, Actual answer: Over-skeletonization can lead to loss of critical system details, inaccurate transient analysis, incorrect pressure predictions, and failure to detect hydraulic issues such as localized pressure drops or surge propagation effects. In extreme cases, it may render the model unreliable for operational decision-making., Predicted answer: Excessive skeletonization in water distribution networks refers to the removal of too many hydrants, valves, and other appurtenances, which can lead to several potential risks. Some of these risks include:\n",
            "\n",
            "1. **Difficulty in Locating Leaks**: With fewer hydrants and valves, it becomes more challenging to locate leaks in the distribution system. This can lead to extended periods of undetected leaks, resulting in wasted water, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "2. **Reduced Fire Protection**: Excessive skeletonization can compromise the fire protection capabilities of the water distribution network. With fewer hydrants and valves, firefighters may struggle to access the necessary water supply to combat fires, potentially leading to property damage and loss of life.\n",
            "\n",
            "3. **Increased Risk of Main Breaks**: When hydrants and valves are removed, it can be more difficult to detect and respond to main breaks. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "4. **Difficulty in Maintaining System Pressure**: Excessive skeletonization can disrupt the hydraulic balance of the distribution system, leading to reduced system pressure. This can result in decreased water flow rates, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "5. **Reduced System Resiliency**: Excessive skeletonization can reduce the overall resiliency of the water distribution network, making it more vulnerable to disruptions and failures. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "6. **Increased Risk of Contamination**: Excessive skeletonization can increase the risk of contamination in the water distribution network. With fewer hydrants and valves, it can be more difficult to detect and respond to contamination events, potentially leading to health risks for consumers.\n",
            "\n",
            "7. **Difficulty in Conducting Maintenance and Rehabilitation**: Excessive skeletonization can make it more challenging to conduct maintenance and rehabilitation activities in the water distribution network. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "In summary, excessive skeletonization in water distribution networks can lead to a range of potential risks, including difficulty in locating leaks, reduced fire protection, increased risk of main breaks, difficulty in maintaining system pressure, reduced system resiliency, increased risk of contamination, and difficulty in conducting maintenance and rehabilitation activities.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the completeness of the information provided in both responses. The actual answer succinctly identifies specific risks associated with excessive skeletonization, such as loss of critical system details, inaccurate transient analysis, and failure to detect hydraulic issues. It emphasizes the potential consequences of these risks, particularly regarding operational decision-making.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, covers a broader range of risks, including difficulties in leak detection, reduced fire protection, increased risk of main breaks, and challenges in maintaining system pressure. It also discusses the implications of these risks, such as wasted water, increased costs, and potential contamination. However, it does not explicitly mention the loss of critical system details or the impact on transient analysis, which are key elements of the actual answer.\n",
            "\n",
            "In terms of completeness, the predicted answer includes many relevant points and provides a thorough overview of the risks associated with excessive skeletonization. However, it lacks some specific elements that are present in the actual answer, particularly regarding the reliability of the model for operational decision-making.\n",
            "\n",
            "Given this analysis, I would assign a score of 4 to the predicted answer, as it covers most elements of a complete answer but misses a few critical aspects.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: What are the potential risks of excessive skeletonization in water distribution networks?, Actual answer: Over-skeletonization can lead to loss of critical system details, inaccurate transient analysis, incorrect pressure predictions, and failure to detect hydraulic issues such as localized pressure drops or surge propagation effects. In extreme cases, it may render the model unreliable for operational decision-making., Predicted answer: Excessive skeletonization in water distribution networks refers to the removal of too many hydrants, valves, and other appurtenances, which can lead to several potential risks. Some of these risks include:\n",
            "\n",
            "1. **Difficulty in Locating Leaks**: With fewer hydrants and valves, it becomes more challenging to locate leaks in the distribution system. This can lead to extended periods of undetected leaks, resulting in wasted water, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "2. **Reduced Fire Protection**: Excessive skeletonization can compromise the fire protection capabilities of the water distribution network. With fewer hydrants and valves, firefighters may struggle to access the necessary water supply to combat fires, potentially leading to property damage and loss of life.\n",
            "\n",
            "3. **Increased Risk of Main Breaks**: When hydrants and valves are removed, it can be more difficult to detect and respond to main breaks. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "4. **Difficulty in Maintaining System Pressure**: Excessive skeletonization can disrupt the hydraulic balance of the distribution system, leading to reduced system pressure. This can result in decreased water flow rates, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "5. **Reduced System Resiliency**: Excessive skeletonization can reduce the overall resiliency of the water distribution network, making it more vulnerable to disruptions and failures. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "6. **Increased Risk of Contamination**: Excessive skeletonization can increase the risk of contamination in the water distribution network. With fewer hydrants and valves, it can be more difficult to detect and respond to contamination events, potentially leading to health risks for consumers.\n",
            "\n",
            "7. **Difficulty in Conducting Maintenance and Rehabilitation**: Excessive skeletonization can make it more challenging to conduct maintenance and rehabilitation activities in the water distribution network. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "In summary, excessive skeletonization in water distribution networks can lead to a range of potential risks, including difficulty in locating leaks, reduced fire protection, increased risk of main breaks, difficulty in maintaining system pressure, reduced system resiliency, increased risk of contamination, and difficulty in conducting maintenance and rehabilitation activities.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the relevance of the information provided in relation to the user's question about the potential risks of excessive skeletonization in water distribution networks.\n",
            "\n",
            "The actual answer succinctly identifies key risks associated with over-skeletonization, such as loss of critical system details, inaccurate transient analysis, and failure to detect hydraulic issues. It emphasizes the implications for operational decision-making, which is crucial for understanding the broader impact of skeletonization.\n",
            "\n",
            "The predicted answer, while lengthy, provides a comprehensive list of risks associated with excessive skeletonization. It covers various aspects such as leak detection, fire protection, main breaks, system pressure, resiliency, contamination risks, and maintenance challenges. Each point is relevant to the question and elaborates on the potential consequences of excessive skeletonization.\n",
            "\n",
            "However, the predicted answer includes a lot of detail that, while relevant, may not be necessary for a concise understanding of the risks. It could be seen as somewhat verbose, which might detract from the clarity of the main points.\n",
            "\n",
            "In summary, the predicted answer effectively addresses the user's question and provides relevant information, but it does contain more detail than necessary, which could be considered slightly excessive.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: What are the potential risks of excessive skeletonization in water distribution networks?, Actual answer: Over-skeletonization can lead to loss of critical system details, inaccurate transient analysis, incorrect pressure predictions, and failure to detect hydraulic issues such as localized pressure drops or surge propagation effects. In extreme cases, it may render the model unreliable for operational decision-making., Predicted answer: Excessive skeletonization in water distribution networks refers to the removal of too many hydrants, valves, and other appurtenances, which can lead to several potential risks. Some of these risks include:\n",
            "\n",
            "1. **Difficulty in Locating Leaks**: With fewer hydrants and valves, it becomes more challenging to locate leaks in the distribution system. This can lead to extended periods of undetected leaks, resulting in wasted water, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "2. **Reduced Fire Protection**: Excessive skeletonization can compromise the fire protection capabilities of the water distribution network. With fewer hydrants and valves, firefighters may struggle to access the necessary water supply to combat fires, potentially leading to property damage and loss of life.\n",
            "\n",
            "3. **Increased Risk of Main Breaks**: When hydrants and valves are removed, it can be more difficult to detect and respond to main breaks. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "4. **Difficulty in Maintaining System Pressure**: Excessive skeletonization can disrupt the hydraulic balance of the distribution system, leading to reduced system pressure. This can result in decreased water flow rates, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "5. **Reduced System Resiliency**: Excessive skeletonization can reduce the overall resiliency of the water distribution network, making it more vulnerable to disruptions and failures. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "6. **Increased Risk of Contamination**: Excessive skeletonization can increase the risk of contamination in the water distribution network. With fewer hydrants and valves, it can be more difficult to detect and respond to contamination events, potentially leading to health risks for consumers.\n",
            "\n",
            "7. **Difficulty in Conducting Maintenance and Rehabilitation**: Excessive skeletonization can make it more challenging to conduct maintenance and rehabilitation activities in the water distribution network. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "In summary, excessive skeletonization in water distribution networks can lead to a range of potential risks, including difficulty in locating leaks, reduced fire protection, increased risk of main breaks, difficulty in maintaining system pressure, reduced system resiliency, increased risk of contamination, and difficulty in conducting maintenance and rehabilitation activities.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we first need to analyze the content and structure of both responses. The actual answer succinctly lists the risks associated with excessive skeletonization in water distribution networks, focusing on critical system details and operational reliability. It is direct and to the point, providing a clear understanding of the potential issues without unnecessary elaboration.\n",
            "\n",
            "In contrast, the predicted answer is significantly longer and includes multiple detailed points, each elaborated with examples and consequences. While it does cover relevant risks, the extensive breakdown into seven separate points introduces a lot of extra information that may not be necessary to answer the question effectively. The predicted response also repeats certain themes, such as contamination and service disruption, which could have been consolidated for brevity.\n",
            "\n",
            "Given these observations, the predicted answer includes a lot of extra information and uses a more flowery language style, which detracts from its conciseness. Therefore, it does not meet the standard of being as short as possible while still answering the prompt.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error running target function: probability tensor contains either `inf`, `nan` or element < 0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mUser message:Question: What are the potential risks of excessive skeletonization in water distribution networks?, Actual answer: Over-skeletonization can lead to loss of critical system details, inaccurate transient analysis, incorrect pressure predictions, and failure to detect hydraulic issues such as localized pressure drops or surge propagation effects. In extreme cases, it may render the model unreliable for operational decision-making., Predicted answer: Excessive skeletonization in water distribution networks refers to the removal of too many hydrants, valves, and other appurtenances, which can lead to several potential risks. Some of these risks include:\n",
            "\n",
            "1. **Difficulty in Locating Leaks**: With fewer hydrants and valves, it becomes more challenging to locate leaks in the distribution system. This can lead to extended periods of undetected leaks, resulting in wasted water, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "2. **Reduced Fire Protection**: Excessive skeletonization can compromise the fire protection capabilities of the water distribution network. With fewer hydrants and valves, firefighters may struggle to access the necessary water supply to combat fires, potentially leading to property damage and loss of life.\n",
            "\n",
            "3. **Increased Risk of Main Breaks**: When hydrants and valves are removed, it can be more difficult to detect and respond to main breaks. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "4. **Difficulty in Maintaining System Pressure**: Excessive skeletonization can disrupt the hydraulic balance of the distribution system, leading to reduced system pressure. This can result in decreased water flow rates, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "5. **Reduced System Resiliency**: Excessive skeletonization can reduce the overall resiliency of the water distribution network, making it more vulnerable to disruptions and failures. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "6. **Increased Risk of Contamination**: Excessive skeletonization can increase the risk of contamination in the water distribution network. With fewer hydrants and valves, it can be more difficult to detect and respond to contamination events, potentially leading to health risks for consumers.\n",
            "\n",
            "7. **Difficulty in Conducting Maintenance and Rehabilitation**: Excessive skeletonization can make it more challenging to conduct maintenance and rehabilitation activities in the water distribution network. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "In summary, excessive skeletonization in water distribution networks can lead to a range of potential risks, including difficulty in locating leaks, reduced fire protection, increased risk of main breaks, difficulty in maintaining system pressure, reduced system resiliency, increased risk of contamination, and difficulty in conducting maintenance and rehabilitation activities.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the confidence conveyed in both responses regarding the risks of excessive skeletonization in water distribution networks. \n",
            "\n",
            "The actual answer succinctly identifies specific risks associated with over-skeletonization, such as loss of critical system details, inaccurate transient analysis, and failure to detect hydraulic issues. It emphasizes the potential consequences of these risks, particularly the reliability of the model for operational decision-making.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, expands on the risks by providing a comprehensive list of potential issues, including difficulties in leak detection, reduced fire protection, and increased risk of contamination. It effectively communicates the implications of excessive skeletonization, demonstrating a clear understanding of the topic.\n",
            "\n",
            "However, the predicted answer does not directly address the specific concerns mentioned in the actual answer, such as the impact on transient analysis and hydraulic issues. Instead, it focuses more on operational challenges and risks, which, while relevant, may not fully align with the core points of the actual answer.\n",
            "\n",
            "In terms of confidence, the predicted answer presents a well-structured argument with multiple points, suggesting a strong level of assurance in its correctness. However, it lacks the precision and focus of the actual answer, which may lead to some uncertainty about its completeness.\n",
            "\n",
            "Given these considerations, I would assign a score of 4 to the predicted answer. It leans towards agreement with the actual answer but acknowledges some uncertainty due to its broader scope and lack of direct alignment with the key points.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: What are the potential risks of excessive skeletonization in water distribution networks?, Actual answer: Over-skeletonization can lead to loss of critical system details, inaccurate transient analysis, incorrect pressure predictions, and failure to detect hydraulic issues such as localized pressure drops or surge propagation effects. In extreme cases, it may render the model unreliable for operational decision-making., Predicted answer: Excessive skeletonization in water distribution networks refers to the removal of too many hydrants, valves, and other appurtenances, which can lead to several potential risks. Some of these risks include:\n",
            "\n",
            "1. **Difficulty in Locating Leaks**: With fewer hydrants and valves, it becomes more challenging to locate leaks in the distribution system. This can lead to extended periods of undetected leaks, resulting in wasted water, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "2. **Reduced Fire Protection**: Excessive skeletonization can compromise the fire protection capabilities of the water distribution network. With fewer hydrants and valves, firefighters may struggle to access the necessary water supply to combat fires, potentially leading to property damage and loss of life.\n",
            "\n",
            "3. **Increased Risk of Main Breaks**: When hydrants and valves are removed, it can be more difficult to detect and respond to main breaks. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "4. **Difficulty in Maintaining System Pressure**: Excessive skeletonization can disrupt the hydraulic balance of the distribution system, leading to reduced system pressure. This can result in decreased water flow rates, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "5. **Reduced System Resiliency**: Excessive skeletonization can reduce the overall resiliency of the water distribution network, making it more vulnerable to disruptions and failures. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "6. **Increased Risk of Contamination**: Excessive skeletonization can increase the risk of contamination in the water distribution network. With fewer hydrants and valves, it can be more difficult to detect and respond to contamination events, potentially leading to health risks for consumers.\n",
            "\n",
            "7. **Difficulty in Conducting Maintenance and Rehabilitation**: Excessive skeletonization can make it more challenging to conduct maintenance and rehabilitation activities in the water distribution network. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "In summary, excessive skeletonization in water distribution networks can lead to a range of potential risks, including difficulty in locating leaks, reduced fire protection, increased risk of main breaks, difficulty in maintaining system pressure, reduced system resiliency, increased risk of contamination, and difficulty in conducting maintenance and rehabilitation activities.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the factual accuracy and relevance of the information presented. The actual answer focuses on specific risks associated with excessive skeletonization, such as loss of critical system details, inaccurate transient analysis, and failure to detect hydraulic issues. \n",
            "\n",
            "The predicted answer, while lengthy and detailed, introduces several relevant points about the risks of excessive skeletonization, including difficulties in locating leaks, reduced fire protection, and increased risk of contamination. However, it diverges from the actual answer by emphasizing operational challenges and risks that are not explicitly mentioned in the actual answer, such as the impact on fire protection and maintenance activities.\n",
            "\n",
            "Despite these differences, the predicted answer does not contain outright hallucinations; rather, it expands on the topic with additional risks that are plausible and relevant to water distribution networks. However, it lacks the precision and focus of the actual answer, which is more concise and directly addresses the core issues.\n",
            "\n",
            "Given this analysis, the predicted answer contains a mix of factual information and some deviations from the core points made in the actual answer. Therefore, it can be rated as follows:\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: What are the potential risks of excessive skeletonization in water distribution networks?, Actual answer: Over-skeletonization can lead to loss of critical system details, inaccurate transient analysis, incorrect pressure predictions, and failure to detect hydraulic issues such as localized pressure drops or surge propagation effects. In extreme cases, it may render the model unreliable for operational decision-making., Predicted answer: Excessive skeletonization in water distribution networks refers to the removal of too many hydrants, valves, and other appurtenances, which can lead to several potential risks. Some of these risks include:\n",
            "\n",
            "1. **Difficulty in Locating Leaks**: With fewer hydrants and valves, it becomes more challenging to locate leaks in the distribution system. This can lead to extended periods of undetected leaks, resulting in wasted water, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "2. **Reduced Fire Protection**: Excessive skeletonization can compromise the fire protection capabilities of the water distribution network. With fewer hydrants and valves, firefighters may struggle to access the necessary water supply to combat fires, potentially leading to property damage and loss of life.\n",
            "\n",
            "3. **Increased Risk of Main Breaks**: When hydrants and valves are removed, it can be more difficult to detect and respond to main breaks. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "4. **Difficulty in Maintaining System Pressure**: Excessive skeletonization can disrupt the hydraulic balance of the distribution system, leading to reduced system pressure. This can result in decreased water flow rates, increased energy costs, and potential contamination of the water supply.\n",
            "\n",
            "5. **Reduced System Resiliency**: Excessive skeletonization can reduce the overall resiliency of the water distribution network, making it more vulnerable to disruptions and failures. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "6. **Increased Risk of Contamination**: Excessive skeletonization can increase the risk of contamination in the water distribution network. With fewer hydrants and valves, it can be more difficult to detect and respond to contamination events, potentially leading to health risks for consumers.\n",
            "\n",
            "7. **Difficulty in Conducting Maintenance and Rehabilitation**: Excessive skeletonization can make it more challenging to conduct maintenance and rehabilitation activities in the water distribution network. This can lead to extended periods of service disruption, increased repair costs, and potential contamination of the water supply.\n",
            "\n",
            "In summary, excessive skeletonization in water distribution networks can lead to a range of potential risks, including difficulty in locating leaks, reduced fire protection, increased risk of main breaks, difficulty in maintaining system pressure, reduced system resiliency, increased risk of contamination, and difficulty in conducting maintenance and rehabilitation activities.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and relevance of the information provided in both responses. The actual answer succinctly identifies the risks associated with excessive skeletonization, focusing on critical system details, transient analysis, pressure predictions, and hydraulic issues. It emphasizes the potential unreliability of the model for operational decision-making.\n",
            "\n",
            "The predicted answer, while lengthy, provides a comprehensive list of risks associated with excessive skeletonization, including difficulties in leak detection, fire protection, main breaks, system pressure maintenance, resiliency, contamination risks, and maintenance challenges. Each point is relevant and expands on the implications of excessive skeletonization, aligning well with the concerns raised in the actual answer.\n",
            "\n",
            "However, the predicted answer does not explicitly mention the loss of critical system details or the impact on transient analysis, which are key aspects highlighted in the actual answer. Instead, it focuses more on operational and practical challenges, which, while valid, may not fully capture the theoretical implications of skeletonization as described in the actual answer.\n",
            "\n",
            "Given that the predicted answer is largely accurate and provides a detailed exploration of the risks, but lacks some of the theoretical aspects mentioned in the actual answer, it demonstrates a strong understanding of the topic without claiming any inaccuracies. Therefore, it does not confidently assert a hallucination as truth, nor does it misinterpret the prompt.\n",
            "\n",
            "Considering these factors, I would assign a score of 4 to the predicted answer, as it is correct but does not fully align with the theoretical aspects emphasized in the actual answer.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4, 'judgement_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: Why is it important to preserve demand distribution when removing minor dead-end pipes?, Actual answer: Removing dead-end pipes without redistributing their demand can lead to inaccurate pressure calculations and misrepresentation of water usage patterns. Proper aggregation ensures that demand is preserved at the remaining nodes, maintaining network integrity., Predicted answer: Preserving demand distribution when removing minor dead-end pipes is crucial in water distribution systems for several reasons:\n",
            "\n",
            "1. **System Reliability**: Minor dead-end pipes often serve low-demand areas, such as single-family homes or small businesses. When these pipes are removed, the remaining pipes in the system may not be able to handle the increased demand, leading to reduced system reliability and potential water shortages.\n",
            "\n",
            "2. **Pressure Management**: Removing minor dead-end pipes can alter the pressure distribution in the system, potentially causing low pressures in areas that were previously served by these pipes. This can lead to reduced water quality, increased risk of contamination, and decreased system performance.\n",
            "\n",
            "3. **Flow Distribution**: Minor dead-end pipes help to distribute flow throughout the system, particularly in areas with low demand. When these pipes are removed, the flow may become concentrated in other areas, leading to overflows, increased energy consumption, and reduced system efficiency.\n",
            "\n",
            "4. **Water Quality**: Preserving demand distribution helps to maintain a consistent water quality throughout the system. When minor dead-end pipes are removed, the remaining pipes may not be able to handle the increased demand, leading to reduced water quality and increased risk of contamination.\n",
            "\n",
            "5. **Energy Efficiency**: Removing minor dead-end pipes can lead to increased energy consumption, as pumps and other equipment may need to work harder to meet the increased demand. Preserving demand distribution helps to maintain a balanced system, reducing energy consumption and costs.\n",
            "\n",
            "6. **Asset Management**: Preserving demand distribution helps to extend the life of system assets, such as pipes, pumps, and valves. By maintaining a balanced system, the risk of premature failure and costly repairs is reduced.\n",
            "\n",
            "To preserve demand distribution when removing minor dead-end pipes, water utilities can use various techniques, such as:\n",
            "\n",
            "1. **Pipe sizing**: Ensuring that the remaining pipes are sized correctly to handle the increased demand.\n",
            "2. **Pressure management**: Implementing pressure management strategies, such as pressure-reducing valves, to maintain a consistent pressure throughout the system.\n",
            "3. **Flow distribution**: Implementing flow distribution strategies, such as flow control valves, to maintain a balanced flow throughout the system.\n",
            "4. **System modeling**: Using system modeling tools to simulate the impact of removing minor dead-end pipes and identify potential issues before they occur.\n",
            "\n",
            "By preserving demand distribution when removing minor dead-end pipes, water utilities can maintain a reliable, efficient, and safe water distribution system that meets the needs of their customers.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the completeness of the information provided in both responses. The actual answer succinctly highlights the importance of preserving demand distribution when removing minor dead-end pipes, focusing on the consequences of not doing so, such as inaccurate pressure calculations and misrepresentation of water usage patterns. It emphasizes the need for proper aggregation to maintain network integrity.\n",
            "\n",
            "The predicted answer, on the other hand, provides a comprehensive overview of the reasons for preserving demand distribution. It covers multiple aspects, including system reliability, pressure management, flow distribution, water quality, energy efficiency, and asset management. Additionally, it suggests techniques for preserving demand distribution, which adds further depth to the response.\n",
            "\n",
            "In terms of completeness, the predicted answer addresses all the key elements necessary to understand the importance of preserving demand distribution and goes beyond the actual answer by providing additional context and practical strategies. Therefore, it can be considered to cover all elements of a complete answer.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 5}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: Why is it important to preserve demand distribution when removing minor dead-end pipes?, Actual answer: Removing dead-end pipes without redistributing their demand can lead to inaccurate pressure calculations and misrepresentation of water usage patterns. Proper aggregation ensures that demand is preserved at the remaining nodes, maintaining network integrity., Predicted answer: Preserving demand distribution when removing minor dead-end pipes is crucial in water distribution systems for several reasons:\n",
            "\n",
            "1. **System Reliability**: Minor dead-end pipes often serve low-demand areas, such as single-family homes or small businesses. When these pipes are removed, the remaining pipes in the system may not be able to handle the increased demand, leading to reduced system reliability and potential water shortages.\n",
            "\n",
            "2. **Pressure Management**: Removing minor dead-end pipes can alter the pressure distribution in the system, potentially causing low pressures in areas that were previously served by these pipes. This can lead to reduced water quality, increased risk of contamination, and decreased system performance.\n",
            "\n",
            "3. **Flow Distribution**: Minor dead-end pipes help to distribute flow throughout the system, particularly in areas with low demand. When these pipes are removed, the flow may become concentrated in other areas, leading to overflows, increased energy consumption, and reduced system efficiency.\n",
            "\n",
            "4. **Water Quality**: Preserving demand distribution helps to maintain a consistent water quality throughout the system. When minor dead-end pipes are removed, the remaining pipes may not be able to handle the increased demand, leading to reduced water quality and increased risk of contamination.\n",
            "\n",
            "5. **Energy Efficiency**: Removing minor dead-end pipes can lead to increased energy consumption, as pumps and other equipment may need to work harder to meet the increased demand. Preserving demand distribution helps to maintain a balanced system, reducing energy consumption and costs.\n",
            "\n",
            "6. **Asset Management**: Preserving demand distribution helps to extend the life of system assets, such as pipes, pumps, and valves. By maintaining a balanced system, the risk of premature failure and costly repairs is reduced.\n",
            "\n",
            "To preserve demand distribution when removing minor dead-end pipes, water utilities can use various techniques, such as:\n",
            "\n",
            "1. **Pipe sizing**: Ensuring that the remaining pipes are sized correctly to handle the increased demand.\n",
            "2. **Pressure management**: Implementing pressure management strategies, such as pressure-reducing valves, to maintain a consistent pressure throughout the system.\n",
            "3. **Flow distribution**: Implementing flow distribution strategies, such as flow control valves, to maintain a balanced flow throughout the system.\n",
            "4. **System modeling**: Using system modeling tools to simulate the impact of removing minor dead-end pipes and identify potential issues before they occur.\n",
            "\n",
            "By preserving demand distribution when removing minor dead-end pipes, water utilities can maintain a reliable, efficient, and safe water distribution system that meets the needs of their customers.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about the importance of preserving demand distribution when removing minor dead-end pipes. \n",
            "\n",
            "The actual answer succinctly highlights the consequences of not preserving demand distribution, specifically mentioning inaccurate pressure calculations and misrepresentation of water usage patterns. It emphasizes the need for proper aggregation to maintain network integrity.\n",
            "\n",
            "The predicted answer, while lengthy, provides a comprehensive overview of various aspects related to the importance of preserving demand distribution. It discusses system reliability, pressure management, flow distribution, water quality, energy efficiency, and asset management. Each point is relevant to the overall theme of maintaining demand distribution in water distribution systems. However, the response includes a lot of detailed information that, while informative, may not be directly necessary to answer the question succinctly.\n",
            "\n",
            "In terms of relevance:\n",
            "- The predicted answer does answer the user's question and provides relevant information.\n",
            "- However, it contains more detail than what is strictly necessary, which could be considered somewhat irrelevant to the core question.\n",
            "\n",
            "Given this analysis, I would assign a score of 4, as the predicted answer is relevant and informative but includes some extraneous details that could be streamlined.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9it [05:11, 32.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : The Generalized Gradient Approximation (GGA) is a type of exchange-correlation functional used in density functional theory (DFT) to approximate the exchange-correlation energy of a many-electron system. Researchers have attempted to improve the GGA in various ways, including:\n",
            "\n",
            "1. **Parallel processing**: To speed up the calculations, researchers have employed parallel processing techniques, such as:\n",
            "\t* **Message Passing Interface (MPI)**: MPI is a standardized and portable message-passing system designed to function on a wide variety of parallel computers.\n",
            "\t* **Open Multi-Processing (OpenMP)**: OpenMP is an API that supports multi-platform shared-memory parallel programming in C, C++, and Fortran.\n",
            "\t* **Graphics Processing Units (GPUs)**: GPUs have been used to accelerate GGA calculations, taking advantage of their massive parallel processing capabilities.\n",
            "2. **Advanced linear algebra routines**: Researchers have employed optimized linear algebra libraries, such as:\n",
            "\t* **BLAS (Basic Linear Algebra Subprograms)**: BLAS is a widely used library for basic linear algebra operations.\n",
            "\t* **LAPACK (Linear Algebra Package)**: LAPACK is a library of Fortran 77 subroutines for solving systems of linear scalar equations, linear least squares problems, eigenvalue problems, and singular value decomposition problems.\n",
            "\t* **MKL (Math Kernel Library)**: MKL is a high-performance linear algebra library developed by Intel.\n",
            "3. **Optimized GGA functionals**: Researchers have developed optimized GGA functionals, such as:\n",
            "\t* **PBE (Perdew-Burke-Ernzerhof)**: PBE is a widely used GGA functional that has been optimized for various systems.\n",
            "\t* **PBEsol**: PBEsol is a modified version of PBE that has been optimized for solids.\n",
            "\t* **SCAN (Strongly Constrained and Appropriately Normed)**: SCAN is a meta-GGA functional that has been optimized for a wide range of systems.\n",
            "4. **Hybrid functionals**: Researchers have combined GGA functionals with Hartree-Fock (HF) exchange to create hybrid functionals, such as:\n",
            "\t* **B3LYP**: B3LYP is a hybrid functional that combines 20% HF exchange with 80% GGA exchange.\n",
            "\t* **PBE0**: PBE0 is a hybrid functional that combines 25% HF exchange with 75% GGA exchange.\n",
            "5. **Machine learning-based GGA functionals**: Researchers have used machine learning techniques to develop new GGA functionals, such as:\n",
            "\t* **ML-GGA**: ML-GGA is a machine learning-based GGA functional that has been optimized for a wide range of systems.\n",
            "\n",
            "These are just a few examples of how researchers have attempted to improve the GGA. The development of new GGA functionals and optimization techniques continues to be an active area of research in the field of density functional theory.\n",
            "\u001b[32mUser message:Question: Why is it important to preserve demand distribution when removing minor dead-end pipes?, Actual answer: Removing dead-end pipes without redistributing their demand can lead to inaccurate pressure calculations and misrepresentation of water usage patterns. Proper aggregation ensures that demand is preserved at the remaining nodes, maintaining network integrity., Predicted answer: Preserving demand distribution when removing minor dead-end pipes is crucial in water distribution systems for several reasons:\n",
            "\n",
            "1. **System Reliability**: Minor dead-end pipes often serve low-demand areas, such as single-family homes or small businesses. When these pipes are removed, the remaining pipes in the system may not be able to handle the increased demand, leading to reduced system reliability and potential water shortages.\n",
            "\n",
            "2. **Pressure Management**: Removing minor dead-end pipes can alter the pressure distribution in the system, potentially causing low pressures in areas that were previously served by these pipes. This can lead to reduced water quality, increased risk of contamination, and decreased system performance.\n",
            "\n",
            "3. **Flow Distribution**: Minor dead-end pipes help to distribute flow throughout the system, particularly in areas with low demand. When these pipes are removed, the flow may become concentrated in other areas, leading to overflows, increased energy consumption, and reduced system efficiency.\n",
            "\n",
            "4. **Water Quality**: Preserving demand distribution helps to maintain a consistent water quality throughout the system. When minor dead-end pipes are removed, the remaining pipes may not be able to handle the increased demand, leading to reduced water quality and increased risk of contamination.\n",
            "\n",
            "5. **Energy Efficiency**: Removing minor dead-end pipes can lead to increased energy consumption, as pumps and other equipment may need to work harder to meet the increased demand. Preserving demand distribution helps to maintain a balanced system, reducing energy consumption and costs.\n",
            "\n",
            "6. **Asset Management**: Preserving demand distribution helps to extend the life of system assets, such as pipes, pumps, and valves. By maintaining a balanced system, the risk of premature failure and costly repairs is reduced.\n",
            "\n",
            "To preserve demand distribution when removing minor dead-end pipes, water utilities can use various techniques, such as:\n",
            "\n",
            "1. **Pipe sizing**: Ensuring that the remaining pipes are sized correctly to handle the increased demand.\n",
            "2. **Pressure management**: Implementing pressure management strategies, such as pressure-reducing valves, to maintain a consistent pressure throughout the system.\n",
            "3. **Flow distribution**: Implementing flow distribution strategies, such as flow control valves, to maintain a balanced flow throughout the system.\n",
            "4. **System modeling**: Using system modeling tools to simulate the impact of removing minor dead-end pipes and identify potential issues before they occur.\n",
            "\n",
            "By preserving demand distribution when removing minor dead-end pipes, water utilities can maintain a reliable, efficient, and safe water distribution system that meets the needs of their customers.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we first need to analyze the content and structure of both responses. \n",
            "\n",
            "The actual answer is succinct and directly addresses the importance of preserving demand distribution when removing minor dead-end pipes. It highlights the consequences of not doing so, such as inaccurate pressure calculations and misrepresentation of water usage patterns, while also emphasizing the need for proper aggregation to maintain network integrity.\n",
            "\n",
            "In contrast, the predicted answer is significantly longer and includes multiple points that elaborate on various aspects of the issue. While it provides detailed explanations regarding system reliability, pressure management, flow distribution, water quality, energy efficiency, and asset management, it introduces a lot of extra information that may not be necessary to answer the original question. The inclusion of specific techniques for preserving demand distribution further adds to the length without directly addressing the core of the question.\n",
            "\n",
            "Given this analysis, the predicted answer includes a lot of extra information and uses flowery language, making it less concise than the actual answer. Therefore, I would assign a score of 3 for the predicted response.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: Why is it important to preserve demand distribution when removing minor dead-end pipes?, Actual answer: Removing dead-end pipes without redistributing their demand can lead to inaccurate pressure calculations and misrepresentation of water usage patterns. Proper aggregation ensures that demand is preserved at the remaining nodes, maintaining network integrity., Predicted answer: Preserving demand distribution when removing minor dead-end pipes is crucial in water distribution systems for several reasons:\n",
            "\n",
            "1. **System Reliability**: Minor dead-end pipes often serve low-demand areas, such as single-family homes or small businesses. When these pipes are removed, the remaining pipes in the system may not be able to handle the increased demand, leading to reduced system reliability and potential water shortages.\n",
            "\n",
            "2. **Pressure Management**: Removing minor dead-end pipes can alter the pressure distribution in the system, potentially causing low pressures in areas that were previously served by these pipes. This can lead to reduced water quality, increased risk of contamination, and decreased system performance.\n",
            "\n",
            "3. **Flow Distribution**: Minor dead-end pipes help to distribute flow throughout the system, particularly in areas with low demand. When these pipes are removed, the flow may become concentrated in other areas, leading to overflows, increased energy consumption, and reduced system efficiency.\n",
            "\n",
            "4. **Water Quality**: Preserving demand distribution helps to maintain a consistent water quality throughout the system. When minor dead-end pipes are removed, the remaining pipes may not be able to handle the increased demand, leading to reduced water quality and increased risk of contamination.\n",
            "\n",
            "5. **Energy Efficiency**: Removing minor dead-end pipes can lead to increased energy consumption, as pumps and other equipment may need to work harder to meet the increased demand. Preserving demand distribution helps to maintain a balanced system, reducing energy consumption and costs.\n",
            "\n",
            "6. **Asset Management**: Preserving demand distribution helps to extend the life of system assets, such as pipes, pumps, and valves. By maintaining a balanced system, the risk of premature failure and costly repairs is reduced.\n",
            "\n",
            "To preserve demand distribution when removing minor dead-end pipes, water utilities can use various techniques, such as:\n",
            "\n",
            "1. **Pipe sizing**: Ensuring that the remaining pipes are sized correctly to handle the increased demand.\n",
            "2. **Pressure management**: Implementing pressure management strategies, such as pressure-reducing valves, to maintain a consistent pressure throughout the system.\n",
            "3. **Flow distribution**: Implementing flow distribution strategies, such as flow control valves, to maintain a balanced flow throughout the system.\n",
            "4. **System modeling**: Using system modeling tools to simulate the impact of removing minor dead-end pipes and identify potential issues before they occur.\n",
            "\n",
            "By preserving demand distribution when removing minor dead-end pipes, water utilities can maintain a reliable, efficient, and safe water distribution system that meets the needs of their customers.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response captures the essence of the actual answer while also conveying confidence in its correctness. \n",
            "\n",
            "The actual answer emphasizes the importance of preserving demand distribution to avoid inaccurate pressure calculations and misrepresentation of water usage patterns, highlighting the need for proper aggregation to maintain network integrity. \n",
            "\n",
            "The predicted answer, while lengthy and detailed, covers several relevant points such as system reliability, pressure management, flow distribution, water quality, energy efficiency, and asset management. It also suggests techniques for preserving demand distribution, which adds depth to the response. However, it does not directly address the specific concerns of inaccurate pressure calculations and misrepresentation of water usage patterns as clearly as the actual answer does. \n",
            "\n",
            "The predicted answer demonstrates a strong understanding of the topic and provides a comprehensive overview, which suggests a high level of confidence. However, the lack of direct alignment with the core points of the actual answer introduces some uncertainty regarding its completeness and focus.\n",
            "\n",
            "Given these considerations, I would assign a score of 4 to the predicted answer. It leans towards agreement with the actual answer but acknowledges some uncertainty due to its broader scope and less direct focus on the key issues raised in the actual answer.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: Why is it important to preserve demand distribution when removing minor dead-end pipes?, Actual answer: Removing dead-end pipes without redistributing their demand can lead to inaccurate pressure calculations and misrepresentation of water usage patterns. Proper aggregation ensures that demand is preserved at the remaining nodes, maintaining network integrity., Predicted answer: Preserving demand distribution when removing minor dead-end pipes is crucial in water distribution systems for several reasons:\n",
            "\n",
            "1. **System Reliability**: Minor dead-end pipes often serve low-demand areas, such as single-family homes or small businesses. When these pipes are removed, the remaining pipes in the system may not be able to handle the increased demand, leading to reduced system reliability and potential water shortages.\n",
            "\n",
            "2. **Pressure Management**: Removing minor dead-end pipes can alter the pressure distribution in the system, potentially causing low pressures in areas that were previously served by these pipes. This can lead to reduced water quality, increased risk of contamination, and decreased system performance.\n",
            "\n",
            "3. **Flow Distribution**: Minor dead-end pipes help to distribute flow throughout the system, particularly in areas with low demand. When these pipes are removed, the flow may become concentrated in other areas, leading to overflows, increased energy consumption, and reduced system efficiency.\n",
            "\n",
            "4. **Water Quality**: Preserving demand distribution helps to maintain a consistent water quality throughout the system. When minor dead-end pipes are removed, the remaining pipes may not be able to handle the increased demand, leading to reduced water quality and increased risk of contamination.\n",
            "\n",
            "5. **Energy Efficiency**: Removing minor dead-end pipes can lead to increased energy consumption, as pumps and other equipment may need to work harder to meet the increased demand. Preserving demand distribution helps to maintain a balanced system, reducing energy consumption and costs.\n",
            "\n",
            "6. **Asset Management**: Preserving demand distribution helps to extend the life of system assets, such as pipes, pumps, and valves. By maintaining a balanced system, the risk of premature failure and costly repairs is reduced.\n",
            "\n",
            "To preserve demand distribution when removing minor dead-end pipes, water utilities can use various techniques, such as:\n",
            "\n",
            "1. **Pipe sizing**: Ensuring that the remaining pipes are sized correctly to handle the increased demand.\n",
            "2. **Pressure management**: Implementing pressure management strategies, such as pressure-reducing valves, to maintain a consistent pressure throughout the system.\n",
            "3. **Flow distribution**: Implementing flow distribution strategies, such as flow control valves, to maintain a balanced flow throughout the system.\n",
            "4. **System modeling**: Using system modeling tools to simulate the impact of removing minor dead-end pipes and identify potential issues before they occur.\n",
            "\n",
            "By preserving demand distribution when removing minor dead-end pipes, water utilities can maintain a reliable, efficient, and safe water distribution system that meets the needs of their customers.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the factual accuracy and relevance of the information presented. The actual answer emphasizes the importance of redistributing demand to maintain accurate pressure calculations and water usage patterns, highlighting the integrity of the network.\n",
            "\n",
            "The predicted answer provides a comprehensive overview of the implications of removing minor dead-end pipes, touching on several relevant aspects such as system reliability, pressure management, flow distribution, water quality, energy efficiency, and asset management. Each point is logically connected to the importance of preserving demand distribution, and the suggested techniques for maintaining demand distribution are practical and relevant.\n",
            "\n",
            "However, while the predicted answer is detailed and informative, it does introduce some additional concepts that are not explicitly mentioned in the actual answer, such as energy efficiency and asset management. These points, while relevant, could be seen as slightly diverging from the core focus of the actual answer, which is primarily about pressure calculations and network integrity.\n",
            "\n",
            "Overall, the predicted answer contains mostly factual information with some slight deviations in focus and additional details that do not directly address the core of the actual answer. Therefore, it can be rated as mostly factual with slight hallucinations.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: Why is it important to preserve demand distribution when removing minor dead-end pipes?, Actual answer: Removing dead-end pipes without redistributing their demand can lead to inaccurate pressure calculations and misrepresentation of water usage patterns. Proper aggregation ensures that demand is preserved at the remaining nodes, maintaining network integrity., Predicted answer: Preserving demand distribution when removing minor dead-end pipes is crucial in water distribution systems for several reasons:\n",
            "\n",
            "1. **System Reliability**: Minor dead-end pipes often serve low-demand areas, such as single-family homes or small businesses. When these pipes are removed, the remaining pipes in the system may not be able to handle the increased demand, leading to reduced system reliability and potential water shortages.\n",
            "\n",
            "2. **Pressure Management**: Removing minor dead-end pipes can alter the pressure distribution in the system, potentially causing low pressures in areas that were previously served by these pipes. This can lead to reduced water quality, increased risk of contamination, and decreased system performance.\n",
            "\n",
            "3. **Flow Distribution**: Minor dead-end pipes help to distribute flow throughout the system, particularly in areas with low demand. When these pipes are removed, the flow may become concentrated in other areas, leading to overflows, increased energy consumption, and reduced system efficiency.\n",
            "\n",
            "4. **Water Quality**: Preserving demand distribution helps to maintain a consistent water quality throughout the system. When minor dead-end pipes are removed, the remaining pipes may not be able to handle the increased demand, leading to reduced water quality and increased risk of contamination.\n",
            "\n",
            "5. **Energy Efficiency**: Removing minor dead-end pipes can lead to increased energy consumption, as pumps and other equipment may need to work harder to meet the increased demand. Preserving demand distribution helps to maintain a balanced system, reducing energy consumption and costs.\n",
            "\n",
            "6. **Asset Management**: Preserving demand distribution helps to extend the life of system assets, such as pipes, pumps, and valves. By maintaining a balanced system, the risk of premature failure and costly repairs is reduced.\n",
            "\n",
            "To preserve demand distribution when removing minor dead-end pipes, water utilities can use various techniques, such as:\n",
            "\n",
            "1. **Pipe sizing**: Ensuring that the remaining pipes are sized correctly to handle the increased demand.\n",
            "2. **Pressure management**: Implementing pressure management strategies, such as pressure-reducing valves, to maintain a consistent pressure throughout the system.\n",
            "3. **Flow distribution**: Implementing flow distribution strategies, such as flow control valves, to maintain a balanced flow throughout the system.\n",
            "4. **System modeling**: Using system modeling tools to simulate the impact of removing minor dead-end pipes and identify potential issues before they occur.\n",
            "\n",
            "By preserving demand distribution when removing minor dead-end pipes, water utilities can maintain a reliable, efficient, and safe water distribution system that meets the needs of their customers.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and relevance of the information provided in both responses. The actual answer succinctly highlights the importance of preserving demand distribution when removing minor dead-end pipes, emphasizing the consequences of not doing so, such as inaccurate pressure calculations and misrepresentation of water usage patterns. \n",
            "\n",
            "The predicted answer, while lengthy, covers several relevant points regarding system reliability, pressure management, flow distribution, water quality, energy efficiency, and asset management. It also suggests techniques for preserving demand distribution, which adds practical value. However, it does not directly address the specific consequences of failing to redistribute demand as clearly as the actual answer does. \n",
            "\n",
            "The predicted answer is informative and demonstrates a good understanding of the topic, but it could be seen as somewhat verbose and less focused on the core issue of demand preservation. It does not misinterpret the information but rather expands on it, which could lead to some uncertainty about the main point.\n",
            "\n",
            "Given these considerations, I would assign a score of 4 to the predicted answer. It is correct in its content but does not clearly state that it is wrong or unable to provide a correct answer, and it could be more concise in addressing the main issue.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4, 'judgement_descr': 4}\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [05:31, 29.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : The Hardy Cross method, developed in the 1930s, is a traditional method for solving pipe network problems in water distribution systems. Although it has been largely replaced by more efficient and accurate computer-based methods, there are still certain circumstances where an engineer might opt to use the Hardy Cross method for hand calculations, despite its slower convergence:\n",
            "\n",
            "1. **Simple pipe networks**: For small, simple pipe networks with a limited number of nodes and branches, the Hardy Cross method can still be a viable option for hand calculations. This is because the method is relatively straightforward to apply, and the calculations can be performed quickly and accurately.\n",
            "2. **Preliminary design**: During the preliminary design phase of a water distribution system, engineers may use the Hardy Cross method to quickly estimate the pipe sizes and pressures required to meet the system's demands. This can help identify potential issues and inform the design process.\n",
            "3. **Limited computational resources**: In some cases, engineers may not have access to advanced computer software or computational resources. In such situations, the Hardy Cross method can be a useful alternative for hand calculations.\n",
            "4. **Education and training**: The Hardy Cross method is still taught in many water resources engineering programs as a way to introduce students to the fundamental principles of pipe network analysis. Using the method for hand calculations can help students develop a deeper understanding of the underlying mathematics and principles.\n",
            "5. **Emergency or field situations**: In emergency or field situations where access to computer software or computational resources is limited, the Hardy Cross method can be a useful tool for quick and rough estimates of pipe network performance.\n",
            "6. **Historical or legacy systems**: For older water distribution systems that were designed using the Hardy Cross method, engineers may still need to use the method for hand calculations to understand and maintain the existing system.\n",
            "7. **Simplification of complex problems**: In some cases, the Hardy Cross method can be used to simplify complex pipe network problems by breaking them down into smaller, more manageable components. This can help engineers identify key issues and develop more effective solutions.\n",
            "\n",
            "Overall, while the Hardy Cross method may not be the most efficient or accurate method for solving pipe network problems, it can still be a useful tool for hand calculations in certain circumstances.\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: How does merging pipes in series or parallel contribute to model reduction?, Actual answer: Merging pipes in series reduces the number of elements by replacing multiple connected pipes with a single equivalent pipe with appropriate hydraulic properties. Merging parallel pipes simplifies looped areas by creating an equivalent single pipe, preserving overall flow characteristics while reducing the computational load., Predicted answer: In water engineering, merging pipes in series or parallel is a common technique used to simplify complex pipe networks and reduce the number of equations required to model the system. This process is known as model reduction.\n",
            "\n",
            "**Merging Pipes in Series:**\n",
            "\n",
            "When pipes are connected in series, the flow rate through each pipe is the same, but the pressure drop across each pipe is additive. By merging pipes in series, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in series, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total pressure drop (ΔP) can be calculated as:\n",
            "\n",
            "ΔP = (f1 \\* L1 / D1^5 \\* Q^2) + (f2 \\* L2 / D2^5 \\* Q^2)\n",
            "\n",
            "where Q is the flow rate through the pipes.\n",
            "\n",
            "By merging the pipes in series, we can simplify the equation to:\n",
            "\n",
            "ΔP = (f \\* L / D^5 \\* Q^2)\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Merging Pipes in Parallel:**\n",
            "\n",
            "When pipes are connected in parallel, the pressure drop across each pipe is the same, but the flow rate through each pipe is additive. By merging pipes in parallel, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in parallel, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total flow rate (Q) can be calculated as:\n",
            "\n",
            "Q = Q1 + Q2\n",
            "\n",
            "where Q1 and Q2 are the flow rates through pipe 1 and pipe 2, respectively.\n",
            "\n",
            "By merging the pipes in parallel, we can simplify the equation to:\n",
            "\n",
            "Q = (D^5 \\* ΔP / (f \\* L))^0.5\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Benefits of Model Reduction:**\n",
            "\n",
            "Merging pipes in series or parallel can significantly reduce the number of equations required to model a complex pipe network, making it easier to analyze and simulate the system. This can lead to several benefits, including:\n",
            "\n",
            "1. Reduced computational time: With fewer equations to solve, simulations can run faster and more efficiently.\n",
            "2. Improved accuracy: By simplifying the model, we can reduce the impact of numerical errors and improve the overall accuracy of the simulation.\n",
            "3. Easier analysis: With a reduced number of equations, it's easier to analyze and understand the behavior of the system.\n",
            "\n",
            "However, it's essential to note that merging pipes in series or parallel can also introduce errors if not done correctly. Therefore, it's crucial to carefully evaluate the impact of model reduction on the accuracy and reliability of the simulation results.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the completeness of the predicted answer compared to the actual answer, we need to consider the key elements that were present in the actual answer and see how well the predicted answer covers those elements.\n",
            "\n",
            "The actual answer discusses two main points regarding merging pipes in series and parallel:\n",
            "1. **Merging Pipes in Series**: It explains that this process reduces the number of elements by replacing multiple connected pipes with a single equivalent pipe that has appropriate hydraulic properties.\n",
            "2. **Merging Pipes in Parallel**: It mentions that this simplifies looped areas by creating an equivalent single pipe while preserving overall flow characteristics and reducing computational load.\n",
            "\n",
            "The predicted answer provides a detailed explanation of both merging pipes in series and parallel, including mathematical formulations and benefits of model reduction. It covers:\n",
            "- The concept of merging pipes in series and parallel.\n",
            "- The mathematical derivation for pressure drop in series and flow rate in parallel.\n",
            "- Benefits of model reduction, such as reduced computational time, improved accuracy, and easier analysis.\n",
            "\n",
            "However, while the predicted answer is comprehensive and includes mathematical details, it does not explicitly mention the concept of replacing multiple pipes with a single equivalent pipe or the preservation of overall flow characteristics, which are critical aspects of the actual answer.\n",
            "\n",
            "In summary, the predicted answer covers most elements of a complete answer but lacks some specific details that are present in the actual answer. Therefore, I would assign a score of 4, as it includes most elements but misses a couple of key points.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: How does merging pipes in series or parallel contribute to model reduction?, Actual answer: Merging pipes in series reduces the number of elements by replacing multiple connected pipes with a single equivalent pipe with appropriate hydraulic properties. Merging parallel pipes simplifies looped areas by creating an equivalent single pipe, preserving overall flow characteristics while reducing the computational load., Predicted answer: In water engineering, merging pipes in series or parallel is a common technique used to simplify complex pipe networks and reduce the number of equations required to model the system. This process is known as model reduction.\n",
            "\n",
            "**Merging Pipes in Series:**\n",
            "\n",
            "When pipes are connected in series, the flow rate through each pipe is the same, but the pressure drop across each pipe is additive. By merging pipes in series, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in series, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total pressure drop (ΔP) can be calculated as:\n",
            "\n",
            "ΔP = (f1 \\* L1 / D1^5 \\* Q^2) + (f2 \\* L2 / D2^5 \\* Q^2)\n",
            "\n",
            "where Q is the flow rate through the pipes.\n",
            "\n",
            "By merging the pipes in series, we can simplify the equation to:\n",
            "\n",
            "ΔP = (f \\* L / D^5 \\* Q^2)\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Merging Pipes in Parallel:**\n",
            "\n",
            "When pipes are connected in parallel, the pressure drop across each pipe is the same, but the flow rate through each pipe is additive. By merging pipes in parallel, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in parallel, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total flow rate (Q) can be calculated as:\n",
            "\n",
            "Q = Q1 + Q2\n",
            "\n",
            "where Q1 and Q2 are the flow rates through pipe 1 and pipe 2, respectively.\n",
            "\n",
            "By merging the pipes in parallel, we can simplify the equation to:\n",
            "\n",
            "Q = (D^5 \\* ΔP / (f \\* L))^0.5\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Benefits of Model Reduction:**\n",
            "\n",
            "Merging pipes in series or parallel can significantly reduce the number of equations required to model a complex pipe network, making it easier to analyze and simulate the system. This can lead to several benefits, including:\n",
            "\n",
            "1. Reduced computational time: With fewer equations to solve, simulations can run faster and more efficiently.\n",
            "2. Improved accuracy: By simplifying the model, we can reduce the impact of numerical errors and improve the overall accuracy of the simulation.\n",
            "3. Easier analysis: With a reduced number of equations, it's easier to analyze and understand the behavior of the system.\n",
            "\n",
            "However, it's essential to note that merging pipes in series or parallel can also introduce errors if not done correctly. Therefore, it's crucial to carefully evaluate the impact of model reduction on the accuracy and reliability of the simulation results.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we first need to identify the key components of the original question, which asks about how merging pipes in series or parallel contributes to model reduction. The actual answer succinctly addresses this by explaining the process of merging pipes in series and parallel, highlighting the reduction of elements and the preservation of hydraulic properties.\n",
            "\n",
            "The predicted answer provides a detailed explanation of merging pipes in series and parallel, including mathematical formulations and benefits of model reduction. While it does answer the user's question, it includes extensive technical details and examples that may not be necessary for a straightforward response. This additional information, while relevant to the topic, could be considered excessive for the specific question asked.\n",
            "\n",
            "In terms of relevance:\n",
            "- The predicted answer does answer the question about model reduction through merging pipes.\n",
            "- However, it contains a significant amount of technical detail and examples that may not be directly relevant to the core question, which is more about the concept of model reduction rather than the specific calculations involved.\n",
            "\n",
            "Given this analysis, the predicted answer is relevant but contains more irrelevant information than necessary for a concise response.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : The Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to several reasons:\n",
            "\n",
            "1. **Scalability**: GGA is a robust and efficient algorithm that can handle large-scale water distribution systems with thousands of pipes, nodes, and loops. It can efficiently solve the nonlinear equations that describe the hydraulic behavior of the system, even with a large number of unknowns.\n",
            "\n",
            "2. **Flexibility**: GGA can accommodate various types of pipe networks, including loops, branches, and junctions. It can also handle different types of pipe materials, diameters, and roughness coefficients, making it a versatile tool for analyzing complex water systems.\n",
            "\n",
            "3. **Accuracy**: GGA provides accurate solutions to the hydraulic equations that govern the behavior of water distribution systems. It takes into account the nonlinear interactions between pipes, nodes, and loops, ensuring that the calculated pressures, flows, and head losses are accurate and reliable.\n",
            "\n",
            "4. **Convergence**: GGA uses a gradient-based approach to converge to the solution, which ensures that the algorithm rapidly converges to the optimal solution, even for large and complex systems. This makes it an efficient tool for analyzing water systems with thousands of pipes and loops.\n",
            "\n",
            "5. **Robustness**: GGA is a robust algorithm that can handle a wide range of input data, including noisy or uncertain data. It can also accommodate different types of boundary conditions, such as fixed pressures, flows, or head losses, making it a reliable tool for analyzing complex water systems.\n",
            "\n",
            "6. **Computational efficiency**: GGA is a computationally efficient algorithm that can solve large-scale water distribution systems in a reasonable amount of time. This makes it an ideal tool for analyzing complex systems, such as those with thousands of pipes and loops, where computational efficiency is critical.\n",
            "\n",
            "In summary, the Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to its scalability, flexibility, accuracy, convergence, robustness, and computational efficiency.\n",
            "\u001b[32mUser message:Question: How does merging pipes in series or parallel contribute to model reduction?, Actual answer: Merging pipes in series reduces the number of elements by replacing multiple connected pipes with a single equivalent pipe with appropriate hydraulic properties. Merging parallel pipes simplifies looped areas by creating an equivalent single pipe, preserving overall flow characteristics while reducing the computational load., Predicted answer: In water engineering, merging pipes in series or parallel is a common technique used to simplify complex pipe networks and reduce the number of equations required to model the system. This process is known as model reduction.\n",
            "\n",
            "**Merging Pipes in Series:**\n",
            "\n",
            "When pipes are connected in series, the flow rate through each pipe is the same, but the pressure drop across each pipe is additive. By merging pipes in series, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in series, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total pressure drop (ΔP) can be calculated as:\n",
            "\n",
            "ΔP = (f1 \\* L1 / D1^5 \\* Q^2) + (f2 \\* L2 / D2^5 \\* Q^2)\n",
            "\n",
            "where Q is the flow rate through the pipes.\n",
            "\n",
            "By merging the pipes in series, we can simplify the equation to:\n",
            "\n",
            "ΔP = (f \\* L / D^5 \\* Q^2)\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Merging Pipes in Parallel:**\n",
            "\n",
            "When pipes are connected in parallel, the pressure drop across each pipe is the same, but the flow rate through each pipe is additive. By merging pipes in parallel, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in parallel, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total flow rate (Q) can be calculated as:\n",
            "\n",
            "Q = Q1 + Q2\n",
            "\n",
            "where Q1 and Q2 are the flow rates through pipe 1 and pipe 2, respectively.\n",
            "\n",
            "By merging the pipes in parallel, we can simplify the equation to:\n",
            "\n",
            "Q = (D^5 \\* ΔP / (f \\* L))^0.5\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Benefits of Model Reduction:**\n",
            "\n",
            "Merging pipes in series or parallel can significantly reduce the number of equations required to model a complex pipe network, making it easier to analyze and simulate the system. This can lead to several benefits, including:\n",
            "\n",
            "1. Reduced computational time: With fewer equations to solve, simulations can run faster and more efficiently.\n",
            "2. Improved accuracy: By simplifying the model, we can reduce the impact of numerical errors and improve the overall accuracy of the simulation.\n",
            "3. Easier analysis: With a reduced number of equations, it's easier to analyze and understand the behavior of the system.\n",
            "\n",
            "However, it's essential to note that merging pipes in series or parallel can also introduce errors if not done correctly. Therefore, it's crucial to carefully evaluate the impact of model reduction on the accuracy and reliability of the simulation results.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we first need to analyze the content and structure of both responses. \n",
            "\n",
            "The actual answer is direct and focused, providing a clear explanation of how merging pipes in series and parallel contributes to model reduction. It succinctly describes the process and its implications without unnecessary elaboration.\n",
            "\n",
            "In contrast, the predicted answer is significantly longer and includes detailed mathematical equations and explanations that, while informative, may not be necessary for a concise response. The predicted answer elaborates on the mechanics of merging pipes in series and parallel, which adds complexity and length that detracts from the main point. It also includes a section on the benefits of model reduction, which, while relevant, extends the response beyond what was asked.\n",
            "\n",
            "Given these observations, the predicted answer includes a lot of extra information and uses flowery language, making it less concise than the actual answer. Therefore, I would assign a score of 3 for the predicted response.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: How does merging pipes in series or parallel contribute to model reduction?, Actual answer: Merging pipes in series reduces the number of elements by replacing multiple connected pipes with a single equivalent pipe with appropriate hydraulic properties. Merging parallel pipes simplifies looped areas by creating an equivalent single pipe, preserving overall flow characteristics while reducing the computational load., Predicted answer: In water engineering, merging pipes in series or parallel is a common technique used to simplify complex pipe networks and reduce the number of equations required to model the system. This process is known as model reduction.\n",
            "\n",
            "**Merging Pipes in Series:**\n",
            "\n",
            "When pipes are connected in series, the flow rate through each pipe is the same, but the pressure drop across each pipe is additive. By merging pipes in series, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in series, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total pressure drop (ΔP) can be calculated as:\n",
            "\n",
            "ΔP = (f1 \\* L1 / D1^5 \\* Q^2) + (f2 \\* L2 / D2^5 \\* Q^2)\n",
            "\n",
            "where Q is the flow rate through the pipes.\n",
            "\n",
            "By merging the pipes in series, we can simplify the equation to:\n",
            "\n",
            "ΔP = (f \\* L / D^5 \\* Q^2)\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Merging Pipes in Parallel:**\n",
            "\n",
            "When pipes are connected in parallel, the pressure drop across each pipe is the same, but the flow rate through each pipe is additive. By merging pipes in parallel, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in parallel, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total flow rate (Q) can be calculated as:\n",
            "\n",
            "Q = Q1 + Q2\n",
            "\n",
            "where Q1 and Q2 are the flow rates through pipe 1 and pipe 2, respectively.\n",
            "\n",
            "By merging the pipes in parallel, we can simplify the equation to:\n",
            "\n",
            "Q = (D^5 \\* ΔP / (f \\* L))^0.5\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Benefits of Model Reduction:**\n",
            "\n",
            "Merging pipes in series or parallel can significantly reduce the number of equations required to model a complex pipe network, making it easier to analyze and simulate the system. This can lead to several benefits, including:\n",
            "\n",
            "1. Reduced computational time: With fewer equations to solve, simulations can run faster and more efficiently.\n",
            "2. Improved accuracy: By simplifying the model, we can reduce the impact of numerical errors and improve the overall accuracy of the simulation.\n",
            "3. Easier analysis: With a reduced number of equations, it's easier to analyze and understand the behavior of the system.\n",
            "\n",
            "However, it's essential to note that merging pipes in series or parallel can also introduce errors if not done correctly. Therefore, it's crucial to carefully evaluate the impact of model reduction on the accuracy and reliability of the simulation results.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response captures the essence of model reduction through merging pipes in series and parallel, as well as the confidence conveyed in its assertions.\n",
            "\n",
            "The actual answer succinctly explains the process of merging pipes in series and parallel, emphasizing the reduction of elements and the preservation of hydraulic properties. It highlights the benefits of model reduction, such as reduced computational load and simplified analysis.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, does provide a comprehensive explanation of the merging process for both series and parallel configurations. It includes mathematical formulations that illustrate how merging affects pressure drop and flow rate, which adds depth to the explanation. However, it does not explicitly mention the preservation of overall flow characteristics or the potential for introducing errors, which are critical points in the actual answer.\n",
            "\n",
            "In terms of confidence, the predicted answer presents its information with a degree of assurance, particularly in its mathematical explanations and benefits of model reduction. However, it lacks the concise clarity and directness of the actual answer, which may lead to some uncertainty about its overall correctness.\n",
            "\n",
            "Given these considerations, I would rate the predicted answer as a 4. It leans towards agreement with the actual answer but acknowledges some uncertainty due to its length and complexity, which could obscure the main points.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: How does merging pipes in series or parallel contribute to model reduction?, Actual answer: Merging pipes in series reduces the number of elements by replacing multiple connected pipes with a single equivalent pipe with appropriate hydraulic properties. Merging parallel pipes simplifies looped areas by creating an equivalent single pipe, preserving overall flow characteristics while reducing the computational load., Predicted answer: In water engineering, merging pipes in series or parallel is a common technique used to simplify complex pipe networks and reduce the number of equations required to model the system. This process is known as model reduction.\n",
            "\n",
            "**Merging Pipes in Series:**\n",
            "\n",
            "When pipes are connected in series, the flow rate through each pipe is the same, but the pressure drop across each pipe is additive. By merging pipes in series, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in series, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total pressure drop (ΔP) can be calculated as:\n",
            "\n",
            "ΔP = (f1 \\* L1 / D1^5 \\* Q^2) + (f2 \\* L2 / D2^5 \\* Q^2)\n",
            "\n",
            "where Q is the flow rate through the pipes.\n",
            "\n",
            "By merging the pipes in series, we can simplify the equation to:\n",
            "\n",
            "ΔP = (f \\* L / D^5 \\* Q^2)\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Merging Pipes in Parallel:**\n",
            "\n",
            "When pipes are connected in parallel, the pressure drop across each pipe is the same, but the flow rate through each pipe is additive. By merging pipes in parallel, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in parallel, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total flow rate (Q) can be calculated as:\n",
            "\n",
            "Q = Q1 + Q2\n",
            "\n",
            "where Q1 and Q2 are the flow rates through pipe 1 and pipe 2, respectively.\n",
            "\n",
            "By merging the pipes in parallel, we can simplify the equation to:\n",
            "\n",
            "Q = (D^5 \\* ΔP / (f \\* L))^0.5\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Benefits of Model Reduction:**\n",
            "\n",
            "Merging pipes in series or parallel can significantly reduce the number of equations required to model a complex pipe network, making it easier to analyze and simulate the system. This can lead to several benefits, including:\n",
            "\n",
            "1. Reduced computational time: With fewer equations to solve, simulations can run faster and more efficiently.\n",
            "2. Improved accuracy: By simplifying the model, we can reduce the impact of numerical errors and improve the overall accuracy of the simulation.\n",
            "3. Easier analysis: With a reduced number of equations, it's easier to analyze and understand the behavior of the system.\n",
            "\n",
            "However, it's essential to note that merging pipes in series or parallel can also introduce errors if not done correctly. Therefore, it's crucial to carefully evaluate the impact of model reduction on the accuracy and reliability of the simulation results.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the key points made in both responses regarding the merging of pipes in series and parallel, and how this contributes to model reduction in water engineering.\n",
            "\n",
            "The actual answer succinctly explains that merging pipes in series reduces the number of elements by creating a single equivalent pipe with appropriate hydraulic properties, while merging parallel pipes simplifies looped areas and preserves overall flow characteristics. This captures the essence of model reduction effectively.\n",
            "\n",
            "The predicted answer elaborates on the process of merging pipes in series and parallel, providing mathematical formulations and discussing the benefits of model reduction. It accurately describes the hydraulic principles involved, such as the additive nature of pressure drops in series and the additive nature of flow rates in parallel. It also highlights the benefits of model reduction, including reduced computational time and improved accuracy.\n",
            "\n",
            "However, while the predicted answer is detailed and informative, it introduces some unnecessary complexity with the mathematical equations, which may not be essential for understanding the concept of model reduction. Additionally, it does not explicitly mention the preservation of overall flow characteristics when merging parallel pipes, which is a critical aspect of the actual answer.\n",
            "\n",
            "Overall, the predicted answer contains a significant amount of factual information and accurately describes the principles of merging pipes in series and parallel. However, it also includes some extraneous details and lacks a few key points from the actual answer.\n",
            "\n",
            "Considering these factors, I would assign a score of 4 to the predicted answer, as it includes mostly factual information with slight hallucinations or omissions.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: How does merging pipes in series or parallel contribute to model reduction?, Actual answer: Merging pipes in series reduces the number of elements by replacing multiple connected pipes with a single equivalent pipe with appropriate hydraulic properties. Merging parallel pipes simplifies looped areas by creating an equivalent single pipe, preserving overall flow characteristics while reducing the computational load., Predicted answer: In water engineering, merging pipes in series or parallel is a common technique used to simplify complex pipe networks and reduce the number of equations required to model the system. This process is known as model reduction.\n",
            "\n",
            "**Merging Pipes in Series:**\n",
            "\n",
            "When pipes are connected in series, the flow rate through each pipe is the same, but the pressure drop across each pipe is additive. By merging pipes in series, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in series, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total pressure drop (ΔP) can be calculated as:\n",
            "\n",
            "ΔP = (f1 \\* L1 / D1^5 \\* Q^2) + (f2 \\* L2 / D2^5 \\* Q^2)\n",
            "\n",
            "where Q is the flow rate through the pipes.\n",
            "\n",
            "By merging the pipes in series, we can simplify the equation to:\n",
            "\n",
            "ΔP = (f \\* L / D^5 \\* Q^2)\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Merging Pipes in Parallel:**\n",
            "\n",
            "When pipes are connected in parallel, the pressure drop across each pipe is the same, but the flow rate through each pipe is additive. By merging pipes in parallel, we can combine the individual pipe equations into a single equation, reducing the number of equations required to model the system.\n",
            "\n",
            "Mathematically, if we have two pipes connected in parallel, with pipe 1 having a length L1, diameter D1, and friction factor f1, and pipe 2 having a length L2, diameter D2, and friction factor f2, the total flow rate (Q) can be calculated as:\n",
            "\n",
            "Q = Q1 + Q2\n",
            "\n",
            "where Q1 and Q2 are the flow rates through pipe 1 and pipe 2, respectively.\n",
            "\n",
            "By merging the pipes in parallel, we can simplify the equation to:\n",
            "\n",
            "Q = (D^5 \\* ΔP / (f \\* L))^0.5\n",
            "\n",
            "where f is the combined friction factor, L is the combined length, and D is the combined diameter.\n",
            "\n",
            "**Benefits of Model Reduction:**\n",
            "\n",
            "Merging pipes in series or parallel can significantly reduce the number of equations required to model a complex pipe network, making it easier to analyze and simulate the system. This can lead to several benefits, including:\n",
            "\n",
            "1. Reduced computational time: With fewer equations to solve, simulations can run faster and more efficiently.\n",
            "2. Improved accuracy: By simplifying the model, we can reduce the impact of numerical errors and improve the overall accuracy of the simulation.\n",
            "3. Easier analysis: With a reduced number of equations, it's easier to analyze and understand the behavior of the system.\n",
            "\n",
            "However, it's essential to note that merging pipes in series or parallel can also introduce errors if not done correctly. Therefore, it's crucial to carefully evaluate the impact of model reduction on the accuracy and reliability of the simulation results.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and clarity of the information presented in both responses. The actual answer succinctly explains how merging pipes in series and parallel contributes to model reduction by emphasizing the replacement of multiple pipes with a single equivalent pipe, which simplifies the hydraulic properties and reduces computational load.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, does provide a comprehensive explanation of the merging process for both series and parallel pipes. It correctly identifies the benefits of model reduction, such as reduced computational time and improved accuracy. However, it introduces some unnecessary complexity with mathematical equations that may not be essential for understanding the concept of model reduction in this context. \n",
            "\n",
            "Moreover, the predicted answer does not explicitly mention the preservation of overall flow characteristics, which is a key point in the actual answer. While the predicted response is informative, it could lead to confusion due to its complexity and the introduction of equations that may not be necessary for a general understanding of the topic.\n",
            "\n",
            "In terms of judgment, the predicted answer does not confidently claim a hallucination as truth (score 1), nor does it misinterpret the information (score 2). It does show some uncertainty in its presentation, but it does not explicitly state that it is unsure (score 3). The response is mostly correct but could be seen as overly complicated and not entirely aligned with the essence of the actual answer (score 4).\n",
            "\n",
            "Therefore, the predicted answer is wrong in some aspects but makes it clear that it is attempting to provide a correct answer, albeit with unnecessary complexity.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4, 'judgement_descr': 4}\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11it [06:13, 32.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : In Water Distribution Systems (WDS) modeling, the solution method that typically requires the fewest number of iterations to converge is the Gradient Method, also known as the Linear Programming (LP) method.\n",
            "\n",
            "The Gradient Method is an optimization technique that uses the gradient of the objective function to find the optimal solution. In the context of WDS modeling, the objective function is typically the total head loss or energy loss in the system.\n",
            "\n",
            "The mathematical reason behind the Gradient Method's efficiency lies in its ability to use the gradient of the objective function to guide the search for the optimal solution. The gradient is a vector that points in the direction of the steepest ascent of the objective function. By moving in the direction of the negative gradient (i.e., the direction of the steepest descent), the algorithm can converge to the optimal solution in a relatively small number of iterations.\n",
            "\n",
            "More specifically, the Gradient Method uses the following equation to update the solution at each iteration:\n",
            "\n",
            "x_new = x_old - α \\* ∇f(x_old)\n",
            "\n",
            "where:\n",
            "\n",
            "* x_old is the current solution\n",
            "* x_new is the new solution\n",
            "* α is the step size (a small positive value)\n",
            "* ∇f(x_old) is the gradient of the objective function at the current solution\n",
            "* f(x_old) is the objective function value at the current solution\n",
            "\n",
            "The Gradient Method requires the fewest number of iterations to converge because it uses the gradient of the objective function to guide the search for the optimal solution. This allows the algorithm to move quickly towards the optimal solution, reducing the number of iterations required to converge.\n",
            "\n",
            "However, it's worth noting that the Gradient Method can be sensitive to the choice of step size (α) and the initial solution. If the step size is too large, the algorithm may overshoot the optimal solution, while a step size that is too small may lead to slow convergence. Additionally, if the initial solution is far from the optimal solution, the algorithm may require more iterations to converge.\n",
            "\n",
            "In contrast, other WDS solution methods, such as the Newton-Raphson method, may require more iterations to converge because they use a more complex update equation that involves the Hessian matrix of the objective function. The Hessian matrix is a matrix of second derivatives that describes the curvature of the objective function. While the Newton-Raphson method can be more efficient than the Gradient Method in some cases, it requires more computational effort to compute the Hessian matrix and its inverse.\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: What are the main techniques for skeletonizing a water distribution network?, Actual answer: Common techniques include merging pipes in series or parallel to create an equivalent hydraulic representation, removing dead-end pipes with minimal hydraulic impact, aggregating demand nodes, and pruning redundant loops. Additionally, resilience-based skeletonization selects pipes for removal based on their contribution to system stability., Predicted answer: Skeletonizing a water distribution network involves reducing the complexity of the network while preserving its essential characteristics. The main techniques for skeletonizing a water distribution network are:\n",
            "\n",
            "1. **Minimum Spanning Tree (MST)**: This technique involves finding the subset of edges in the network that connects all nodes while minimizing the total length of the edges. MST is a widely used method for skeletonizing water distribution networks, as it preserves the connectivity of the network while reducing its complexity.\n",
            "\n",
            "2. **Maximum Spanning Tree (MST)**: This technique is similar to MST, but it finds the subset of edges that connects all nodes while maximizing the total length of the edges. MST is useful for identifying the most critical components of the network.\n",
            "\n",
            "3. **Hierarchical Network Decomposition (HND)**: This technique involves decomposing the network into a hierarchy of sub-networks, with each sub-network representing a level of abstraction. HND is useful for identifying the most critical components of the network and for simplifying the network while preserving its essential characteristics.\n",
            "\n",
            "4. **Graph Simplification**: This technique involves removing edges or nodes from the network while preserving its connectivity. Graph simplification can be used to reduce the complexity of the network while preserving its essential characteristics.\n",
            "\n",
            "5. **Network Reduction**: This technique involves reducing the number of nodes or edges in the network while preserving its connectivity. Network reduction can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "6. **Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. Clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "7. **Principal Component Analysis (PCA)**: This technique involves reducing the dimensionality of the network by projecting it onto a lower-dimensional space. PCA can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "8. **K-Means Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. K-Means clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "9. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. DBSCAN can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "These techniques can be used individually or in combination to skeletonize a water distribution network. The choice of technique depends on the specific characteristics of the network and the goals of the skeletonization process.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the completeness of the predicted answer compared to the actual answer, we need to analyze the key elements present in both responses. \n",
            "\n",
            "The actual answer mentions specific techniques for skeletonizing a water distribution network, including merging pipes, removing dead-end pipes, aggregating demand nodes, pruning redundant loops, and resilience-based skeletonization. These techniques focus on maintaining hydraulic integrity and system stability.\n",
            "\n",
            "The predicted answer, while extensive, introduces several techniques that are not explicitly mentioned in the actual answer, such as Minimum Spanning Tree, Maximum Spanning Tree, Hierarchical Network Decomposition, Graph Simplification, Network Reduction, Clustering, Principal Component Analysis, K-Means Clustering, and DBSCAN. While these techniques may be relevant to network simplification, they do not directly address the specific techniques highlighted in the actual answer.\n",
            "\n",
            "The predicted response does cover a range of methods for skeletonization, but it lacks the specific focus on hydraulic representation and system stability that the actual answer emphasizes. It also introduces concepts that may not be directly applicable to the context of water distribution networks.\n",
            "\n",
            "In summary, the predicted answer includes many relevant techniques but does not fully align with the specific techniques and focus areas outlined in the actual answer. Therefore, it presents a mix of relevant and less relevant information.\n",
            "\n",
            "Given this analysis, I would assign a score of 3, as the predicted answer contains some relevant elements but does not fully capture the completeness of the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: What are the main techniques for skeletonizing a water distribution network?, Actual answer: Common techniques include merging pipes in series or parallel to create an equivalent hydraulic representation, removing dead-end pipes with minimal hydraulic impact, aggregating demand nodes, and pruning redundant loops. Additionally, resilience-based skeletonization selects pipes for removal based on their contribution to system stability., Predicted answer: Skeletonizing a water distribution network involves reducing the complexity of the network while preserving its essential characteristics. The main techniques for skeletonizing a water distribution network are:\n",
            "\n",
            "1. **Minimum Spanning Tree (MST)**: This technique involves finding the subset of edges in the network that connects all nodes while minimizing the total length of the edges. MST is a widely used method for skeletonizing water distribution networks, as it preserves the connectivity of the network while reducing its complexity.\n",
            "\n",
            "2. **Maximum Spanning Tree (MST)**: This technique is similar to MST, but it finds the subset of edges that connects all nodes while maximizing the total length of the edges. MST is useful for identifying the most critical components of the network.\n",
            "\n",
            "3. **Hierarchical Network Decomposition (HND)**: This technique involves decomposing the network into a hierarchy of sub-networks, with each sub-network representing a level of abstraction. HND is useful for identifying the most critical components of the network and for simplifying the network while preserving its essential characteristics.\n",
            "\n",
            "4. **Graph Simplification**: This technique involves removing edges or nodes from the network while preserving its connectivity. Graph simplification can be used to reduce the complexity of the network while preserving its essential characteristics.\n",
            "\n",
            "5. **Network Reduction**: This technique involves reducing the number of nodes or edges in the network while preserving its connectivity. Network reduction can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "6. **Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. Clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "7. **Principal Component Analysis (PCA)**: This technique involves reducing the dimensionality of the network by projecting it onto a lower-dimensional space. PCA can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "8. **K-Means Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. K-Means clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "9. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. DBSCAN can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "These techniques can be used individually or in combination to skeletonize a water distribution network. The choice of technique depends on the specific characteristics of the network and the goals of the skeletonization process.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the relevance of the information provided in both responses concerning the user's question about the main techniques for skeletonizing a water distribution network.\n",
            "\n",
            "The actual answer lists specific techniques such as merging pipes, removing dead-end pipes, aggregating demand nodes, pruning redundant loops, and resilience-based skeletonization. These techniques are directly related to the hydraulic representation and operational efficiency of water distribution networks.\n",
            "\n",
            "The predicted answer, while providing a comprehensive list of techniques, includes methods like Minimum Spanning Tree, Maximum Spanning Tree, Hierarchical Network Decomposition, and various clustering techniques. While these methods may be relevant in a broader context of network analysis, they do not directly align with the specific techniques mentioned in the actual answer. Additionally, some techniques like PCA and DBSCAN, while useful in data analysis, may not be standard practices in the context of skeletonizing water distribution networks.\n",
            "\n",
            "Overall, the predicted answer does provide some relevant information but also includes a significant amount of irrelevant content that does not directly address the user's question. Therefore, it does not fully meet the criteria for a high relevance score.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: What are the main techniques for skeletonizing a water distribution network?, Actual answer: Common techniques include merging pipes in series or parallel to create an equivalent hydraulic representation, removing dead-end pipes with minimal hydraulic impact, aggregating demand nodes, and pruning redundant loops. Additionally, resilience-based skeletonization selects pipes for removal based on their contribution to system stability., Predicted answer: Skeletonizing a water distribution network involves reducing the complexity of the network while preserving its essential characteristics. The main techniques for skeletonizing a water distribution network are:\n",
            "\n",
            "1. **Minimum Spanning Tree (MST)**: This technique involves finding the subset of edges in the network that connects all nodes while minimizing the total length of the edges. MST is a widely used method for skeletonizing water distribution networks, as it preserves the connectivity of the network while reducing its complexity.\n",
            "\n",
            "2. **Maximum Spanning Tree (MST)**: This technique is similar to MST, but it finds the subset of edges that connects all nodes while maximizing the total length of the edges. MST is useful for identifying the most critical components of the network.\n",
            "\n",
            "3. **Hierarchical Network Decomposition (HND)**: This technique involves decomposing the network into a hierarchy of sub-networks, with each sub-network representing a level of abstraction. HND is useful for identifying the most critical components of the network and for simplifying the network while preserving its essential characteristics.\n",
            "\n",
            "4. **Graph Simplification**: This technique involves removing edges or nodes from the network while preserving its connectivity. Graph simplification can be used to reduce the complexity of the network while preserving its essential characteristics.\n",
            "\n",
            "5. **Network Reduction**: This technique involves reducing the number of nodes or edges in the network while preserving its connectivity. Network reduction can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "6. **Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. Clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "7. **Principal Component Analysis (PCA)**: This technique involves reducing the dimensionality of the network by projecting it onto a lower-dimensional space. PCA can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "8. **K-Means Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. K-Means clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "9. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. DBSCAN can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "These techniques can be used individually or in combination to skeletonize a water distribution network. The choice of technique depends on the specific characteristics of the network and the goals of the skeletonization process.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information provided in the predicted response. The actual answer succinctly lists the main techniques for skeletonizing a water distribution network, focusing on practical methods without unnecessary elaboration. In contrast, the predicted answer provides an extensive list of techniques, many of which are not commonly associated with water distribution networks, and includes detailed explanations for each technique.\n",
            "\n",
            "The predicted answer is significantly longer and includes a lot of extra information, such as definitions and applications of techniques like Minimum Spanning Tree, Maximum Spanning Tree, and various clustering methods. This additional detail detracts from the conciseness of the response, making it less effective in directly addressing the question.\n",
            "\n",
            "Given this analysis, the predicted response includes a lot of extra information and uses flowery language, which makes it less concise than the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 3, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: What are the main techniques for skeletonizing a water distribution network?, Actual answer: Common techniques include merging pipes in series or parallel to create an equivalent hydraulic representation, removing dead-end pipes with minimal hydraulic impact, aggregating demand nodes, and pruning redundant loops. Additionally, resilience-based skeletonization selects pipes for removal based on their contribution to system stability., Predicted answer: Skeletonizing a water distribution network involves reducing the complexity of the network while preserving its essential characteristics. The main techniques for skeletonizing a water distribution network are:\n",
            "\n",
            "1. **Minimum Spanning Tree (MST)**: This technique involves finding the subset of edges in the network that connects all nodes while minimizing the total length of the edges. MST is a widely used method for skeletonizing water distribution networks, as it preserves the connectivity of the network while reducing its complexity.\n",
            "\n",
            "2. **Maximum Spanning Tree (MST)**: This technique is similar to MST, but it finds the subset of edges that connects all nodes while maximizing the total length of the edges. MST is useful for identifying the most critical components of the network.\n",
            "\n",
            "3. **Hierarchical Network Decomposition (HND)**: This technique involves decomposing the network into a hierarchy of sub-networks, with each sub-network representing a level of abstraction. HND is useful for identifying the most critical components of the network and for simplifying the network while preserving its essential characteristics.\n",
            "\n",
            "4. **Graph Simplification**: This technique involves removing edges or nodes from the network while preserving its connectivity. Graph simplification can be used to reduce the complexity of the network while preserving its essential characteristics.\n",
            "\n",
            "5. **Network Reduction**: This technique involves reducing the number of nodes or edges in the network while preserving its connectivity. Network reduction can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "6. **Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. Clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "7. **Principal Component Analysis (PCA)**: This technique involves reducing the dimensionality of the network by projecting it onto a lower-dimensional space. PCA can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "8. **K-Means Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. K-Means clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "9. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. DBSCAN can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "These techniques can be used individually or in combination to skeletonize a water distribution network. The choice of technique depends on the specific characteristics of the network and the goals of the skeletonization process.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the confidence conveyed in both responses regarding the techniques for skeletonizing a water distribution network. \n",
            "\n",
            "The actual answer provides a concise list of common techniques, emphasizing practical methods such as merging pipes, removing dead-end pipes, and resilience-based skeletonization. It reflects a clear understanding of the subject matter and presents techniques that are widely recognized in the field.\n",
            "\n",
            "In contrast, the predicted answer presents a more extensive list of techniques, including some that are less conventional or not typically associated with water distribution networks, such as Principal Component Analysis (PCA) and clustering methods like K-Means and DBSCAN. While these methods may have applications in data analysis or other fields, their relevance to skeletonizing water distribution networks is questionable. The predicted answer does convey a sense of thoroughness and attempts to cover various methods, but it lacks the focused confidence that the actual answer demonstrates.\n",
            "\n",
            "The predicted answer's confidence is somewhat diluted by the inclusion of less relevant techniques and the overall complexity of the response. It does not clearly assert the correctness of the techniques listed, leading to a sense of uncertainty about the appropriateness of the methods mentioned.\n",
            "\n",
            "Given these considerations, I would assign a score of 3 to the predicted answer, indicating uncertainty. It presents a range of techniques but lacks the focused confidence and relevance found in the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: What are the main techniques for skeletonizing a water distribution network?, Actual answer: Common techniques include merging pipes in series or parallel to create an equivalent hydraulic representation, removing dead-end pipes with minimal hydraulic impact, aggregating demand nodes, and pruning redundant loops. Additionally, resilience-based skeletonization selects pipes for removal based on their contribution to system stability., Predicted answer: Skeletonizing a water distribution network involves reducing the complexity of the network while preserving its essential characteristics. The main techniques for skeletonizing a water distribution network are:\n",
            "\n",
            "1. **Minimum Spanning Tree (MST)**: This technique involves finding the subset of edges in the network that connects all nodes while minimizing the total length of the edges. MST is a widely used method for skeletonizing water distribution networks, as it preserves the connectivity of the network while reducing its complexity.\n",
            "\n",
            "2. **Maximum Spanning Tree (MST)**: This technique is similar to MST, but it finds the subset of edges that connects all nodes while maximizing the total length of the edges. MST is useful for identifying the most critical components of the network.\n",
            "\n",
            "3. **Hierarchical Network Decomposition (HND)**: This technique involves decomposing the network into a hierarchy of sub-networks, with each sub-network representing a level of abstraction. HND is useful for identifying the most critical components of the network and for simplifying the network while preserving its essential characteristics.\n",
            "\n",
            "4. **Graph Simplification**: This technique involves removing edges or nodes from the network while preserving its connectivity. Graph simplification can be used to reduce the complexity of the network while preserving its essential characteristics.\n",
            "\n",
            "5. **Network Reduction**: This technique involves reducing the number of nodes or edges in the network while preserving its connectivity. Network reduction can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "6. **Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. Clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "7. **Principal Component Analysis (PCA)**: This technique involves reducing the dimensionality of the network by projecting it onto a lower-dimensional space. PCA can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "8. **K-Means Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. K-Means clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "9. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. DBSCAN can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "These techniques can be used individually or in combination to skeletonize a water distribution network. The choice of technique depends on the specific characteristics of the network and the goals of the skeletonization process.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the factual accuracy of the techniques mentioned and their relevance to skeletonizing a water distribution network. \n",
            "\n",
            "The actual answer lists specific techniques that are directly related to the hydraulic representation and operational efficiency of water distribution networks, such as merging pipes, removing dead-end pipes, aggregating demand nodes, and pruning redundant loops. It also mentions resilience-based skeletonization, which is a critical aspect of maintaining system stability.\n",
            "\n",
            "In contrast, the predicted answer introduces several techniques that, while they may be relevant in broader contexts of network analysis or graph theory, do not specifically align with the established practices in water distribution network skeletonization. For example, the Minimum Spanning Tree (MST) and Maximum Spanning Tree (MST) are more general graph theory concepts and may not directly apply to the hydraulic considerations of water distribution systems. Techniques like Principal Component Analysis (PCA) and clustering methods (K-Means, DBSCAN) are also more aligned with data analysis rather than the practical engineering of water distribution networks.\n",
            "\n",
            "The predicted answer contains a mix of relevant and irrelevant techniques, leading to a significant amount of factual inaccuracies regarding the specific context of water distribution networks. Therefore, it does not fully align with the actual answer's focus on hydraulic representation and operational efficiency.\n",
            "\n",
            "Given this analysis, I would assign a score of 3 to the predicted answer, as it contains a mix of both factual information and hallucinations, but does not fully capture the essence of the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 3, 'factuality_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error running target function: probability tensor contains either `inf`, `nan` or element < 0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mUser message:Question: What are the main techniques for skeletonizing a water distribution network?, Actual answer: Common techniques include merging pipes in series or parallel to create an equivalent hydraulic representation, removing dead-end pipes with minimal hydraulic impact, aggregating demand nodes, and pruning redundant loops. Additionally, resilience-based skeletonization selects pipes for removal based on their contribution to system stability., Predicted answer: Skeletonizing a water distribution network involves reducing the complexity of the network while preserving its essential characteristics. The main techniques for skeletonizing a water distribution network are:\n",
            "\n",
            "1. **Minimum Spanning Tree (MST)**: This technique involves finding the subset of edges in the network that connects all nodes while minimizing the total length of the edges. MST is a widely used method for skeletonizing water distribution networks, as it preserves the connectivity of the network while reducing its complexity.\n",
            "\n",
            "2. **Maximum Spanning Tree (MST)**: This technique is similar to MST, but it finds the subset of edges that connects all nodes while maximizing the total length of the edges. MST is useful for identifying the most critical components of the network.\n",
            "\n",
            "3. **Hierarchical Network Decomposition (HND)**: This technique involves decomposing the network into a hierarchy of sub-networks, with each sub-network representing a level of abstraction. HND is useful for identifying the most critical components of the network and for simplifying the network while preserving its essential characteristics.\n",
            "\n",
            "4. **Graph Simplification**: This technique involves removing edges or nodes from the network while preserving its connectivity. Graph simplification can be used to reduce the complexity of the network while preserving its essential characteristics.\n",
            "\n",
            "5. **Network Reduction**: This technique involves reducing the number of nodes or edges in the network while preserving its connectivity. Network reduction can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "6. **Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. Clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "7. **Principal Component Analysis (PCA)**: This technique involves reducing the dimensionality of the network by projecting it onto a lower-dimensional space. PCA can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "8. **K-Means Clustering**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. K-Means clustering can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "9. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: This technique involves grouping nodes or edges in the network into clusters, with each cluster representing a level of abstraction. DBSCAN can be used to simplify the network while preserving its essential characteristics.\n",
            "\n",
            "These techniques can be used individually or in combination to skeletonize a water distribution network. The choice of technique depends on the specific characteristics of the network and the goals of the skeletonization process.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and relevance of the techniques mentioned in both responses. The actual answer provides a concise list of techniques that are specifically tailored to the context of water distribution networks, such as merging pipes, removing dead-end pipes, and resilience-based skeletonization. These techniques are practical and directly applicable to the task of skeletonizing a water distribution network.\n",
            "\n",
            "In contrast, the predicted answer introduces several techniques that, while they may be relevant in a broader context of network analysis, do not specifically address the unique requirements of water distribution networks. For example, techniques like Minimum Spanning Tree (MST) and Maximum Spanning Tree (MST) are more general graph theory concepts and may not directly apply to the hydraulic considerations of water distribution systems. Additionally, methods like Principal Component Analysis (PCA) and clustering techniques, while useful in data analysis, do not align with the practical hydraulic focus of the actual answer.\n",
            "\n",
            "The predicted answer does provide a comprehensive overview of various techniques, but it lacks the specificity and relevance to water distribution networks that the actual answer demonstrates. This indicates a misunderstanding of the prompt's requirements.\n",
            "\n",
            "Given these considerations, the predicted answer shows a lack of alignment with the actual answer's focus and specificity, leading to a judgment that it misinterprets the information received in the prompt.\n",
            "\n",
            "FINAL SCORE: 2\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 3, 'factuality_descr': 3, 'judgement_descr': 2}\n",
            "\n",
            "\n",
            "No output from LLM\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: How have researchers attempted to further improve the GGA, such as by using parallel processing or advanced linear algebra routines?, Actual answer: Many researchers have examined alternative factorization methods (e.g., iterative solvers, multigrid approaches) or have parallelized the matrix assembly and solution steps to exploit modern multi-core CPUs and GPUs. In some studies, domain decomposition is used to split large networks into subregions that can be solved in parallel, with the solutions then merged at each iteration. While these techniques can offer speedups for extremely large models, the gains vary depending on network structure and overhead associated with partitioning and communication between subdomains., Predicted answer: The Generalized Gradient Approximation (GGA) is a type of exchange-correlation functional used in density functional theory (DFT) to approximate the exchange-correlation energy of a many-electron system. Researchers have attempted to improve the GGA in various ways, including:\n",
            "\n",
            "1. **Parallel processing**: To speed up the calculations, researchers have employed parallel processing techniques, such as:\n",
            "\t* **Message Passing Interface (MPI)**: MPI is a standardized and portable message-passing system designed to function on a wide variety of parallel computers.\n",
            "\t* **Open Multi-Processing (OpenMP)**: OpenMP is an API that supports multi-platform shared-memory parallel programming in C, C++, and Fortran.\n",
            "\t* **Graphics Processing Units (GPUs)**: GPUs have been used to accelerate GGA calculations, taking advantage of their massive parallel processing capabilities.\n",
            "2. **Advanced linear algebra routines**: Researchers have employed optimized linear algebra libraries, such as:\n",
            "\t* **BLAS (Basic Linear Algebra Subprograms)**: BLAS is a widely used library for basic linear algebra operations.\n",
            "\t* **LAPACK (Linear Algebra Package)**: LAPACK is a library of Fortran 77 subroutines for solving systems of linear scalar equations, linear least squares problems, eigenvalue problems, and singular value decomposition problems.\n",
            "\t* **MKL (Math Kernel Library)**: MKL is a high-performance linear algebra library developed by Intel.\n",
            "3. **Optimized GGA functionals**: Researchers have developed optimized GGA functionals, such as:\n",
            "\t* **PBE (Perdew-Burke-Ernzerhof)**: PBE is a widely used GGA functional that has been optimized for various systems.\n",
            "\t* **PBEsol**: PBEsol is a modified version of PBE that has been optimized for solids.\n",
            "\t* **SCAN (Strongly Constrained and Appropriately Normed)**: SCAN is a meta-GGA functional that has been optimized for a wide range of systems.\n",
            "4. **Hybrid functionals**: Researchers have combined GGA functionals with Hartree-Fock (HF) exchange to create hybrid functionals, such as:\n",
            "\t* **B3LYP**: B3LYP is a hybrid functional that combines 20% HF exchange with 80% GGA exchange.\n",
            "\t* **PBE0**: PBE0 is a hybrid functional that combines 25% HF exchange with 75% GGA exchange.\n",
            "5. **Machine learning-based GGA functionals**: Researchers have used machine learning techniques to develop new GGA functionals, such as:\n",
            "\t* **ML-GGA**: ML-GGA is a machine learning-based GGA functional that has been optimized for a wide range of systems.\n",
            "\n",
            "These are just a few examples of how researchers have attempted to improve the GGA. The development of new GGA functionals and optimization techniques continues to be an active area of research in the field of density functional theory.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the completeness of the predicted answer compared to the actual answer, we need to analyze the key elements present in both responses. The actual answer focuses on specific methods researchers have used to improve the Generalized Gradient Approximation (GGA), including alternative factorization methods, parallel processing, and domain decomposition. It also mentions the variability of speedup gains based on network structure and overhead.\n",
            "\n",
            "The predicted answer, while extensive, primarily discusses parallel processing techniques, advanced linear algebra routines, optimized GGA functionals, hybrid functionals, and machine learning-based GGA functionals. It does cover parallel processing in detail, which is relevant, but it lacks the mention of alternative factorization methods and domain decomposition, which are crucial elements of the actual answer. Additionally, the predicted answer does not address the variability of performance gains based on network structure, which is an important aspect of the actual response.\n",
            "\n",
            "Overall, the predicted answer includes many relevant points but misses some critical elements that would make it a complete response. Therefore, it can be rated as having most elements of a complete answer but not all.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12it [07:04, 38.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : In modern water distribution systems, gradient-based methods are widely used for hydraulic analysis and optimization. When dealing with nodes where the available pressure is insufficient to meet the specified demand, these methods employ various techniques to handle such situations. Here are some common approaches:\n",
            "\n",
            "1. **Pressure-Dependent Demand (PDD) Modeling**: In this approach, the demand at a node is modeled as a function of the available pressure. If the pressure is below a certain threshold, the demand is reduced accordingly. This allows the model to capture the non-linear relationship between pressure and demand.\n",
            "2. **Demand Reduction**: When the available pressure is insufficient, the demand at the node is reduced to match the available pressure. This can be done using a demand reduction factor, which is a function of the pressure deficit.\n",
            "3. **Pressure-Driven Demand**: In this approach, the demand at a node is driven by the available pressure. If the pressure is below a certain threshold, the demand is reduced, and if the pressure is above the threshold, the demand is increased.\n",
            "4. **Node Splitting**: If the available pressure is insufficient to meet the specified demand at a node, the node can be split into multiple smaller nodes, each with a reduced demand. This allows the model to better capture the hydraulic behavior of the system.\n",
            "5. **Pressure-Dependent Pipe Roughness**: In some models, the pipe roughness is modeled as a function of the available pressure. If the pressure is below a certain threshold, the pipe roughness is increased, which can lead to a reduction in the available pressure.\n",
            "6. **Hydraulic Reliability Index (HRI)**: The HRI is a measure of the hydraulic reliability of a node, which takes into account the available pressure, demand, and pipe roughness. If the HRI is below a certain threshold, the node is considered unreliable, and the demand is reduced accordingly.\n",
            "7. **Gradient-Based Optimization**: Gradient-based optimization methods, such as gradient descent or quasi-Newton methods, can be used to optimize the water distribution system to meet the specified demands while minimizing the pressure deficits.\n",
            "\n",
            "These are some of the common techniques used in modern gradient-based methods to handle nodes where the available pressure is insufficient to meet the specified demand. The choice of technique depends on the specific problem, the available data, and the desired level of accuracy.\n",
            "\u001b[32mUser message:Question: How have researchers attempted to further improve the GGA, such as by using parallel processing or advanced linear algebra routines?, Actual answer: Many researchers have examined alternative factorization methods (e.g., iterative solvers, multigrid approaches) or have parallelized the matrix assembly and solution steps to exploit modern multi-core CPUs and GPUs. In some studies, domain decomposition is used to split large networks into subregions that can be solved in parallel, with the solutions then merged at each iteration. While these techniques can offer speedups for extremely large models, the gains vary depending on network structure and overhead associated with partitioning and communication between subdomains., Predicted answer: The Generalized Gradient Approximation (GGA) is a type of exchange-correlation functional used in density functional theory (DFT) to approximate the exchange-correlation energy of a many-electron system. Researchers have attempted to improve the GGA in various ways, including:\n",
            "\n",
            "1. **Parallel processing**: To speed up the calculations, researchers have employed parallel processing techniques, such as:\n",
            "\t* **Message Passing Interface (MPI)**: MPI is a standardized and portable message-passing system designed to function on a wide variety of parallel computers.\n",
            "\t* **Open Multi-Processing (OpenMP)**: OpenMP is an API that supports multi-platform shared-memory parallel programming in C, C++, and Fortran.\n",
            "\t* **Graphics Processing Units (GPUs)**: GPUs have been used to accelerate GGA calculations, taking advantage of their massive parallel processing capabilities.\n",
            "2. **Advanced linear algebra routines**: Researchers have employed optimized linear algebra libraries, such as:\n",
            "\t* **BLAS (Basic Linear Algebra Subprograms)**: BLAS is a widely used library for basic linear algebra operations.\n",
            "\t* **LAPACK (Linear Algebra Package)**: LAPACK is a library of Fortran 77 subroutines for solving systems of linear scalar equations, linear least squares problems, eigenvalue problems, and singular value decomposition problems.\n",
            "\t* **MKL (Math Kernel Library)**: MKL is a high-performance linear algebra library developed by Intel.\n",
            "3. **Optimized GGA functionals**: Researchers have developed optimized GGA functionals, such as:\n",
            "\t* **PBE (Perdew-Burke-Ernzerhof)**: PBE is a widely used GGA functional that has been optimized for various systems.\n",
            "\t* **PBEsol**: PBEsol is a modified version of PBE that has been optimized for solids.\n",
            "\t* **SCAN (Strongly Constrained and Appropriately Normed)**: SCAN is a meta-GGA functional that has been optimized for a wide range of systems.\n",
            "4. **Hybrid functionals**: Researchers have combined GGA functionals with Hartree-Fock (HF) exchange to create hybrid functionals, such as:\n",
            "\t* **B3LYP**: B3LYP is a hybrid functional that combines 20% HF exchange with 80% GGA exchange.\n",
            "\t* **PBE0**: PBE0 is a hybrid functional that combines 25% HF exchange with 75% GGA exchange.\n",
            "5. **Machine learning-based GGA functionals**: Researchers have used machine learning techniques to develop new GGA functionals, such as:\n",
            "\t* **ML-GGA**: ML-GGA is a machine learning-based GGA functional that has been optimized for a wide range of systems.\n",
            "\n",
            "These are just a few examples of how researchers have attempted to improve the GGA. The development of new GGA functionals and optimization techniques continues to be an active area of research in the field of density functional theory.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about improvements to the Generalized Gradient Approximation (GGA) through parallel processing and advanced linear algebra routines. \n",
            "\n",
            "The actual answer focuses specifically on methods like iterative solvers, multigrid approaches, and domain decomposition, emphasizing their application in parallel processing and the context of large networks. It also discusses the trade-offs involved in these methods.\n",
            "\n",
            "The predicted answer, while informative and detailed, diverges from the specific focus of the question. It provides a broad overview of GGA, including various methods of improvement such as parallel processing techniques (MPI, OpenMP, GPUs), advanced linear algebra routines (BLAS, LAPACK, MKL), optimized GGA functionals, hybrid functionals, and machine learning-based functionals. While it does mention parallel processing and advanced linear algebra, it includes a lot of additional information that is not directly relevant to the user's question.\n",
            "\n",
            "Given this analysis, the predicted answer does answer the user's question but contains a significant amount of irrelevant information, making it less focused than the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: How have researchers attempted to further improve the GGA, such as by using parallel processing or advanced linear algebra routines?, Actual answer: Many researchers have examined alternative factorization methods (e.g., iterative solvers, multigrid approaches) or have parallelized the matrix assembly and solution steps to exploit modern multi-core CPUs and GPUs. In some studies, domain decomposition is used to split large networks into subregions that can be solved in parallel, with the solutions then merged at each iteration. While these techniques can offer speedups for extremely large models, the gains vary depending on network structure and overhead associated with partitioning and communication between subdomains., Predicted answer: The Generalized Gradient Approximation (GGA) is a type of exchange-correlation functional used in density functional theory (DFT) to approximate the exchange-correlation energy of a many-electron system. Researchers have attempted to improve the GGA in various ways, including:\n",
            "\n",
            "1. **Parallel processing**: To speed up the calculations, researchers have employed parallel processing techniques, such as:\n",
            "\t* **Message Passing Interface (MPI)**: MPI is a standardized and portable message-passing system designed to function on a wide variety of parallel computers.\n",
            "\t* **Open Multi-Processing (OpenMP)**: OpenMP is an API that supports multi-platform shared-memory parallel programming in C, C++, and Fortran.\n",
            "\t* **Graphics Processing Units (GPUs)**: GPUs have been used to accelerate GGA calculations, taking advantage of their massive parallel processing capabilities.\n",
            "2. **Advanced linear algebra routines**: Researchers have employed optimized linear algebra libraries, such as:\n",
            "\t* **BLAS (Basic Linear Algebra Subprograms)**: BLAS is a widely used library for basic linear algebra operations.\n",
            "\t* **LAPACK (Linear Algebra Package)**: LAPACK is a library of Fortran 77 subroutines for solving systems of linear scalar equations, linear least squares problems, eigenvalue problems, and singular value decomposition problems.\n",
            "\t* **MKL (Math Kernel Library)**: MKL is a high-performance linear algebra library developed by Intel.\n",
            "3. **Optimized GGA functionals**: Researchers have developed optimized GGA functionals, such as:\n",
            "\t* **PBE (Perdew-Burke-Ernzerhof)**: PBE is a widely used GGA functional that has been optimized for various systems.\n",
            "\t* **PBEsol**: PBEsol is a modified version of PBE that has been optimized for solids.\n",
            "\t* **SCAN (Strongly Constrained and Appropriately Normed)**: SCAN is a meta-GGA functional that has been optimized for a wide range of systems.\n",
            "4. **Hybrid functionals**: Researchers have combined GGA functionals with Hartree-Fock (HF) exchange to create hybrid functionals, such as:\n",
            "\t* **B3LYP**: B3LYP is a hybrid functional that combines 20% HF exchange with 80% GGA exchange.\n",
            "\t* **PBE0**: PBE0 is a hybrid functional that combines 25% HF exchange with 75% GGA exchange.\n",
            "5. **Machine learning-based GGA functionals**: Researchers have used machine learning techniques to develop new GGA functionals, such as:\n",
            "\t* **ML-GGA**: ML-GGA is a machine learning-based GGA functional that has been optimized for a wide range of systems.\n",
            "\n",
            "These are just a few examples of how researchers have attempted to improve the GGA. The development of new GGA functionals and optimization techniques continues to be an active area of research in the field of density functional theory.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information provided in the predicted response relative to the user's question. The actual answer is focused and directly addresses the improvements in GGA through specific methods like parallel processing and advanced linear algebra routines, while the predicted answer expands significantly on these points.\n",
            "\n",
            "The predicted answer begins with a detailed introduction to GGA, which, while informative, is not directly relevant to the question about improvements. It then lists various methods in a structured format, including parallel processing techniques and advanced linear algebra routines, but also includes extensive details about each method, such as specific libraries and functionals, which may not be necessary for a concise response.\n",
            "\n",
            "In contrast, the actual answer succinctly summarizes the key improvements without delving into excessive detail or unrelated background information. The predicted answer, while thorough, includes a lot of extra information and uses a flowery structure that detracts from its conciseness.\n",
            "\n",
            "Given this analysis, I would assign the predicted response a score of 3, as it includes a lot of extra information and uses flowery language, making it less concise than the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: How have researchers attempted to further improve the GGA, such as by using parallel processing or advanced linear algebra routines?, Actual answer: Many researchers have examined alternative factorization methods (e.g., iterative solvers, multigrid approaches) or have parallelized the matrix assembly and solution steps to exploit modern multi-core CPUs and GPUs. In some studies, domain decomposition is used to split large networks into subregions that can be solved in parallel, with the solutions then merged at each iteration. While these techniques can offer speedups for extremely large models, the gains vary depending on network structure and overhead associated with partitioning and communication between subdomains., Predicted answer: The Generalized Gradient Approximation (GGA) is a type of exchange-correlation functional used in density functional theory (DFT) to approximate the exchange-correlation energy of a many-electron system. Researchers have attempted to improve the GGA in various ways, including:\n",
            "\n",
            "1. **Parallel processing**: To speed up the calculations, researchers have employed parallel processing techniques, such as:\n",
            "\t* **Message Passing Interface (MPI)**: MPI is a standardized and portable message-passing system designed to function on a wide variety of parallel computers.\n",
            "\t* **Open Multi-Processing (OpenMP)**: OpenMP is an API that supports multi-platform shared-memory parallel programming in C, C++, and Fortran.\n",
            "\t* **Graphics Processing Units (GPUs)**: GPUs have been used to accelerate GGA calculations, taking advantage of their massive parallel processing capabilities.\n",
            "2. **Advanced linear algebra routines**: Researchers have employed optimized linear algebra libraries, such as:\n",
            "\t* **BLAS (Basic Linear Algebra Subprograms)**: BLAS is a widely used library for basic linear algebra operations.\n",
            "\t* **LAPACK (Linear Algebra Package)**: LAPACK is a library of Fortran 77 subroutines for solving systems of linear scalar equations, linear least squares problems, eigenvalue problems, and singular value decomposition problems.\n",
            "\t* **MKL (Math Kernel Library)**: MKL is a high-performance linear algebra library developed by Intel.\n",
            "3. **Optimized GGA functionals**: Researchers have developed optimized GGA functionals, such as:\n",
            "\t* **PBE (Perdew-Burke-Ernzerhof)**: PBE is a widely used GGA functional that has been optimized for various systems.\n",
            "\t* **PBEsol**: PBEsol is a modified version of PBE that has been optimized for solids.\n",
            "\t* **SCAN (Strongly Constrained and Appropriately Normed)**: SCAN is a meta-GGA functional that has been optimized for a wide range of systems.\n",
            "4. **Hybrid functionals**: Researchers have combined GGA functionals with Hartree-Fock (HF) exchange to create hybrid functionals, such as:\n",
            "\t* **B3LYP**: B3LYP is a hybrid functional that combines 20% HF exchange with 80% GGA exchange.\n",
            "\t* **PBE0**: PBE0 is a hybrid functional that combines 25% HF exchange with 75% GGA exchange.\n",
            "5. **Machine learning-based GGA functionals**: Researchers have used machine learning techniques to develop new GGA functionals, such as:\n",
            "\t* **ML-GGA**: ML-GGA is a machine learning-based GGA functional that has been optimized for a wide range of systems.\n",
            "\n",
            "These are just a few examples of how researchers have attempted to improve the GGA. The development of new GGA functionals and optimization techniques continues to be an active area of research in the field of density functional theory.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the confidence conveyed in both responses regarding the improvements made to the Generalized Gradient Approximation (GGA). \n",
            "\n",
            "The actual answer provides a concise overview of specific methods researchers have employed to enhance GGA, such as alternative factorization methods, parallel processing, and domain decomposition. It also mentions the variability of speedup gains based on network structure and overhead, which adds a layer of nuance and realism to the discussion.\n",
            "\n",
            "In contrast, the predicted answer, while informative and detailed, diverges from the actual answer by focusing heavily on the technical aspects of GGA, including various parallel processing techniques and advanced linear algebra routines. It lists multiple methods and examples, which, while relevant, may not directly address the core of the question about improvements specifically related to GGA. The predicted answer lacks the same level of contextualization regarding the effectiveness and variability of these methods, which is a critical aspect highlighted in the actual answer.\n",
            "\n",
            "Given this analysis, the predicted answer demonstrates a moderate level of confidence in its assertions about improvements to GGA, but it does not fully align with the actual answer's focus and depth. Therefore, I would assign a score of 3, indicating uncertainty, as the predicted answer could be correct but lacks sufficient evidence and alignment with the actual response.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: How have researchers attempted to further improve the GGA, such as by using parallel processing or advanced linear algebra routines?, Actual answer: Many researchers have examined alternative factorization methods (e.g., iterative solvers, multigrid approaches) or have parallelized the matrix assembly and solution steps to exploit modern multi-core CPUs and GPUs. In some studies, domain decomposition is used to split large networks into subregions that can be solved in parallel, with the solutions then merged at each iteration. While these techniques can offer speedups for extremely large models, the gains vary depending on network structure and overhead associated with partitioning and communication between subdomains., Predicted answer: The Generalized Gradient Approximation (GGA) is a type of exchange-correlation functional used in density functional theory (DFT) to approximate the exchange-correlation energy of a many-electron system. Researchers have attempted to improve the GGA in various ways, including:\n",
            "\n",
            "1. **Parallel processing**: To speed up the calculations, researchers have employed parallel processing techniques, such as:\n",
            "\t* **Message Passing Interface (MPI)**: MPI is a standardized and portable message-passing system designed to function on a wide variety of parallel computers.\n",
            "\t* **Open Multi-Processing (OpenMP)**: OpenMP is an API that supports multi-platform shared-memory parallel programming in C, C++, and Fortran.\n",
            "\t* **Graphics Processing Units (GPUs)**: GPUs have been used to accelerate GGA calculations, taking advantage of their massive parallel processing capabilities.\n",
            "2. **Advanced linear algebra routines**: Researchers have employed optimized linear algebra libraries, such as:\n",
            "\t* **BLAS (Basic Linear Algebra Subprograms)**: BLAS is a widely used library for basic linear algebra operations.\n",
            "\t* **LAPACK (Linear Algebra Package)**: LAPACK is a library of Fortran 77 subroutines for solving systems of linear scalar equations, linear least squares problems, eigenvalue problems, and singular value decomposition problems.\n",
            "\t* **MKL (Math Kernel Library)**: MKL is a high-performance linear algebra library developed by Intel.\n",
            "3. **Optimized GGA functionals**: Researchers have developed optimized GGA functionals, such as:\n",
            "\t* **PBE (Perdew-Burke-Ernzerhof)**: PBE is a widely used GGA functional that has been optimized for various systems.\n",
            "\t* **PBEsol**: PBEsol is a modified version of PBE that has been optimized for solids.\n",
            "\t* **SCAN (Strongly Constrained and Appropriately Normed)**: SCAN is a meta-GGA functional that has been optimized for a wide range of systems.\n",
            "4. **Hybrid functionals**: Researchers have combined GGA functionals with Hartree-Fock (HF) exchange to create hybrid functionals, such as:\n",
            "\t* **B3LYP**: B3LYP is a hybrid functional that combines 20% HF exchange with 80% GGA exchange.\n",
            "\t* **PBE0**: PBE0 is a hybrid functional that combines 25% HF exchange with 75% GGA exchange.\n",
            "5. **Machine learning-based GGA functionals**: Researchers have used machine learning techniques to develop new GGA functionals, such as:\n",
            "\t* **ML-GGA**: ML-GGA is a machine learning-based GGA functional that has been optimized for a wide range of systems.\n",
            "\n",
            "These are just a few examples of how researchers have attempted to improve the GGA. The development of new GGA functionals and optimization techniques continues to be an active area of research in the field of density functional theory.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the factual accuracy and relevance of the information provided in both responses. The actual answer focuses specifically on improvements to the Generalized Gradient Approximation (GGA) through methods like alternative factorization, parallel processing, and domain decomposition. It emphasizes the practical applications and the variability of gains based on network structure.\n",
            "\n",
            "The predicted answer, while informative and detailed, diverges from the actual answer in several ways. It begins with a definition of GGA, which is not directly relevant to the question about improvements. The predicted answer does mention parallel processing and advanced linear algebra routines, which are relevant, but it also includes a lot of additional information about various GGA functionals and machine learning approaches that, while interesting, do not directly address the specific improvements mentioned in the actual answer. \n",
            "\n",
            "The predicted answer contains factual information but also includes extraneous details that could lead to confusion about the main focus of the question. Therefore, it does not fully align with the actual answer's emphasis on specific improvements and their implications.\n",
            "\n",
            "Considering these points, I would rate the predicted answer as follows: it contains a mix of factual information and some irrelevant details, leading to a score that reflects both its strengths and weaknesses.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 3, 'factuality_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: How have researchers attempted to further improve the GGA, such as by using parallel processing or advanced linear algebra routines?, Actual answer: Many researchers have examined alternative factorization methods (e.g., iterative solvers, multigrid approaches) or have parallelized the matrix assembly and solution steps to exploit modern multi-core CPUs and GPUs. In some studies, domain decomposition is used to split large networks into subregions that can be solved in parallel, with the solutions then merged at each iteration. While these techniques can offer speedups for extremely large models, the gains vary depending on network structure and overhead associated with partitioning and communication between subdomains., Predicted answer: The Generalized Gradient Approximation (GGA) is a type of exchange-correlation functional used in density functional theory (DFT) to approximate the exchange-correlation energy of a many-electron system. Researchers have attempted to improve the GGA in various ways, including:\n",
            "\n",
            "1. **Parallel processing**: To speed up the calculations, researchers have employed parallel processing techniques, such as:\n",
            "\t* **Message Passing Interface (MPI)**: MPI is a standardized and portable message-passing system designed to function on a wide variety of parallel computers.\n",
            "\t* **Open Multi-Processing (OpenMP)**: OpenMP is an API that supports multi-platform shared-memory parallel programming in C, C++, and Fortran.\n",
            "\t* **Graphics Processing Units (GPUs)**: GPUs have been used to accelerate GGA calculations, taking advantage of their massive parallel processing capabilities.\n",
            "2. **Advanced linear algebra routines**: Researchers have employed optimized linear algebra libraries, such as:\n",
            "\t* **BLAS (Basic Linear Algebra Subprograms)**: BLAS is a widely used library for basic linear algebra operations.\n",
            "\t* **LAPACK (Linear Algebra Package)**: LAPACK is a library of Fortran 77 subroutines for solving systems of linear scalar equations, linear least squares problems, eigenvalue problems, and singular value decomposition problems.\n",
            "\t* **MKL (Math Kernel Library)**: MKL is a high-performance linear algebra library developed by Intel.\n",
            "3. **Optimized GGA functionals**: Researchers have developed optimized GGA functionals, such as:\n",
            "\t* **PBE (Perdew-Burke-Ernzerhof)**: PBE is a widely used GGA functional that has been optimized for various systems.\n",
            "\t* **PBEsol**: PBEsol is a modified version of PBE that has been optimized for solids.\n",
            "\t* **SCAN (Strongly Constrained and Appropriately Normed)**: SCAN is a meta-GGA functional that has been optimized for a wide range of systems.\n",
            "4. **Hybrid functionals**: Researchers have combined GGA functionals with Hartree-Fock (HF) exchange to create hybrid functionals, such as:\n",
            "\t* **B3LYP**: B3LYP is a hybrid functional that combines 20% HF exchange with 80% GGA exchange.\n",
            "\t* **PBE0**: PBE0 is a hybrid functional that combines 25% HF exchange with 75% GGA exchange.\n",
            "5. **Machine learning-based GGA functionals**: Researchers have used machine learning techniques to develop new GGA functionals, such as:\n",
            "\t* **ML-GGA**: ML-GGA is a machine learning-based GGA functional that has been optimized for a wide range of systems.\n",
            "\n",
            "These are just a few examples of how researchers have attempted to improve the GGA. The development of new GGA functionals and optimization techniques continues to be an active area of research in the field of density functional theory.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and relevance of the information provided in both responses. The actual answer focuses specifically on improvements to the Generalized Gradient Approximation (GGA) through parallel processing and advanced linear algebra routines, mentioning techniques like iterative solvers, multigrid approaches, and domain decomposition. It emphasizes the practical implications of these methods, including their variable effectiveness based on network structure.\n",
            "\n",
            "The predicted answer, while informative and detailed, diverges from the specific focus of the question. It provides a broad overview of GGA, including various methods of improvement such as parallel processing, advanced linear algebra routines, optimized functionals, hybrid functionals, and machine learning-based functionals. However, it does not directly address the specific improvements related to parallel processing and advanced linear algebra routines as outlined in the actual answer. Instead, it lists various techniques and libraries without connecting them back to the context of GGA improvements in a focused manner.\n",
            "\n",
            "Given this analysis, the predicted answer does not misinterpret the information but rather expands on it in a way that may lead to confusion regarding the specific improvements sought in the question. It shows a level of confidence in the information presented but lacks the precision and relevance to the original question.\n",
            "\n",
            "Therefore, I would assign a score of 3 to the predicted answer, as it shows that the model is unsure about the answer or states that information is theoretical, without directly addressing the specific improvements mentioned in the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 3, 'factuality_descr': 3, 'judgement_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: Under what circumstances might an engineer still opt to use the Hardy Cross method for hand calculations, despite its slower convergence?, Actual answer: An engineer might use Hardy Cross for teaching or demonstration purposes, as it provides clear insights into how flows are balanced in loops. It can also be convenient for very small networks or conceptual designs where quick, approximate solutions are acceptable and computational tools are not immediately available. In such cases, the simplicity and directness of Hardy Cross calculations can be beneficial, even though more advanced solvers are faster and more robust for larger systems., Predicted answer: The Hardy Cross method, developed in the 1930s, is a traditional method for solving pipe network problems in water distribution systems. Although it has been largely replaced by more efficient and accurate computer-based methods, there are still certain circumstances where an engineer might opt to use the Hardy Cross method for hand calculations, despite its slower convergence:\n",
            "\n",
            "1. **Simple pipe networks**: For small, simple pipe networks with a limited number of nodes and branches, the Hardy Cross method can still be a viable option for hand calculations. This is because the method is relatively straightforward to apply, and the calculations can be performed quickly and accurately.\n",
            "2. **Preliminary design**: During the preliminary design phase of a water distribution system, engineers may use the Hardy Cross method to quickly estimate the pipe sizes and pressures required to meet the system's demands. This can help identify potential issues and inform the design process.\n",
            "3. **Limited computational resources**: In some cases, engineers may not have access to advanced computer software or computational resources. In such situations, the Hardy Cross method can be a useful alternative for hand calculations.\n",
            "4. **Education and training**: The Hardy Cross method is still taught in many water resources engineering programs as a way to introduce students to the fundamental principles of pipe network analysis. Using the method for hand calculations can help students develop a deeper understanding of the underlying mathematics and principles.\n",
            "5. **Emergency or field situations**: In emergency or field situations where access to computer software or computational resources is limited, the Hardy Cross method can be a useful tool for quick and rough estimates of pipe network performance.\n",
            "6. **Historical or legacy systems**: For older water distribution systems that were designed using the Hardy Cross method, engineers may still need to use the method for hand calculations to understand and maintain the existing system.\n",
            "7. **Simplification of complex problems**: In some cases, the Hardy Cross method can be used to simplify complex pipe network problems by breaking them down into smaller, more manageable components. This can help engineers identify key issues and develop more effective solutions.\n",
            "\n",
            "Overall, while the Hardy Cross method may not be the most efficient or accurate method for solving pipe network problems, it can still be a useful tool for hand calculations in certain circumstances.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the completeness of the information provided in both responses. The actual answer succinctly identifies specific circumstances under which an engineer might choose to use the Hardy Cross method, emphasizing its educational value, convenience for small networks, and applicability in situations with limited computational resources.\n",
            "\n",
            "The predicted answer, on the other hand, provides a comprehensive list of circumstances, including:\n",
            "\n",
            "1. Simple pipe networks\n",
            "2. Preliminary design\n",
            "3. Limited computational resources\n",
            "4. Education and training\n",
            "5. Emergency or field situations\n",
            "6. Historical or legacy systems\n",
            "7. Simplification of complex problems\n",
            "\n",
            "Each of these points aligns well with the themes presented in the actual answer, and the predicted response elaborates on these points with additional context and examples. It covers all the elements of a complete answer, addressing the question thoroughly and providing a well-rounded perspective on the use of the Hardy Cross method.\n",
            "\n",
            "Given this analysis, the predicted answer includes all relevant elements and provides a detailed explanation that matches the completeness of the actual answer.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 5}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "14it [07:37, 28.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : Incorporating pump curves or valve characteristics into Newton-based or gradient-based Water Distribution System (WDS) solvers involves several steps. Here's a general process:\n",
            "\n",
            "**Pump Curves:**\n",
            "\n",
            "1. **Pump Curve Representation**: Represent the pump curve as a function of flow rate (Q) and head (H). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Pump Curve Interpolation**: Interpolate the pump curve to obtain the head-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Pump Curve Implementation**: Implement the pump curve in the WDS solver as a function that takes the flow rate as input and returns the corresponding head.\n",
            "\n",
            "**Valve Characteristics:**\n",
            "\n",
            "1. **Valve Characteristic Representation**: Represent the valve characteristic as a function of flow rate (Q) and pressure drop (ΔP). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Valve Characteristic Interpolation**: Interpolate the valve characteristic to obtain the pressure drop-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Valve Characteristic Implementation**: Implement the valve characteristic in the WDS solver as a function that takes the flow rate as input and returns the corresponding pressure drop.\n",
            "\n",
            "**Incorporating Pump Curves and Valve Characteristics into the WDS Solver:**\n",
            "\n",
            "1. **Modify the WDS Solver**: Modify the WDS solver to include the pump curve and valve characteristic functions. This may involve adding new variables, equations, or constraints to the solver.\n",
            "2. **Update the Jacobian Matrix**: Update the Jacobian matrix of the WDS solver to include the derivatives of the pump curve and valve characteristic functions with respect to the flow rates.\n",
            "3. **Update the Residual Equations**: Update the residual equations of the WDS solver to include the pump curve and valve characteristic functions.\n",
            "4. **Solve the Updated System**: Solve the updated system of equations using a Newton-based or gradient-based solver.\n",
            "\n",
            "**Example of Pump Curve Implementation:**\n",
            "\n",
            "Suppose we have a pump curve represented by the following equation:\n",
            "\n",
            "H = a \\* Q^2 + b \\* Q + c\n",
            "\n",
            "where H is the head, Q is the flow rate, and a, b, and c are constants.\n",
            "\n",
            "In the WDS solver, we can implement this pump curve as a function that takes the flow rate as input and returns the corresponding head:\n",
            "\n",
            "```python\n",
            "def pump_curve(Q):\n",
            "    a = 0.1\n",
            "    b = 0.2\n",
            "    c = 10\n",
            "    return a * Q**2 + b * Q + c\n",
            "```\n",
            "\n",
            "**Example of Valve Characteristic Implementation:**\n",
            "\n",
            "Suppose we have a valve characteristic represented by the following equation:\n",
            "\n",
            "ΔP = d \\* Q^2 + e \\* Q + f\n",
            "\n",
            "where ΔP is the pressure drop, Q is the flow rate, and d, e, and f are constants.\n",
            "\n",
            "In the WDS solver, we can implement this valve characteristic as a function that takes the flow rate as input and returns the corresponding pressure drop:\n",
            "\n",
            "```python\n",
            "def valve_characteristic(Q):\n",
            "    d = 0.1\n",
            "    e = 0.2\n",
            "    f = 10\n",
            "    return d * Q**2 + e * Q + f\n",
            "```\n",
            "\n",
            "Note that these are simplified examples and actual pump curves and valve characteristics may be more complex and require more sophisticated mathematical representations.\n",
            "\u001b[32mUser message:Question: Under what circumstances might an engineer still opt to use the Hardy Cross method for hand calculations, despite its slower convergence?, Actual answer: An engineer might use Hardy Cross for teaching or demonstration purposes, as it provides clear insights into how flows are balanced in loops. It can also be convenient for very small networks or conceptual designs where quick, approximate solutions are acceptable and computational tools are not immediately available. In such cases, the simplicity and directness of Hardy Cross calculations can be beneficial, even though more advanced solvers are faster and more robust for larger systems., Predicted answer: The Hardy Cross method, developed in the 1930s, is a traditional method for solving pipe network problems in water distribution systems. Although it has been largely replaced by more efficient and accurate computer-based methods, there are still certain circumstances where an engineer might opt to use the Hardy Cross method for hand calculations, despite its slower convergence:\n",
            "\n",
            "1. **Simple pipe networks**: For small, simple pipe networks with a limited number of nodes and branches, the Hardy Cross method can still be a viable option for hand calculations. This is because the method is relatively straightforward to apply, and the calculations can be performed quickly and accurately.\n",
            "2. **Preliminary design**: During the preliminary design phase of a water distribution system, engineers may use the Hardy Cross method to quickly estimate the pipe sizes and pressures required to meet the system's demands. This can help identify potential issues and inform the design process.\n",
            "3. **Limited computational resources**: In some cases, engineers may not have access to advanced computer software or computational resources. In such situations, the Hardy Cross method can be a useful alternative for hand calculations.\n",
            "4. **Education and training**: The Hardy Cross method is still taught in many water resources engineering programs as a way to introduce students to the fundamental principles of pipe network analysis. Using the method for hand calculations can help students develop a deeper understanding of the underlying mathematics and principles.\n",
            "5. **Emergency or field situations**: In emergency or field situations where access to computer software or computational resources is limited, the Hardy Cross method can be a useful tool for quick and rough estimates of pipe network performance.\n",
            "6. **Historical or legacy systems**: For older water distribution systems that were designed using the Hardy Cross method, engineers may still need to use the method for hand calculations to understand and maintain the existing system.\n",
            "7. **Simplification of complex problems**: In some cases, the Hardy Cross method can be used to simplify complex pipe network problems by breaking them down into smaller, more manageable components. This can help engineers identify key issues and develop more effective solutions.\n",
            "\n",
            "Overall, while the Hardy Cross method may not be the most efficient or accurate method for solving pipe network problems, it can still be a useful tool for hand calculations in certain circumstances.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well each response addresses the user's question regarding the circumstances under which an engineer might still opt to use the Hardy Cross method for hand calculations, despite its slower convergence.\n",
            "\n",
            "The actual answer succinctly identifies key scenarios: teaching or demonstration purposes, small networks, conceptual designs, and situations where computational tools are unavailable. It emphasizes the method's simplicity and directness as advantages in these contexts.\n",
            "\n",
            "The predicted answer, while lengthy, provides a comprehensive list of circumstances where the Hardy Cross method might still be used. It covers similar points, such as simple pipe networks, preliminary design, limited computational resources, education and training, emergency situations, historical systems, and simplification of complex problems. However, it includes a lot of detail that, while relevant, may not be necessary for a direct answer to the question. \n",
            "\n",
            "The predicted answer does answer the user's question and contains relevant information, but it also includes more detail than needed, which could be considered somewhat irrelevant in the context of the question. \n",
            "\n",
            "Given this analysis, the predicted answer is relevant but contains more information than necessary, leading to a score of 4.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: Under what circumstances might an engineer still opt to use the Hardy Cross method for hand calculations, despite its slower convergence?, Actual answer: An engineer might use Hardy Cross for teaching or demonstration purposes, as it provides clear insights into how flows are balanced in loops. It can also be convenient for very small networks or conceptual designs where quick, approximate solutions are acceptable and computational tools are not immediately available. In such cases, the simplicity and directness of Hardy Cross calculations can be beneficial, even though more advanced solvers are faster and more robust for larger systems., Predicted answer: The Hardy Cross method, developed in the 1930s, is a traditional method for solving pipe network problems in water distribution systems. Although it has been largely replaced by more efficient and accurate computer-based methods, there are still certain circumstances where an engineer might opt to use the Hardy Cross method for hand calculations, despite its slower convergence:\n",
            "\n",
            "1. **Simple pipe networks**: For small, simple pipe networks with a limited number of nodes and branches, the Hardy Cross method can still be a viable option for hand calculations. This is because the method is relatively straightforward to apply, and the calculations can be performed quickly and accurately.\n",
            "2. **Preliminary design**: During the preliminary design phase of a water distribution system, engineers may use the Hardy Cross method to quickly estimate the pipe sizes and pressures required to meet the system's demands. This can help identify potential issues and inform the design process.\n",
            "3. **Limited computational resources**: In some cases, engineers may not have access to advanced computer software or computational resources. In such situations, the Hardy Cross method can be a useful alternative for hand calculations.\n",
            "4. **Education and training**: The Hardy Cross method is still taught in many water resources engineering programs as a way to introduce students to the fundamental principles of pipe network analysis. Using the method for hand calculations can help students develop a deeper understanding of the underlying mathematics and principles.\n",
            "5. **Emergency or field situations**: In emergency or field situations where access to computer software or computational resources is limited, the Hardy Cross method can be a useful tool for quick and rough estimates of pipe network performance.\n",
            "6. **Historical or legacy systems**: For older water distribution systems that were designed using the Hardy Cross method, engineers may still need to use the method for hand calculations to understand and maintain the existing system.\n",
            "7. **Simplification of complex problems**: In some cases, the Hardy Cross method can be used to simplify complex pipe network problems by breaking them down into smaller, more manageable components. This can help engineers identify key issues and develop more effective solutions.\n",
            "\n",
            "Overall, while the Hardy Cross method may not be the most efficient or accurate method for solving pipe network problems, it can still be a useful tool for hand calculations in certain circumstances.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information provided and how directly it addresses the question. \n",
            "\n",
            "The actual answer succinctly identifies specific circumstances under which the Hardy Cross method might be used, focusing on teaching, small networks, and situations lacking computational resources. It maintains clarity and relevance without unnecessary elaboration.\n",
            "\n",
            "In contrast, the predicted answer provides a detailed historical context and lists multiple scenarios in a structured format. While this may be informative, it introduces a significant amount of extra information that is not strictly necessary to answer the question. The inclusion of historical context, detailed explanations for each circumstance, and the structured list format contributes to a longer response that could be seen as excessive.\n",
            "\n",
            "Given these observations, the predicted answer includes a lot of extra information and uses a more elaborate structure than needed, which detracts from its conciseness.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: Under what circumstances might an engineer still opt to use the Hardy Cross method for hand calculations, despite its slower convergence?, Actual answer: An engineer might use Hardy Cross for teaching or demonstration purposes, as it provides clear insights into how flows are balanced in loops. It can also be convenient for very small networks or conceptual designs where quick, approximate solutions are acceptable and computational tools are not immediately available. In such cases, the simplicity and directness of Hardy Cross calculations can be beneficial, even though more advanced solvers are faster and more robust for larger systems., Predicted answer: The Hardy Cross method, developed in the 1930s, is a traditional method for solving pipe network problems in water distribution systems. Although it has been largely replaced by more efficient and accurate computer-based methods, there are still certain circumstances where an engineer might opt to use the Hardy Cross method for hand calculations, despite its slower convergence:\n",
            "\n",
            "1. **Simple pipe networks**: For small, simple pipe networks with a limited number of nodes and branches, the Hardy Cross method can still be a viable option for hand calculations. This is because the method is relatively straightforward to apply, and the calculations can be performed quickly and accurately.\n",
            "2. **Preliminary design**: During the preliminary design phase of a water distribution system, engineers may use the Hardy Cross method to quickly estimate the pipe sizes and pressures required to meet the system's demands. This can help identify potential issues and inform the design process.\n",
            "3. **Limited computational resources**: In some cases, engineers may not have access to advanced computer software or computational resources. In such situations, the Hardy Cross method can be a useful alternative for hand calculations.\n",
            "4. **Education and training**: The Hardy Cross method is still taught in many water resources engineering programs as a way to introduce students to the fundamental principles of pipe network analysis. Using the method for hand calculations can help students develop a deeper understanding of the underlying mathematics and principles.\n",
            "5. **Emergency or field situations**: In emergency or field situations where access to computer software or computational resources is limited, the Hardy Cross method can be a useful tool for quick and rough estimates of pipe network performance.\n",
            "6. **Historical or legacy systems**: For older water distribution systems that were designed using the Hardy Cross method, engineers may still need to use the method for hand calculations to understand and maintain the existing system.\n",
            "7. **Simplification of complex problems**: In some cases, the Hardy Cross method can be used to simplify complex pipe network problems by breaking them down into smaller, more manageable components. This can help engineers identify key issues and develop more effective solutions.\n",
            "\n",
            "Overall, while the Hardy Cross method may not be the most efficient or accurate method for solving pipe network problems, it can still be a useful tool for hand calculations in certain circumstances.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the confidence conveyed in both responses regarding the use of the Hardy Cross method for hand calculations. \n",
            "\n",
            "The actual answer succinctly identifies specific scenarios where the Hardy Cross method remains relevant, such as teaching, small networks, and situations with limited computational resources. It emphasizes the method's simplicity and directness, which are key reasons for its continued use despite the availability of more advanced methods.\n",
            "\n",
            "The predicted answer, while comprehensive and detailed, covers many of the same points but does so in a more elaborate manner. It lists multiple circumstances where the method might be used, including preliminary design, education, emergency situations, and historical contexts. This thoroughness suggests a strong understanding of the topic, but it may also introduce a slight dilution of confidence due to the sheer volume of information presented.\n",
            "\n",
            "In terms of confidence, the predicted answer does not express doubt or uncertainty; rather, it provides a well-rounded view that supports the continued use of the Hardy Cross method. However, the length and complexity of the response could lead to a perception of uncertainty in the main assertion, as it may seem to hedge by providing numerous scenarios rather than focusing on the most compelling reasons.\n",
            "\n",
            "Overall, the predicted answer aligns well with the actual answer and conveys a high level of confidence in the continued relevance of the Hardy Cross method, albeit with a more extensive explanation.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: Under what circumstances might an engineer still opt to use the Hardy Cross method for hand calculations, despite its slower convergence?, Actual answer: An engineer might use Hardy Cross for teaching or demonstration purposes, as it provides clear insights into how flows are balanced in loops. It can also be convenient for very small networks or conceptual designs where quick, approximate solutions are acceptable and computational tools are not immediately available. In such cases, the simplicity and directness of Hardy Cross calculations can be beneficial, even though more advanced solvers are faster and more robust for larger systems., Predicted answer: The Hardy Cross method, developed in the 1930s, is a traditional method for solving pipe network problems in water distribution systems. Although it has been largely replaced by more efficient and accurate computer-based methods, there are still certain circumstances where an engineer might opt to use the Hardy Cross method for hand calculations, despite its slower convergence:\n",
            "\n",
            "1. **Simple pipe networks**: For small, simple pipe networks with a limited number of nodes and branches, the Hardy Cross method can still be a viable option for hand calculations. This is because the method is relatively straightforward to apply, and the calculations can be performed quickly and accurately.\n",
            "2. **Preliminary design**: During the preliminary design phase of a water distribution system, engineers may use the Hardy Cross method to quickly estimate the pipe sizes and pressures required to meet the system's demands. This can help identify potential issues and inform the design process.\n",
            "3. **Limited computational resources**: In some cases, engineers may not have access to advanced computer software or computational resources. In such situations, the Hardy Cross method can be a useful alternative for hand calculations.\n",
            "4. **Education and training**: The Hardy Cross method is still taught in many water resources engineering programs as a way to introduce students to the fundamental principles of pipe network analysis. Using the method for hand calculations can help students develop a deeper understanding of the underlying mathematics and principles.\n",
            "5. **Emergency or field situations**: In emergency or field situations where access to computer software or computational resources is limited, the Hardy Cross method can be a useful tool for quick and rough estimates of pipe network performance.\n",
            "6. **Historical or legacy systems**: For older water distribution systems that were designed using the Hardy Cross method, engineers may still need to use the method for hand calculations to understand and maintain the existing system.\n",
            "7. **Simplification of complex problems**: In some cases, the Hardy Cross method can be used to simplify complex pipe network problems by breaking them down into smaller, more manageable components. This can help engineers identify key issues and develop more effective solutions.\n",
            "\n",
            "Overall, while the Hardy Cross method may not be the most efficient or accurate method for solving pipe network problems, it can still be a useful tool for hand calculations in certain circumstances.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the factual accuracy and relevance of the information provided in both responses. \n",
            "\n",
            "The actual answer succinctly identifies key circumstances under which an engineer might still opt to use the Hardy Cross method, emphasizing its educational value, convenience for small networks, and its role in conceptual designs. It highlights the method's simplicity and directness, which are valid points.\n",
            "\n",
            "The predicted answer, while more detailed, covers similar points but expands on them significantly. It includes several valid circumstances such as the use in simple pipe networks, preliminary design, limited computational resources, education and training, emergency situations, historical systems, and simplification of complex problems. Each of these points is factually accurate and relevant to the question, providing a comprehensive view of the method's applicability.\n",
            "\n",
            "However, the predicted answer is somewhat verbose and includes more examples than the actual answer, which could be seen as unnecessary for the context of the question. Despite this, the additional details do not introduce any hallucinations or inaccuracies; they simply elaborate on the circumstances mentioned in the actual answer.\n",
            "\n",
            "In summary, the predicted answer is largely factual and aligns well with the actual answer, albeit with more elaboration. There are no significant inaccuracies or hallucinations present.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 5}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: Under what circumstances might an engineer still opt to use the Hardy Cross method for hand calculations, despite its slower convergence?, Actual answer: An engineer might use Hardy Cross for teaching or demonstration purposes, as it provides clear insights into how flows are balanced in loops. It can also be convenient for very small networks or conceptual designs where quick, approximate solutions are acceptable and computational tools are not immediately available. In such cases, the simplicity and directness of Hardy Cross calculations can be beneficial, even though more advanced solvers are faster and more robust for larger systems., Predicted answer: The Hardy Cross method, developed in the 1930s, is a traditional method for solving pipe network problems in water distribution systems. Although it has been largely replaced by more efficient and accurate computer-based methods, there are still certain circumstances where an engineer might opt to use the Hardy Cross method for hand calculations, despite its slower convergence:\n",
            "\n",
            "1. **Simple pipe networks**: For small, simple pipe networks with a limited number of nodes and branches, the Hardy Cross method can still be a viable option for hand calculations. This is because the method is relatively straightforward to apply, and the calculations can be performed quickly and accurately.\n",
            "2. **Preliminary design**: During the preliminary design phase of a water distribution system, engineers may use the Hardy Cross method to quickly estimate the pipe sizes and pressures required to meet the system's demands. This can help identify potential issues and inform the design process.\n",
            "3. **Limited computational resources**: In some cases, engineers may not have access to advanced computer software or computational resources. In such situations, the Hardy Cross method can be a useful alternative for hand calculations.\n",
            "4. **Education and training**: The Hardy Cross method is still taught in many water resources engineering programs as a way to introduce students to the fundamental principles of pipe network analysis. Using the method for hand calculations can help students develop a deeper understanding of the underlying mathematics and principles.\n",
            "5. **Emergency or field situations**: In emergency or field situations where access to computer software or computational resources is limited, the Hardy Cross method can be a useful tool for quick and rough estimates of pipe network performance.\n",
            "6. **Historical or legacy systems**: For older water distribution systems that were designed using the Hardy Cross method, engineers may still need to use the method for hand calculations to understand and maintain the existing system.\n",
            "7. **Simplification of complex problems**: In some cases, the Hardy Cross method can be used to simplify complex pipe network problems by breaking them down into smaller, more manageable components. This can help engineers identify key issues and develop more effective solutions.\n",
            "\n",
            "Overall, while the Hardy Cross method may not be the most efficient or accurate method for solving pipe network problems, it can still be a useful tool for hand calculations in certain circumstances.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and relevance of the information provided in both responses. The actual answer succinctly identifies specific scenarios where the Hardy Cross method remains applicable, such as teaching, small networks, and conceptual designs. It emphasizes the method's simplicity and directness, which are key reasons for its continued use despite the availability of more advanced computational tools.\n",
            "\n",
            "The predicted answer, while lengthy, covers many of the same points as the actual answer. It mentions simple pipe networks, preliminary design, limited computational resources, education and training, emergency situations, historical systems, and simplification of complex problems. Each of these points aligns well with the actual answer's themes, demonstrating a comprehensive understanding of the circumstances under which the Hardy Cross method might still be employed.\n",
            "\n",
            "However, the predicted answer is somewhat verbose and could be seen as slightly less focused than the actual answer. It does not explicitly mention the concept of \"quick, approximate solutions\" as a reason for using the method, which is a key aspect of the actual answer. Nevertheless, it does convey the correct information and context regarding the Hardy Cross method's application.\n",
            "\n",
            "Given that the predicted answer accurately reflects the circumstances under which the Hardy Cross method might be used, albeit with some additional detail and less conciseness, it does not misinterpret the information or present any hallucinations. Therefore, it can be rated positively.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 5, 'judgement_descr': 5}\n",
            "\n",
            "\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: Why is the GGA particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops?, Actual answer: Large networks benefit from the GGA’s global approach, where each iteration efficiently updates all node heads via a sparse matrix solution and then flows in each pipe. Because it leverages sparse matrix techniques and well-structured linear equations, it scales very effectively as the number of pipes and nodes grows. Additionally, the method’s robustness means it can handle broad variations in pipe sizes, demands, and complex layouts without excessive iteration counts., Predicted answer: The Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to several reasons:\n",
            "\n",
            "1. **Scalability**: GGA is a robust and efficient algorithm that can handle large-scale water distribution systems with thousands of pipes, nodes, and loops. It can efficiently solve the nonlinear equations that describe the hydraulic behavior of the system, even with a large number of unknowns.\n",
            "\n",
            "2. **Flexibility**: GGA can accommodate various types of pipe networks, including loops, branches, and junctions. It can also handle different types of pipe materials, diameters, and roughness coefficients, making it a versatile tool for analyzing complex water systems.\n",
            "\n",
            "3. **Accuracy**: GGA provides accurate solutions to the hydraulic equations that govern the behavior of water distribution systems. It takes into account the nonlinear interactions between pipes, nodes, and loops, ensuring that the calculated pressures, flows, and head losses are accurate and reliable.\n",
            "\n",
            "4. **Convergence**: GGA uses a gradient-based approach to converge to the solution, which ensures that the algorithm rapidly converges to the optimal solution, even for large and complex systems. This makes it an efficient tool for analyzing water systems with thousands of pipes and loops.\n",
            "\n",
            "5. **Robustness**: GGA is a robust algorithm that can handle a wide range of input data, including noisy or uncertain data. It can also accommodate different types of boundary conditions, such as fixed pressures, flows, or head losses, making it a reliable tool for analyzing complex water systems.\n",
            "\n",
            "6. **Computational efficiency**: GGA is a computationally efficient algorithm that can solve large-scale water distribution systems in a reasonable amount of time. This makes it an ideal tool for analyzing complex systems, such as those with thousands of pipes and loops, where computational efficiency is critical.\n",
            "\n",
            "In summary, the Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to its scalability, flexibility, accuracy, convergence, robustness, and computational efficiency.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the completeness of the predicted answer compared to the actual answer, we need to analyze the key elements present in both responses.\n",
            "\n",
            "The actual answer highlights the following points:\n",
            "1. The GGA's global approach and efficiency in updating node heads and flows.\n",
            "2. The use of sparse matrix techniques and well-structured linear equations for effective scaling.\n",
            "3. The robustness of the method in handling variations in pipe sizes, demands, and complex layouts without excessive iterations.\n",
            "\n",
            "The predicted answer, while comprehensive, includes several additional aspects:\n",
            "1. Scalability and efficiency in solving nonlinear equations.\n",
            "2. Flexibility in accommodating various pipe network types and materials.\n",
            "3. Accuracy in providing reliable solutions to hydraulic equations.\n",
            "4. Convergence properties of the algorithm.\n",
            "5. Robustness in handling uncertain data and boundary conditions.\n",
            "6. Computational efficiency for large-scale systems.\n",
            "\n",
            "While the predicted answer covers many relevant aspects of the GGA, it does not explicitly mention the global approach or the specific use of sparse matrix techniques, which are critical to understanding why the GGA is particularly well-suited for large networks. It also introduces additional elements that, while relevant, may not be necessary for a complete answer to the specific question asked.\n",
            "\n",
            "Overall, the predicted answer includes most elements of a complete answer but lacks some specific details that are crucial for full completeness. Therefore, I would assign a score of 4, as it covers most elements but misses some key points from the actual answer.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: Why is the GGA particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops?, Actual answer: Large networks benefit from the GGA’s global approach, where each iteration efficiently updates all node heads via a sparse matrix solution and then flows in each pipe. Because it leverages sparse matrix techniques and well-structured linear equations, it scales very effectively as the number of pipes and nodes grows. Additionally, the method’s robustness means it can handle broad variations in pipe sizes, demands, and complex layouts without excessive iteration counts., Predicted answer: The Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to several reasons:\n",
            "\n",
            "1. **Scalability**: GGA is a robust and efficient algorithm that can handle large-scale water distribution systems with thousands of pipes, nodes, and loops. It can efficiently solve the nonlinear equations that describe the hydraulic behavior of the system, even with a large number of unknowns.\n",
            "\n",
            "2. **Flexibility**: GGA can accommodate various types of pipe networks, including loops, branches, and junctions. It can also handle different types of pipe materials, diameters, and roughness coefficients, making it a versatile tool for analyzing complex water systems.\n",
            "\n",
            "3. **Accuracy**: GGA provides accurate solutions to the hydraulic equations that govern the behavior of water distribution systems. It takes into account the nonlinear interactions between pipes, nodes, and loops, ensuring that the calculated pressures, flows, and head losses are accurate and reliable.\n",
            "\n",
            "4. **Convergence**: GGA uses a gradient-based approach to converge to the solution, which ensures that the algorithm rapidly converges to the optimal solution, even for large and complex systems. This makes it an efficient tool for analyzing water systems with thousands of pipes and loops.\n",
            "\n",
            "5. **Robustness**: GGA is a robust algorithm that can handle a wide range of input data, including noisy or uncertain data. It can also accommodate different types of boundary conditions, such as fixed pressures, flows, or head losses, making it a reliable tool for analyzing complex water systems.\n",
            "\n",
            "6. **Computational efficiency**: GGA is a computationally efficient algorithm that can solve large-scale water distribution systems in a reasonable amount of time. This makes it an ideal tool for analyzing complex systems, such as those with thousands of pipes and loops, where computational efficiency is critical.\n",
            "\n",
            "In summary, the Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to its scalability, flexibility, accuracy, convergence, robustness, and computational efficiency.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about the suitability of the Generalized Gradient Algorithm (GGA) for analyzing complex water systems. \n",
            "\n",
            "The actual answer emphasizes the GGA's global approach, its efficiency in updating node heads, the use of sparse matrix techniques, and its robustness in handling variations in pipe sizes and demands. It highlights the algorithm's effectiveness in scaling with the number of pipes and nodes, which is crucial for large networks.\n",
            "\n",
            "The predicted answer, while providing a comprehensive overview of the GGA's features, includes several points that, while relevant, may not directly address the specific aspects mentioned in the actual answer. For instance, it discusses scalability, flexibility, accuracy, convergence, robustness, and computational efficiency in detail, but it does not explicitly mention the sparse matrix solution or the iterative updating of node heads, which are key components of the actual answer.\n",
            "\n",
            "Overall, the predicted answer does answer the user's question and provides relevant information, but it contains more general information about the GGA rather than focusing on the specific reasons that make it well-suited for large water systems as highlighted in the actual answer. \n",
            "\n",
            "Thus, I would rate the predicted response as follows: it answers the question but includes a significant amount of information that, while related, is not as directly relevant as the actual answer.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: Why is the GGA particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops?, Actual answer: Large networks benefit from the GGA’s global approach, where each iteration efficiently updates all node heads via a sparse matrix solution and then flows in each pipe. Because it leverages sparse matrix techniques and well-structured linear equations, it scales very effectively as the number of pipes and nodes grows. Additionally, the method’s robustness means it can handle broad variations in pipe sizes, demands, and complex layouts without excessive iteration counts., Predicted answer: The Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to several reasons:\n",
            "\n",
            "1. **Scalability**: GGA is a robust and efficient algorithm that can handle large-scale water distribution systems with thousands of pipes, nodes, and loops. It can efficiently solve the nonlinear equations that describe the hydraulic behavior of the system, even with a large number of unknowns.\n",
            "\n",
            "2. **Flexibility**: GGA can accommodate various types of pipe networks, including loops, branches, and junctions. It can also handle different types of pipe materials, diameters, and roughness coefficients, making it a versatile tool for analyzing complex water systems.\n",
            "\n",
            "3. **Accuracy**: GGA provides accurate solutions to the hydraulic equations that govern the behavior of water distribution systems. It takes into account the nonlinear interactions between pipes, nodes, and loops, ensuring that the calculated pressures, flows, and head losses are accurate and reliable.\n",
            "\n",
            "4. **Convergence**: GGA uses a gradient-based approach to converge to the solution, which ensures that the algorithm rapidly converges to the optimal solution, even for large and complex systems. This makes it an efficient tool for analyzing water systems with thousands of pipes and loops.\n",
            "\n",
            "5. **Robustness**: GGA is a robust algorithm that can handle a wide range of input data, including noisy or uncertain data. It can also accommodate different types of boundary conditions, such as fixed pressures, flows, or head losses, making it a reliable tool for analyzing complex water systems.\n",
            "\n",
            "6. **Computational efficiency**: GGA is a computationally efficient algorithm that can solve large-scale water distribution systems in a reasonable amount of time. This makes it an ideal tool for analyzing complex systems, such as those with thousands of pipes and loops, where computational efficiency is critical.\n",
            "\n",
            "In summary, the Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to its scalability, flexibility, accuracy, convergence, robustness, and computational efficiency.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information provided in the predicted response. The actual answer is succinct and directly addresses the question by highlighting the GGA's global approach, efficiency with sparse matrix solutions, and its robustness in handling variations in pipe sizes and layouts.\n",
            "\n",
            "In contrast, the predicted answer elaborates on multiple aspects of the GGA, including scalability, flexibility, accuracy, convergence, robustness, and computational efficiency. While these points are relevant, the level of detail and the number of points presented lead to a significantly longer response than necessary to answer the question. The predicted answer includes a lot of extra information and uses a structured format that, while informative, detracts from conciseness.\n",
            "\n",
            "Given this analysis, the predicted response can be rated as follows:\n",
            "\n",
            "- It includes a lot of extra information (multiple points elaborated in detail).\n",
            "- It uses a structured format that adds to the length without directly answering the prompt in a concise manner.\n",
            "\n",
            "Therefore, I would assign a score of 3 for the predicted response, as it includes a lot of extra information or uses flowery language.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15it [08:14, 30.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : The Hardy Cross method and the Newton-Raphson method, as well as the Global Gradient Adjustment (GGA) method, are all iterative techniques used to solve network flow problems in water engineering. However, they differ fundamentally in how they update the flows simultaneously or sequentially.\n",
            "\n",
            "**Hardy Cross Method (Sequential Loop-by-Loop Corrections)**\n",
            "\n",
            "In the Hardy Cross method, the flow corrections are made sequentially, one loop at a time. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the corrections to the flow rates in each pipe.\n",
            "5.  Update the flow rates in each pipe using the corrections.\n",
            "6.  Repeat steps 2-5 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Hardy Cross method is that the flow corrections are made sequentially, one loop at a time. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the previous loop.\n",
            "\n",
            "**Newton-Raphson Method (Simultaneous Updates)**\n",
            "\n",
            "In contrast, the Newton-Raphson method updates the flow rates simultaneously, rather than sequentially. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the Jacobian matrix, which represents the sensitivity of the flow imbalances to changes in the flow rates.\n",
            "5.  Use the Jacobian matrix to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Newton-Raphson method is that the flow corrections are made simultaneously, rather than sequentially. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the current iteration, rather than the previous iteration.\n",
            "\n",
            "**Global Gradient Adjustment (GGA) Method (Simultaneous Updates)**\n",
            "\n",
            "The GGA method is similar to the Newton-Raphson method in that it updates the flow rates simultaneously. However, the GGA method uses a different approach to calculate the corrections to the flow rates. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the gradient of the flow imbalances with respect to the flow rates.\n",
            "5.  Use the gradient to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the GGA method is that it uses a gradient-based approach to calculate the corrections to the flow rates, rather than the Jacobian matrix used in the Newton-Raphson method.\n",
            "\n",
            "In summary, the Hardy Cross method updates the flow rates sequentially, one loop at a time, while the Newton-Raphson method and the GGA method update the flow rates simultaneously. The Newton-Raphson method uses a Jacobian matrix to calculate the corrections to the flow rates, while the GGA method uses a gradient-based approach.\n",
            "\u001b[32mUser message:Question: Why is the GGA particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops?, Actual answer: Large networks benefit from the GGA’s global approach, where each iteration efficiently updates all node heads via a sparse matrix solution and then flows in each pipe. Because it leverages sparse matrix techniques and well-structured linear equations, it scales very effectively as the number of pipes and nodes grows. Additionally, the method’s robustness means it can handle broad variations in pipe sizes, demands, and complex layouts without excessive iteration counts., Predicted answer: The Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to several reasons:\n",
            "\n",
            "1. **Scalability**: GGA is a robust and efficient algorithm that can handle large-scale water distribution systems with thousands of pipes, nodes, and loops. It can efficiently solve the nonlinear equations that describe the hydraulic behavior of the system, even with a large number of unknowns.\n",
            "\n",
            "2. **Flexibility**: GGA can accommodate various types of pipe networks, including loops, branches, and junctions. It can also handle different types of pipe materials, diameters, and roughness coefficients, making it a versatile tool for analyzing complex water systems.\n",
            "\n",
            "3. **Accuracy**: GGA provides accurate solutions to the hydraulic equations that govern the behavior of water distribution systems. It takes into account the nonlinear interactions between pipes, nodes, and loops, ensuring that the calculated pressures, flows, and head losses are accurate and reliable.\n",
            "\n",
            "4. **Convergence**: GGA uses a gradient-based approach to converge to the solution, which ensures that the algorithm rapidly converges to the optimal solution, even for large and complex systems. This makes it an efficient tool for analyzing water systems with thousands of pipes and loops.\n",
            "\n",
            "5. **Robustness**: GGA is a robust algorithm that can handle a wide range of input data, including noisy or uncertain data. It can also accommodate different types of boundary conditions, such as fixed pressures, flows, or head losses, making it a reliable tool for analyzing complex water systems.\n",
            "\n",
            "6. **Computational efficiency**: GGA is a computationally efficient algorithm that can solve large-scale water distribution systems in a reasonable amount of time. This makes it an ideal tool for analyzing complex systems, such as those with thousands of pipes and loops, where computational efficiency is critical.\n",
            "\n",
            "In summary, the Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to its scalability, flexibility, accuracy, convergence, robustness, and computational efficiency.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response captures the key points made in the actual answer while also assessing the confidence conveyed in the response.\n",
            "\n",
            "The actual answer emphasizes the GGA's global approach, its efficiency in updating node heads through sparse matrix solutions, and its ability to handle variations in pipe sizes and demands without excessive iterations. It highlights the algorithm's scalability and robustness in the context of large networks.\n",
            "\n",
            "The predicted answer, while comprehensive, introduces several additional points such as flexibility, accuracy, convergence, and computational efficiency. These points are relevant and contribute to a broader understanding of the GGA's capabilities. However, it does not explicitly mention the sparse matrix solution or the global approach, which are critical aspects of the actual answer. \n",
            "\n",
            "In terms of confidence, the predicted answer presents a well-structured and detailed explanation, which suggests a high level of assurance in the correctness of the information provided. However, the lack of direct alignment with the key points of the actual answer introduces some uncertainty regarding its completeness.\n",
            "\n",
            "Overall, the predicted answer leans towards being correct but does not fully encapsulate the essence of the actual answer, leading to a moderate level of agreement.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: Why is the GGA particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops?, Actual answer: Large networks benefit from the GGA’s global approach, where each iteration efficiently updates all node heads via a sparse matrix solution and then flows in each pipe. Because it leverages sparse matrix techniques and well-structured linear equations, it scales very effectively as the number of pipes and nodes grows. Additionally, the method’s robustness means it can handle broad variations in pipe sizes, demands, and complex layouts without excessive iteration counts., Predicted answer: The Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to several reasons:\n",
            "\n",
            "1. **Scalability**: GGA is a robust and efficient algorithm that can handle large-scale water distribution systems with thousands of pipes, nodes, and loops. It can efficiently solve the nonlinear equations that describe the hydraulic behavior of the system, even with a large number of unknowns.\n",
            "\n",
            "2. **Flexibility**: GGA can accommodate various types of pipe networks, including loops, branches, and junctions. It can also handle different types of pipe materials, diameters, and roughness coefficients, making it a versatile tool for analyzing complex water systems.\n",
            "\n",
            "3. **Accuracy**: GGA provides accurate solutions to the hydraulic equations that govern the behavior of water distribution systems. It takes into account the nonlinear interactions between pipes, nodes, and loops, ensuring that the calculated pressures, flows, and head losses are accurate and reliable.\n",
            "\n",
            "4. **Convergence**: GGA uses a gradient-based approach to converge to the solution, which ensures that the algorithm rapidly converges to the optimal solution, even for large and complex systems. This makes it an efficient tool for analyzing water systems with thousands of pipes and loops.\n",
            "\n",
            "5. **Robustness**: GGA is a robust algorithm that can handle a wide range of input data, including noisy or uncertain data. It can also accommodate different types of boundary conditions, such as fixed pressures, flows, or head losses, making it a reliable tool for analyzing complex water systems.\n",
            "\n",
            "6. **Computational efficiency**: GGA is a computationally efficient algorithm that can solve large-scale water distribution systems in a reasonable amount of time. This makes it an ideal tool for analyzing complex systems, such as those with thousands of pipes and loops, where computational efficiency is critical.\n",
            "\n",
            "In summary, the Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to its scalability, flexibility, accuracy, convergence, robustness, and computational efficiency.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the factual accuracy of the information presented in both responses. The actual answer emphasizes the GGA's global approach, its use of sparse matrix techniques, and its ability to handle variations in pipe sizes and demands efficiently. It highlights the algorithm's effectiveness in scaling with the number of pipes and nodes, as well as its robustness in complex layouts.\n",
            "\n",
            "The predicted answer, while providing a comprehensive overview of the GGA's capabilities, introduces several points that are not explicitly mentioned in the actual answer. It discusses scalability, flexibility, accuracy, convergence, robustness, and computational efficiency in detail. However, it does not specifically mention the sparse matrix solution or the efficiency of updating node heads, which are critical aspects of the actual answer. \n",
            "\n",
            "Moreover, while the predicted answer is largely factual and aligns with the general understanding of the GGA, it does contain some embellishments and additional details that may not be strictly necessary or directly supported by the actual answer. This leads to a mix of factual information and some degree of interpretation or extrapolation.\n",
            "\n",
            "Given these considerations, the predicted answer contains a significant amount of factual information but also includes some elements that could be seen as over-explaining or deviating from the core points made in the actual answer. Therefore, it does not fully align with the actual answer but is not entirely inaccurate either.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: Why is the GGA particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops?, Actual answer: Large networks benefit from the GGA’s global approach, where each iteration efficiently updates all node heads via a sparse matrix solution and then flows in each pipe. Because it leverages sparse matrix techniques and well-structured linear equations, it scales very effectively as the number of pipes and nodes grows. Additionally, the method’s robustness means it can handle broad variations in pipe sizes, demands, and complex layouts without excessive iteration counts., Predicted answer: The Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to several reasons:\n",
            "\n",
            "1. **Scalability**: GGA is a robust and efficient algorithm that can handle large-scale water distribution systems with thousands of pipes, nodes, and loops. It can efficiently solve the nonlinear equations that describe the hydraulic behavior of the system, even with a large number of unknowns.\n",
            "\n",
            "2. **Flexibility**: GGA can accommodate various types of pipe networks, including loops, branches, and junctions. It can also handle different types of pipe materials, diameters, and roughness coefficients, making it a versatile tool for analyzing complex water systems.\n",
            "\n",
            "3. **Accuracy**: GGA provides accurate solutions to the hydraulic equations that govern the behavior of water distribution systems. It takes into account the nonlinear interactions between pipes, nodes, and loops, ensuring that the calculated pressures, flows, and head losses are accurate and reliable.\n",
            "\n",
            "4. **Convergence**: GGA uses a gradient-based approach to converge to the solution, which ensures that the algorithm rapidly converges to the optimal solution, even for large and complex systems. This makes it an efficient tool for analyzing water systems with thousands of pipes and loops.\n",
            "\n",
            "5. **Robustness**: GGA is a robust algorithm that can handle a wide range of input data, including noisy or uncertain data. It can also accommodate different types of boundary conditions, such as fixed pressures, flows, or head losses, making it a reliable tool for analyzing complex water systems.\n",
            "\n",
            "6. **Computational efficiency**: GGA is a computationally efficient algorithm that can solve large-scale water distribution systems in a reasonable amount of time. This makes it an ideal tool for analyzing complex systems, such as those with thousands of pipes and loops, where computational efficiency is critical.\n",
            "\n",
            "In summary, the Generalized Gradient Algorithm (GGA) is particularly well-suited for analyzing water systems with thousands of pipes and numerous interconnected loops due to its scalability, flexibility, accuracy, convergence, robustness, and computational efficiency.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the key points made in both responses regarding the Generalized Gradient Algorithm (GGA) and its suitability for analyzing complex water systems.\n",
            "\n",
            "The actual answer emphasizes the GGA's global approach, its use of sparse matrix techniques, and its ability to efficiently update node heads and flows in pipes. It highlights the algorithm's scalability and robustness in handling variations in pipe sizes, demands, and layouts without excessive iterations.\n",
            "\n",
            "The predicted answer, while providing a comprehensive overview of the GGA's features, does not specifically mention the sparse matrix solution or the iterative updating of node heads, which are critical aspects of the actual answer. Instead, it focuses on general attributes like scalability, flexibility, accuracy, convergence, robustness, and computational efficiency. While these points are relevant, they lack the specificity and depth found in the actual answer.\n",
            "\n",
            "The predicted response does not misinterpret the information, nor does it confidently assert incorrect information. However, it does not fully align with the actual answer's focus on the GGA's specific methodologies and advantages in the context of water systems.\n",
            "\n",
            "Given this analysis, the predicted answer shows a good understanding of the GGA's capabilities but lacks the precision and specific context provided in the actual answer. Therefore, it does not fully meet the criteria for correctness.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4, 'judgement_descr': 4}\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error running target function: probability tensor contains either `inf`, `nan` or element < 0\n",
            "16it [08:33, 27.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: Which WDS solution method typically requires the fewest number of iterations to converge, and what is the mathematical reason behind it?, Actual answer: Newton-based methods, especially the Global Gradient Algorithm, often require the fewest iterations because they use the first-order derivative (Jacobian or gradient) of the system’s equations. This derivative information provides a clear path to reduce error in each iteration, leading to near-quadratic convergence under normal conditions. Loop-based methods generally lack this global derivative insight, thus requiring more iterations to zero in on the final solution., Predicted answer: In Water Distribution Systems (WDS) modeling, the solution method that typically requires the fewest number of iterations to converge is the Gradient Method, also known as the Linear Programming (LP) method.\n",
            "\n",
            "The Gradient Method is an optimization technique that uses the gradient of the objective function to find the optimal solution. In the context of WDS modeling, the objective function is typically the total head loss or energy loss in the system.\n",
            "\n",
            "The mathematical reason behind the Gradient Method's efficiency lies in its ability to use the gradient of the objective function to guide the search for the optimal solution. The gradient is a vector that points in the direction of the steepest ascent of the objective function. By moving in the direction of the negative gradient (i.e., the direction of the steepest descent), the algorithm can converge to the optimal solution in a relatively small number of iterations.\n",
            "\n",
            "More specifically, the Gradient Method uses the following equation to update the solution at each iteration:\n",
            "\n",
            "x_new = x_old - α \\* ∇f(x_old)\n",
            "\n",
            "where:\n",
            "\n",
            "* x_old is the current solution\n",
            "* x_new is the new solution\n",
            "* α is the step size (a small positive value)\n",
            "* ∇f(x_old) is the gradient of the objective function at the current solution\n",
            "* f(x_old) is the objective function value at the current solution\n",
            "\n",
            "The Gradient Method requires the fewest number of iterations to converge because it uses the gradient of the objective function to guide the search for the optimal solution. This allows the algorithm to move quickly towards the optimal solution, reducing the number of iterations required to converge.\n",
            "\n",
            "However, it's worth noting that the Gradient Method can be sensitive to the choice of step size (α) and the initial solution. If the step size is too large, the algorithm may overshoot the optimal solution, while a step size that is too small may lead to slow convergence. Additionally, if the initial solution is far from the optimal solution, the algorithm may require more iterations to converge.\n",
            "\n",
            "In contrast, other WDS solution methods, such as the Newton-Raphson method, may require more iterations to converge because they use a more complex update equation that involves the Hessian matrix of the objective function. The Hessian matrix is a matrix of second derivatives that describes the curvature of the objective function. While the Newton-Raphson method can be more efficient than the Gradient Method in some cases, it requires more computational effort to compute the Hessian matrix and its inverse.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the completeness of the predicted answer compared to the actual answer, we need to analyze the key elements that were addressed in both responses.\n",
            "\n",
            "The actual answer identifies Newton-based methods, specifically the Global Gradient Algorithm, as the solution method that typically requires the fewest iterations to converge. It explains the mathematical reasoning behind this by discussing the use of the first-order derivative (Jacobian or gradient) and how this leads to near-quadratic convergence. It also contrasts this with loop-based methods, which lack global derivative insight.\n",
            "\n",
            "The predicted answer, on the other hand, incorrectly identifies the Gradient Method as the solution method that requires the fewest iterations. While it provides a detailed explanation of the Gradient Method, including its mathematical formulation and the role of the gradient, it fails to mention Newton-based methods or the Global Gradient Algorithm, which is crucial to fully answering the question. Additionally, it discusses the sensitivity of the Gradient Method to step size and initial conditions, which, while relevant, does not address the core of the question regarding convergence iterations.\n",
            "\n",
            "In summary, the predicted answer contains some relevant information about the Gradient Method but misses the key point about Newton-based methods and their efficiency in terms of iterations. It also lacks a direct comparison with other methods, which is essential for completeness.\n",
            "\n",
            "Given this analysis, I would assign a score of 3 to the predicted answer, as it includes some elements of a complete answer but does not fully address the question as posed.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: Which WDS solution method typically requires the fewest number of iterations to converge, and what is the mathematical reason behind it?, Actual answer: Newton-based methods, especially the Global Gradient Algorithm, often require the fewest iterations because they use the first-order derivative (Jacobian or gradient) of the system’s equations. This derivative information provides a clear path to reduce error in each iteration, leading to near-quadratic convergence under normal conditions. Loop-based methods generally lack this global derivative insight, thus requiring more iterations to zero in on the final solution., Predicted answer: In Water Distribution Systems (WDS) modeling, the solution method that typically requires the fewest number of iterations to converge is the Gradient Method, also known as the Linear Programming (LP) method.\n",
            "\n",
            "The Gradient Method is an optimization technique that uses the gradient of the objective function to find the optimal solution. In the context of WDS modeling, the objective function is typically the total head loss or energy loss in the system.\n",
            "\n",
            "The mathematical reason behind the Gradient Method's efficiency lies in its ability to use the gradient of the objective function to guide the search for the optimal solution. The gradient is a vector that points in the direction of the steepest ascent of the objective function. By moving in the direction of the negative gradient (i.e., the direction of the steepest descent), the algorithm can converge to the optimal solution in a relatively small number of iterations.\n",
            "\n",
            "More specifically, the Gradient Method uses the following equation to update the solution at each iteration:\n",
            "\n",
            "x_new = x_old - α \\* ∇f(x_old)\n",
            "\n",
            "where:\n",
            "\n",
            "* x_old is the current solution\n",
            "* x_new is the new solution\n",
            "* α is the step size (a small positive value)\n",
            "* ∇f(x_old) is the gradient of the objective function at the current solution\n",
            "* f(x_old) is the objective function value at the current solution\n",
            "\n",
            "The Gradient Method requires the fewest number of iterations to converge because it uses the gradient of the objective function to guide the search for the optimal solution. This allows the algorithm to move quickly towards the optimal solution, reducing the number of iterations required to converge.\n",
            "\n",
            "However, it's worth noting that the Gradient Method can be sensitive to the choice of step size (α) and the initial solution. If the step size is too large, the algorithm may overshoot the optimal solution, while a step size that is too small may lead to slow convergence. Additionally, if the initial solution is far from the optimal solution, the algorithm may require more iterations to converge.\n",
            "\n",
            "In contrast, other WDS solution methods, such as the Newton-Raphson method, may require more iterations to converge because they use a more complex update equation that involves the Hessian matrix of the objective function. The Hessian matrix is a matrix of second derivatives that describes the curvature of the objective function. While the Newton-Raphson method can be more efficient than the Gradient Method in some cases, it requires more computational effort to compute the Hessian matrix and its inverse.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the relevance of the information provided in relation to the user's question about which Water Distribution System (WDS) solution method requires the fewest iterations to converge and the mathematical reasoning behind it.\n",
            "\n",
            "The actual answer correctly identifies Newton-based methods, particularly the Global Gradient Algorithm, as the solution method that typically requires the fewest iterations. It explains that these methods utilize the first-order derivative (Jacobian or gradient) of the system's equations, which leads to near-quadratic convergence. This is a precise and relevant response to the question.\n",
            "\n",
            "In contrast, the predicted answer incorrectly identifies the Gradient Method as the solution method that requires the fewest iterations. While it provides a detailed explanation of how the Gradient Method works and its mathematical basis, it fails to address the specific question about the method that converges the fastest in the context of WDS. Additionally, it introduces unnecessary comparisons with the Newton-Raphson method, which, while informative, detracts from the main focus of the question.\n",
            "\n",
            "Overall, the predicted answer does not accurately answer the user's question and contains a significant amount of irrelevant information regarding the Gradient Method and its comparison to other methods. Therefore, it does not meet the criteria for a relevant response.\n",
            "\n",
            "FINAL SCORE: 2\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 2}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: Which WDS solution method typically requires the fewest number of iterations to converge, and what is the mathematical reason behind it?, Actual answer: Newton-based methods, especially the Global Gradient Algorithm, often require the fewest iterations because they use the first-order derivative (Jacobian or gradient) of the system’s equations. This derivative information provides a clear path to reduce error in each iteration, leading to near-quadratic convergence under normal conditions. Loop-based methods generally lack this global derivative insight, thus requiring more iterations to zero in on the final solution., Predicted answer: In Water Distribution Systems (WDS) modeling, the solution method that typically requires the fewest number of iterations to converge is the Gradient Method, also known as the Linear Programming (LP) method.\n",
            "\n",
            "The Gradient Method is an optimization technique that uses the gradient of the objective function to find the optimal solution. In the context of WDS modeling, the objective function is typically the total head loss or energy loss in the system.\n",
            "\n",
            "The mathematical reason behind the Gradient Method's efficiency lies in its ability to use the gradient of the objective function to guide the search for the optimal solution. The gradient is a vector that points in the direction of the steepest ascent of the objective function. By moving in the direction of the negative gradient (i.e., the direction of the steepest descent), the algorithm can converge to the optimal solution in a relatively small number of iterations.\n",
            "\n",
            "More specifically, the Gradient Method uses the following equation to update the solution at each iteration:\n",
            "\n",
            "x_new = x_old - α \\* ∇f(x_old)\n",
            "\n",
            "where:\n",
            "\n",
            "* x_old is the current solution\n",
            "* x_new is the new solution\n",
            "* α is the step size (a small positive value)\n",
            "* ∇f(x_old) is the gradient of the objective function at the current solution\n",
            "* f(x_old) is the objective function value at the current solution\n",
            "\n",
            "The Gradient Method requires the fewest number of iterations to converge because it uses the gradient of the objective function to guide the search for the optimal solution. This allows the algorithm to move quickly towards the optimal solution, reducing the number of iterations required to converge.\n",
            "\n",
            "However, it's worth noting that the Gradient Method can be sensitive to the choice of step size (α) and the initial solution. If the step size is too large, the algorithm may overshoot the optimal solution, while a step size that is too small may lead to slow convergence. Additionally, if the initial solution is far from the optimal solution, the algorithm may require more iterations to converge.\n",
            "\n",
            "In contrast, other WDS solution methods, such as the Newton-Raphson method, may require more iterations to converge because they use a more complex update equation that involves the Hessian matrix of the objective function. The Hessian matrix is a matrix of second derivatives that describes the curvature of the objective function. While the Newton-Raphson method can be more efficient than the Gradient Method in some cases, it requires more computational effort to compute the Hessian matrix and its inverse.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we first need to analyze the content and structure of both responses. \n",
            "\n",
            "The actual answer succinctly identifies Newton-based methods, particularly the Global Gradient Algorithm, as the most efficient in terms of iterations required for convergence. It provides a clear mathematical rationale, emphasizing the use of the first-order derivative (Jacobian or gradient) and the concept of near-quadratic convergence. The explanation is direct and focused on the question without unnecessary elaboration.\n",
            "\n",
            "In contrast, the predicted answer incorrectly identifies the Gradient Method as the most efficient method and provides an extensive explanation of how the Gradient Method works, including its mathematical formulation and potential pitfalls. While it does touch on relevant concepts, it diverges significantly from the original question by introducing unnecessary details about the Gradient Method, its sensitivity to step size, and comparisons with the Newton-Raphson method. This additional information detracts from the conciseness of the response.\n",
            "\n",
            "Given these observations, the predicted answer includes a lot of extra information and uses flowery language, making it less concise than the actual answer. Therefore, I would assign a score of 3 for the predicted response.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 2, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: Which WDS solution method typically requires the fewest number of iterations to converge, and what is the mathematical reason behind it?, Actual answer: Newton-based methods, especially the Global Gradient Algorithm, often require the fewest iterations because they use the first-order derivative (Jacobian or gradient) of the system’s equations. This derivative information provides a clear path to reduce error in each iteration, leading to near-quadratic convergence under normal conditions. Loop-based methods generally lack this global derivative insight, thus requiring more iterations to zero in on the final solution., Predicted answer: In Water Distribution Systems (WDS) modeling, the solution method that typically requires the fewest number of iterations to converge is the Gradient Method, also known as the Linear Programming (LP) method.\n",
            "\n",
            "The Gradient Method is an optimization technique that uses the gradient of the objective function to find the optimal solution. In the context of WDS modeling, the objective function is typically the total head loss or energy loss in the system.\n",
            "\n",
            "The mathematical reason behind the Gradient Method's efficiency lies in its ability to use the gradient of the objective function to guide the search for the optimal solution. The gradient is a vector that points in the direction of the steepest ascent of the objective function. By moving in the direction of the negative gradient (i.e., the direction of the steepest descent), the algorithm can converge to the optimal solution in a relatively small number of iterations.\n",
            "\n",
            "More specifically, the Gradient Method uses the following equation to update the solution at each iteration:\n",
            "\n",
            "x_new = x_old - α \\* ∇f(x_old)\n",
            "\n",
            "where:\n",
            "\n",
            "* x_old is the current solution\n",
            "* x_new is the new solution\n",
            "* α is the step size (a small positive value)\n",
            "* ∇f(x_old) is the gradient of the objective function at the current solution\n",
            "* f(x_old) is the objective function value at the current solution\n",
            "\n",
            "The Gradient Method requires the fewest number of iterations to converge because it uses the gradient of the objective function to guide the search for the optimal solution. This allows the algorithm to move quickly towards the optimal solution, reducing the number of iterations required to converge.\n",
            "\n",
            "However, it's worth noting that the Gradient Method can be sensitive to the choice of step size (α) and the initial solution. If the step size is too large, the algorithm may overshoot the optimal solution, while a step size that is too small may lead to slow convergence. Additionally, if the initial solution is far from the optimal solution, the algorithm may require more iterations to converge.\n",
            "\n",
            "In contrast, other WDS solution methods, such as the Newton-Raphson method, may require more iterations to converge because they use a more complex update equation that involves the Hessian matrix of the objective function. The Hessian matrix is a matrix of second derivatives that describes the curvature of the objective function. While the Newton-Raphson method can be more efficient than the Gradient Method in some cases, it requires more computational effort to compute the Hessian matrix and its inverse.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the confidence conveyed in each response regarding the convergence of solution methods for Water Distribution Systems (WDS). \n",
            "\n",
            "The actual answer correctly identifies Newton-based methods, particularly the Global Gradient Algorithm, as the solution method that typically requires the fewest iterations to converge. It provides a clear mathematical rationale, emphasizing the use of the first-order derivative (Jacobian or gradient) and the near-quadratic convergence characteristic of these methods. This demonstrates a strong understanding of the underlying principles and effectively communicates the reasons for the convergence behavior.\n",
            "\n",
            "In contrast, the predicted answer incorrectly identifies the Gradient Method as the most efficient in terms of iterations. While it explains the mechanics of the Gradient Method and its reliance on the gradient of the objective function, it fails to recognize that Newton-based methods generally outperform it in terms of convergence speed. The predicted answer also introduces unnecessary complexity by discussing the sensitivity of the Gradient Method to step size and initial conditions, which detracts from the main point. \n",
            "\n",
            "Overall, the predicted answer shows significant misunderstanding of the question and misrepresents the comparative efficiency of the methods discussed. It does not align with the actual answer's confidence and correctness.\n",
            "\n",
            "Given these considerations, I would assign a score of 2 to the predicted answer, as it suggests that the answer is likely incorrect and raises significant concerns about its validity.\n",
            "\n",
            "FINAL SCORE: 2\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 2, 'conciseness_descr': 3, 'confidence_descr': 2}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: Which WDS solution method typically requires the fewest number of iterations to converge, and what is the mathematical reason behind it?, Actual answer: Newton-based methods, especially the Global Gradient Algorithm, often require the fewest iterations because they use the first-order derivative (Jacobian or gradient) of the system’s equations. This derivative information provides a clear path to reduce error in each iteration, leading to near-quadratic convergence under normal conditions. Loop-based methods generally lack this global derivative insight, thus requiring more iterations to zero in on the final solution., Predicted answer: In Water Distribution Systems (WDS) modeling, the solution method that typically requires the fewest number of iterations to converge is the Gradient Method, also known as the Linear Programming (LP) method.\n",
            "\n",
            "The Gradient Method is an optimization technique that uses the gradient of the objective function to find the optimal solution. In the context of WDS modeling, the objective function is typically the total head loss or energy loss in the system.\n",
            "\n",
            "The mathematical reason behind the Gradient Method's efficiency lies in its ability to use the gradient of the objective function to guide the search for the optimal solution. The gradient is a vector that points in the direction of the steepest ascent of the objective function. By moving in the direction of the negative gradient (i.e., the direction of the steepest descent), the algorithm can converge to the optimal solution in a relatively small number of iterations.\n",
            "\n",
            "More specifically, the Gradient Method uses the following equation to update the solution at each iteration:\n",
            "\n",
            "x_new = x_old - α \\* ∇f(x_old)\n",
            "\n",
            "where:\n",
            "\n",
            "* x_old is the current solution\n",
            "* x_new is the new solution\n",
            "* α is the step size (a small positive value)\n",
            "* ∇f(x_old) is the gradient of the objective function at the current solution\n",
            "* f(x_old) is the objective function value at the current solution\n",
            "\n",
            "The Gradient Method requires the fewest number of iterations to converge because it uses the gradient of the objective function to guide the search for the optimal solution. This allows the algorithm to move quickly towards the optimal solution, reducing the number of iterations required to converge.\n",
            "\n",
            "However, it's worth noting that the Gradient Method can be sensitive to the choice of step size (α) and the initial solution. If the step size is too large, the algorithm may overshoot the optimal solution, while a step size that is too small may lead to slow convergence. Additionally, if the initial solution is far from the optimal solution, the algorithm may require more iterations to converge.\n",
            "\n",
            "In contrast, other WDS solution methods, such as the Newton-Raphson method, may require more iterations to converge because they use a more complex update equation that involves the Hessian matrix of the objective function. The Hessian matrix is a matrix of second derivatives that describes the curvature of the objective function. While the Newton-Raphson method can be more efficient than the Gradient Method in some cases, it requires more computational effort to compute the Hessian matrix and its inverse.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the key points made in both responses regarding the Water Distribution Systems (WDS) solution methods and their convergence characteristics.\n",
            "\n",
            "The actual answer correctly identifies Newton-based methods, particularly the Global Gradient Algorithm, as the solution method that typically requires the fewest iterations to converge. It explains that these methods utilize the first-order derivative (Jacobian or gradient) of the system's equations, which allows for near-quadratic convergence under normal conditions. This is a crucial point because it highlights the efficiency of using derivative information in guiding the solution process.\n",
            "\n",
            "In contrast, the predicted answer incorrectly identifies the Gradient Method as the method requiring the fewest iterations. While it provides a detailed explanation of how the Gradient Method works, it fails to recognize that Newton-based methods, which leverage both first and second derivatives, generally converge faster than gradient-based methods. The predicted answer also introduces concepts like the Hessian matrix and discusses the limitations of the Gradient Method, but these points do not align with the original question's focus on which method converges the fastest.\n",
            "\n",
            "Overall, the predicted answer contains significant inaccuracies regarding the identification of the most efficient method and misrepresents the comparative convergence characteristics of the methods discussed. Therefore, it contains large amounts of both factual information and hallucinations, leading to a lower factuality score.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 2, 'conciseness_descr': 3, 'confidence_descr': 2, 'factuality_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : Sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of partial differential equations (PDEs).\n",
            "\n",
            "**What are sparse matrices?**\n",
            "\n",
            "A sparse matrix is a matrix in which most of the elements are zero. In the context of water engineering, sparse matrices often arise from the discretization of PDEs, such as the Navier-Stokes equations or the shallow water equations, using finite element or finite difference methods. These matrices have a large number of zero elements, which can be exploited to improve computational efficiency.\n",
            "\n",
            "**Why are sparse matrices important in gradient-based solvers?**\n",
            "\n",
            "Gradient-based solvers, such as the conjugate gradient method or the quasi-Newton method, are commonly used to solve systems of linear equations that arise from the discretization of PDEs. These solvers require repeated matrix-vector multiplications, which can be computationally expensive for large-scale problems.\n",
            "\n",
            "Sparse matrix techniques can improve the computational efficiency of gradient-based solvers in several ways:\n",
            "\n",
            "1.  **Reduced memory requirements**: By storing only the non-zero elements of the matrix, sparse matrix techniques can significantly reduce the memory requirements of the solver.\n",
            "2.  **Faster matrix-vector multiplications**: Sparse matrix techniques can be used to perform matrix-vector multiplications more efficiently, as only the non-zero elements of the matrix need to be accessed.\n",
            "3.  **Improved solver convergence**: By exploiting the sparsity of the matrix, sparse matrix techniques can improve the convergence of gradient-based solvers, leading to faster solution times.\n",
            "\n",
            "**Common sparse matrix techniques used in gradient-based solvers**\n",
            "\n",
            "Some common sparse matrix techniques used in gradient-based solvers include:\n",
            "\n",
            "1.  **Compressed sparse row (CSR) storage**: This is a popular storage format for sparse matrices, in which each row of the matrix is stored as a contiguous block of non-zero elements.\n",
            "2.  **Compressed sparse column (CSC) storage**: This is another popular storage format for sparse matrices, in which each column of the matrix is stored as a contiguous block of non-zero elements.\n",
            "3.  **Sparse matrix factorization**: This involves factorizing the sparse matrix into a product of two sparse matrices, which can be used to improve the efficiency of matrix-vector multiplications.\n",
            "4.  **Preconditioning**: This involves using a sparse matrix to precondition the original matrix, which can improve the convergence of gradient-based solvers.\n",
            "\n",
            "**Real-world applications of sparse matrix techniques in water engineering**\n",
            "\n",
            "Sparse matrix techniques have numerous applications in water engineering, including:\n",
            "\n",
            "1.  **Hydrodynamic modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the Navier-Stokes equations or the shallow water equations.\n",
            "2.  **Groundwater flow modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the groundwater flow equations.\n",
            "3.  **Water quality modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the water quality equations.\n",
            "\n",
            "In summary, sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of PDEs. By exploiting the sparsity of the matrix, sparse matrix techniques can reduce memory requirements, improve solver convergence, and accelerate matrix-vector multiplications.\n",
            "\u001b[32mUser message:Question: Which WDS solution method typically requires the fewest number of iterations to converge, and what is the mathematical reason behind it?, Actual answer: Newton-based methods, especially the Global Gradient Algorithm, often require the fewest iterations because they use the first-order derivative (Jacobian or gradient) of the system’s equations. This derivative information provides a clear path to reduce error in each iteration, leading to near-quadratic convergence under normal conditions. Loop-based methods generally lack this global derivative insight, thus requiring more iterations to zero in on the final solution., Predicted answer: In Water Distribution Systems (WDS) modeling, the solution method that typically requires the fewest number of iterations to converge is the Gradient Method, also known as the Linear Programming (LP) method.\n",
            "\n",
            "The Gradient Method is an optimization technique that uses the gradient of the objective function to find the optimal solution. In the context of WDS modeling, the objective function is typically the total head loss or energy loss in the system.\n",
            "\n",
            "The mathematical reason behind the Gradient Method's efficiency lies in its ability to use the gradient of the objective function to guide the search for the optimal solution. The gradient is a vector that points in the direction of the steepest ascent of the objective function. By moving in the direction of the negative gradient (i.e., the direction of the steepest descent), the algorithm can converge to the optimal solution in a relatively small number of iterations.\n",
            "\n",
            "More specifically, the Gradient Method uses the following equation to update the solution at each iteration:\n",
            "\n",
            "x_new = x_old - α \\* ∇f(x_old)\n",
            "\n",
            "where:\n",
            "\n",
            "* x_old is the current solution\n",
            "* x_new is the new solution\n",
            "* α is the step size (a small positive value)\n",
            "* ∇f(x_old) is the gradient of the objective function at the current solution\n",
            "* f(x_old) is the objective function value at the current solution\n",
            "\n",
            "The Gradient Method requires the fewest number of iterations to converge because it uses the gradient of the objective function to guide the search for the optimal solution. This allows the algorithm to move quickly towards the optimal solution, reducing the number of iterations required to converge.\n",
            "\n",
            "However, it's worth noting that the Gradient Method can be sensitive to the choice of step size (α) and the initial solution. If the step size is too large, the algorithm may overshoot the optimal solution, while a step size that is too small may lead to slow convergence. Additionally, if the initial solution is far from the optimal solution, the algorithm may require more iterations to converge.\n",
            "\n",
            "In contrast, other WDS solution methods, such as the Newton-Raphson method, may require more iterations to converge because they use a more complex update equation that involves the Hessian matrix of the objective function. The Hessian matrix is a matrix of second derivatives that describes the curvature of the objective function. While the Newton-Raphson method can be more efficient than the Gradient Method in some cases, it requires more computational effort to compute the Hessian matrix and its inverse.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy of the information presented and how confidently it is stated. The actual answer correctly identifies Newton-based methods, particularly the Global Gradient Algorithm, as the solution method that typically requires the fewest iterations to converge. It explains the mathematical reasoning behind this by discussing the use of the first-order derivative (Jacobian or gradient) and the concept of near-quadratic convergence.\n",
            "\n",
            "In contrast, the predicted answer incorrectly identifies the Gradient Method as the solution method that requires the fewest iterations. While it provides a detailed explanation of the Gradient Method and its mathematical foundation, it fails to recognize that Newton-based methods are generally more efficient in terms of convergence speed due to their use of derivative information. The predicted answer also introduces unnecessary complexity by discussing the sensitivity of the Gradient Method to step size and initial conditions, which detracts from the main point.\n",
            "\n",
            "The predicted answer misinterprets the prompt by asserting that the Gradient Method is the most efficient, which is not accurate. Therefore, it shows a lack of understanding of the context and the specific methods being compared.\n",
            "\n",
            "Given these considerations, the predicted answer demonstrates a clear misinterpretation of the information received in the prompt, leading to an incorrect conclusion.\n",
            "\n",
            "FINAL SCORE: 2\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 2, 'conciseness_descr': 3, 'confidence_descr': 2, 'factuality_descr': 3, 'judgement_descr': 2}\n",
            "\n",
            "\n",
            "No output from LLM\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: How do modern gradient-based methods handle nodes where the available pressure is insufficient to meet the specified demand?, Actual answer: Classical demand-driven algorithms would produce negative pressures at nodes with inadequate supply. Modern extensions introduce pressure-dependent demand (PDD) formulations or use an iterative scheme where node demands are reduced when pressure falls below certain thresholds. In gradient-based methods, this is done by modifying the demand equation at each iteration or introducing emitter-like relationships, ensuring that the system accurately reflects the reduced outflow when pressure is low., Predicted answer: In modern water distribution systems, gradient-based methods are widely used for hydraulic analysis and optimization. When dealing with nodes where the available pressure is insufficient to meet the specified demand, these methods employ various techniques to handle such situations. Here are some common approaches:\n",
            "\n",
            "1. **Pressure-Dependent Demand (PDD) Modeling**: In this approach, the demand at a node is modeled as a function of the available pressure. If the pressure is below a certain threshold, the demand is reduced accordingly. This allows the model to capture the non-linear relationship between pressure and demand.\n",
            "2. **Demand Reduction**: When the available pressure is insufficient, the demand at the node is reduced to match the available pressure. This can be done using a demand reduction factor, which is a function of the pressure deficit.\n",
            "3. **Pressure-Driven Demand**: In this approach, the demand at a node is driven by the available pressure. If the pressure is below a certain threshold, the demand is reduced, and if the pressure is above the threshold, the demand is increased.\n",
            "4. **Node Splitting**: If the available pressure is insufficient to meet the specified demand at a node, the node can be split into multiple smaller nodes, each with a reduced demand. This allows the model to better capture the hydraulic behavior of the system.\n",
            "5. **Pressure-Dependent Pipe Roughness**: In some models, the pipe roughness is modeled as a function of the available pressure. If the pressure is below a certain threshold, the pipe roughness is increased, which can lead to a reduction in the available pressure.\n",
            "6. **Hydraulic Reliability Index (HRI)**: The HRI is a measure of the hydraulic reliability of a node, which takes into account the available pressure, demand, and pipe roughness. If the HRI is below a certain threshold, the node is considered unreliable, and the demand is reduced accordingly.\n",
            "7. **Gradient-Based Optimization**: Gradient-based optimization methods, such as gradient descent or quasi-Newton methods, can be used to optimize the water distribution system to meet the specified demands while minimizing the pressure deficits.\n",
            "\n",
            "These are some of the common techniques used in modern gradient-based methods to handle nodes where the available pressure is insufficient to meet the specified demand. The choice of technique depends on the specific problem, the available data, and the desired level of accuracy.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the completeness of the predicted answer compared to the actual answer, we need to analyze both responses in terms of the key elements they cover regarding how modern gradient-based methods handle nodes with insufficient pressure to meet demand.\n",
            "\n",
            "The actual answer succinctly identifies the limitations of classical demand-driven algorithms, which can lead to negative pressures, and highlights modern approaches such as pressure-dependent demand (PDD) formulations and iterative schemes that adjust demands based on pressure thresholds. It emphasizes the importance of modifying demand equations or using emitter-like relationships to accurately reflect reduced outflow under low pressure conditions.\n",
            "\n",
            "The predicted answer, on the other hand, provides a comprehensive overview of various techniques employed in modern gradient-based methods. It covers several relevant approaches, including PDD modeling, demand reduction, pressure-driven demand, node splitting, pressure-dependent pipe roughness, hydraulic reliability index, and gradient-based optimization. Each technique is explained in a way that demonstrates how it addresses the issue of insufficient pressure at nodes.\n",
            "\n",
            "In terms of completeness, the predicted answer includes all the essential elements found in the actual answer and expands upon them with additional relevant techniques. It effectively captures the complexity of the problem and the various strategies that can be employed to manage insufficient pressure in water distribution systems.\n",
            "\n",
            "Given this analysis, the predicted answer covers all elements of a complete answer and provides additional insights, making it a thorough response to the question.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 5}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "17it [09:31, 35.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : EPANET is a widely used software for analyzing the hydraulic and water quality behavior of pressurized pipe networks. For analyzing steady-state flows, EPANET uses the Darcy-Weisbach equation and the Hardy-Cross method.\n",
            "\n",
            "The Darcy-Weisbach equation is a fundamental equation in fluid dynamics that describes the head loss in a pipe due to friction. It is given by:\n",
            "\n",
            "h_f = f \\* (L / D) \\* (V^2 / (2 \\* g))\n",
            "\n",
            "where:\n",
            "- h_f is the head loss due to friction\n",
            "- f is the Darcy-Weisbach friction factor\n",
            "- L is the length of the pipe\n",
            "- D is the diameter of the pipe\n",
            "- V is the average velocity of the fluid\n",
            "- g is the acceleration due to gravity\n",
            "\n",
            "The Hardy-Cross method is an iterative method used to solve the steady-state flow equations in a pipe network. It involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in each pipe.\n",
            "2.  Calculate the head losses in each pipe using the Darcy-Weisbach equation.\n",
            "3.  Calculate the pressure head at each node using the head losses and the elevation of the node.\n",
            "4.  Check if the pressure head at each node is within the acceptable range.\n",
            "5.  If not, adjust the flow rates in each pipe and repeat steps 2-4 until the pressure head at each node is within the acceptable range.\n",
            "\n",
            "EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it widely regarded as a robust and efficient solver for analyzing steady-state flows in pipe networks. The Darcy-Weisbach equation is a well-established and widely accepted equation for calculating head losses in pipes, and the Hardy-Cross method is a reliable and efficient method for solving the steady-state flow equations in a pipe network.\n",
            "\n",
            "The robustness and efficiency of EPANET's solver can be attributed to the following factors:\n",
            "\n",
            "*   **Accuracy**: EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method ensures accurate calculations of head losses and pressure heads in the pipe network.\n",
            "*   **Efficiency**: The Hardy-Cross method is an iterative method that converges quickly to the solution, making it efficient for large pipe networks.\n",
            "*   **Flexibility**: EPANET can handle a wide range of pipe network configurations, including loops, branches, and junctions.\n",
            "*   **Scalability**: EPANET can handle large pipe networks with thousands of pipes and nodes.\n",
            "\n",
            "Overall, EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it a reliable and efficient tool for analyzing steady-state flows in pipe networks.\n",
            "\u001b[32mUser message:Question: How do modern gradient-based methods handle nodes where the available pressure is insufficient to meet the specified demand?, Actual answer: Classical demand-driven algorithms would produce negative pressures at nodes with inadequate supply. Modern extensions introduce pressure-dependent demand (PDD) formulations or use an iterative scheme where node demands are reduced when pressure falls below certain thresholds. In gradient-based methods, this is done by modifying the demand equation at each iteration or introducing emitter-like relationships, ensuring that the system accurately reflects the reduced outflow when pressure is low., Predicted answer: In modern water distribution systems, gradient-based methods are widely used for hydraulic analysis and optimization. When dealing with nodes where the available pressure is insufficient to meet the specified demand, these methods employ various techniques to handle such situations. Here are some common approaches:\n",
            "\n",
            "1. **Pressure-Dependent Demand (PDD) Modeling**: In this approach, the demand at a node is modeled as a function of the available pressure. If the pressure is below a certain threshold, the demand is reduced accordingly. This allows the model to capture the non-linear relationship between pressure and demand.\n",
            "2. **Demand Reduction**: When the available pressure is insufficient, the demand at the node is reduced to match the available pressure. This can be done using a demand reduction factor, which is a function of the pressure deficit.\n",
            "3. **Pressure-Driven Demand**: In this approach, the demand at a node is driven by the available pressure. If the pressure is below a certain threshold, the demand is reduced, and if the pressure is above the threshold, the demand is increased.\n",
            "4. **Node Splitting**: If the available pressure is insufficient to meet the specified demand at a node, the node can be split into multiple smaller nodes, each with a reduced demand. This allows the model to better capture the hydraulic behavior of the system.\n",
            "5. **Pressure-Dependent Pipe Roughness**: In some models, the pipe roughness is modeled as a function of the available pressure. If the pressure is below a certain threshold, the pipe roughness is increased, which can lead to a reduction in the available pressure.\n",
            "6. **Hydraulic Reliability Index (HRI)**: The HRI is a measure of the hydraulic reliability of a node, which takes into account the available pressure, demand, and pipe roughness. If the HRI is below a certain threshold, the node is considered unreliable, and the demand is reduced accordingly.\n",
            "7. **Gradient-Based Optimization**: Gradient-based optimization methods, such as gradient descent or quasi-Newton methods, can be used to optimize the water distribution system to meet the specified demands while minimizing the pressure deficits.\n",
            "\n",
            "These are some of the common techniques used in modern gradient-based methods to handle nodes where the available pressure is insufficient to meet the specified demand. The choice of technique depends on the specific problem, the available data, and the desired level of accuracy.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question regarding how modern gradient-based methods handle nodes with insufficient pressure to meet demand. \n",
            "\n",
            "The actual answer succinctly describes the limitations of classical demand-driven algorithms and highlights modern approaches, specifically mentioning pressure-dependent demand (PDD) formulations and iterative schemes that adjust demand based on pressure thresholds. It emphasizes the importance of accurately reflecting reduced outflow when pressure is low.\n",
            "\n",
            "The predicted answer, while lengthy, provides a comprehensive overview of various techniques used in modern gradient-based methods. It includes relevant concepts such as Pressure-Dependent Demand (PDD) modeling, demand reduction, and pressure-driven demand. However, it also introduces additional methods like node splitting and hydraulic reliability index, which, while related, may not be directly necessary to answer the specific question about handling insufficient pressure.\n",
            "\n",
            "The predicted response does answer the user's question and includes relevant information, but it also contains some extraneous details that could be considered less relevant to the core inquiry. Therefore, while it is informative, it does not maintain the same level of focus as the actual answer.\n",
            "\n",
            "Considering these points, I would assign a score of 4 to the predicted answer, as it answers the question and shares a bit of irrelevant information.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: How do modern gradient-based methods handle nodes where the available pressure is insufficient to meet the specified demand?, Actual answer: Classical demand-driven algorithms would produce negative pressures at nodes with inadequate supply. Modern extensions introduce pressure-dependent demand (PDD) formulations or use an iterative scheme where node demands are reduced when pressure falls below certain thresholds. In gradient-based methods, this is done by modifying the demand equation at each iteration or introducing emitter-like relationships, ensuring that the system accurately reflects the reduced outflow when pressure is low., Predicted answer: In modern water distribution systems, gradient-based methods are widely used for hydraulic analysis and optimization. When dealing with nodes where the available pressure is insufficient to meet the specified demand, these methods employ various techniques to handle such situations. Here are some common approaches:\n",
            "\n",
            "1. **Pressure-Dependent Demand (PDD) Modeling**: In this approach, the demand at a node is modeled as a function of the available pressure. If the pressure is below a certain threshold, the demand is reduced accordingly. This allows the model to capture the non-linear relationship between pressure and demand.\n",
            "2. **Demand Reduction**: When the available pressure is insufficient, the demand at the node is reduced to match the available pressure. This can be done using a demand reduction factor, which is a function of the pressure deficit.\n",
            "3. **Pressure-Driven Demand**: In this approach, the demand at a node is driven by the available pressure. If the pressure is below a certain threshold, the demand is reduced, and if the pressure is above the threshold, the demand is increased.\n",
            "4. **Node Splitting**: If the available pressure is insufficient to meet the specified demand at a node, the node can be split into multiple smaller nodes, each with a reduced demand. This allows the model to better capture the hydraulic behavior of the system.\n",
            "5. **Pressure-Dependent Pipe Roughness**: In some models, the pipe roughness is modeled as a function of the available pressure. If the pressure is below a certain threshold, the pipe roughness is increased, which can lead to a reduction in the available pressure.\n",
            "6. **Hydraulic Reliability Index (HRI)**: The HRI is a measure of the hydraulic reliability of a node, which takes into account the available pressure, demand, and pipe roughness. If the HRI is below a certain threshold, the node is considered unreliable, and the demand is reduced accordingly.\n",
            "7. **Gradient-Based Optimization**: Gradient-based optimization methods, such as gradient descent or quasi-Newton methods, can be used to optimize the water distribution system to meet the specified demands while minimizing the pressure deficits.\n",
            "\n",
            "These are some of the common techniques used in modern gradient-based methods to handle nodes where the available pressure is insufficient to meet the specified demand. The choice of technique depends on the specific problem, the available data, and the desired level of accuracy.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information provided in the predicted response relative to the user's question. \n",
            "\n",
            "The actual answer succinctly addresses the issue of insufficient pressure at nodes by mentioning classical demand-driven algorithms and modern extensions like pressure-dependent demand (PDD) formulations. It also briefly explains how gradient-based methods modify demand equations or introduce emitter-like relationships to reflect reduced outflow.\n",
            "\n",
            "In contrast, the predicted answer is significantly longer and includes multiple detailed approaches (seven in total) to handle insufficient pressure. While these approaches are relevant, the level of detail and the number of techniques presented contribute to a verbose response that goes beyond what was necessary to answer the question. The inclusion of specific methods like \"Node Splitting\" and \"Hydraulic Reliability Index\" adds extra layers of information that may not be directly relevant to the core question.\n",
            "\n",
            "Given this analysis, the predicted answer includes a lot of extra information and uses flowery language, which detracts from its conciseness.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: How do modern gradient-based methods handle nodes where the available pressure is insufficient to meet the specified demand?, Actual answer: Classical demand-driven algorithms would produce negative pressures at nodes with inadequate supply. Modern extensions introduce pressure-dependent demand (PDD) formulations or use an iterative scheme where node demands are reduced when pressure falls below certain thresholds. In gradient-based methods, this is done by modifying the demand equation at each iteration or introducing emitter-like relationships, ensuring that the system accurately reflects the reduced outflow when pressure is low., Predicted answer: In modern water distribution systems, gradient-based methods are widely used for hydraulic analysis and optimization. When dealing with nodes where the available pressure is insufficient to meet the specified demand, these methods employ various techniques to handle such situations. Here are some common approaches:\n",
            "\n",
            "1. **Pressure-Dependent Demand (PDD) Modeling**: In this approach, the demand at a node is modeled as a function of the available pressure. If the pressure is below a certain threshold, the demand is reduced accordingly. This allows the model to capture the non-linear relationship between pressure and demand.\n",
            "2. **Demand Reduction**: When the available pressure is insufficient, the demand at the node is reduced to match the available pressure. This can be done using a demand reduction factor, which is a function of the pressure deficit.\n",
            "3. **Pressure-Driven Demand**: In this approach, the demand at a node is driven by the available pressure. If the pressure is below a certain threshold, the demand is reduced, and if the pressure is above the threshold, the demand is increased.\n",
            "4. **Node Splitting**: If the available pressure is insufficient to meet the specified demand at a node, the node can be split into multiple smaller nodes, each with a reduced demand. This allows the model to better capture the hydraulic behavior of the system.\n",
            "5. **Pressure-Dependent Pipe Roughness**: In some models, the pipe roughness is modeled as a function of the available pressure. If the pressure is below a certain threshold, the pipe roughness is increased, which can lead to a reduction in the available pressure.\n",
            "6. **Hydraulic Reliability Index (HRI)**: The HRI is a measure of the hydraulic reliability of a node, which takes into account the available pressure, demand, and pipe roughness. If the HRI is below a certain threshold, the node is considered unreliable, and the demand is reduced accordingly.\n",
            "7. **Gradient-Based Optimization**: Gradient-based optimization methods, such as gradient descent or quasi-Newton methods, can be used to optimize the water distribution system to meet the specified demands while minimizing the pressure deficits.\n",
            "\n",
            "These are some of the common techniques used in modern gradient-based methods to handle nodes where the available pressure is insufficient to meet the specified demand. The choice of technique depends on the specific problem, the available data, and the desired level of accuracy.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the confidence conveyed in both responses regarding how modern gradient-based methods handle nodes with insufficient pressure to meet demand.\n",
            "\n",
            "The actual answer succinctly describes the limitations of classical demand-driven algorithms and highlights modern approaches, specifically mentioning pressure-dependent demand (PDD) formulations and iterative schemes that adjust demand based on pressure thresholds. It emphasizes the importance of accurately reflecting reduced outflow when pressure is low, which is a critical aspect of hydraulic modeling.\n",
            "\n",
            "The predicted answer, while comprehensive and detailed, presents a broader range of techniques and methods that may not all be directly relevant to the specific question. It lists several approaches, including pressure-dependent demand modeling, demand reduction, node splitting, and hydraulic reliability index, among others. While these methods are valid in the context of hydraulic analysis, the response could be seen as somewhat verbose and less focused on the core issue of how gradient-based methods specifically address the problem of insufficient pressure.\n",
            "\n",
            "In terms of confidence, the predicted answer does convey a sense of assurance in the techniques discussed, but it lacks the precision and directness of the actual answer. The actual answer is more concise and directly addresses the question, which may lead to a higher confidence score.\n",
            "\n",
            "Given these considerations, I would assign the predicted answer a score of 4 for moderate agreement, as it provides relevant information but lacks the focused clarity of the actual answer.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error running target function: probability tensor contains either `inf`, `nan` or element < 0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mUser message:Question: How do modern gradient-based methods handle nodes where the available pressure is insufficient to meet the specified demand?, Actual answer: Classical demand-driven algorithms would produce negative pressures at nodes with inadequate supply. Modern extensions introduce pressure-dependent demand (PDD) formulations or use an iterative scheme where node demands are reduced when pressure falls below certain thresholds. In gradient-based methods, this is done by modifying the demand equation at each iteration or introducing emitter-like relationships, ensuring that the system accurately reflects the reduced outflow when pressure is low., Predicted answer: In modern water distribution systems, gradient-based methods are widely used for hydraulic analysis and optimization. When dealing with nodes where the available pressure is insufficient to meet the specified demand, these methods employ various techniques to handle such situations. Here are some common approaches:\n",
            "\n",
            "1. **Pressure-Dependent Demand (PDD) Modeling**: In this approach, the demand at a node is modeled as a function of the available pressure. If the pressure is below a certain threshold, the demand is reduced accordingly. This allows the model to capture the non-linear relationship between pressure and demand.\n",
            "2. **Demand Reduction**: When the available pressure is insufficient, the demand at the node is reduced to match the available pressure. This can be done using a demand reduction factor, which is a function of the pressure deficit.\n",
            "3. **Pressure-Driven Demand**: In this approach, the demand at a node is driven by the available pressure. If the pressure is below a certain threshold, the demand is reduced, and if the pressure is above the threshold, the demand is increased.\n",
            "4. **Node Splitting**: If the available pressure is insufficient to meet the specified demand at a node, the node can be split into multiple smaller nodes, each with a reduced demand. This allows the model to better capture the hydraulic behavior of the system.\n",
            "5. **Pressure-Dependent Pipe Roughness**: In some models, the pipe roughness is modeled as a function of the available pressure. If the pressure is below a certain threshold, the pipe roughness is increased, which can lead to a reduction in the available pressure.\n",
            "6. **Hydraulic Reliability Index (HRI)**: The HRI is a measure of the hydraulic reliability of a node, which takes into account the available pressure, demand, and pipe roughness. If the HRI is below a certain threshold, the node is considered unreliable, and the demand is reduced accordingly.\n",
            "7. **Gradient-Based Optimization**: Gradient-based optimization methods, such as gradient descent or quasi-Newton methods, can be used to optimize the water distribution system to meet the specified demands while minimizing the pressure deficits.\n",
            "\n",
            "These are some of the common techniques used in modern gradient-based methods to handle nodes where the available pressure is insufficient to meet the specified demand. The choice of technique depends on the specific problem, the available data, and the desired level of accuracy.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to analyze the content for factual accuracy and alignment with the principles of modern gradient-based methods in water distribution systems.\n",
            "\n",
            "The actual answer succinctly describes how classical demand-driven algorithms can lead to negative pressures and how modern methods address this issue through pressure-dependent demand (PDD) formulations and iterative schemes. It emphasizes the modification of demand equations and the introduction of emitter-like relationships to accurately reflect reduced outflow under low pressure conditions.\n",
            "\n",
            "The predicted answer, while lengthy, covers several relevant techniques that modern gradient-based methods might employ, such as PDD modeling, demand reduction, and hydraulic reliability indices. However, it introduces some concepts that may not be standard or widely recognized in the context of gradient-based methods, such as \"node splitting\" and \"pressure-dependent pipe roughness,\" which could be seen as less relevant or even speculative in this context. Additionally, the mention of \"gradient-based optimization\" is somewhat vague and does not directly address how these methods specifically handle insufficient pressure at nodes.\n",
            "\n",
            "Overall, while the predicted answer contains a lot of factual information and relevant concepts, it also includes some elements that may not be directly applicable or could be considered as hallucinations in the context of the question. The response does not fully align with the concise and focused nature of the actual answer.\n",
            "\n",
            "Given this analysis, I would assign a score of 4, as the predicted answer includes mostly factual information with slight hallucinations.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : The Generalized Gradient Algorithm (GGA) procedure is a widely used method in water distribution network analysis. The two main calculation steps that define the GGA procedure for determining both nodal heads and pipe flows are:\n",
            "\n",
            "1. **Linearization**: In this step, the nonlinear equations of the water distribution network are linearized around the current estimate of the solution. This involves approximating the nonlinear relationships between nodal heads and pipe flows using linear equations.\n",
            "\n",
            "2. **Iteration**: In this step, the linearized equations are solved to obtain a new estimate of the nodal heads and pipe flows. This process is repeated until convergence is achieved, i.e., until the difference between successive estimates of the solution is within a specified tolerance.\n",
            "\n",
            "These two steps are repeated iteratively until the solution converges, resulting in the determination of both nodal heads and pipe flows in the water distribution network.\n",
            "\u001b[32mUser message:Question: How do modern gradient-based methods handle nodes where the available pressure is insufficient to meet the specified demand?, Actual answer: Classical demand-driven algorithms would produce negative pressures at nodes with inadequate supply. Modern extensions introduce pressure-dependent demand (PDD) formulations or use an iterative scheme where node demands are reduced when pressure falls below certain thresholds. In gradient-based methods, this is done by modifying the demand equation at each iteration or introducing emitter-like relationships, ensuring that the system accurately reflects the reduced outflow when pressure is low., Predicted answer: In modern water distribution systems, gradient-based methods are widely used for hydraulic analysis and optimization. When dealing with nodes where the available pressure is insufficient to meet the specified demand, these methods employ various techniques to handle such situations. Here are some common approaches:\n",
            "\n",
            "1. **Pressure-Dependent Demand (PDD) Modeling**: In this approach, the demand at a node is modeled as a function of the available pressure. If the pressure is below a certain threshold, the demand is reduced accordingly. This allows the model to capture the non-linear relationship between pressure and demand.\n",
            "2. **Demand Reduction**: When the available pressure is insufficient, the demand at the node is reduced to match the available pressure. This can be done using a demand reduction factor, which is a function of the pressure deficit.\n",
            "3. **Pressure-Driven Demand**: In this approach, the demand at a node is driven by the available pressure. If the pressure is below a certain threshold, the demand is reduced, and if the pressure is above the threshold, the demand is increased.\n",
            "4. **Node Splitting**: If the available pressure is insufficient to meet the specified demand at a node, the node can be split into multiple smaller nodes, each with a reduced demand. This allows the model to better capture the hydraulic behavior of the system.\n",
            "5. **Pressure-Dependent Pipe Roughness**: In some models, the pipe roughness is modeled as a function of the available pressure. If the pressure is below a certain threshold, the pipe roughness is increased, which can lead to a reduction in the available pressure.\n",
            "6. **Hydraulic Reliability Index (HRI)**: The HRI is a measure of the hydraulic reliability of a node, which takes into account the available pressure, demand, and pipe roughness. If the HRI is below a certain threshold, the node is considered unreliable, and the demand is reduced accordingly.\n",
            "7. **Gradient-Based Optimization**: Gradient-based optimization methods, such as gradient descent or quasi-Newton methods, can be used to optimize the water distribution system to meet the specified demands while minimizing the pressure deficits.\n",
            "\n",
            "These are some of the common techniques used in modern gradient-based methods to handle nodes where the available pressure is insufficient to meet the specified demand. The choice of technique depends on the specific problem, the available data, and the desired level of accuracy.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and clarity of the information presented in both responses. The actual answer succinctly describes how classical demand-driven algorithms fail by producing negative pressures and highlights modern approaches like pressure-dependent demand (PDD) formulations and iterative schemes that adjust demands based on pressure thresholds. It emphasizes the importance of accurately reflecting reduced outflow when pressure is low.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, covers several techniques that are relevant to modern gradient-based methods. It mentions PDD modeling, demand reduction, pressure-driven demand, node splitting, pressure-dependent pipe roughness, hydraulic reliability index, and gradient-based optimization. However, it lacks the clarity and focus of the actual answer. It introduces multiple concepts that may not be directly relevant to the specific question about handling nodes with insufficient pressure, which could lead to confusion.\n",
            "\n",
            "The predicted answer does not misinterpret the prompt but rather expands on it with additional techniques. However, it does not clearly state that these methods are specifically designed to address the issue of insufficient pressure, which could lead to a misunderstanding of their applicability. The response does not confidently assert any hallucinations as truth, nor does it show uncertainty about the information provided.\n",
            "\n",
            "Given these considerations, the predicted answer is informative but somewhat unfocused and could mislead the reader regarding the specific context of handling insufficient pressure at nodes. Therefore, it does not fully meet the criteria for a correct answer.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 5, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4, 'judgement_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: What is the general process for incorporating pump curves or valve characteristics into Newton-based or gradient-based WDS solvers?, Actual answer: Pump curves and valve relationships are typically expressed as additional head-loss or head-gain equations that relate flow to head across these devices. In a Newton or gradient-based solver, these equations are included in the overall system of nodal continuity and pipe head-loss equations. Their partial derivatives (for Newton) or gradient coefficients (for GGA) are computed so that each iteration can adjust flows and pressures in a manner consistent with the pump or valve’s performance curve., Predicted answer: Incorporating pump curves or valve characteristics into Newton-based or gradient-based Water Distribution System (WDS) solvers involves several steps. Here's a general process:\n",
            "\n",
            "**Pump Curves:**\n",
            "\n",
            "1. **Pump Curve Representation**: Represent the pump curve as a function of flow rate (Q) and head (H). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Pump Curve Interpolation**: Interpolate the pump curve to obtain the head-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Pump Curve Implementation**: Implement the pump curve in the WDS solver as a function that takes the flow rate as input and returns the corresponding head.\n",
            "\n",
            "**Valve Characteristics:**\n",
            "\n",
            "1. **Valve Characteristic Representation**: Represent the valve characteristic as a function of flow rate (Q) and pressure drop (ΔP). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Valve Characteristic Interpolation**: Interpolate the valve characteristic to obtain the pressure drop-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Valve Characteristic Implementation**: Implement the valve characteristic in the WDS solver as a function that takes the flow rate as input and returns the corresponding pressure drop.\n",
            "\n",
            "**Incorporating Pump Curves and Valve Characteristics into the WDS Solver:**\n",
            "\n",
            "1. **Modify the WDS Solver**: Modify the WDS solver to include the pump curve and valve characteristic functions. This may involve adding new variables, equations, or constraints to the solver.\n",
            "2. **Update the Jacobian Matrix**: Update the Jacobian matrix of the WDS solver to include the derivatives of the pump curve and valve characteristic functions with respect to the flow rates.\n",
            "3. **Update the Residual Equations**: Update the residual equations of the WDS solver to include the pump curve and valve characteristic functions.\n",
            "4. **Solve the Updated System**: Solve the updated system of equations using a Newton-based or gradient-based solver.\n",
            "\n",
            "**Example of Pump Curve Implementation:**\n",
            "\n",
            "Suppose we have a pump curve represented by the following equation:\n",
            "\n",
            "H = a \\* Q^2 + b \\* Q + c\n",
            "\n",
            "where H is the head, Q is the flow rate, and a, b, and c are constants.\n",
            "\n",
            "In the WDS solver, we can implement this pump curve as a function that takes the flow rate as input and returns the corresponding head:\n",
            "\n",
            "```python\n",
            "def pump_curve(Q):\n",
            "    a = 0.1\n",
            "    b = 0.2\n",
            "    c = 10\n",
            "    return a * Q**2 + b * Q + c\n",
            "```\n",
            "\n",
            "**Example of Valve Characteristic Implementation:**\n",
            "\n",
            "Suppose we have a valve characteristic represented by the following equation:\n",
            "\n",
            "ΔP = d \\* Q^2 + e \\* Q + f\n",
            "\n",
            "where ΔP is the pressure drop, Q is the flow rate, and d, e, and f are constants.\n",
            "\n",
            "In the WDS solver, we can implement this valve characteristic as a function that takes the flow rate as input and returns the corresponding pressure drop:\n",
            "\n",
            "```python\n",
            "def valve_characteristic(Q):\n",
            "    d = 0.1\n",
            "    e = 0.2\n",
            "    f = 10\n",
            "    return d * Q**2 + e * Q + f\n",
            "```\n",
            "\n",
            "Note that these are simplified examples and actual pump curves and valve characteristics may be more complex and require more sophisticated mathematical representations.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the completeness of the predicted answer compared to the actual answer, we need to analyze the key elements present in both responses. \n",
            "\n",
            "The actual answer succinctly describes how pump curves and valve characteristics are integrated into Newton-based or gradient-based WDS solvers. It emphasizes the representation of these curves as head-loss or head-gain equations, their inclusion in the overall system of equations, and the computation of partial derivatives or gradient coefficients for iterative adjustments.\n",
            "\n",
            "The predicted answer, on the other hand, provides a detailed step-by-step process for incorporating pump curves and valve characteristics. It includes specific methods for representation, interpolation, implementation, and updating the solver's equations and Jacobian matrix. Additionally, it offers examples of how to implement these characteristics in code, which adds practical value.\n",
            "\n",
            "In terms of completeness:\n",
            "- The predicted answer covers the representation and implementation of pump curves and valve characteristics, which aligns with the actual answer's focus on head-loss and head-gain equations.\n",
            "- It also includes the necessary steps to modify the WDS solver and update the Jacobian matrix, which are critical for a complete understanding of the process.\n",
            "- However, the predicted answer does not explicitly mention the relationship of these characteristics to nodal continuity and pipe head-loss equations, which is a key aspect of the actual answer.\n",
            "\n",
            "Overall, the predicted answer includes most elements of a complete answer but lacks some specific connections to the overall system of equations as highlighted in the actual answer. Therefore, I would assign a score of 4, as it covers most elements but misses a few critical connections.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "19it [10:14, 29.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : The Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks for several reasons:\n",
            "\n",
            "1.  **Iterative Convergence**: The Hardy Cross method is an iterative approach that relies on successive approximations to converge to the solution. However, as the network size increases, the number of iterations required to achieve convergence also increases, which can lead to numerical instability and divergence. In contrast, the Linear Theory approach uses a direct solution method, which is less prone to numerical instability.\n",
            "\n",
            "2.  **Sensitivity to Initial Conditions**: The Hardy Cross method is sensitive to the initial conditions used to start the iteration process. Small changes in the initial conditions can lead to significantly different solutions, which can be problematic in large or complex networks. The Linear Theory approach, on the other hand, is less sensitive to initial conditions, as it uses a direct solution method that is less dependent on the starting point.\n",
            "\n",
            "3.  **Computational Efficiency**: The Linear Theory approach is generally more computationally efficient than the Hardy Cross method, especially for large or complex networks. This is because the Linear Theory approach uses a direct solution method, which can be solved using standard linear algebra techniques, whereas the Hardy Cross method requires iterative calculations that can be computationally intensive.\n",
            "\n",
            "4.  **Numerical Stability**: The Linear Theory approach is generally more numerically stable than the Hardy Cross method, especially when dealing with large or complex networks. This is because the Linear Theory approach uses a direct solution method that is less prone to numerical instability, whereas the Hardy Cross method relies on iterative calculations that can be sensitive to numerical errors.\n",
            "\n",
            "5.  **Scalability**: The Linear Theory approach is generally more scalable than the Hardy Cross method, especially for very large or complex networks. This is because the Linear Theory approach uses a direct solution method that can be easily parallelized, whereas the Hardy Cross method relies on iterative calculations that can be difficult to parallelize.\n",
            "\n",
            "In summary, the Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks due to its direct solution method, reduced sensitivity to initial conditions, computational efficiency, numerical stability, and scalability.\n",
            "\u001b[32mUser message:Question: What is the general process for incorporating pump curves or valve characteristics into Newton-based or gradient-based WDS solvers?, Actual answer: Pump curves and valve relationships are typically expressed as additional head-loss or head-gain equations that relate flow to head across these devices. In a Newton or gradient-based solver, these equations are included in the overall system of nodal continuity and pipe head-loss equations. Their partial derivatives (for Newton) or gradient coefficients (for GGA) are computed so that each iteration can adjust flows and pressures in a manner consistent with the pump or valve’s performance curve., Predicted answer: Incorporating pump curves or valve characteristics into Newton-based or gradient-based Water Distribution System (WDS) solvers involves several steps. Here's a general process:\n",
            "\n",
            "**Pump Curves:**\n",
            "\n",
            "1. **Pump Curve Representation**: Represent the pump curve as a function of flow rate (Q) and head (H). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Pump Curve Interpolation**: Interpolate the pump curve to obtain the head-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Pump Curve Implementation**: Implement the pump curve in the WDS solver as a function that takes the flow rate as input and returns the corresponding head.\n",
            "\n",
            "**Valve Characteristics:**\n",
            "\n",
            "1. **Valve Characteristic Representation**: Represent the valve characteristic as a function of flow rate (Q) and pressure drop (ΔP). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Valve Characteristic Interpolation**: Interpolate the valve characteristic to obtain the pressure drop-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Valve Characteristic Implementation**: Implement the valve characteristic in the WDS solver as a function that takes the flow rate as input and returns the corresponding pressure drop.\n",
            "\n",
            "**Incorporating Pump Curves and Valve Characteristics into the WDS Solver:**\n",
            "\n",
            "1. **Modify the WDS Solver**: Modify the WDS solver to include the pump curve and valve characteristic functions. This may involve adding new variables, equations, or constraints to the solver.\n",
            "2. **Update the Jacobian Matrix**: Update the Jacobian matrix of the WDS solver to include the derivatives of the pump curve and valve characteristic functions with respect to the flow rates.\n",
            "3. **Update the Residual Equations**: Update the residual equations of the WDS solver to include the pump curve and valve characteristic functions.\n",
            "4. **Solve the Updated System**: Solve the updated system of equations using a Newton-based or gradient-based solver.\n",
            "\n",
            "**Example of Pump Curve Implementation:**\n",
            "\n",
            "Suppose we have a pump curve represented by the following equation:\n",
            "\n",
            "H = a \\* Q^2 + b \\* Q + c\n",
            "\n",
            "where H is the head, Q is the flow rate, and a, b, and c are constants.\n",
            "\n",
            "In the WDS solver, we can implement this pump curve as a function that takes the flow rate as input and returns the corresponding head:\n",
            "\n",
            "```python\n",
            "def pump_curve(Q):\n",
            "    a = 0.1\n",
            "    b = 0.2\n",
            "    c = 10\n",
            "    return a * Q**2 + b * Q + c\n",
            "```\n",
            "\n",
            "**Example of Valve Characteristic Implementation:**\n",
            "\n",
            "Suppose we have a valve characteristic represented by the following equation:\n",
            "\n",
            "ΔP = d \\* Q^2 + e \\* Q + f\n",
            "\n",
            "where ΔP is the pressure drop, Q is the flow rate, and d, e, and f are constants.\n",
            "\n",
            "In the WDS solver, we can implement this valve characteristic as a function that takes the flow rate as input and returns the corresponding pressure drop:\n",
            "\n",
            "```python\n",
            "def valve_characteristic(Q):\n",
            "    d = 0.1\n",
            "    e = 0.2\n",
            "    f = 10\n",
            "    return d * Q**2 + e * Q + f\n",
            "```\n",
            "\n",
            "Note that these are simplified examples and actual pump curves and valve characteristics may be more complex and require more sophisticated mathematical representations.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about incorporating pump curves and valve characteristics into Newton-based or gradient-based Water Distribution System (WDS) solvers.\n",
            "\n",
            "The actual answer succinctly explains that pump curves and valve relationships are expressed as additional head-loss or head-gain equations, which are integrated into the overall system of equations used by the solver. It emphasizes the importance of computing partial derivatives or gradient coefficients for the iterative process.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, provides a step-by-step process for incorporating pump curves and valve characteristics. It includes specific methods for representation, interpolation, implementation, and updating the solver. However, it diverges from the core focus of the actual answer by elaborating on interpolation techniques and providing code examples, which may not be necessary for a general understanding of the process.\n",
            "\n",
            "In terms of relevance:\n",
            "- The predicted answer does address the user's question and provides a comprehensive overview of the process.\n",
            "- However, it includes a significant amount of detail that may be considered extraneous, such as specific interpolation methods and code examples, which could detract from the main point.\n",
            "\n",
            "Given this analysis, the predicted answer is relevant but contains more irrelevant information than necessary for a straightforward understanding of the incorporation process.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: What is the general process for incorporating pump curves or valve characteristics into Newton-based or gradient-based WDS solvers?, Actual answer: Pump curves and valve relationships are typically expressed as additional head-loss or head-gain equations that relate flow to head across these devices. In a Newton or gradient-based solver, these equations are included in the overall system of nodal continuity and pipe head-loss equations. Their partial derivatives (for Newton) or gradient coefficients (for GGA) are computed so that each iteration can adjust flows and pressures in a manner consistent with the pump or valve’s performance curve., Predicted answer: Incorporating pump curves or valve characteristics into Newton-based or gradient-based Water Distribution System (WDS) solvers involves several steps. Here's a general process:\n",
            "\n",
            "**Pump Curves:**\n",
            "\n",
            "1. **Pump Curve Representation**: Represent the pump curve as a function of flow rate (Q) and head (H). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Pump Curve Interpolation**: Interpolate the pump curve to obtain the head-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Pump Curve Implementation**: Implement the pump curve in the WDS solver as a function that takes the flow rate as input and returns the corresponding head.\n",
            "\n",
            "**Valve Characteristics:**\n",
            "\n",
            "1. **Valve Characteristic Representation**: Represent the valve characteristic as a function of flow rate (Q) and pressure drop (ΔP). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Valve Characteristic Interpolation**: Interpolate the valve characteristic to obtain the pressure drop-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Valve Characteristic Implementation**: Implement the valve characteristic in the WDS solver as a function that takes the flow rate as input and returns the corresponding pressure drop.\n",
            "\n",
            "**Incorporating Pump Curves and Valve Characteristics into the WDS Solver:**\n",
            "\n",
            "1. **Modify the WDS Solver**: Modify the WDS solver to include the pump curve and valve characteristic functions. This may involve adding new variables, equations, or constraints to the solver.\n",
            "2. **Update the Jacobian Matrix**: Update the Jacobian matrix of the WDS solver to include the derivatives of the pump curve and valve characteristic functions with respect to the flow rates.\n",
            "3. **Update the Residual Equations**: Update the residual equations of the WDS solver to include the pump curve and valve characteristic functions.\n",
            "4. **Solve the Updated System**: Solve the updated system of equations using a Newton-based or gradient-based solver.\n",
            "\n",
            "**Example of Pump Curve Implementation:**\n",
            "\n",
            "Suppose we have a pump curve represented by the following equation:\n",
            "\n",
            "H = a \\* Q^2 + b \\* Q + c\n",
            "\n",
            "where H is the head, Q is the flow rate, and a, b, and c are constants.\n",
            "\n",
            "In the WDS solver, we can implement this pump curve as a function that takes the flow rate as input and returns the corresponding head:\n",
            "\n",
            "```python\n",
            "def pump_curve(Q):\n",
            "    a = 0.1\n",
            "    b = 0.2\n",
            "    c = 10\n",
            "    return a * Q**2 + b * Q + c\n",
            "```\n",
            "\n",
            "**Example of Valve Characteristic Implementation:**\n",
            "\n",
            "Suppose we have a valve characteristic represented by the following equation:\n",
            "\n",
            "ΔP = d \\* Q^2 + e \\* Q + f\n",
            "\n",
            "where ΔP is the pressure drop, Q is the flow rate, and d, e, and f are constants.\n",
            "\n",
            "In the WDS solver, we can implement this valve characteristic as a function that takes the flow rate as input and returns the corresponding pressure drop:\n",
            "\n",
            "```python\n",
            "def valve_characteristic(Q):\n",
            "    d = 0.1\n",
            "    e = 0.2\n",
            "    f = 10\n",
            "    return d * Q**2 + e * Q + f\n",
            "```\n",
            "\n",
            "Note that these are simplified examples and actual pump curves and valve characteristics may be more complex and require more sophisticated mathematical representations.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information provided in the predicted response relative to the original question. \n",
            "\n",
            "The actual answer succinctly explains how pump curves and valve characteristics are incorporated into Newton-based or gradient-based WDS solvers by focusing on the essential concepts of head-loss or head-gain equations and their integration into the system of equations. It emphasizes the need for computing partial derivatives or gradient coefficients without delving into excessive detail.\n",
            "\n",
            "In contrast, the predicted answer provides a detailed step-by-step process that includes multiple sub-steps for both pump curves and valve characteristics, along with examples of implementation in Python. While this information is relevant, it is significantly more detailed than what was necessary to answer the question. The inclusion of interpolation methods, specific implementation examples, and the breakdown of the process into numerous steps adds a considerable amount of extra information that may not be required for a general understanding of the process.\n",
            "\n",
            "Given this analysis, the predicted answer includes a lot of extra information and uses flowery language, which detracts from its conciseness.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: What is the general process for incorporating pump curves or valve characteristics into Newton-based or gradient-based WDS solvers?, Actual answer: Pump curves and valve relationships are typically expressed as additional head-loss or head-gain equations that relate flow to head across these devices. In a Newton or gradient-based solver, these equations are included in the overall system of nodal continuity and pipe head-loss equations. Their partial derivatives (for Newton) or gradient coefficients (for GGA) are computed so that each iteration can adjust flows and pressures in a manner consistent with the pump or valve’s performance curve., Predicted answer: Incorporating pump curves or valve characteristics into Newton-based or gradient-based Water Distribution System (WDS) solvers involves several steps. Here's a general process:\n",
            "\n",
            "**Pump Curves:**\n",
            "\n",
            "1. **Pump Curve Representation**: Represent the pump curve as a function of flow rate (Q) and head (H). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Pump Curve Interpolation**: Interpolate the pump curve to obtain the head-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Pump Curve Implementation**: Implement the pump curve in the WDS solver as a function that takes the flow rate as input and returns the corresponding head.\n",
            "\n",
            "**Valve Characteristics:**\n",
            "\n",
            "1. **Valve Characteristic Representation**: Represent the valve characteristic as a function of flow rate (Q) and pressure drop (ΔP). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Valve Characteristic Interpolation**: Interpolate the valve characteristic to obtain the pressure drop-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Valve Characteristic Implementation**: Implement the valve characteristic in the WDS solver as a function that takes the flow rate as input and returns the corresponding pressure drop.\n",
            "\n",
            "**Incorporating Pump Curves and Valve Characteristics into the WDS Solver:**\n",
            "\n",
            "1. **Modify the WDS Solver**: Modify the WDS solver to include the pump curve and valve characteristic functions. This may involve adding new variables, equations, or constraints to the solver.\n",
            "2. **Update the Jacobian Matrix**: Update the Jacobian matrix of the WDS solver to include the derivatives of the pump curve and valve characteristic functions with respect to the flow rates.\n",
            "3. **Update the Residual Equations**: Update the residual equations of the WDS solver to include the pump curve and valve characteristic functions.\n",
            "4. **Solve the Updated System**: Solve the updated system of equations using a Newton-based or gradient-based solver.\n",
            "\n",
            "**Example of Pump Curve Implementation:**\n",
            "\n",
            "Suppose we have a pump curve represented by the following equation:\n",
            "\n",
            "H = a \\* Q^2 + b \\* Q + c\n",
            "\n",
            "where H is the head, Q is the flow rate, and a, b, and c are constants.\n",
            "\n",
            "In the WDS solver, we can implement this pump curve as a function that takes the flow rate as input and returns the corresponding head:\n",
            "\n",
            "```python\n",
            "def pump_curve(Q):\n",
            "    a = 0.1\n",
            "    b = 0.2\n",
            "    c = 10\n",
            "    return a * Q**2 + b * Q + c\n",
            "```\n",
            "\n",
            "**Example of Valve Characteristic Implementation:**\n",
            "\n",
            "Suppose we have a valve characteristic represented by the following equation:\n",
            "\n",
            "ΔP = d \\* Q^2 + e \\* Q + f\n",
            "\n",
            "where ΔP is the pressure drop, Q is the flow rate, and d, e, and f are constants.\n",
            "\n",
            "In the WDS solver, we can implement this valve characteristic as a function that takes the flow rate as input and returns the corresponding pressure drop:\n",
            "\n",
            "```python\n",
            "def valve_characteristic(Q):\n",
            "    d = 0.1\n",
            "    e = 0.2\n",
            "    f = 10\n",
            "    return d * Q**2 + e * Q + f\n",
            "```\n",
            "\n",
            "Note that these are simplified examples and actual pump curves and valve characteristics may be more complex and require more sophisticated mathematical representations.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response captures the essential elements of the process for incorporating pump curves and valve characteristics into Newton-based or gradient-based Water Distribution System (WDS) solvers.\n",
            "\n",
            "The actual answer succinctly describes the integration of pump curves and valve characteristics as additional head-loss or head-gain equations, emphasizing their role in the overall system of nodal continuity and pipe head-loss equations. It also mentions the importance of computing partial derivatives or gradient coefficients for the iterative process.\n",
            "\n",
            "The predicted answer, while detailed and structured, provides a step-by-step breakdown of the process, including representation, interpolation, implementation, and modification of the WDS solver. It also includes examples of mathematical representations for pump curves and valve characteristics. However, it lacks the concise integration of these elements into the overall system of equations as highlighted in the actual answer. \n",
            "\n",
            "The predicted answer does convey a high level of confidence in the process described, but it may introduce unnecessary complexity by detailing interpolation methods and specific implementation examples, which could detract from the clarity of the overall integration process.\n",
            "\n",
            "Given these considerations, the predicted answer demonstrates a moderate level of agreement with the actual answer, but it does not fully encapsulate the essence of the integration process as effectively as the actual answer does.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: What is the general process for incorporating pump curves or valve characteristics into Newton-based or gradient-based WDS solvers?, Actual answer: Pump curves and valve relationships are typically expressed as additional head-loss or head-gain equations that relate flow to head across these devices. In a Newton or gradient-based solver, these equations are included in the overall system of nodal continuity and pipe head-loss equations. Their partial derivatives (for Newton) or gradient coefficients (for GGA) are computed so that each iteration can adjust flows and pressures in a manner consistent with the pump or valve’s performance curve., Predicted answer: Incorporating pump curves or valve characteristics into Newton-based or gradient-based Water Distribution System (WDS) solvers involves several steps. Here's a general process:\n",
            "\n",
            "**Pump Curves:**\n",
            "\n",
            "1. **Pump Curve Representation**: Represent the pump curve as a function of flow rate (Q) and head (H). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Pump Curve Interpolation**: Interpolate the pump curve to obtain the head-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Pump Curve Implementation**: Implement the pump curve in the WDS solver as a function that takes the flow rate as input and returns the corresponding head.\n",
            "\n",
            "**Valve Characteristics:**\n",
            "\n",
            "1. **Valve Characteristic Representation**: Represent the valve characteristic as a function of flow rate (Q) and pressure drop (ΔP). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Valve Characteristic Interpolation**: Interpolate the valve characteristic to obtain the pressure drop-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Valve Characteristic Implementation**: Implement the valve characteristic in the WDS solver as a function that takes the flow rate as input and returns the corresponding pressure drop.\n",
            "\n",
            "**Incorporating Pump Curves and Valve Characteristics into the WDS Solver:**\n",
            "\n",
            "1. **Modify the WDS Solver**: Modify the WDS solver to include the pump curve and valve characteristic functions. This may involve adding new variables, equations, or constraints to the solver.\n",
            "2. **Update the Jacobian Matrix**: Update the Jacobian matrix of the WDS solver to include the derivatives of the pump curve and valve characteristic functions with respect to the flow rates.\n",
            "3. **Update the Residual Equations**: Update the residual equations of the WDS solver to include the pump curve and valve characteristic functions.\n",
            "4. **Solve the Updated System**: Solve the updated system of equations using a Newton-based or gradient-based solver.\n",
            "\n",
            "**Example of Pump Curve Implementation:**\n",
            "\n",
            "Suppose we have a pump curve represented by the following equation:\n",
            "\n",
            "H = a \\* Q^2 + b \\* Q + c\n",
            "\n",
            "where H is the head, Q is the flow rate, and a, b, and c are constants.\n",
            "\n",
            "In the WDS solver, we can implement this pump curve as a function that takes the flow rate as input and returns the corresponding head:\n",
            "\n",
            "```python\n",
            "def pump_curve(Q):\n",
            "    a = 0.1\n",
            "    b = 0.2\n",
            "    c = 10\n",
            "    return a * Q**2 + b * Q + c\n",
            "```\n",
            "\n",
            "**Example of Valve Characteristic Implementation:**\n",
            "\n",
            "Suppose we have a valve characteristic represented by the following equation:\n",
            "\n",
            "ΔP = d \\* Q^2 + e \\* Q + f\n",
            "\n",
            "where ΔP is the pressure drop, Q is the flow rate, and d, e, and f are constants.\n",
            "\n",
            "In the WDS solver, we can implement this valve characteristic as a function that takes the flow rate as input and returns the corresponding pressure drop:\n",
            "\n",
            "```python\n",
            "def valve_characteristic(Q):\n",
            "    d = 0.1\n",
            "    e = 0.2\n",
            "    f = 10\n",
            "    return d * Q**2 + e * Q + f\n",
            "```\n",
            "\n",
            "Note that these are simplified examples and actual pump curves and valve characteristics may be more complex and require more sophisticated mathematical representations.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and completeness of the information provided in both responses regarding the incorporation of pump curves and valve characteristics into Newton-based or gradient-based Water Distribution System (WDS) solvers.\n",
            "\n",
            "The actual answer succinctly describes how pump curves and valve relationships are integrated into the solver by expressing them as additional head-loss or head-gain equations. It emphasizes the importance of including these equations in the overall system of nodal continuity and pipe head-loss equations, along with the computation of their partial derivatives or gradient coefficients for iterative adjustments.\n",
            "\n",
            "The predicted answer, while more detailed and structured, provides a comprehensive step-by-step process for incorporating pump curves and valve characteristics. It includes specific methods for representation, interpolation, implementation, and updating the solver, which are all relevant to the question. The examples given for pump curve and valve characteristic implementation are practical and illustrate the concepts well.\n",
            "\n",
            "However, the predicted answer does not explicitly mention the integration of these characteristics into the overall system of equations or the need for their derivatives in the context of a Newton or gradient-based solver, which is a key aspect highlighted in the actual answer. This omission could lead to a misunderstanding of how these components interact within the solver framework.\n",
            "\n",
            "Overall, the predicted answer contains a wealth of factual information and is largely accurate, but it lacks some critical connections to the overall system dynamics that the actual answer emphasizes. Therefore, it contains both factual information and some omissions.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: What is the general process for incorporating pump curves or valve characteristics into Newton-based or gradient-based WDS solvers?, Actual answer: Pump curves and valve relationships are typically expressed as additional head-loss or head-gain equations that relate flow to head across these devices. In a Newton or gradient-based solver, these equations are included in the overall system of nodal continuity and pipe head-loss equations. Their partial derivatives (for Newton) or gradient coefficients (for GGA) are computed so that each iteration can adjust flows and pressures in a manner consistent with the pump or valve’s performance curve., Predicted answer: Incorporating pump curves or valve characteristics into Newton-based or gradient-based Water Distribution System (WDS) solvers involves several steps. Here's a general process:\n",
            "\n",
            "**Pump Curves:**\n",
            "\n",
            "1. **Pump Curve Representation**: Represent the pump curve as a function of flow rate (Q) and head (H). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Pump Curve Interpolation**: Interpolate the pump curve to obtain the head-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Pump Curve Implementation**: Implement the pump curve in the WDS solver as a function that takes the flow rate as input and returns the corresponding head.\n",
            "\n",
            "**Valve Characteristics:**\n",
            "\n",
            "1. **Valve Characteristic Representation**: Represent the valve characteristic as a function of flow rate (Q) and pressure drop (ΔP). This can be done using a mathematical equation or a lookup table.\n",
            "2. **Valve Characteristic Interpolation**: Interpolate the valve characteristic to obtain the pressure drop-flow relationship at intermediate flow rates. This can be done using techniques such as linear interpolation or cubic spline interpolation.\n",
            "3. **Valve Characteristic Implementation**: Implement the valve characteristic in the WDS solver as a function that takes the flow rate as input and returns the corresponding pressure drop.\n",
            "\n",
            "**Incorporating Pump Curves and Valve Characteristics into the WDS Solver:**\n",
            "\n",
            "1. **Modify the WDS Solver**: Modify the WDS solver to include the pump curve and valve characteristic functions. This may involve adding new variables, equations, or constraints to the solver.\n",
            "2. **Update the Jacobian Matrix**: Update the Jacobian matrix of the WDS solver to include the derivatives of the pump curve and valve characteristic functions with respect to the flow rates.\n",
            "3. **Update the Residual Equations**: Update the residual equations of the WDS solver to include the pump curve and valve characteristic functions.\n",
            "4. **Solve the Updated System**: Solve the updated system of equations using a Newton-based or gradient-based solver.\n",
            "\n",
            "**Example of Pump Curve Implementation:**\n",
            "\n",
            "Suppose we have a pump curve represented by the following equation:\n",
            "\n",
            "H = a \\* Q^2 + b \\* Q + c\n",
            "\n",
            "where H is the head, Q is the flow rate, and a, b, and c are constants.\n",
            "\n",
            "In the WDS solver, we can implement this pump curve as a function that takes the flow rate as input and returns the corresponding head:\n",
            "\n",
            "```python\n",
            "def pump_curve(Q):\n",
            "    a = 0.1\n",
            "    b = 0.2\n",
            "    c = 10\n",
            "    return a * Q**2 + b * Q + c\n",
            "```\n",
            "\n",
            "**Example of Valve Characteristic Implementation:**\n",
            "\n",
            "Suppose we have a valve characteristic represented by the following equation:\n",
            "\n",
            "ΔP = d \\* Q^2 + e \\* Q + f\n",
            "\n",
            "where ΔP is the pressure drop, Q is the flow rate, and d, e, and f are constants.\n",
            "\n",
            "In the WDS solver, we can implement this valve characteristic as a function that takes the flow rate as input and returns the corresponding pressure drop:\n",
            "\n",
            "```python\n",
            "def valve_characteristic(Q):\n",
            "    d = 0.1\n",
            "    e = 0.2\n",
            "    f = 10\n",
            "    return d * Q**2 + e * Q + f\n",
            "```\n",
            "\n",
            "Note that these are simplified examples and actual pump curves and valve characteristics may be more complex and require more sophisticated mathematical representations.\u001b[0m\n",
            "\u001b[31mAI message:The predicted answer provides a detailed and structured approach to incorporating pump curves and valve characteristics into Newton-based or gradient-based Water Distribution System (WDS) solvers. It outlines the process in a clear manner, breaking it down into steps for both pump curves and valve characteristics, which is beneficial for understanding the implementation.\n",
            "\n",
            "The actual answer, while concise, captures the essence of the process by emphasizing the integration of head-loss or head-gain equations into the overall system of equations. It also mentions the importance of computing partial derivatives or gradient coefficients, which is crucial for the iterative nature of these solvers.\n",
            "\n",
            "In comparing the two responses, the predicted answer is more comprehensive and provides practical examples, which enhances its utility for someone looking to implement these concepts. However, it does not explicitly mention the integration of these equations into the nodal continuity and pipe head-loss equations, which is a key aspect highlighted in the actual answer.\n",
            "\n",
            "Overall, the predicted answer is accurate and demonstrates a strong understanding of the topic, but it lacks some of the succinctness and focus of the actual answer. It does not misinterpret any information and presents the information confidently.\n",
            "\n",
            "Given these considerations, I would assign the predicted answer a score of 5, as it is correct and provides a thorough explanation of the process.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4, 'judgement_descr': 5}\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "20it [10:45, 29.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : In the Linear Theory (Simultaneous Pipe) method, linearizing the head-loss equation is a crucial step that enables the entire network to be solved in a single system of equations per iteration. Here's how it works:\n",
            "\n",
            "1. **Head-loss equation**: The head-loss equation in a pipe network is typically given by the Darcy-Weisbach equation or the Hazen-Williams equation. These equations relate the head loss (h_f) in a pipe to the flow rate (Q), pipe diameter (D), length (L), and friction factor (f).\n",
            "2. **Linearization**: To linearize the head-loss equation, we can use a Taylor series expansion around a reference point (Q_ref, h_f_ref). This expansion approximates the head-loss equation as a linear function of the flow rate (Q) around the reference point.\n",
            "3. **Linearized head-loss equation**: The linearized head-loss equation can be written as:\n",
            "\n",
            "h_f ≈ h_f_ref + ∂h_f/∂Q \\* (Q - Q_ref)\n",
            "\n",
            "where ∂h_f/∂Q is the partial derivative of head loss with respect to flow rate, evaluated at the reference point.\n",
            "\n",
            "4. **System of equations**: By linearizing the head-loss equation for each pipe in the network, we can create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be written in matrix form as:\n",
            "\n",
            "A \\* Q = B\n",
            "\n",
            "where A is a matrix of coefficients, Q is a vector of flow rates, and B is a vector of head losses.\n",
            "\n",
            "5. **Single system of equations per iteration**: By linearizing the head-loss equation for each pipe in the network, we can create a single system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be solved using standard linear algebra techniques, such as Gaussian elimination or LU decomposition.\n",
            "\n",
            "The key insight here is that the linearized head-loss equation allows us to decouple the flow rates (Q) in each pipe from the head losses (h_f) in each pipe. This decoupling enables us to solve the entire network in a single system of equations per iteration, rather than having to solve a separate system of equations for each pipe.\n",
            "\n",
            "In practice, the Linear Theory (Simultaneous Pipe) method involves the following steps:\n",
            "\n",
            "1. Initialize the flow rates (Q) in each pipe.\n",
            "2. Linearize the head-loss equation for each pipe using the Taylor series expansion.\n",
            "3. Create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe.\n",
            "4. Solve the system of equations using standard linear algebra techniques.\n",
            "5. Update the flow rates (Q) in each pipe based on the solution to the system of equations.\n",
            "6. Repeat steps 2-5 until convergence is achieved.\n",
            "\n",
            "The Linear Theory (Simultaneous Pipe) method is a powerful tool for solving pipe network problems, and its ability to linearize the head-loss equation and solve the entire network in a single system of equations per iteration is a key feature of its success.\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: How do simultaneous or global updates of flows in Newton-Raphson or GGA methods differ fundamentally from the sequential loop-by-loop corrections in Hardy Cross?, Actual answer: In Newton-Raphson and GGA methods, all unknowns—either node heads or pipe flows—are solved together in a system of equations, accounting for the entire network’s interactions at each iteration. This means a single change in flow is influenced by, and simultaneously influences, the other flows and heads. Hardy Cross, by contrast, updates each loop independently and then moves on to the next, creating the possibility that a correction in one loop has to be revisited if it disrupts previously balanced loops., Predicted answer: The Hardy Cross method and the Newton-Raphson method, as well as the Global Gradient Adjustment (GGA) method, are all iterative techniques used to solve network flow problems in water engineering. However, they differ fundamentally in how they update the flows simultaneously or sequentially.\n",
            "\n",
            "**Hardy Cross Method (Sequential Loop-by-Loop Corrections)**\n",
            "\n",
            "In the Hardy Cross method, the flow corrections are made sequentially, one loop at a time. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the corrections to the flow rates in each pipe.\n",
            "5.  Update the flow rates in each pipe using the corrections.\n",
            "6.  Repeat steps 2-5 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Hardy Cross method is that the flow corrections are made sequentially, one loop at a time. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the previous loop.\n",
            "\n",
            "**Newton-Raphson Method (Simultaneous Updates)**\n",
            "\n",
            "In contrast, the Newton-Raphson method updates the flow rates simultaneously, rather than sequentially. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the Jacobian matrix, which represents the sensitivity of the flow imbalances to changes in the flow rates.\n",
            "5.  Use the Jacobian matrix to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Newton-Raphson method is that the flow corrections are made simultaneously, rather than sequentially. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the current iteration, rather than the previous iteration.\n",
            "\n",
            "**Global Gradient Adjustment (GGA) Method (Simultaneous Updates)**\n",
            "\n",
            "The GGA method is similar to the Newton-Raphson method in that it updates the flow rates simultaneously. However, the GGA method uses a different approach to calculate the corrections to the flow rates. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the gradient of the flow imbalances with respect to the flow rates.\n",
            "5.  Use the gradient to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the GGA method is that it uses a gradient-based approach to calculate the corrections to the flow rates, rather than the Jacobian matrix used in the Newton-Raphson method.\n",
            "\n",
            "In summary, the Hardy Cross method updates the flow rates sequentially, one loop at a time, while the Newton-Raphson method and the GGA method update the flow rates simultaneously. The Newton-Raphson method uses a Jacobian matrix to calculate the corrections to the flow rates, while the GGA method uses a gradient-based approach.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the completeness of the information provided in both responses regarding the differences between the Newton-Raphson, GGA, and Hardy Cross methods.\n",
            "\n",
            "The actual answer succinctly captures the essence of the differences: it emphasizes that Newton-Raphson and GGA methods solve for all unknowns simultaneously, reflecting the interconnectedness of the network, while Hardy Cross operates on a loop-by-loop basis, which may require revisiting corrections. This highlights the fundamental operational differences in how these methods approach flow corrections.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, does cover the fundamental differences between the methods. It explains the sequential nature of the Hardy Cross method and the simultaneous updates in the Newton-Raphson and GGA methods. It also outlines the steps involved in each method, which adds clarity. However, it lacks the concise summary that directly addresses the core question about the fundamental differences in the context of simultaneous versus sequential updates. \n",
            "\n",
            "Overall, the predicted answer includes most elements of a complete answer but does not fully encapsulate the essence of the differences as clearly as the actual answer does. Therefore, it can be rated as having most elements present but lacking in clarity and conciseness.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: How do simultaneous or global updates of flows in Newton-Raphson or GGA methods differ fundamentally from the sequential loop-by-loop corrections in Hardy Cross?, Actual answer: In Newton-Raphson and GGA methods, all unknowns—either node heads or pipe flows—are solved together in a system of equations, accounting for the entire network’s interactions at each iteration. This means a single change in flow is influenced by, and simultaneously influences, the other flows and heads. Hardy Cross, by contrast, updates each loop independently and then moves on to the next, creating the possibility that a correction in one loop has to be revisited if it disrupts previously balanced loops., Predicted answer: The Hardy Cross method and the Newton-Raphson method, as well as the Global Gradient Adjustment (GGA) method, are all iterative techniques used to solve network flow problems in water engineering. However, they differ fundamentally in how they update the flows simultaneously or sequentially.\n",
            "\n",
            "**Hardy Cross Method (Sequential Loop-by-Loop Corrections)**\n",
            "\n",
            "In the Hardy Cross method, the flow corrections are made sequentially, one loop at a time. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the corrections to the flow rates in each pipe.\n",
            "5.  Update the flow rates in each pipe using the corrections.\n",
            "6.  Repeat steps 2-5 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Hardy Cross method is that the flow corrections are made sequentially, one loop at a time. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the previous loop.\n",
            "\n",
            "**Newton-Raphson Method (Simultaneous Updates)**\n",
            "\n",
            "In contrast, the Newton-Raphson method updates the flow rates simultaneously, rather than sequentially. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the Jacobian matrix, which represents the sensitivity of the flow imbalances to changes in the flow rates.\n",
            "5.  Use the Jacobian matrix to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Newton-Raphson method is that the flow corrections are made simultaneously, rather than sequentially. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the current iteration, rather than the previous iteration.\n",
            "\n",
            "**Global Gradient Adjustment (GGA) Method (Simultaneous Updates)**\n",
            "\n",
            "The GGA method is similar to the Newton-Raphson method in that it updates the flow rates simultaneously. However, the GGA method uses a different approach to calculate the corrections to the flow rates. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the gradient of the flow imbalances with respect to the flow rates.\n",
            "5.  Use the gradient to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the GGA method is that it uses a gradient-based approach to calculate the corrections to the flow rates, rather than the Jacobian matrix used in the Newton-Raphson method.\n",
            "\n",
            "In summary, the Hardy Cross method updates the flow rates sequentially, one loop at a time, while the Newton-Raphson method and the GGA method update the flow rates simultaneously. The Newton-Raphson method uses a Jacobian matrix to calculate the corrections to the flow rates, while the GGA method uses a gradient-based approach.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about the fundamental differences between simultaneous updates in Newton-Raphson and GGA methods versus the sequential corrections in the Hardy Cross method.\n",
            "\n",
            "The actual answer succinctly explains the core differences: Newton-Raphson and GGA methods solve for all unknowns simultaneously, which allows for interdependencies among flows and heads to be accounted for in each iteration. In contrast, the Hardy Cross method updates flows sequentially, which can lead to the need for revisiting corrections if they disrupt previously balanced loops.\n",
            "\n",
            "The predicted answer, while providing a detailed explanation of each method, includes a lot of procedural information that may not be directly relevant to the user's question. It outlines the steps involved in the Hardy Cross, Newton-Raphson, and GGA methods, which, while informative, does not focus on the fundamental differences as clearly as the actual answer does. The predicted response does mention the sequential versus simultaneous nature of the updates, but it gets bogged down in the details of the processes rather than emphasizing the implications of these differences.\n",
            "\n",
            "Given this analysis, the predicted answer does address the user's question but contains a significant amount of irrelevant procedural information that detracts from its relevance.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: How do simultaneous or global updates of flows in Newton-Raphson or GGA methods differ fundamentally from the sequential loop-by-loop corrections in Hardy Cross?, Actual answer: In Newton-Raphson and GGA methods, all unknowns—either node heads or pipe flows—are solved together in a system of equations, accounting for the entire network’s interactions at each iteration. This means a single change in flow is influenced by, and simultaneously influences, the other flows and heads. Hardy Cross, by contrast, updates each loop independently and then moves on to the next, creating the possibility that a correction in one loop has to be revisited if it disrupts previously balanced loops., Predicted answer: The Hardy Cross method and the Newton-Raphson method, as well as the Global Gradient Adjustment (GGA) method, are all iterative techniques used to solve network flow problems in water engineering. However, they differ fundamentally in how they update the flows simultaneously or sequentially.\n",
            "\n",
            "**Hardy Cross Method (Sequential Loop-by-Loop Corrections)**\n",
            "\n",
            "In the Hardy Cross method, the flow corrections are made sequentially, one loop at a time. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the corrections to the flow rates in each pipe.\n",
            "5.  Update the flow rates in each pipe using the corrections.\n",
            "6.  Repeat steps 2-5 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Hardy Cross method is that the flow corrections are made sequentially, one loop at a time. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the previous loop.\n",
            "\n",
            "**Newton-Raphson Method (Simultaneous Updates)**\n",
            "\n",
            "In contrast, the Newton-Raphson method updates the flow rates simultaneously, rather than sequentially. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the Jacobian matrix, which represents the sensitivity of the flow imbalances to changes in the flow rates.\n",
            "5.  Use the Jacobian matrix to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Newton-Raphson method is that the flow corrections are made simultaneously, rather than sequentially. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the current iteration, rather than the previous iteration.\n",
            "\n",
            "**Global Gradient Adjustment (GGA) Method (Simultaneous Updates)**\n",
            "\n",
            "The GGA method is similar to the Newton-Raphson method in that it updates the flow rates simultaneously. However, the GGA method uses a different approach to calculate the corrections to the flow rates. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the gradient of the flow imbalances with respect to the flow rates.\n",
            "5.  Use the gradient to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the GGA method is that it uses a gradient-based approach to calculate the corrections to the flow rates, rather than the Jacobian matrix used in the Newton-Raphson method.\n",
            "\n",
            "In summary, the Hardy Cross method updates the flow rates sequentially, one loop at a time, while the Newton-Raphson method and the GGA method update the flow rates simultaneously. The Newton-Raphson method uses a Jacobian matrix to calculate the corrections to the flow rates, while the GGA method uses a gradient-based approach.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information provided in the predicted response. The actual answer succinctly explains the fundamental differences between the methods without unnecessary elaboration. In contrast, the predicted answer provides a detailed breakdown of each method, including step-by-step processes that, while informative, may not be necessary to directly address the question posed.\n",
            "\n",
            "The predicted answer includes extensive descriptions of the Hardy Cross, Newton-Raphson, and GGA methods, which introduces a significant amount of extra information that could be considered flowery or excessive for the context of the question. The actual answer is more focused and directly addresses the core differences without delving into procedural details.\n",
            "\n",
            "Given this analysis, the predicted response is longer than necessary and includes a lot of extra information, which detracts from its conciseness.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: How do simultaneous or global updates of flows in Newton-Raphson or GGA methods differ fundamentally from the sequential loop-by-loop corrections in Hardy Cross?, Actual answer: In Newton-Raphson and GGA methods, all unknowns—either node heads or pipe flows—are solved together in a system of equations, accounting for the entire network’s interactions at each iteration. This means a single change in flow is influenced by, and simultaneously influences, the other flows and heads. Hardy Cross, by contrast, updates each loop independently and then moves on to the next, creating the possibility that a correction in one loop has to be revisited if it disrupts previously balanced loops., Predicted answer: The Hardy Cross method and the Newton-Raphson method, as well as the Global Gradient Adjustment (GGA) method, are all iterative techniques used to solve network flow problems in water engineering. However, they differ fundamentally in how they update the flows simultaneously or sequentially.\n",
            "\n",
            "**Hardy Cross Method (Sequential Loop-by-Loop Corrections)**\n",
            "\n",
            "In the Hardy Cross method, the flow corrections are made sequentially, one loop at a time. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the corrections to the flow rates in each pipe.\n",
            "5.  Update the flow rates in each pipe using the corrections.\n",
            "6.  Repeat steps 2-5 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Hardy Cross method is that the flow corrections are made sequentially, one loop at a time. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the previous loop.\n",
            "\n",
            "**Newton-Raphson Method (Simultaneous Updates)**\n",
            "\n",
            "In contrast, the Newton-Raphson method updates the flow rates simultaneously, rather than sequentially. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the Jacobian matrix, which represents the sensitivity of the flow imbalances to changes in the flow rates.\n",
            "5.  Use the Jacobian matrix to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Newton-Raphson method is that the flow corrections are made simultaneously, rather than sequentially. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the current iteration, rather than the previous iteration.\n",
            "\n",
            "**Global Gradient Adjustment (GGA) Method (Simultaneous Updates)**\n",
            "\n",
            "The GGA method is similar to the Newton-Raphson method in that it updates the flow rates simultaneously. However, the GGA method uses a different approach to calculate the corrections to the flow rates. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the gradient of the flow imbalances with respect to the flow rates.\n",
            "5.  Use the gradient to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the GGA method is that it uses a gradient-based approach to calculate the corrections to the flow rates, rather than the Jacobian matrix used in the Newton-Raphson method.\n",
            "\n",
            "In summary, the Hardy Cross method updates the flow rates sequentially, one loop at a time, while the Newton-Raphson method and the GGA method update the flow rates simultaneously. The Newton-Raphson method uses a Jacobian matrix to calculate the corrections to the flow rates, while the GGA method uses a gradient-based approach.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response captures the fundamental differences between the Hardy Cross method and the simultaneous update methods (Newton-Raphson and GGA). \n",
            "\n",
            "The actual answer succinctly explains that the Newton-Raphson and GGA methods solve for all unknowns simultaneously, which allows for interdependencies between flows and heads to be accounted for in each iteration. In contrast, the Hardy Cross method updates flows sequentially, which can lead to the need for revisiting corrections if they disrupt previously balanced loops.\n",
            "\n",
            "The predicted answer provides a detailed breakdown of each method, explaining the iterative processes involved. It correctly identifies the sequential nature of the Hardy Cross method and the simultaneous updates in the Newton-Raphson and GGA methods. However, while it does describe the processes well, it lacks a clear emphasis on the implications of these differences, particularly the interdependence of flows in the simultaneous methods versus the independence in the Hardy Cross method. \n",
            "\n",
            "The predicted answer is informative and mostly accurate, but it does not convey the same level of confidence in asserting the fundamental differences as the actual answer does. It presents the information in a more procedural manner rather than emphasizing the conceptual distinctions.\n",
            "\n",
            "Given this analysis, I would assign a score of 4 to the predicted answer. It shows moderate agreement with the actual answer but does not fully capture the confidence and clarity of the fundamental differences.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: How do simultaneous or global updates of flows in Newton-Raphson or GGA methods differ fundamentally from the sequential loop-by-loop corrections in Hardy Cross?, Actual answer: In Newton-Raphson and GGA methods, all unknowns—either node heads or pipe flows—are solved together in a system of equations, accounting for the entire network’s interactions at each iteration. This means a single change in flow is influenced by, and simultaneously influences, the other flows and heads. Hardy Cross, by contrast, updates each loop independently and then moves on to the next, creating the possibility that a correction in one loop has to be revisited if it disrupts previously balanced loops., Predicted answer: The Hardy Cross method and the Newton-Raphson method, as well as the Global Gradient Adjustment (GGA) method, are all iterative techniques used to solve network flow problems in water engineering. However, they differ fundamentally in how they update the flows simultaneously or sequentially.\n",
            "\n",
            "**Hardy Cross Method (Sequential Loop-by-Loop Corrections)**\n",
            "\n",
            "In the Hardy Cross method, the flow corrections are made sequentially, one loop at a time. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the corrections to the flow rates in each pipe.\n",
            "5.  Update the flow rates in each pipe using the corrections.\n",
            "6.  Repeat steps 2-5 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Hardy Cross method is that the flow corrections are made sequentially, one loop at a time. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the previous loop.\n",
            "\n",
            "**Newton-Raphson Method (Simultaneous Updates)**\n",
            "\n",
            "In contrast, the Newton-Raphson method updates the flow rates simultaneously, rather than sequentially. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the Jacobian matrix, which represents the sensitivity of the flow imbalances to changes in the flow rates.\n",
            "5.  Use the Jacobian matrix to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Newton-Raphson method is that the flow corrections are made simultaneously, rather than sequentially. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the current iteration, rather than the previous iteration.\n",
            "\n",
            "**Global Gradient Adjustment (GGA) Method (Simultaneous Updates)**\n",
            "\n",
            "The GGA method is similar to the Newton-Raphson method in that it updates the flow rates simultaneously. However, the GGA method uses a different approach to calculate the corrections to the flow rates. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the gradient of the flow imbalances with respect to the flow rates.\n",
            "5.  Use the gradient to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the GGA method is that it uses a gradient-based approach to calculate the corrections to the flow rates, rather than the Jacobian matrix used in the Newton-Raphson method.\n",
            "\n",
            "In summary, the Hardy Cross method updates the flow rates sequentially, one loop at a time, while the Newton-Raphson method and the GGA method update the flow rates simultaneously. The Newton-Raphson method uses a Jacobian matrix to calculate the corrections to the flow rates, while the GGA method uses a gradient-based approach.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and completeness of the information provided in both responses. \n",
            "\n",
            "The actual answer succinctly explains the fundamental differences between the Newton-Raphson and GGA methods, which solve for all unknowns simultaneously, and the Hardy Cross method, which operates on a loop-by-loop basis. It emphasizes the interconnectedness of flow corrections in the simultaneous methods versus the independent updates in Hardy Cross.\n",
            "\n",
            "The predicted answer, while detailed and structured, contains some inaccuracies and unnecessary elaboration. It correctly identifies the sequential nature of the Hardy Cross method and the simultaneous updates in the Newton-Raphson and GGA methods. However, it introduces a level of detail that may not be necessary for a direct comparison, such as the specific steps involved in each method. Additionally, it inaccurately implies that the GGA method is fundamentally different from the Newton-Raphson method without clearly stating that both methods share the characteristic of simultaneous updates.\n",
            "\n",
            "Overall, the predicted answer contains a mix of factual information and some inaccuracies, particularly in the interpretation of the GGA method's relationship to the Newton-Raphson method. Therefore, it does not fully align with the factuality of the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: How do simultaneous or global updates of flows in Newton-Raphson or GGA methods differ fundamentally from the sequential loop-by-loop corrections in Hardy Cross?, Actual answer: In Newton-Raphson and GGA methods, all unknowns—either node heads or pipe flows—are solved together in a system of equations, accounting for the entire network’s interactions at each iteration. This means a single change in flow is influenced by, and simultaneously influences, the other flows and heads. Hardy Cross, by contrast, updates each loop independently and then moves on to the next, creating the possibility that a correction in one loop has to be revisited if it disrupts previously balanced loops., Predicted answer: The Hardy Cross method and the Newton-Raphson method, as well as the Global Gradient Adjustment (GGA) method, are all iterative techniques used to solve network flow problems in water engineering. However, they differ fundamentally in how they update the flows simultaneously or sequentially.\n",
            "\n",
            "**Hardy Cross Method (Sequential Loop-by-Loop Corrections)**\n",
            "\n",
            "In the Hardy Cross method, the flow corrections are made sequentially, one loop at a time. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the corrections to the flow rates in each pipe.\n",
            "5.  Update the flow rates in each pipe using the corrections.\n",
            "6.  Repeat steps 2-5 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Hardy Cross method is that the flow corrections are made sequentially, one loop at a time. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the previous loop.\n",
            "\n",
            "**Newton-Raphson Method (Simultaneous Updates)**\n",
            "\n",
            "In contrast, the Newton-Raphson method updates the flow rates simultaneously, rather than sequentially. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the Jacobian matrix, which represents the sensitivity of the flow imbalances to changes in the flow rates.\n",
            "5.  Use the Jacobian matrix to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the Newton-Raphson method is that the flow corrections are made simultaneously, rather than sequentially. This means that the flow rates in each pipe are updated based on the flow imbalances calculated in the current iteration, rather than the previous iteration.\n",
            "\n",
            "**Global Gradient Adjustment (GGA) Method (Simultaneous Updates)**\n",
            "\n",
            "The GGA method is similar to the Newton-Raphson method in that it updates the flow rates simultaneously. However, the GGA method uses a different approach to calculate the corrections to the flow rates. The process involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in the network.\n",
            "2.  Calculate the head losses in each pipe using the initial flow rates.\n",
            "3.  Calculate the flow imbalances at each node (i.e., the difference between the inflow and outflow at each node).\n",
            "4.  Use the flow imbalances to calculate the gradient of the flow imbalances with respect to the flow rates.\n",
            "5.  Use the gradient to calculate the corrections to the flow rates in each pipe.\n",
            "6.  Update the flow rates in each pipe using the corrections.\n",
            "7.  Repeat steps 2-6 until the flow imbalances are within a specified tolerance.\n",
            "\n",
            "The key feature of the GGA method is that it uses a gradient-based approach to calculate the corrections to the flow rates, rather than the Jacobian matrix used in the Newton-Raphson method.\n",
            "\n",
            "In summary, the Hardy Cross method updates the flow rates sequentially, one loop at a time, while the Newton-Raphson method and the GGA method update the flow rates simultaneously. The Newton-Raphson method uses a Jacobian matrix to calculate the corrections to the flow rates, while the GGA method uses a gradient-based approach.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and clarity of the information presented in both responses. The actual answer succinctly explains the fundamental differences between the Hardy Cross method and the simultaneous update methods (Newton-Raphson and GGA) in terms of their iterative processes. It emphasizes the simultaneous nature of updates in the latter methods and the sequential nature of Hardy Cross, highlighting the implications of these differences on flow corrections.\n",
            "\n",
            "The predicted answer, while detailed and structured, does not fully capture the essence of the differences as clearly as the actual answer. It provides a thorough breakdown of the steps involved in each method, which is informative, but it lacks the concise comparison that directly addresses the question. Additionally, it does not explicitly mention the influence of one loop's correction on others in the Hardy Cross method, which is a critical point made in the actual answer.\n",
            "\n",
            "Overall, the predicted answer shows a good understanding of the methods but does not effectively convey the fundamental differences in a way that directly answers the question. It presents the information in a somewhat convoluted manner, which may lead to confusion about the core distinctions.\n",
            "\n",
            "Given these considerations, I would assign the predicted answer a score of 3. It shows an understanding of the topic but does not clearly articulate the differences or the implications of those differences.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 3, 'judgement_descr': 3}\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error running target function: probability tensor contains either `inf`, `nan` or element < 0\n",
            "21it [11:18, 30.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No output from LLM\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: What role do sparse matrix techniques play in improving the computational efficiency of large-scale gradient-based solvers?, Actual answer: Sparse matrix techniques take advantage of the fact that most entries in the system’s coefficient matrix are zero (since each node is only connected to a few others). Efficient data structures and factorization algorithms, such as sparse Cholesky or LU decomposition, reduce both the memory requirements and computation time. This can significantly speed up solving linearized systems in each iteration of a gradient-based method, which is critical for large networks with thousands of pipes and nodes., Predicted answer: Sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of partial differential equations (PDEs).\n",
            "\n",
            "**What are sparse matrices?**\n",
            "\n",
            "A sparse matrix is a matrix in which most of the elements are zero. In the context of water engineering, sparse matrices often arise from the discretization of PDEs, such as the Navier-Stokes equations or the shallow water equations, using finite element or finite difference methods. These matrices have a large number of zero elements, which can be exploited to improve computational efficiency.\n",
            "\n",
            "**Why are sparse matrices important in gradient-based solvers?**\n",
            "\n",
            "Gradient-based solvers, such as the conjugate gradient method or the quasi-Newton method, are commonly used to solve systems of linear equations that arise from the discretization of PDEs. These solvers require repeated matrix-vector multiplications, which can be computationally expensive for large-scale problems.\n",
            "\n",
            "Sparse matrix techniques can improve the computational efficiency of gradient-based solvers in several ways:\n",
            "\n",
            "1.  **Reduced memory requirements**: By storing only the non-zero elements of the matrix, sparse matrix techniques can significantly reduce the memory requirements of the solver.\n",
            "2.  **Faster matrix-vector multiplications**: Sparse matrix techniques can be used to perform matrix-vector multiplications more efficiently, as only the non-zero elements of the matrix need to be accessed.\n",
            "3.  **Improved solver convergence**: By exploiting the sparsity of the matrix, sparse matrix techniques can improve the convergence of gradient-based solvers, leading to faster solution times.\n",
            "\n",
            "**Common sparse matrix techniques used in gradient-based solvers**\n",
            "\n",
            "Some common sparse matrix techniques used in gradient-based solvers include:\n",
            "\n",
            "1.  **Compressed sparse row (CSR) storage**: This is a popular storage format for sparse matrices, in which each row of the matrix is stored as a contiguous block of non-zero elements.\n",
            "2.  **Compressed sparse column (CSC) storage**: This is another popular storage format for sparse matrices, in which each column of the matrix is stored as a contiguous block of non-zero elements.\n",
            "3.  **Sparse matrix factorization**: This involves factorizing the sparse matrix into a product of two sparse matrices, which can be used to improve the efficiency of matrix-vector multiplications.\n",
            "4.  **Preconditioning**: This involves using a sparse matrix to precondition the original matrix, which can improve the convergence of gradient-based solvers.\n",
            "\n",
            "**Real-world applications of sparse matrix techniques in water engineering**\n",
            "\n",
            "Sparse matrix techniques have numerous applications in water engineering, including:\n",
            "\n",
            "1.  **Hydrodynamic modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the Navier-Stokes equations or the shallow water equations.\n",
            "2.  **Groundwater flow modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the groundwater flow equations.\n",
            "3.  **Water quality modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the water quality equations.\n",
            "\n",
            "In summary, sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of PDEs. By exploiting the sparsity of the matrix, sparse matrix techniques can reduce memory requirements, improve solver convergence, and accelerate matrix-vector multiplications.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the completeness of the response in addressing the question about the role of sparse matrix techniques in improving the computational efficiency of large-scale gradient-based solvers.\n",
            "\n",
            "The actual answer succinctly identifies the key aspects of sparse matrix techniques, including their ability to exploit the sparsity of coefficient matrices, the use of efficient data structures and factorization algorithms, and the impact on memory requirements and computation time. It also emphasizes the significance of these techniques in speeding up the solving of linearized systems in gradient-based methods, particularly in the context of large networks.\n",
            "\n",
            "The predicted answer, while comprehensive, includes additional context about sparse matrices, their definitions, and various techniques used in gradient-based solvers. It discusses the importance of sparse matrices in gradient-based solvers, outlines several techniques, and provides real-world applications in water engineering. However, it does not explicitly mention the specific factorization algorithms (like sparse Cholesky or LU decomposition) that are crucial for improving computational efficiency, which is a key element of the actual answer.\n",
            "\n",
            "Overall, the predicted answer covers most elements of a complete answer but lacks some specific details that would enhance its completeness. It provides a thorough explanation of sparse matrix techniques and their applications but does not fully encapsulate the direct impact on computational efficiency as highlighted in the actual answer.\n",
            "\n",
            "Given this analysis, I would assign a score of 4, as the predicted answer includes most elements of a complete answer but misses some specific details that would make it fully comprehensive.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: What role do sparse matrix techniques play in improving the computational efficiency of large-scale gradient-based solvers?, Actual answer: Sparse matrix techniques take advantage of the fact that most entries in the system’s coefficient matrix are zero (since each node is only connected to a few others). Efficient data structures and factorization algorithms, such as sparse Cholesky or LU decomposition, reduce both the memory requirements and computation time. This can significantly speed up solving linearized systems in each iteration of a gradient-based method, which is critical for large networks with thousands of pipes and nodes., Predicted answer: Sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of partial differential equations (PDEs).\n",
            "\n",
            "**What are sparse matrices?**\n",
            "\n",
            "A sparse matrix is a matrix in which most of the elements are zero. In the context of water engineering, sparse matrices often arise from the discretization of PDEs, such as the Navier-Stokes equations or the shallow water equations, using finite element or finite difference methods. These matrices have a large number of zero elements, which can be exploited to improve computational efficiency.\n",
            "\n",
            "**Why are sparse matrices important in gradient-based solvers?**\n",
            "\n",
            "Gradient-based solvers, such as the conjugate gradient method or the quasi-Newton method, are commonly used to solve systems of linear equations that arise from the discretization of PDEs. These solvers require repeated matrix-vector multiplications, which can be computationally expensive for large-scale problems.\n",
            "\n",
            "Sparse matrix techniques can improve the computational efficiency of gradient-based solvers in several ways:\n",
            "\n",
            "1.  **Reduced memory requirements**: By storing only the non-zero elements of the matrix, sparse matrix techniques can significantly reduce the memory requirements of the solver.\n",
            "2.  **Faster matrix-vector multiplications**: Sparse matrix techniques can be used to perform matrix-vector multiplications more efficiently, as only the non-zero elements of the matrix need to be accessed.\n",
            "3.  **Improved solver convergence**: By exploiting the sparsity of the matrix, sparse matrix techniques can improve the convergence of gradient-based solvers, leading to faster solution times.\n",
            "\n",
            "**Common sparse matrix techniques used in gradient-based solvers**\n",
            "\n",
            "Some common sparse matrix techniques used in gradient-based solvers include:\n",
            "\n",
            "1.  **Compressed sparse row (CSR) storage**: This is a popular storage format for sparse matrices, in which each row of the matrix is stored as a contiguous block of non-zero elements.\n",
            "2.  **Compressed sparse column (CSC) storage**: This is another popular storage format for sparse matrices, in which each column of the matrix is stored as a contiguous block of non-zero elements.\n",
            "3.  **Sparse matrix factorization**: This involves factorizing the sparse matrix into a product of two sparse matrices, which can be used to improve the efficiency of matrix-vector multiplications.\n",
            "4.  **Preconditioning**: This involves using a sparse matrix to precondition the original matrix, which can improve the convergence of gradient-based solvers.\n",
            "\n",
            "**Real-world applications of sparse matrix techniques in water engineering**\n",
            "\n",
            "Sparse matrix techniques have numerous applications in water engineering, including:\n",
            "\n",
            "1.  **Hydrodynamic modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the Navier-Stokes equations or the shallow water equations.\n",
            "2.  **Groundwater flow modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the groundwater flow equations.\n",
            "3.  **Water quality modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the water quality equations.\n",
            "\n",
            "In summary, sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of PDEs. By exploiting the sparsity of the matrix, sparse matrix techniques can reduce memory requirements, improve solver convergence, and accelerate matrix-vector multiplications.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about the role of sparse matrix techniques in improving the computational efficiency of large-scale gradient-based solvers. \n",
            "\n",
            "The actual answer succinctly explains the importance of sparse matrix techniques, highlighting their ability to exploit the sparsity of matrices to reduce memory requirements and computation time, which is crucial for solving linearized systems in gradient-based methods. It also mentions specific algorithms like sparse Cholesky or LU decomposition, which are relevant to the context.\n",
            "\n",
            "The predicted answer, while informative and detailed, includes a significant amount of background information about sparse matrices, their definitions, and various techniques. It elaborates on the importance of sparse matrices in gradient-based solvers and provides examples of applications in water engineering. However, it diverges from the core focus of the question by introducing extensive explanations and examples that, while relevant, may not be necessary for directly answering the question.\n",
            "\n",
            "In terms of relevance:\n",
            "- The predicted answer does address the user's question about the role of sparse matrix techniques but includes a lot of additional information that could be considered extraneous.\n",
            "- The detailed explanations about sparse matrices and their applications, while informative, may detract from the direct answer to the question.\n",
            "\n",
            "Given this analysis, the predicted answer contains more irrelevant information than relevant information, but it still answers the user's question adequately.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: What role do sparse matrix techniques play in improving the computational efficiency of large-scale gradient-based solvers?, Actual answer: Sparse matrix techniques take advantage of the fact that most entries in the system’s coefficient matrix are zero (since each node is only connected to a few others). Efficient data structures and factorization algorithms, such as sparse Cholesky or LU decomposition, reduce both the memory requirements and computation time. This can significantly speed up solving linearized systems in each iteration of a gradient-based method, which is critical for large networks with thousands of pipes and nodes., Predicted answer: Sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of partial differential equations (PDEs).\n",
            "\n",
            "**What are sparse matrices?**\n",
            "\n",
            "A sparse matrix is a matrix in which most of the elements are zero. In the context of water engineering, sparse matrices often arise from the discretization of PDEs, such as the Navier-Stokes equations or the shallow water equations, using finite element or finite difference methods. These matrices have a large number of zero elements, which can be exploited to improve computational efficiency.\n",
            "\n",
            "**Why are sparse matrices important in gradient-based solvers?**\n",
            "\n",
            "Gradient-based solvers, such as the conjugate gradient method or the quasi-Newton method, are commonly used to solve systems of linear equations that arise from the discretization of PDEs. These solvers require repeated matrix-vector multiplications, which can be computationally expensive for large-scale problems.\n",
            "\n",
            "Sparse matrix techniques can improve the computational efficiency of gradient-based solvers in several ways:\n",
            "\n",
            "1.  **Reduced memory requirements**: By storing only the non-zero elements of the matrix, sparse matrix techniques can significantly reduce the memory requirements of the solver.\n",
            "2.  **Faster matrix-vector multiplications**: Sparse matrix techniques can be used to perform matrix-vector multiplications more efficiently, as only the non-zero elements of the matrix need to be accessed.\n",
            "3.  **Improved solver convergence**: By exploiting the sparsity of the matrix, sparse matrix techniques can improve the convergence of gradient-based solvers, leading to faster solution times.\n",
            "\n",
            "**Common sparse matrix techniques used in gradient-based solvers**\n",
            "\n",
            "Some common sparse matrix techniques used in gradient-based solvers include:\n",
            "\n",
            "1.  **Compressed sparse row (CSR) storage**: This is a popular storage format for sparse matrices, in which each row of the matrix is stored as a contiguous block of non-zero elements.\n",
            "2.  **Compressed sparse column (CSC) storage**: This is another popular storage format for sparse matrices, in which each column of the matrix is stored as a contiguous block of non-zero elements.\n",
            "3.  **Sparse matrix factorization**: This involves factorizing the sparse matrix into a product of two sparse matrices, which can be used to improve the efficiency of matrix-vector multiplications.\n",
            "4.  **Preconditioning**: This involves using a sparse matrix to precondition the original matrix, which can improve the convergence of gradient-based solvers.\n",
            "\n",
            "**Real-world applications of sparse matrix techniques in water engineering**\n",
            "\n",
            "Sparse matrix techniques have numerous applications in water engineering, including:\n",
            "\n",
            "1.  **Hydrodynamic modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the Navier-Stokes equations or the shallow water equations.\n",
            "2.  **Groundwater flow modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the groundwater flow equations.\n",
            "3.  **Water quality modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the water quality equations.\n",
            "\n",
            "In summary, sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of PDEs. By exploiting the sparsity of the matrix, sparse matrix techniques can reduce memory requirements, improve solver convergence, and accelerate matrix-vector multiplications.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we first need to identify the key points made in both responses. The actual answer succinctly explains the role of sparse matrix techniques in improving computational efficiency, focusing on the benefits of reduced memory requirements and faster computation times in the context of gradient-based methods.\n",
            "\n",
            "In contrast, the predicted answer provides a comprehensive overview of sparse matrices, their importance in gradient-based solvers, common techniques, and real-world applications. While this information is relevant, it includes a significant amount of extra detail that goes beyond the original question. The inclusion of definitions, explanations of various techniques, and specific applications contributes to a lengthy response that could overwhelm the reader.\n",
            "\n",
            "The actual answer is concise and directly addresses the question, while the predicted answer, although informative, is verbose and contains unnecessary elaboration. Therefore, it does not meet the criteria for conciseness as effectively as the actual answer.\n",
            "\n",
            "Considering these points, I would assign the predicted response a score of 3, as it includes a lot of extra information and uses flowery language, making it less concise than necessary.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [11:39, 28.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : The calculation of partial derivatives, also known as the Jacobian matrix, is critical in Newton-Raphson solvers for water networks for several reasons:\n",
            "\n",
            "1. **Convergence and Stability**: The Newton-Raphson method relies on the Jacobian matrix to determine the direction of the next iteration. If the Jacobian matrix is not accurately calculated, the method may not converge or may even diverge. In water networks, small errors in the Jacobian can lead to large errors in the solution, which can have significant consequences, such as pipe over-pressurization or under-pressurization.\n",
            "2. **Sensitivity Analysis**: The Jacobian matrix provides a measure of the sensitivity of the system to changes in the variables. In water networks, understanding the sensitivity of the system to changes in demand, pipe roughness, or other parameters is crucial for designing and operating the network efficiently.\n",
            "3. **Non-Linearity**: Water networks are inherently non-linear systems, meaning that small changes in the variables can lead to large changes in the solution. The Jacobian matrix helps to capture these non-linear relationships, allowing the Newton-Raphson method to converge to the correct solution.\n",
            "4. **Pipe Flow Equations**: The pipe flow equations, such as the Darcy-Weisbach equation or the Colebrook-White equation, are non-linear and involve complex relationships between variables such as flow rate, head loss, and pipe diameter. The Jacobian matrix helps to capture these complex relationships, allowing the Newton-Raphson method to solve the pipe flow equations accurately.\n",
            "5. **Network Topology**: Water networks have a complex topology, with multiple pipes, nodes, and loops. The Jacobian matrix helps to capture the interactions between these components, allowing the Newton-Raphson method to solve the network equations accurately.\n",
            "\n",
            "To calculate the Jacobian matrix for a water network, engineers typically use numerical methods, such as finite differences or automatic differentiation. These methods involve approximating the partial derivatives of the system equations with respect to the variables, which are then used to construct the Jacobian matrix.\n",
            "\n",
            "In summary, the calculation of the Jacobian matrix is critical in Newton-Raphson solvers for water networks because it provides a measure of the sensitivity of the system to changes in the variables, captures the non-linear relationships between variables, and helps to ensure convergence and stability of the method.\n",
            "\u001b[32mUser message:Question: What role do sparse matrix techniques play in improving the computational efficiency of large-scale gradient-based solvers?, Actual answer: Sparse matrix techniques take advantage of the fact that most entries in the system’s coefficient matrix are zero (since each node is only connected to a few others). Efficient data structures and factorization algorithms, such as sparse Cholesky or LU decomposition, reduce both the memory requirements and computation time. This can significantly speed up solving linearized systems in each iteration of a gradient-based method, which is critical for large networks with thousands of pipes and nodes., Predicted answer: Sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of partial differential equations (PDEs).\n",
            "\n",
            "**What are sparse matrices?**\n",
            "\n",
            "A sparse matrix is a matrix in which most of the elements are zero. In the context of water engineering, sparse matrices often arise from the discretization of PDEs, such as the Navier-Stokes equations or the shallow water equations, using finite element or finite difference methods. These matrices have a large number of zero elements, which can be exploited to improve computational efficiency.\n",
            "\n",
            "**Why are sparse matrices important in gradient-based solvers?**\n",
            "\n",
            "Gradient-based solvers, such as the conjugate gradient method or the quasi-Newton method, are commonly used to solve systems of linear equations that arise from the discretization of PDEs. These solvers require repeated matrix-vector multiplications, which can be computationally expensive for large-scale problems.\n",
            "\n",
            "Sparse matrix techniques can improve the computational efficiency of gradient-based solvers in several ways:\n",
            "\n",
            "1.  **Reduced memory requirements**: By storing only the non-zero elements of the matrix, sparse matrix techniques can significantly reduce the memory requirements of the solver.\n",
            "2.  **Faster matrix-vector multiplications**: Sparse matrix techniques can be used to perform matrix-vector multiplications more efficiently, as only the non-zero elements of the matrix need to be accessed.\n",
            "3.  **Improved solver convergence**: By exploiting the sparsity of the matrix, sparse matrix techniques can improve the convergence of gradient-based solvers, leading to faster solution times.\n",
            "\n",
            "**Common sparse matrix techniques used in gradient-based solvers**\n",
            "\n",
            "Some common sparse matrix techniques used in gradient-based solvers include:\n",
            "\n",
            "1.  **Compressed sparse row (CSR) storage**: This is a popular storage format for sparse matrices, in which each row of the matrix is stored as a contiguous block of non-zero elements.\n",
            "2.  **Compressed sparse column (CSC) storage**: This is another popular storage format for sparse matrices, in which each column of the matrix is stored as a contiguous block of non-zero elements.\n",
            "3.  **Sparse matrix factorization**: This involves factorizing the sparse matrix into a product of two sparse matrices, which can be used to improve the efficiency of matrix-vector multiplications.\n",
            "4.  **Preconditioning**: This involves using a sparse matrix to precondition the original matrix, which can improve the convergence of gradient-based solvers.\n",
            "\n",
            "**Real-world applications of sparse matrix techniques in water engineering**\n",
            "\n",
            "Sparse matrix techniques have numerous applications in water engineering, including:\n",
            "\n",
            "1.  **Hydrodynamic modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the Navier-Stokes equations or the shallow water equations.\n",
            "2.  **Groundwater flow modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the groundwater flow equations.\n",
            "3.  **Water quality modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the water quality equations.\n",
            "\n",
            "In summary, sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of PDEs. By exploiting the sparsity of the matrix, sparse matrix techniques can reduce memory requirements, improve solver convergence, and accelerate matrix-vector multiplications.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response captures the essence of the actual answer while also conveying confidence in its correctness. \n",
            "\n",
            "The actual answer succinctly explains the role of sparse matrix techniques in enhancing computational efficiency, specifically mentioning the advantages of reduced memory requirements and faster computation times. It also highlights the importance of these techniques in the context of large-scale gradient-based methods used in water engineering.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, does cover many relevant aspects of sparse matrix techniques, including definitions, importance, common techniques, and real-world applications. However, it lacks the concise focus on the specific benefits mentioned in the actual answer, such as the mention of efficient data structures and factorization algorithms like sparse Cholesky or LU decomposition. \n",
            "\n",
            "Moreover, the predicted answer does not explicitly state the significant impact of these techniques on the speed of solving linearized systems in gradient-based methods, which is a critical point in the actual answer. Instead, it provides a broader overview of sparse matrices and their applications, which may dilute the confidence in its correctness regarding the specific question asked.\n",
            "\n",
            "Given these observations, the predicted answer demonstrates a good understanding of the topic but does not convey the same level of confidence or precision as the actual answer. It leans towards being informative but lacks the assertiveness needed to fully endorse the correctness of the answer.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: What role do sparse matrix techniques play in improving the computational efficiency of large-scale gradient-based solvers?, Actual answer: Sparse matrix techniques take advantage of the fact that most entries in the system’s coefficient matrix are zero (since each node is only connected to a few others). Efficient data structures and factorization algorithms, such as sparse Cholesky or LU decomposition, reduce both the memory requirements and computation time. This can significantly speed up solving linearized systems in each iteration of a gradient-based method, which is critical for large networks with thousands of pipes and nodes., Predicted answer: Sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of partial differential equations (PDEs).\n",
            "\n",
            "**What are sparse matrices?**\n",
            "\n",
            "A sparse matrix is a matrix in which most of the elements are zero. In the context of water engineering, sparse matrices often arise from the discretization of PDEs, such as the Navier-Stokes equations or the shallow water equations, using finite element or finite difference methods. These matrices have a large number of zero elements, which can be exploited to improve computational efficiency.\n",
            "\n",
            "**Why are sparse matrices important in gradient-based solvers?**\n",
            "\n",
            "Gradient-based solvers, such as the conjugate gradient method or the quasi-Newton method, are commonly used to solve systems of linear equations that arise from the discretization of PDEs. These solvers require repeated matrix-vector multiplications, which can be computationally expensive for large-scale problems.\n",
            "\n",
            "Sparse matrix techniques can improve the computational efficiency of gradient-based solvers in several ways:\n",
            "\n",
            "1.  **Reduced memory requirements**: By storing only the non-zero elements of the matrix, sparse matrix techniques can significantly reduce the memory requirements of the solver.\n",
            "2.  **Faster matrix-vector multiplications**: Sparse matrix techniques can be used to perform matrix-vector multiplications more efficiently, as only the non-zero elements of the matrix need to be accessed.\n",
            "3.  **Improved solver convergence**: By exploiting the sparsity of the matrix, sparse matrix techniques can improve the convergence of gradient-based solvers, leading to faster solution times.\n",
            "\n",
            "**Common sparse matrix techniques used in gradient-based solvers**\n",
            "\n",
            "Some common sparse matrix techniques used in gradient-based solvers include:\n",
            "\n",
            "1.  **Compressed sparse row (CSR) storage**: This is a popular storage format for sparse matrices, in which each row of the matrix is stored as a contiguous block of non-zero elements.\n",
            "2.  **Compressed sparse column (CSC) storage**: This is another popular storage format for sparse matrices, in which each column of the matrix is stored as a contiguous block of non-zero elements.\n",
            "3.  **Sparse matrix factorization**: This involves factorizing the sparse matrix into a product of two sparse matrices, which can be used to improve the efficiency of matrix-vector multiplications.\n",
            "4.  **Preconditioning**: This involves using a sparse matrix to precondition the original matrix, which can improve the convergence of gradient-based solvers.\n",
            "\n",
            "**Real-world applications of sparse matrix techniques in water engineering**\n",
            "\n",
            "Sparse matrix techniques have numerous applications in water engineering, including:\n",
            "\n",
            "1.  **Hydrodynamic modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the Navier-Stokes equations or the shallow water equations.\n",
            "2.  **Groundwater flow modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the groundwater flow equations.\n",
            "3.  **Water quality modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the water quality equations.\n",
            "\n",
            "In summary, sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of PDEs. By exploiting the sparsity of the matrix, sparse matrix techniques can reduce memory requirements, improve solver convergence, and accelerate matrix-vector multiplications.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the factual accuracy and completeness of the information presented. The actual answer emphasizes the role of sparse matrix techniques in reducing memory requirements and computation time, particularly through efficient data structures and factorization algorithms. It also highlights the importance of these techniques in speeding up the solving of linearized systems in gradient-based methods, especially in the context of large networks in water engineering.\n",
            "\n",
            "The predicted answer provides a comprehensive overview of sparse matrices, their significance in gradient-based solvers, and various techniques used to exploit sparsity. It correctly identifies that sparse matrices arise from the discretization of PDEs and discusses the benefits of using sparse matrix techniques, such as reduced memory requirements and faster matrix-vector multiplications. Additionally, it lists common techniques and real-world applications in water engineering, which aligns well with the context of the question.\n",
            "\n",
            "However, while the predicted answer is informative and largely accurate, it does not explicitly mention the specific factorization algorithms (like sparse Cholesky or LU decomposition) that are crucial for improving computational efficiency, which is a key point in the actual answer. This omission slightly detracts from the completeness of the response.\n",
            "\n",
            "Overall, the predicted answer contains mostly factual information with some minor omissions and lacks the specific emphasis on factorization algorithms that the actual answer provides. Therefore, I would rate the predicted answer as a 4, indicating that it includes mostly factual information with slight hallucinations.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: What role do sparse matrix techniques play in improving the computational efficiency of large-scale gradient-based solvers?, Actual answer: Sparse matrix techniques take advantage of the fact that most entries in the system’s coefficient matrix are zero (since each node is only connected to a few others). Efficient data structures and factorization algorithms, such as sparse Cholesky or LU decomposition, reduce both the memory requirements and computation time. This can significantly speed up solving linearized systems in each iteration of a gradient-based method, which is critical for large networks with thousands of pipes and nodes., Predicted answer: Sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of partial differential equations (PDEs).\n",
            "\n",
            "**What are sparse matrices?**\n",
            "\n",
            "A sparse matrix is a matrix in which most of the elements are zero. In the context of water engineering, sparse matrices often arise from the discretization of PDEs, such as the Navier-Stokes equations or the shallow water equations, using finite element or finite difference methods. These matrices have a large number of zero elements, which can be exploited to improve computational efficiency.\n",
            "\n",
            "**Why are sparse matrices important in gradient-based solvers?**\n",
            "\n",
            "Gradient-based solvers, such as the conjugate gradient method or the quasi-Newton method, are commonly used to solve systems of linear equations that arise from the discretization of PDEs. These solvers require repeated matrix-vector multiplications, which can be computationally expensive for large-scale problems.\n",
            "\n",
            "Sparse matrix techniques can improve the computational efficiency of gradient-based solvers in several ways:\n",
            "\n",
            "1.  **Reduced memory requirements**: By storing only the non-zero elements of the matrix, sparse matrix techniques can significantly reduce the memory requirements of the solver.\n",
            "2.  **Faster matrix-vector multiplications**: Sparse matrix techniques can be used to perform matrix-vector multiplications more efficiently, as only the non-zero elements of the matrix need to be accessed.\n",
            "3.  **Improved solver convergence**: By exploiting the sparsity of the matrix, sparse matrix techniques can improve the convergence of gradient-based solvers, leading to faster solution times.\n",
            "\n",
            "**Common sparse matrix techniques used in gradient-based solvers**\n",
            "\n",
            "Some common sparse matrix techniques used in gradient-based solvers include:\n",
            "\n",
            "1.  **Compressed sparse row (CSR) storage**: This is a popular storage format for sparse matrices, in which each row of the matrix is stored as a contiguous block of non-zero elements.\n",
            "2.  **Compressed sparse column (CSC) storage**: This is another popular storage format for sparse matrices, in which each column of the matrix is stored as a contiguous block of non-zero elements.\n",
            "3.  **Sparse matrix factorization**: This involves factorizing the sparse matrix into a product of two sparse matrices, which can be used to improve the efficiency of matrix-vector multiplications.\n",
            "4.  **Preconditioning**: This involves using a sparse matrix to precondition the original matrix, which can improve the convergence of gradient-based solvers.\n",
            "\n",
            "**Real-world applications of sparse matrix techniques in water engineering**\n",
            "\n",
            "Sparse matrix techniques have numerous applications in water engineering, including:\n",
            "\n",
            "1.  **Hydrodynamic modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the Navier-Stokes equations or the shallow water equations.\n",
            "2.  **Groundwater flow modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the groundwater flow equations.\n",
            "3.  **Water quality modeling**: Sparse matrix techniques can be used to solve systems of linear equations that arise from the discretization of the water quality equations.\n",
            "\n",
            "In summary, sparse matrix techniques play a crucial role in improving the computational efficiency of large-scale gradient-based solvers in water engineering, particularly in solving systems of linear equations that arise from the discretization of PDEs. By exploiting the sparsity of the matrix, sparse matrix techniques can reduce memory requirements, improve solver convergence, and accelerate matrix-vector multiplications.\u001b[0m\n",
            "\u001b[31mAI message:The predicted answer provides a comprehensive overview of sparse matrix techniques and their significance in enhancing the computational efficiency of large-scale gradient-based solvers, particularly in the context of water engineering. It correctly identifies the nature of sparse matrices and their relevance to solving systems of linear equations derived from the discretization of partial differential equations (PDEs). \n",
            "\n",
            "The answer elaborates on the benefits of using sparse matrix techniques, such as reduced memory requirements, faster matrix-vector multiplications, and improved solver convergence. It also lists common techniques like CSR and CSC storage formats, sparse matrix factorization, and preconditioning, which are all relevant to the topic. Furthermore, the predicted answer includes real-world applications in hydrodynamic modeling, groundwater flow modeling, and water quality modeling, which adds depth to the explanation.\n",
            "\n",
            "However, while the predicted answer is detailed and informative, it does not explicitly mention the specific algorithms like sparse Cholesky or LU decomposition that are highlighted in the actual answer. This omission slightly detracts from the completeness of the response, but it does not fundamentally misinterpret the information.\n",
            "\n",
            "Overall, the predicted answer demonstrates a strong understanding of the topic and conveys its correctness, albeit with some minor gaps in specificity compared to the actual answer.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4, 'judgement_descr': 5}\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23it [11:57, 25.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : The Newton-Raphson technique generally leads to faster convergence compared to loop-based iterative methods due to the following aspects:\n",
            "\n",
            "1. **Quadratic Convergence**: The Newton-Raphson method exhibits quadratic convergence, meaning that the number of correct digits in the solution approximately doubles with each iteration. This is in contrast to linear convergence, which is typical of loop-based iterative methods, where the number of correct digits increases linearly with each iteration.\n",
            "\n",
            "2. **Use of Derivatives**: The Newton-Raphson method uses the first and second derivatives of the function, which provides a more accurate estimate of the solution at each iteration. This is because the derivative of the function provides information about the rate of change of the function, and the second derivative provides information about the curvature of the function.\n",
            "\n",
            "3. **Local Convergence**: The Newton-Raphson method converges locally, meaning that it converges to a solution that is close to the initial guess. This is in contrast to loop-based iterative methods, which may converge to a solution that is far from the initial guess.\n",
            "\n",
            "4. **Reduced Number of Iterations**: The Newton-Raphson method typically requires fewer iterations to converge to a solution compared to loop-based iterative methods. This is because the Newton-Raphson method uses a more accurate estimate of the solution at each iteration, which reduces the number of iterations required to converge.\n",
            "\n",
            "5. **Robustness to Initial Guess**: The Newton-Raphson method is relatively robust to the choice of initial guess, meaning that it can converge to a solution even if the initial guess is not close to the actual solution. This is in contrast to loop-based iterative methods, which may not converge to a solution if the initial guess is not close to the actual solution.\n",
            "\n",
            "Overall, the Newton-Raphson technique leads to faster convergence compared to loop-based iterative methods due to its quadratic convergence, use of derivatives, local convergence, reduced number of iterations, and robustness to initial guess.\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: Which algorithm does EPANET use for analyzing steady-state flows, and what makes it widely regarded as a robust and efficient solver?, Actual answer: EPANET uses the Global Gradient Algorithm (GGA) to compute flows and pressures throughout the network. This method is efficient because it solves node heads in a single matrix system and then updates pipe flows using the head-loss derivatives. It is robust thanks to its ability to converge reliably from a wide range of initial guesses, handle various network components (pumps, valves, etc.), and scale efficiently to large systems with thousands of pipes., Predicted answer: EPANET is a widely used software for analyzing the hydraulic and water quality behavior of pressurized pipe networks. For analyzing steady-state flows, EPANET uses the Darcy-Weisbach equation and the Hardy-Cross method.\n",
            "\n",
            "The Darcy-Weisbach equation is a fundamental equation in fluid dynamics that describes the head loss in a pipe due to friction. It is given by:\n",
            "\n",
            "h_f = f \\* (L / D) \\* (V^2 / (2 \\* g))\n",
            "\n",
            "where:\n",
            "- h_f is the head loss due to friction\n",
            "- f is the Darcy-Weisbach friction factor\n",
            "- L is the length of the pipe\n",
            "- D is the diameter of the pipe\n",
            "- V is the average velocity of the fluid\n",
            "- g is the acceleration due to gravity\n",
            "\n",
            "The Hardy-Cross method is an iterative method used to solve the steady-state flow equations in a pipe network. It involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in each pipe.\n",
            "2.  Calculate the head losses in each pipe using the Darcy-Weisbach equation.\n",
            "3.  Calculate the pressure head at each node using the head losses and the elevation of the node.\n",
            "4.  Check if the pressure head at each node is within the acceptable range.\n",
            "5.  If not, adjust the flow rates in each pipe and repeat steps 2-4 until the pressure head at each node is within the acceptable range.\n",
            "\n",
            "EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it widely regarded as a robust and efficient solver for analyzing steady-state flows in pipe networks. The Darcy-Weisbach equation is a well-established and widely accepted equation for calculating head losses in pipes, and the Hardy-Cross method is a reliable and efficient method for solving the steady-state flow equations in a pipe network.\n",
            "\n",
            "The robustness and efficiency of EPANET's solver can be attributed to the following factors:\n",
            "\n",
            "*   **Accuracy**: EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method ensures accurate calculations of head losses and pressure heads in the pipe network.\n",
            "*   **Efficiency**: The Hardy-Cross method is an iterative method that converges quickly to the solution, making it efficient for large pipe networks.\n",
            "*   **Flexibility**: EPANET can handle a wide range of pipe network configurations, including loops, branches, and junctions.\n",
            "*   **Scalability**: EPANET can handle large pipe networks with thousands of pipes and nodes.\n",
            "\n",
            "Overall, EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it a reliable and efficient tool for analyzing steady-state flows in pipe networks.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the completeness of the information provided in both responses. The actual answer specifies that EPANET uses the Global Gradient Algorithm (GGA) for analyzing steady-state flows, highlighting its efficiency and robustness due to its ability to handle various network components and converge from a wide range of initial guesses. \n",
            "\n",
            "In contrast, the predicted answer incorrectly states that EPANET uses the Darcy-Weisbach equation and the Hardy-Cross method, which are not the primary algorithms used for steady-state flow analysis in EPANET. While it provides a detailed explanation of these methods, it fails to mention the GGA, which is a critical element of the actual answer. Additionally, the predicted answer does discuss the robustness and efficiency of the methods it describes, but it does not align with the specific algorithm used in EPANET.\n",
            "\n",
            "Given that the predicted answer contains some relevant information about flow analysis in pipe networks but fundamentally misidentifies the algorithm used by EPANET, it lacks key elements necessary for a complete answer. Therefore, it can be assessed as having few elements of a complete answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: Which algorithm does EPANET use for analyzing steady-state flows, and what makes it widely regarded as a robust and efficient solver?, Actual answer: EPANET uses the Global Gradient Algorithm (GGA) to compute flows and pressures throughout the network. This method is efficient because it solves node heads in a single matrix system and then updates pipe flows using the head-loss derivatives. It is robust thanks to its ability to converge reliably from a wide range of initial guesses, handle various network components (pumps, valves, etc.), and scale efficiently to large systems with thousands of pipes., Predicted answer: EPANET is a widely used software for analyzing the hydraulic and water quality behavior of pressurized pipe networks. For analyzing steady-state flows, EPANET uses the Darcy-Weisbach equation and the Hardy-Cross method.\n",
            "\n",
            "The Darcy-Weisbach equation is a fundamental equation in fluid dynamics that describes the head loss in a pipe due to friction. It is given by:\n",
            "\n",
            "h_f = f \\* (L / D) \\* (V^2 / (2 \\* g))\n",
            "\n",
            "where:\n",
            "- h_f is the head loss due to friction\n",
            "- f is the Darcy-Weisbach friction factor\n",
            "- L is the length of the pipe\n",
            "- D is the diameter of the pipe\n",
            "- V is the average velocity of the fluid\n",
            "- g is the acceleration due to gravity\n",
            "\n",
            "The Hardy-Cross method is an iterative method used to solve the steady-state flow equations in a pipe network. It involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in each pipe.\n",
            "2.  Calculate the head losses in each pipe using the Darcy-Weisbach equation.\n",
            "3.  Calculate the pressure head at each node using the head losses and the elevation of the node.\n",
            "4.  Check if the pressure head at each node is within the acceptable range.\n",
            "5.  If not, adjust the flow rates in each pipe and repeat steps 2-4 until the pressure head at each node is within the acceptable range.\n",
            "\n",
            "EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it widely regarded as a robust and efficient solver for analyzing steady-state flows in pipe networks. The Darcy-Weisbach equation is a well-established and widely accepted equation for calculating head losses in pipes, and the Hardy-Cross method is a reliable and efficient method for solving the steady-state flow equations in a pipe network.\n",
            "\n",
            "The robustness and efficiency of EPANET's solver can be attributed to the following factors:\n",
            "\n",
            "*   **Accuracy**: EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method ensures accurate calculations of head losses and pressure heads in the pipe network.\n",
            "*   **Efficiency**: The Hardy-Cross method is an iterative method that converges quickly to the solution, making it efficient for large pipe networks.\n",
            "*   **Flexibility**: EPANET can handle a wide range of pipe network configurations, including loops, branches, and junctions.\n",
            "*   **Scalability**: EPANET can handle large pipe networks with thousands of pipes and nodes.\n",
            "\n",
            "Overall, EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it a reliable and efficient tool for analyzing steady-state flows in pipe networks.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we first need to identify the key components of the user's question: the specific algorithm used by EPANET for analyzing steady-state flows and the reasons for its robustness and efficiency. \n",
            "\n",
            "The actual answer correctly identifies the Global Gradient Algorithm (GGA) as the algorithm used by EPANET and provides a concise explanation of its efficiency and robustness, including its ability to converge from various initial guesses and handle different network components.\n",
            "\n",
            "In contrast, the predicted answer incorrectly states that EPANET uses the Darcy-Weisbach equation and the Hardy-Cross method, which are not the primary algorithms for steady-state flow analysis in EPANET. While it does provide a detailed explanation of these methods, this information is irrelevant to the specific question asked. The predicted answer also includes a lot of extraneous detail about the equations and methods, which detracts from the main point.\n",
            "\n",
            "Given that the predicted answer does not address the user's question correctly and contains mostly irrelevant information, it falls short of providing a relevant response.\n",
            "\n",
            "FINAL SCORE: 1\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 1}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: Which algorithm does EPANET use for analyzing steady-state flows, and what makes it widely regarded as a robust and efficient solver?, Actual answer: EPANET uses the Global Gradient Algorithm (GGA) to compute flows and pressures throughout the network. This method is efficient because it solves node heads in a single matrix system and then updates pipe flows using the head-loss derivatives. It is robust thanks to its ability to converge reliably from a wide range of initial guesses, handle various network components (pumps, valves, etc.), and scale efficiently to large systems with thousands of pipes., Predicted answer: EPANET is a widely used software for analyzing the hydraulic and water quality behavior of pressurized pipe networks. For analyzing steady-state flows, EPANET uses the Darcy-Weisbach equation and the Hardy-Cross method.\n",
            "\n",
            "The Darcy-Weisbach equation is a fundamental equation in fluid dynamics that describes the head loss in a pipe due to friction. It is given by:\n",
            "\n",
            "h_f = f \\* (L / D) \\* (V^2 / (2 \\* g))\n",
            "\n",
            "where:\n",
            "- h_f is the head loss due to friction\n",
            "- f is the Darcy-Weisbach friction factor\n",
            "- L is the length of the pipe\n",
            "- D is the diameter of the pipe\n",
            "- V is the average velocity of the fluid\n",
            "- g is the acceleration due to gravity\n",
            "\n",
            "The Hardy-Cross method is an iterative method used to solve the steady-state flow equations in a pipe network. It involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in each pipe.\n",
            "2.  Calculate the head losses in each pipe using the Darcy-Weisbach equation.\n",
            "3.  Calculate the pressure head at each node using the head losses and the elevation of the node.\n",
            "4.  Check if the pressure head at each node is within the acceptable range.\n",
            "5.  If not, adjust the flow rates in each pipe and repeat steps 2-4 until the pressure head at each node is within the acceptable range.\n",
            "\n",
            "EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it widely regarded as a robust and efficient solver for analyzing steady-state flows in pipe networks. The Darcy-Weisbach equation is a well-established and widely accepted equation for calculating head losses in pipes, and the Hardy-Cross method is a reliable and efficient method for solving the steady-state flow equations in a pipe network.\n",
            "\n",
            "The robustness and efficiency of EPANET's solver can be attributed to the following factors:\n",
            "\n",
            "*   **Accuracy**: EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method ensures accurate calculations of head losses and pressure heads in the pipe network.\n",
            "*   **Efficiency**: The Hardy-Cross method is an iterative method that converges quickly to the solution, making it efficient for large pipe networks.\n",
            "*   **Flexibility**: EPANET can handle a wide range of pipe network configurations, including loops, branches, and junctions.\n",
            "*   **Scalability**: EPANET can handle large pipe networks with thousands of pipes and nodes.\n",
            "\n",
            "Overall, EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it a reliable and efficient tool for analyzing steady-state flows in pipe networks.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we first need to identify the key components of the original question and the corresponding responses.\n",
            "\n",
            "The question specifically asks about the algorithm used by EPANET for analyzing steady-state flows and the reasons for its robustness and efficiency. The actual answer succinctly identifies the Global Gradient Algorithm (GGA) and provides a brief explanation of its efficiency and robustness.\n",
            "\n",
            "In contrast, the predicted answer diverges significantly from the actual answer by incorrectly stating that EPANET uses the Darcy-Weisbach equation and the Hardy-Cross method, which are not the primary algorithms used for steady-state flow analysis in EPANET. Furthermore, the predicted answer includes extensive explanations of these methods, their equations, and their iterative processes, which are not necessary to answer the question directly. \n",
            "\n",
            "The predicted response is lengthy, contains a lot of extra information, and uses flowery language, making it less concise than the actual answer. It also fails to directly address the specific algorithm (GGA) mentioned in the actual answer.\n",
            "\n",
            "Given these observations, I would assign a score of 2 to the predicted response for its excessive length and inclusion of unnecessary details.\n",
            "\n",
            "FINAL SCORE: 2\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 1, 'conciseness_descr': 2}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error running target function: probability tensor contains either `inf`, `nan` or element < 0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mUser message:Question: Which algorithm does EPANET use for analyzing steady-state flows, and what makes it widely regarded as a robust and efficient solver?, Actual answer: EPANET uses the Global Gradient Algorithm (GGA) to compute flows and pressures throughout the network. This method is efficient because it solves node heads in a single matrix system and then updates pipe flows using the head-loss derivatives. It is robust thanks to its ability to converge reliably from a wide range of initial guesses, handle various network components (pumps, valves, etc.), and scale efficiently to large systems with thousands of pipes., Predicted answer: EPANET is a widely used software for analyzing the hydraulic and water quality behavior of pressurized pipe networks. For analyzing steady-state flows, EPANET uses the Darcy-Weisbach equation and the Hardy-Cross method.\n",
            "\n",
            "The Darcy-Weisbach equation is a fundamental equation in fluid dynamics that describes the head loss in a pipe due to friction. It is given by:\n",
            "\n",
            "h_f = f \\* (L / D) \\* (V^2 / (2 \\* g))\n",
            "\n",
            "where:\n",
            "- h_f is the head loss due to friction\n",
            "- f is the Darcy-Weisbach friction factor\n",
            "- L is the length of the pipe\n",
            "- D is the diameter of the pipe\n",
            "- V is the average velocity of the fluid\n",
            "- g is the acceleration due to gravity\n",
            "\n",
            "The Hardy-Cross method is an iterative method used to solve the steady-state flow equations in a pipe network. It involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in each pipe.\n",
            "2.  Calculate the head losses in each pipe using the Darcy-Weisbach equation.\n",
            "3.  Calculate the pressure head at each node using the head losses and the elevation of the node.\n",
            "4.  Check if the pressure head at each node is within the acceptable range.\n",
            "5.  If not, adjust the flow rates in each pipe and repeat steps 2-4 until the pressure head at each node is within the acceptable range.\n",
            "\n",
            "EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it widely regarded as a robust and efficient solver for analyzing steady-state flows in pipe networks. The Darcy-Weisbach equation is a well-established and widely accepted equation for calculating head losses in pipes, and the Hardy-Cross method is a reliable and efficient method for solving the steady-state flow equations in a pipe network.\n",
            "\n",
            "The robustness and efficiency of EPANET's solver can be attributed to the following factors:\n",
            "\n",
            "*   **Accuracy**: EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method ensures accurate calculations of head losses and pressure heads in the pipe network.\n",
            "*   **Efficiency**: The Hardy-Cross method is an iterative method that converges quickly to the solution, making it efficient for large pipe networks.\n",
            "*   **Flexibility**: EPANET can handle a wide range of pipe network configurations, including loops, branches, and junctions.\n",
            "*   **Scalability**: EPANET can handle large pipe networks with thousands of pipes and nodes.\n",
            "\n",
            "Overall, EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it a reliable and efficient tool for analyzing steady-state flows in pipe networks.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we first need to identify the key components of both responses. The actual answer correctly identifies that EPANET uses the Global Gradient Algorithm (GGA) for analyzing steady-state flows, highlighting its efficiency and robustness due to its ability to converge from various initial guesses and handle complex network components. \n",
            "\n",
            "In contrast, the predicted answer incorrectly states that EPANET uses the Darcy-Weisbach equation and the Hardy-Cross method for steady-state flow analysis. While these methods are relevant in fluid dynamics and network analysis, they do not represent the primary algorithm used by EPANET. The predicted answer provides a detailed explanation of these methods, which may be informative, but it fundamentally misrepresents the core algorithm employed by EPANET.\n",
            "\n",
            "Given that the predicted answer not only fails to identify the correct algorithm but also presents an alternative that is not applicable in this context, it conveys a significant level of doubt regarding the accuracy of the information. The response does not acknowledge the actual algorithm used, nor does it provide a basis for confidence in the alternative methods mentioned.\n",
            "\n",
            "Therefore, the confidence level for the predicted answer should reflect this substantial error and lack of alignment with the actual answer.\n",
            "\n",
            "FINAL SCORE: 1\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 1, 'conciseness_descr': 2, 'confidence_descr': 1}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: Which algorithm does EPANET use for analyzing steady-state flows, and what makes it widely regarded as a robust and efficient solver?, Actual answer: EPANET uses the Global Gradient Algorithm (GGA) to compute flows and pressures throughout the network. This method is efficient because it solves node heads in a single matrix system and then updates pipe flows using the head-loss derivatives. It is robust thanks to its ability to converge reliably from a wide range of initial guesses, handle various network components (pumps, valves, etc.), and scale efficiently to large systems with thousands of pipes., Predicted answer: EPANET is a widely used software for analyzing the hydraulic and water quality behavior of pressurized pipe networks. For analyzing steady-state flows, EPANET uses the Darcy-Weisbach equation and the Hardy-Cross method.\n",
            "\n",
            "The Darcy-Weisbach equation is a fundamental equation in fluid dynamics that describes the head loss in a pipe due to friction. It is given by:\n",
            "\n",
            "h_f = f \\* (L / D) \\* (V^2 / (2 \\* g))\n",
            "\n",
            "where:\n",
            "- h_f is the head loss due to friction\n",
            "- f is the Darcy-Weisbach friction factor\n",
            "- L is the length of the pipe\n",
            "- D is the diameter of the pipe\n",
            "- V is the average velocity of the fluid\n",
            "- g is the acceleration due to gravity\n",
            "\n",
            "The Hardy-Cross method is an iterative method used to solve the steady-state flow equations in a pipe network. It involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in each pipe.\n",
            "2.  Calculate the head losses in each pipe using the Darcy-Weisbach equation.\n",
            "3.  Calculate the pressure head at each node using the head losses and the elevation of the node.\n",
            "4.  Check if the pressure head at each node is within the acceptable range.\n",
            "5.  If not, adjust the flow rates in each pipe and repeat steps 2-4 until the pressure head at each node is within the acceptable range.\n",
            "\n",
            "EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it widely regarded as a robust and efficient solver for analyzing steady-state flows in pipe networks. The Darcy-Weisbach equation is a well-established and widely accepted equation for calculating head losses in pipes, and the Hardy-Cross method is a reliable and efficient method for solving the steady-state flow equations in a pipe network.\n",
            "\n",
            "The robustness and efficiency of EPANET's solver can be attributed to the following factors:\n",
            "\n",
            "*   **Accuracy**: EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method ensures accurate calculations of head losses and pressure heads in the pipe network.\n",
            "*   **Efficiency**: The Hardy-Cross method is an iterative method that converges quickly to the solution, making it efficient for large pipe networks.\n",
            "*   **Flexibility**: EPANET can handle a wide range of pipe network configurations, including loops, branches, and junctions.\n",
            "*   **Scalability**: EPANET can handle large pipe networks with thousands of pipes and nodes.\n",
            "\n",
            "Overall, EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it a reliable and efficient tool for analyzing steady-state flows in pipe networks.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to focus on the key components of the question regarding the algorithm used by EPANET for analyzing steady-state flows and the reasons for its robustness and efficiency.\n",
            "\n",
            "The actual answer states that EPANET uses the Global Gradient Algorithm (GGA) for flow and pressure analysis, highlighting its efficiency in solving node heads in a single matrix system and its robustness in converging from various initial guesses. In contrast, the predicted answer incorrectly claims that EPANET uses the Darcy-Weisbach equation and the Hardy-Cross method. While these methods are indeed relevant in fluid dynamics and can be used in hydraulic analysis, they are not the primary algorithms employed by EPANET for steady-state flow analysis.\n",
            "\n",
            "The predicted answer does provide a detailed explanation of the Darcy-Weisbach equation and the Hardy-Cross method, including their applications and advantages. However, since the core claim about the algorithm used by EPANET is incorrect, this fundamentally undermines the factual accuracy of the response.\n",
            "\n",
            "Given that the predicted answer contains significant inaccuracies regarding the algorithm used, but does not completely misrepresent the context of hydraulic analysis, it falls into the category of containing large amounts of both hallucinations and factual information.\n",
            "\n",
            "Therefore, I would assign a score of 3 to the predicted answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 1, 'conciseness_descr': 2, 'confidence_descr': 1, 'factuality_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n",
            "\u001b[32mUser message:Question: Which algorithm does EPANET use for analyzing steady-state flows, and what makes it widely regarded as a robust and efficient solver?, Actual answer: EPANET uses the Global Gradient Algorithm (GGA) to compute flows and pressures throughout the network. This method is efficient because it solves node heads in a single matrix system and then updates pipe flows using the head-loss derivatives. It is robust thanks to its ability to converge reliably from a wide range of initial guesses, handle various network components (pumps, valves, etc.), and scale efficiently to large systems with thousands of pipes., Predicted answer: EPANET is a widely used software for analyzing the hydraulic and water quality behavior of pressurized pipe networks. For analyzing steady-state flows, EPANET uses the Darcy-Weisbach equation and the Hardy-Cross method.\n",
            "\n",
            "The Darcy-Weisbach equation is a fundamental equation in fluid dynamics that describes the head loss in a pipe due to friction. It is given by:\n",
            "\n",
            "h_f = f \\* (L / D) \\* (V^2 / (2 \\* g))\n",
            "\n",
            "where:\n",
            "- h_f is the head loss due to friction\n",
            "- f is the Darcy-Weisbach friction factor\n",
            "- L is the length of the pipe\n",
            "- D is the diameter of the pipe\n",
            "- V is the average velocity of the fluid\n",
            "- g is the acceleration due to gravity\n",
            "\n",
            "The Hardy-Cross method is an iterative method used to solve the steady-state flow equations in a pipe network. It involves the following steps:\n",
            "\n",
            "1.  Initialize the flow rates in each pipe.\n",
            "2.  Calculate the head losses in each pipe using the Darcy-Weisbach equation.\n",
            "3.  Calculate the pressure head at each node using the head losses and the elevation of the node.\n",
            "4.  Check if the pressure head at each node is within the acceptable range.\n",
            "5.  If not, adjust the flow rates in each pipe and repeat steps 2-4 until the pressure head at each node is within the acceptable range.\n",
            "\n",
            "EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it widely regarded as a robust and efficient solver for analyzing steady-state flows in pipe networks. The Darcy-Weisbach equation is a well-established and widely accepted equation for calculating head losses in pipes, and the Hardy-Cross method is a reliable and efficient method for solving the steady-state flow equations in a pipe network.\n",
            "\n",
            "The robustness and efficiency of EPANET's solver can be attributed to the following factors:\n",
            "\n",
            "*   **Accuracy**: EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method ensures accurate calculations of head losses and pressure heads in the pipe network.\n",
            "*   **Efficiency**: The Hardy-Cross method is an iterative method that converges quickly to the solution, making it efficient for large pipe networks.\n",
            "*   **Flexibility**: EPANET can handle a wide range of pipe network configurations, including loops, branches, and junctions.\n",
            "*   **Scalability**: EPANET can handle large pipe networks with thousands of pipes and nodes.\n",
            "\n",
            "Overall, EPANET's use of the Darcy-Weisbach equation and the Hardy-Cross method makes it a reliable and efficient tool for analyzing steady-state flows in pipe networks.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy of the information provided and how confidently it is presented. The actual answer correctly identifies that EPANET uses the Global Gradient Algorithm (GGA) for analyzing steady-state flows, highlighting its efficiency and robustness. In contrast, the predicted answer incorrectly states that EPANET uses the Darcy-Weisbach equation and the Hardy-Cross method, which are not the primary algorithms used by EPANET for this purpose.\n",
            "\n",
            "The predicted answer does provide a detailed explanation of the Darcy-Weisbach equation and the Hardy-Cross method, including their roles in fluid dynamics and network analysis. However, since it fundamentally misrepresents the algorithm used by EPANET, it fails to meet the accuracy required for a correct response. The confidence in the predicted answer is misleading, as it presents incorrect information as if it were factual.\n",
            "\n",
            "Given these considerations, the predicted answer misinterprets the information received in the prompt by asserting the wrong algorithm and providing a detailed but incorrect explanation. Therefore, it deserves a score of 2.\n",
            "\n",
            "FINAL SCORE: 2\u001b[0m\n",
            "Scores: {'completeness_descr': 3, 'relevance_descr': 1, 'conciseness_descr': 2, 'confidence_descr': 1, 'factuality_descr': 3, 'judgement_descr': 2}\n",
            "\n",
            "\n",
            "No output from LLM\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: Which two main calculation steps define the GGA procedure for determining both nodal heads and pipe flows?, Actual answer: The Global Gradient Algorithm typically involves (1) solving a linearized matrix equation that relates changes in nodal heads to flow imbalances in the network and (2) updating pipe flows using the head differences between connected nodes and the derivative (gradient) of the head-loss equation. These two steps repeat until both nodal heads and flows satisfy continuity and energy conservation within a preset tolerance., Predicted answer: The Generalized Gradient Algorithm (GGA) procedure is a widely used method in water distribution network analysis. The two main calculation steps that define the GGA procedure for determining both nodal heads and pipe flows are:\n",
            "\n",
            "1. **Linearization**: In this step, the nonlinear equations of the water distribution network are linearized around the current estimate of the solution. This involves approximating the nonlinear relationships between nodal heads and pipe flows using linear equations.\n",
            "\n",
            "2. **Iteration**: In this step, the linearized equations are solved to obtain a new estimate of the nodal heads and pipe flows. This process is repeated until convergence is achieved, i.e., until the difference between successive estimates of the solution is within a specified tolerance.\n",
            "\n",
            "These two steps are repeated iteratively until the solution converges, resulting in the determination of both nodal heads and pipe flows in the water distribution network.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the completeness of the predicted answer compared to the actual answer, we need to analyze the key elements present in both responses.\n",
            "\n",
            "The actual answer specifies two main calculation steps of the Global Gradient Algorithm (GGA):\n",
            "1. Solving a linearized matrix equation that relates changes in nodal heads to flow imbalances.\n",
            "2. Updating pipe flows using head differences and the derivative of the head-loss equation.\n",
            "\n",
            "The predicted answer also outlines two steps:\n",
            "1. Linearization of the nonlinear equations.\n",
            "2. Iteration to solve the linearized equations and achieve convergence.\n",
            "\n",
            "While both answers mention the iterative nature of the process and the need for convergence, the predicted answer lacks specific details about the relationship between nodal heads and flow imbalances, as well as the use of the head-loss equation's derivative, which are crucial for a complete understanding of the GGA procedure.\n",
            "\n",
            "The predicted answer does cover the general process of the GGA but misses some critical technical details that are essential for a full understanding of the method. Therefore, it includes some elements of a complete answer but does not fully address all aspects mentioned in the actual answer.\n",
            "\n",
            "Based on this analysis, I would assign a score of 4 to the predicted response, as it covers most elements of a complete answer but lacks some specific details.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: Which two main calculation steps define the GGA procedure for determining both nodal heads and pipe flows?, Actual answer: The Global Gradient Algorithm typically involves (1) solving a linearized matrix equation that relates changes in nodal heads to flow imbalances in the network and (2) updating pipe flows using the head differences between connected nodes and the derivative (gradient) of the head-loss equation. These two steps repeat until both nodal heads and flows satisfy continuity and energy conservation within a preset tolerance., Predicted answer: The Generalized Gradient Algorithm (GGA) procedure is a widely used method in water distribution network analysis. The two main calculation steps that define the GGA procedure for determining both nodal heads and pipe flows are:\n",
            "\n",
            "1. **Linearization**: In this step, the nonlinear equations of the water distribution network are linearized around the current estimate of the solution. This involves approximating the nonlinear relationships between nodal heads and pipe flows using linear equations.\n",
            "\n",
            "2. **Iteration**: In this step, the linearized equations are solved to obtain a new estimate of the nodal heads and pipe flows. This process is repeated until convergence is achieved, i.e., until the difference between successive estimates of the solution is within a specified tolerance.\n",
            "\n",
            "These two steps are repeated iteratively until the solution converges, resulting in the determination of both nodal heads and pipe flows in the water distribution network.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about the two main calculation steps of the GGA procedure for determining nodal heads and pipe flows.\n",
            "\n",
            "The actual answer clearly outlines the two main steps: solving a linearized matrix equation and updating pipe flows based on head differences and the gradient of the head-loss equation. It emphasizes the iterative nature of the process and the importance of achieving continuity and energy conservation.\n",
            "\n",
            "The predicted answer, while providing a structured response, introduces the terms \"Linearization\" and \"Iteration\" without explicitly connecting them to the specific processes described in the actual answer. It mentions linearizing the nonlinear equations and solving them iteratively, which is relevant but lacks the specificity of the actual answer regarding the matrix equation and the head-loss gradient. Additionally, the predicted answer does not mention the importance of continuity and energy conservation, which is a critical aspect of the GGA procedure.\n",
            "\n",
            "Overall, the predicted answer does address the user's question but includes some irrelevant details and lacks the precision found in the actual answer. Therefore, it contains more irrelevant information than relevant information.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: Which two main calculation steps define the GGA procedure for determining both nodal heads and pipe flows?, Actual answer: The Global Gradient Algorithm typically involves (1) solving a linearized matrix equation that relates changes in nodal heads to flow imbalances in the network and (2) updating pipe flows using the head differences between connected nodes and the derivative (gradient) of the head-loss equation. These two steps repeat until both nodal heads and flows satisfy continuity and energy conservation within a preset tolerance., Predicted answer: The Generalized Gradient Algorithm (GGA) procedure is a widely used method in water distribution network analysis. The two main calculation steps that define the GGA procedure for determining both nodal heads and pipe flows are:\n",
            "\n",
            "1. **Linearization**: In this step, the nonlinear equations of the water distribution network are linearized around the current estimate of the solution. This involves approximating the nonlinear relationships between nodal heads and pipe flows using linear equations.\n",
            "\n",
            "2. **Iteration**: In this step, the linearized equations are solved to obtain a new estimate of the nodal heads and pipe flows. This process is repeated until convergence is achieved, i.e., until the difference between successive estimates of the solution is within a specified tolerance.\n",
            "\n",
            "These two steps are repeated iteratively until the solution converges, resulting in the determination of both nodal heads and pipe flows in the water distribution network.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to analyze the amount of extra information and the overall length of each response. \n",
            "\n",
            "The actual answer is direct and focused on the two main steps of the GGA procedure, providing a clear and concise explanation without unnecessary elaboration. It succinctly describes the steps involved and emphasizes the iterative nature of the process.\n",
            "\n",
            "In contrast, the predicted answer introduces additional context by explaining the Generalized Gradient Algorithm (GGA) and elaborating on the concepts of linearization and iteration. While these details may be relevant to someone unfamiliar with the GGA, they add unnecessary length and complexity for the specific question asked. The predicted answer also includes a more detailed explanation of the linearization process and the convergence criteria, which, while informative, diverges from the core of the question.\n",
            "\n",
            "Given this analysis, the predicted answer includes a significant amount of extra information and uses more elaborate language than necessary, which detracts from its conciseness.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24it [12:48, 32.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/Meta-Llama-3.1-8B-Instruct : In the Hardy Cross method, flow corrections are applied around each loop to satisfy the continuity equation at each junction. Here's a step-by-step explanation of how flow corrections are applied and why flow continuity must be maintained at every junction:\n",
            "\n",
            "**Flow Corrections around a Loop:**\n",
            "\n",
            "1.  **Select a Loop:** Choose a loop in the network, which is a path that starts and ends at the same node (junction).\n",
            "2.  **Calculate the Net Head Loss:** Calculate the net head loss (ΔH) for the loop by summing the head losses (h\\_f) for each pipe in the loop. The head loss for each pipe can be calculated using the Darcy-Weisbach equation or the Hazen-Williams equation.\n",
            "3.  **Calculate the Net Flow:** Calculate the net flow (Q\\_net) for the loop by summing the flows (Q) for each pipe in the loop. The flow for each pipe can be calculated using the Manning equation or the Darcy-Weisbach equation.\n",
            "4.  **Calculate the Flow Correction:** Calculate the flow correction (ΔQ) for the loop by dividing the net head loss (ΔH) by the net flow (Q\\_net). The flow correction represents the change in flow that is needed to balance the loop.\n",
            "5.  **Apply the Flow Correction:** Apply the flow correction (ΔQ) to each pipe in the loop by adding or subtracting the correction from the original flow (Q) for each pipe.\n",
            "\n",
            "**Maintaining Flow Continuity at Every Junction:**\n",
            "\n",
            "Flow continuity must be maintained at every junction because the sum of the flows entering a junction must equal the sum of the flows leaving the junction. This is based on the principle of conservation of mass, which states that mass cannot be created or destroyed in a closed system.\n",
            "\n",
            "In the Hardy Cross method, flow continuity is maintained at every junction by ensuring that the sum of the flows entering a junction equals the sum of the flows leaving the junction. This is achieved by applying flow corrections around each loop in the network, as described above.\n",
            "\n",
            "**Why Flow Continuity is Important:**\n",
            "\n",
            "Maintaining flow continuity at every junction is essential for several reasons:\n",
            "\n",
            "1.  **Accurate Flow Calculations:** Flow continuity ensures that the flows calculated using the Hardy Cross method are accurate and reliable.\n",
            "2.  **Conservation of Mass:** Flow continuity ensures that the principle of conservation of mass is satisfied, which is a fundamental principle in physics and engineering.\n",
            "3.  **Stable Network Operation:** Flow continuity helps to ensure that the network operates stably and efficiently, with no excessive pressure drops or flow surges.\n",
            "\n",
            "In summary, flow corrections are applied around each loop in the Hardy Cross method to satisfy the continuity equation at each junction. Maintaining flow continuity at every junction is essential for accurate flow calculations, conservation of mass, and stable network operation.\n",
            "\u001b[32mUser message:Question: Which two main calculation steps define the GGA procedure for determining both nodal heads and pipe flows?, Actual answer: The Global Gradient Algorithm typically involves (1) solving a linearized matrix equation that relates changes in nodal heads to flow imbalances in the network and (2) updating pipe flows using the head differences between connected nodes and the derivative (gradient) of the head-loss equation. These two steps repeat until both nodal heads and flows satisfy continuity and energy conservation within a preset tolerance., Predicted answer: The Generalized Gradient Algorithm (GGA) procedure is a widely used method in water distribution network analysis. The two main calculation steps that define the GGA procedure for determining both nodal heads and pipe flows are:\n",
            "\n",
            "1. **Linearization**: In this step, the nonlinear equations of the water distribution network are linearized around the current estimate of the solution. This involves approximating the nonlinear relationships between nodal heads and pipe flows using linear equations.\n",
            "\n",
            "2. **Iteration**: In this step, the linearized equations are solved to obtain a new estimate of the nodal heads and pipe flows. This process is repeated until convergence is achieved, i.e., until the difference between successive estimates of the solution is within a specified tolerance.\n",
            "\n",
            "These two steps are repeated iteratively until the solution converges, resulting in the determination of both nodal heads and pipe flows in the water distribution network.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and completeness of the information provided in both responses. \n",
            "\n",
            "The actual answer correctly identifies the two main steps of the Global Gradient Algorithm (GGA) as solving a linearized matrix equation and updating pipe flows based on head differences and the gradient of the head-loss equation. It emphasizes the iterative nature of the process and the importance of achieving continuity and energy conservation within a specified tolerance.\n",
            "\n",
            "The predicted answer, while providing a reasonable overview of the GGA procedure, introduces some inaccuracies. It refers to the method as the Generalized Gradient Algorithm instead of the Global Gradient Algorithm, which is a significant error. Additionally, while it mentions linearization and iteration, it does not explicitly address the relationship between nodal heads and flow imbalances or the specifics of updating pipe flows based on head differences, which are crucial elements of the GGA process.\n",
            "\n",
            "Given these considerations, the predicted answer shows some understanding of the GGA procedure but lacks precision and contains a critical error in terminology. Therefore, it does not convey a high level of confidence in its correctness.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: Which two main calculation steps define the GGA procedure for determining both nodal heads and pipe flows?, Actual answer: The Global Gradient Algorithm typically involves (1) solving a linearized matrix equation that relates changes in nodal heads to flow imbalances in the network and (2) updating pipe flows using the head differences between connected nodes and the derivative (gradient) of the head-loss equation. These two steps repeat until both nodal heads and flows satisfy continuity and energy conservation within a preset tolerance., Predicted answer: The Generalized Gradient Algorithm (GGA) procedure is a widely used method in water distribution network analysis. The two main calculation steps that define the GGA procedure for determining both nodal heads and pipe flows are:\n",
            "\n",
            "1. **Linearization**: In this step, the nonlinear equations of the water distribution network are linearized around the current estimate of the solution. This involves approximating the nonlinear relationships between nodal heads and pipe flows using linear equations.\n",
            "\n",
            "2. **Iteration**: In this step, the linearized equations are solved to obtain a new estimate of the nodal heads and pipe flows. This process is repeated until convergence is achieved, i.e., until the difference between successive estimates of the solution is within a specified tolerance.\n",
            "\n",
            "These two steps are repeated iteratively until the solution converges, resulting in the determination of both nodal heads and pipe flows in the water distribution network.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to analyze the key components of both responses in relation to the GGA procedure.\n",
            "\n",
            "The actual answer correctly identifies the two main steps of the Global Gradient Algorithm (GGA) as: \n",
            "1. Solving a linearized matrix equation that relates changes in nodal heads to flow imbalances.\n",
            "2. Updating pipe flows using head differences and the gradient of the head-loss equation.\n",
            "\n",
            "The predicted answer, while it provides a coherent explanation, introduces some inaccuracies. It refers to the method as the \"Generalized Gradient Algorithm,\" which is incorrect; the correct term is \"Global Gradient Algorithm.\" Additionally, the predicted answer describes the steps as \"Linearization\" and \"Iteration,\" which, while related to the process, do not capture the specific details of the actual steps as outlined in the actual answer. The predicted answer lacks the emphasis on the relationship between nodal heads and flow imbalances and the specific use of the head-loss equation.\n",
            "\n",
            "Given these observations, the predicted answer contains significant inaccuracies and mischaracterizations of the GGA procedure, but it does not completely deviate from the general concept of iterative methods in water distribution analysis.\n",
            "\n",
            "Therefore, I would assign a score of 3, as the predicted answer contains both factual information and notable inaccuracies.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 3, 'factuality_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "26it [12:59, 20.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mUser message:Question: Which two main calculation steps define the GGA procedure for determining both nodal heads and pipe flows?, Actual answer: The Global Gradient Algorithm typically involves (1) solving a linearized matrix equation that relates changes in nodal heads to flow imbalances in the network and (2) updating pipe flows using the head differences between connected nodes and the derivative (gradient) of the head-loss equation. These two steps repeat until both nodal heads and flows satisfy continuity and energy conservation within a preset tolerance., Predicted answer: The Generalized Gradient Algorithm (GGA) procedure is a widely used method in water distribution network analysis. The two main calculation steps that define the GGA procedure for determining both nodal heads and pipe flows are:\n",
            "\n",
            "1. **Linearization**: In this step, the nonlinear equations of the water distribution network are linearized around the current estimate of the solution. This involves approximating the nonlinear relationships between nodal heads and pipe flows using linear equations.\n",
            "\n",
            "2. **Iteration**: In this step, the linearized equations are solved to obtain a new estimate of the nodal heads and pipe flows. This process is repeated until convergence is achieved, i.e., until the difference between successive estimates of the solution is within a specified tolerance.\n",
            "\n",
            "These two steps are repeated iteratively until the solution converges, resulting in the determination of both nodal heads and pipe flows in the water distribution network.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and clarity of the information presented in both responses. \n",
            "\n",
            "The actual answer correctly identifies the two main steps of the Global Gradient Algorithm (GGA) as solving a linearized matrix equation and updating pipe flows based on head differences and the gradient of the head-loss equation. It emphasizes the iterative nature of the process and the importance of achieving continuity and energy conservation within a specified tolerance.\n",
            "\n",
            "The predicted answer, while providing a structured response, misidentifies the algorithm as the Generalized Gradient Algorithm instead of the Global Gradient Algorithm. It describes the steps of linearization and iteration, which are relevant to the process, but lacks the specific details about head differences and the head-loss equation that are crucial for a complete understanding of the GGA procedure. Additionally, it does not mention the need for continuity and energy conservation, which are essential aspects of the algorithm.\n",
            "\n",
            "Given these points, the predicted answer shows a misunderstanding of the specific terminology and lacks some critical details, but it does not confidently assert incorrect information as truth. Instead, it presents a theoretical framework that is somewhat related to the GGA process.\n",
            "\n",
            "Therefore, I would assign a score of 3 to the predicted answer, as it shows uncertainty and misinterpretation of the information.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 3, 'factuality_descr': 3, 'judgement_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: Why is the Linear Theory approach typically more stable than Hardy Cross when applied to larger or more complex networks?, Actual answer: The Linear Theory method treats the entire network in a global manner, updating flows simultaneously. In contrast, the Hardy Cross method updates each loop one at a time and then moves to the next. For large or interconnected systems, local corrections in one loop can unbalance other loops, making sequential iteration prone to slow convergence or oscillation. The global perspective of the Linear Theory method keeps all parts of the network balanced at each iteration, which generally improves convergence stability., Predicted answer: The Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks for several reasons:\n",
            "\n",
            "1.  **Iterative Convergence**: The Hardy Cross method is an iterative approach that relies on successive approximations to converge to the solution. However, as the network size increases, the number of iterations required to achieve convergence also increases, which can lead to numerical instability and divergence. In contrast, the Linear Theory approach uses a direct solution method, which is less prone to numerical instability.\n",
            "\n",
            "2.  **Sensitivity to Initial Conditions**: The Hardy Cross method is sensitive to the initial conditions used to start the iteration process. Small changes in the initial conditions can lead to significantly different solutions, which can be problematic in large or complex networks. The Linear Theory approach, on the other hand, is less sensitive to initial conditions, as it uses a direct solution method that is less dependent on the starting point.\n",
            "\n",
            "3.  **Computational Efficiency**: The Linear Theory approach is generally more computationally efficient than the Hardy Cross method, especially for large or complex networks. This is because the Linear Theory approach uses a direct solution method, which can be solved using standard linear algebra techniques, whereas the Hardy Cross method requires iterative calculations that can be computationally intensive.\n",
            "\n",
            "4.  **Numerical Stability**: The Linear Theory approach is generally more numerically stable than the Hardy Cross method, especially when dealing with large or complex networks. This is because the Linear Theory approach uses a direct solution method that is less prone to numerical instability, whereas the Hardy Cross method relies on iterative calculations that can be sensitive to numerical errors.\n",
            "\n",
            "5.  **Scalability**: The Linear Theory approach is generally more scalable than the Hardy Cross method, especially for very large or complex networks. This is because the Linear Theory approach uses a direct solution method that can be easily parallelized, whereas the Hardy Cross method relies on iterative calculations that can be difficult to parallelize.\n",
            "\n",
            "In summary, the Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks due to its direct solution method, reduced sensitivity to initial conditions, computational efficiency, numerical stability, and scalability.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the completeness of the predicted response in addressing the question about the stability of the Linear Theory approach compared to the Hardy Cross method in larger or more complex networks.\n",
            "\n",
            "The actual answer highlights several key points:\n",
            "1. The global nature of the Linear Theory method versus the local corrections of the Hardy Cross method.\n",
            "2. The issue of unbalancing other loops in the Hardy Cross method due to its sequential nature.\n",
            "3. The overall improvement in convergence stability provided by the Linear Theory method.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, covers several relevant aspects:\n",
            "1. It discusses iterative convergence and the potential for numerical instability in the Hardy Cross method.\n",
            "2. It mentions sensitivity to initial conditions, which is a valid point.\n",
            "3. It addresses computational efficiency and numerical stability, both of which are important in the context of larger networks.\n",
            "4. It also touches on scalability, which is relevant for complex networks.\n",
            "\n",
            "However, the predicted answer does not explicitly mention the global versus local approach distinction, which is a critical aspect of the actual answer. It also lacks a direct reference to how local corrections in the Hardy Cross method can lead to instability in interconnected systems, which is a significant point made in the actual answer.\n",
            "\n",
            "Overall, while the predicted answer contains many relevant elements and provides a comprehensive discussion, it misses some key points that are essential for a complete answer. Therefore, I would rate the completeness of the predicted response as a 4, as it covers most elements of a complete answer but lacks some critical details.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: Why is the Linear Theory approach typically more stable than Hardy Cross when applied to larger or more complex networks?, Actual answer: The Linear Theory method treats the entire network in a global manner, updating flows simultaneously. In contrast, the Hardy Cross method updates each loop one at a time and then moves to the next. For large or interconnected systems, local corrections in one loop can unbalance other loops, making sequential iteration prone to slow convergence or oscillation. The global perspective of the Linear Theory method keeps all parts of the network balanced at each iteration, which generally improves convergence stability., Predicted answer: The Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks for several reasons:\n",
            "\n",
            "1.  **Iterative Convergence**: The Hardy Cross method is an iterative approach that relies on successive approximations to converge to the solution. However, as the network size increases, the number of iterations required to achieve convergence also increases, which can lead to numerical instability and divergence. In contrast, the Linear Theory approach uses a direct solution method, which is less prone to numerical instability.\n",
            "\n",
            "2.  **Sensitivity to Initial Conditions**: The Hardy Cross method is sensitive to the initial conditions used to start the iteration process. Small changes in the initial conditions can lead to significantly different solutions, which can be problematic in large or complex networks. The Linear Theory approach, on the other hand, is less sensitive to initial conditions, as it uses a direct solution method that is less dependent on the starting point.\n",
            "\n",
            "3.  **Computational Efficiency**: The Linear Theory approach is generally more computationally efficient than the Hardy Cross method, especially for large or complex networks. This is because the Linear Theory approach uses a direct solution method, which can be solved using standard linear algebra techniques, whereas the Hardy Cross method requires iterative calculations that can be computationally intensive.\n",
            "\n",
            "4.  **Numerical Stability**: The Linear Theory approach is generally more numerically stable than the Hardy Cross method, especially when dealing with large or complex networks. This is because the Linear Theory approach uses a direct solution method that is less prone to numerical instability, whereas the Hardy Cross method relies on iterative calculations that can be sensitive to numerical errors.\n",
            "\n",
            "5.  **Scalability**: The Linear Theory approach is generally more scalable than the Hardy Cross method, especially for very large or complex networks. This is because the Linear Theory approach uses a direct solution method that can be easily parallelized, whereas the Hardy Cross method relies on iterative calculations that can be difficult to parallelize.\n",
            "\n",
            "In summary, the Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks due to its direct solution method, reduced sensitivity to initial conditions, computational efficiency, numerical stability, and scalability.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about the stability of the Linear Theory approach compared to the Hardy Cross method in larger or more complex networks.\n",
            "\n",
            "The actual answer succinctly explains that the Linear Theory method treats the entire network globally, updating flows simultaneously, which helps maintain balance and stability. It contrasts this with the Hardy Cross method, which updates loops sequentially, leading to potential instability due to local corrections affecting other loops.\n",
            "\n",
            "The predicted answer, while lengthy, does provide relevant information regarding the iterative nature of the Hardy Cross method, its sensitivity to initial conditions, computational efficiency, numerical stability, and scalability. Each of these points relates to the stability of the methods in question. However, the predicted answer introduces a lot of detail that, while informative, may not be directly necessary to answer the question succinctly. \n",
            "\n",
            "The predicted response does not stray from the topic but includes more information than what is strictly relevant to the question, which could overwhelm the main points. Therefore, it does answer the user's question but contains more irrelevant information than relevant information.\n",
            "\n",
            "Considering these factors, I would assign a score of 3 to the predicted response.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: Why is the Linear Theory approach typically more stable than Hardy Cross when applied to larger or more complex networks?, Actual answer: The Linear Theory method treats the entire network in a global manner, updating flows simultaneously. In contrast, the Hardy Cross method updates each loop one at a time and then moves to the next. For large or interconnected systems, local corrections in one loop can unbalance other loops, making sequential iteration prone to slow convergence or oscillation. The global perspective of the Linear Theory method keeps all parts of the network balanced at each iteration, which generally improves convergence stability., Predicted answer: The Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks for several reasons:\n",
            "\n",
            "1.  **Iterative Convergence**: The Hardy Cross method is an iterative approach that relies on successive approximations to converge to the solution. However, as the network size increases, the number of iterations required to achieve convergence also increases, which can lead to numerical instability and divergence. In contrast, the Linear Theory approach uses a direct solution method, which is less prone to numerical instability.\n",
            "\n",
            "2.  **Sensitivity to Initial Conditions**: The Hardy Cross method is sensitive to the initial conditions used to start the iteration process. Small changes in the initial conditions can lead to significantly different solutions, which can be problematic in large or complex networks. The Linear Theory approach, on the other hand, is less sensitive to initial conditions, as it uses a direct solution method that is less dependent on the starting point.\n",
            "\n",
            "3.  **Computational Efficiency**: The Linear Theory approach is generally more computationally efficient than the Hardy Cross method, especially for large or complex networks. This is because the Linear Theory approach uses a direct solution method, which can be solved using standard linear algebra techniques, whereas the Hardy Cross method requires iterative calculations that can be computationally intensive.\n",
            "\n",
            "4.  **Numerical Stability**: The Linear Theory approach is generally more numerically stable than the Hardy Cross method, especially when dealing with large or complex networks. This is because the Linear Theory approach uses a direct solution method that is less prone to numerical instability, whereas the Hardy Cross method relies on iterative calculations that can be sensitive to numerical errors.\n",
            "\n",
            "5.  **Scalability**: The Linear Theory approach is generally more scalable than the Hardy Cross method, especially for very large or complex networks. This is because the Linear Theory approach uses a direct solution method that can be easily parallelized, whereas the Hardy Cross method relies on iterative calculations that can be difficult to parallelize.\n",
            "\n",
            "In summary, the Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks due to its direct solution method, reduced sensitivity to initial conditions, computational efficiency, numerical stability, and scalability.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information and the overall length of the response. \n",
            "\n",
            "The actual answer succinctly explains the key differences between the Linear Theory and Hardy Cross methods, focusing on the global versus local approach and how this affects stability in larger networks. It provides a clear rationale without unnecessary elaboration.\n",
            "\n",
            "In contrast, the predicted answer is significantly longer and includes multiple points that, while relevant, introduce a lot of extra detail. It breaks down the reasons into five distinct categories, which adds complexity and verbosity. Each point elaborates on aspects like iterative convergence, sensitivity to initial conditions, computational efficiency, numerical stability, and scalability. While these points are informative, they stray from the concise nature of the original answer and introduce redundancy.\n",
            "\n",
            "Given this analysis, the predicted answer includes a lot of extra information and uses a more elaborate structure than necessary to convey the main idea. Therefore, it does not meet the standard of conciseness set by the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: Why is the Linear Theory approach typically more stable than Hardy Cross when applied to larger or more complex networks?, Actual answer: The Linear Theory method treats the entire network in a global manner, updating flows simultaneously. In contrast, the Hardy Cross method updates each loop one at a time and then moves to the next. For large or interconnected systems, local corrections in one loop can unbalance other loops, making sequential iteration prone to slow convergence or oscillation. The global perspective of the Linear Theory method keeps all parts of the network balanced at each iteration, which generally improves convergence stability., Predicted answer: The Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks for several reasons:\n",
            "\n",
            "1.  **Iterative Convergence**: The Hardy Cross method is an iterative approach that relies on successive approximations to converge to the solution. However, as the network size increases, the number of iterations required to achieve convergence also increases, which can lead to numerical instability and divergence. In contrast, the Linear Theory approach uses a direct solution method, which is less prone to numerical instability.\n",
            "\n",
            "2.  **Sensitivity to Initial Conditions**: The Hardy Cross method is sensitive to the initial conditions used to start the iteration process. Small changes in the initial conditions can lead to significantly different solutions, which can be problematic in large or complex networks. The Linear Theory approach, on the other hand, is less sensitive to initial conditions, as it uses a direct solution method that is less dependent on the starting point.\n",
            "\n",
            "3.  **Computational Efficiency**: The Linear Theory approach is generally more computationally efficient than the Hardy Cross method, especially for large or complex networks. This is because the Linear Theory approach uses a direct solution method, which can be solved using standard linear algebra techniques, whereas the Hardy Cross method requires iterative calculations that can be computationally intensive.\n",
            "\n",
            "4.  **Numerical Stability**: The Linear Theory approach is generally more numerically stable than the Hardy Cross method, especially when dealing with large or complex networks. This is because the Linear Theory approach uses a direct solution method that is less prone to numerical instability, whereas the Hardy Cross method relies on iterative calculations that can be sensitive to numerical errors.\n",
            "\n",
            "5.  **Scalability**: The Linear Theory approach is generally more scalable than the Hardy Cross method, especially for very large or complex networks. This is because the Linear Theory approach uses a direct solution method that can be easily parallelized, whereas the Hardy Cross method relies on iterative calculations that can be difficult to parallelize.\n",
            "\n",
            "In summary, the Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks due to its direct solution method, reduced sensitivity to initial conditions, computational efficiency, numerical stability, and scalability.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response captures the essence of the actual answer while also assessing the confidence conveyed in the explanation.\n",
            "\n",
            "The actual answer succinctly explains that the Linear Theory method treats the entire network globally, which helps maintain balance and stability during iterations, especially in larger or interconnected systems. It emphasizes the drawbacks of the Hardy Cross method, particularly its sequential nature and the potential for unbalancing other loops, leading to slow convergence or oscillation.\n",
            "\n",
            "The predicted answer, while lengthy, covers several relevant points: iterative convergence, sensitivity to initial conditions, computational efficiency, numerical stability, and scalability. Each of these points aligns with the core reasons why the Linear Theory approach is more stable. However, the predicted answer introduces some redundancy and could be seen as overly detailed, which may detract from the clarity and directness of the explanation.\n",
            "\n",
            "In terms of confidence, the predicted answer presents its points assertively and provides a comprehensive rationale for why the Linear Theory method is superior. It does not express doubt or uncertainty, which suggests a high level of confidence in the correctness of the information provided.\n",
            "\n",
            "Given these considerations, I would assign a score of 5 to the predicted answer, as it confidently asserts the correctness of the comparison between the two methods and provides a thorough explanation that aligns well with the actual answer.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 5}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: Why is the Linear Theory approach typically more stable than Hardy Cross when applied to larger or more complex networks?, Actual answer: The Linear Theory method treats the entire network in a global manner, updating flows simultaneously. In contrast, the Hardy Cross method updates each loop one at a time and then moves to the next. For large or interconnected systems, local corrections in one loop can unbalance other loops, making sequential iteration prone to slow convergence or oscillation. The global perspective of the Linear Theory method keeps all parts of the network balanced at each iteration, which generally improves convergence stability., Predicted answer: The Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks for several reasons:\n",
            "\n",
            "1.  **Iterative Convergence**: The Hardy Cross method is an iterative approach that relies on successive approximations to converge to the solution. However, as the network size increases, the number of iterations required to achieve convergence also increases, which can lead to numerical instability and divergence. In contrast, the Linear Theory approach uses a direct solution method, which is less prone to numerical instability.\n",
            "\n",
            "2.  **Sensitivity to Initial Conditions**: The Hardy Cross method is sensitive to the initial conditions used to start the iteration process. Small changes in the initial conditions can lead to significantly different solutions, which can be problematic in large or complex networks. The Linear Theory approach, on the other hand, is less sensitive to initial conditions, as it uses a direct solution method that is less dependent on the starting point.\n",
            "\n",
            "3.  **Computational Efficiency**: The Linear Theory approach is generally more computationally efficient than the Hardy Cross method, especially for large or complex networks. This is because the Linear Theory approach uses a direct solution method, which can be solved using standard linear algebra techniques, whereas the Hardy Cross method requires iterative calculations that can be computationally intensive.\n",
            "\n",
            "4.  **Numerical Stability**: The Linear Theory approach is generally more numerically stable than the Hardy Cross method, especially when dealing with large or complex networks. This is because the Linear Theory approach uses a direct solution method that is less prone to numerical instability, whereas the Hardy Cross method relies on iterative calculations that can be sensitive to numerical errors.\n",
            "\n",
            "5.  **Scalability**: The Linear Theory approach is generally more scalable than the Hardy Cross method, especially for very large or complex networks. This is because the Linear Theory approach uses a direct solution method that can be easily parallelized, whereas the Hardy Cross method relies on iterative calculations that can be difficult to parallelize.\n",
            "\n",
            "In summary, the Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks due to its direct solution method, reduced sensitivity to initial conditions, computational efficiency, numerical stability, and scalability.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and relevance of the information presented in both responses. The actual answer succinctly explains the reasons for the stability of the Linear Theory approach compared to the Hardy Cross method, emphasizing the global treatment of the network and the issues with local corrections in the Hardy Cross method.\n",
            "\n",
            "The predicted answer, while providing a detailed breakdown of several factors, introduces some inaccuracies and misinterpretations. For instance, it mentions \"iterative convergence\" and \"sensitivity to initial conditions\" as key points, which are not explicitly highlighted in the actual answer. Additionally, while it discusses computational efficiency and numerical stability, it does not accurately reflect the core reason for the stability advantage, which is the simultaneous updating of flows in the Linear Theory method.\n",
            "\n",
            "Overall, the predicted answer contains a mix of factual information and some inaccuracies, particularly in how it frames the comparison between the two methods. It does not fully align with the actual answer's focus on the global versus local approach.\n",
            "\n",
            "Given this analysis, I would assign a score of 3 to the predicted answer, as it contains both factual information and some inaccuracies.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 5, 'factuality_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "27it [13:53, 28.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mUser message:Question: Why is the Linear Theory approach typically more stable than Hardy Cross when applied to larger or more complex networks?, Actual answer: The Linear Theory method treats the entire network in a global manner, updating flows simultaneously. In contrast, the Hardy Cross method updates each loop one at a time and then moves to the next. For large or interconnected systems, local corrections in one loop can unbalance other loops, making sequential iteration prone to slow convergence or oscillation. The global perspective of the Linear Theory method keeps all parts of the network balanced at each iteration, which generally improves convergence stability., Predicted answer: The Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks for several reasons:\n",
            "\n",
            "1.  **Iterative Convergence**: The Hardy Cross method is an iterative approach that relies on successive approximations to converge to the solution. However, as the network size increases, the number of iterations required to achieve convergence also increases, which can lead to numerical instability and divergence. In contrast, the Linear Theory approach uses a direct solution method, which is less prone to numerical instability.\n",
            "\n",
            "2.  **Sensitivity to Initial Conditions**: The Hardy Cross method is sensitive to the initial conditions used to start the iteration process. Small changes in the initial conditions can lead to significantly different solutions, which can be problematic in large or complex networks. The Linear Theory approach, on the other hand, is less sensitive to initial conditions, as it uses a direct solution method that is less dependent on the starting point.\n",
            "\n",
            "3.  **Computational Efficiency**: The Linear Theory approach is generally more computationally efficient than the Hardy Cross method, especially for large or complex networks. This is because the Linear Theory approach uses a direct solution method, which can be solved using standard linear algebra techniques, whereas the Hardy Cross method requires iterative calculations that can be computationally intensive.\n",
            "\n",
            "4.  **Numerical Stability**: The Linear Theory approach is generally more numerically stable than the Hardy Cross method, especially when dealing with large or complex networks. This is because the Linear Theory approach uses a direct solution method that is less prone to numerical instability, whereas the Hardy Cross method relies on iterative calculations that can be sensitive to numerical errors.\n",
            "\n",
            "5.  **Scalability**: The Linear Theory approach is generally more scalable than the Hardy Cross method, especially for very large or complex networks. This is because the Linear Theory approach uses a direct solution method that can be easily parallelized, whereas the Hardy Cross method relies on iterative calculations that can be difficult to parallelize.\n",
            "\n",
            "In summary, the Linear Theory approach is typically more stable than the Hardy Cross method when applied to larger or more complex networks due to its direct solution method, reduced sensitivity to initial conditions, computational efficiency, numerical stability, and scalability.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and clarity of the information presented. The actual answer succinctly explains the reasons for the stability of the Linear Theory approach compared to the Hardy Cross method, emphasizing the global treatment of the network and the issues with local corrections in iterative methods.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, does provide a comprehensive overview of the reasons why the Linear Theory approach is more stable. It discusses iterative convergence, sensitivity to initial conditions, computational efficiency, numerical stability, and scalability. However, it introduces some inaccuracies and misinterpretations:\n",
            "\n",
            "1. The predicted answer suggests that the Linear Theory approach uses a \"direct solution method,\" which may not be entirely accurate in the context of hydraulic network analysis, as both methods can be iterative in nature.\n",
            "2. The claim about the Hardy Cross method being sensitive to initial conditions is somewhat misleading; while it can be affected by initial guesses, the primary issue is the sequential nature of its updates leading to potential oscillations.\n",
            "3. The predicted answer does not explicitly mention the global perspective of the Linear Theory method, which is a key point in the actual answer.\n",
            "\n",
            "Overall, while the predicted answer contains relevant information, it lacks precision and clarity in some areas, leading to a less confident presentation of the concepts.\n",
            "\n",
            "Given these considerations, I would assign a score of 3 to the predicted answer, as it shows some understanding of the topic but also contains inaccuracies and lacks the clarity of the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 5, 'factuality_descr': 3, 'judgement_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: How does linearizing the head-loss equation in the Linear Theory (Simultaneous Pipe) method allow the entire network to be solved in a single system of equations per iteration?, Actual answer: Linearizing the head-loss equation entails approximating the nonlinear relationship (e.g., Darcy-Weisbach or Hazen-Williams) by evaluating its gradient at a known flow and using a linear slope around that point. This transforms the network equations into a linear system that can be solved simultaneously for all pipes in one step. After solving flows for the iteration, the head-loss slopes are updated based on the new flows, and the process repeats until convergence. Because all pipes and demands are included in the linear system, the method can update flows in the entire network in one global solve per iteration., Predicted answer: In the Linear Theory (Simultaneous Pipe) method, linearizing the head-loss equation is a crucial step that enables the entire network to be solved in a single system of equations per iteration. Here's how it works:\n",
            "\n",
            "1. **Head-loss equation**: The head-loss equation in a pipe network is typically given by the Darcy-Weisbach equation or the Hazen-Williams equation. These equations relate the head loss (h_f) in a pipe to the flow rate (Q), pipe diameter (D), length (L), and friction factor (f).\n",
            "2. **Linearization**: To linearize the head-loss equation, we can use a Taylor series expansion around a reference point (Q_ref, h_f_ref). This expansion approximates the head-loss equation as a linear function of the flow rate (Q) around the reference point.\n",
            "3. **Linearized head-loss equation**: The linearized head-loss equation can be written as:\n",
            "\n",
            "h_f ≈ h_f_ref + ∂h_f/∂Q \\* (Q - Q_ref)\n",
            "\n",
            "where ∂h_f/∂Q is the partial derivative of head loss with respect to flow rate, evaluated at the reference point.\n",
            "\n",
            "4. **System of equations**: By linearizing the head-loss equation for each pipe in the network, we can create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be written in matrix form as:\n",
            "\n",
            "A \\* Q = B\n",
            "\n",
            "where A is a matrix of coefficients, Q is a vector of flow rates, and B is a vector of head losses.\n",
            "\n",
            "5. **Single system of equations per iteration**: By linearizing the head-loss equation for each pipe in the network, we can create a single system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be solved using standard linear algebra techniques, such as Gaussian elimination or LU decomposition.\n",
            "\n",
            "The key insight here is that the linearized head-loss equation allows us to decouple the flow rates (Q) in each pipe from the head losses (h_f) in each pipe. This decoupling enables us to solve the entire network in a single system of equations per iteration, rather than having to solve a separate system of equations for each pipe.\n",
            "\n",
            "In practice, the Linear Theory (Simultaneous Pipe) method involves the following steps:\n",
            "\n",
            "1. Initialize the flow rates (Q) in each pipe.\n",
            "2. Linearize the head-loss equation for each pipe using the Taylor series expansion.\n",
            "3. Create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe.\n",
            "4. Solve the system of equations using standard linear algebra techniques.\n",
            "5. Update the flow rates (Q) in each pipe based on the solution to the system of equations.\n",
            "6. Repeat steps 2-5 until convergence is achieved.\n",
            "\n",
            "The Linear Theory (Simultaneous Pipe) method is a powerful tool for solving pipe network problems, and its ability to linearize the head-loss equation and solve the entire network in a single system of equations per iteration is a key feature of its success.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the completeness of the predicted answer compared to the actual answer, we need to analyze how well the predicted response addresses the question regarding the linearization of the head-loss equation in the context of the Linear Theory (Simultaneous Pipe) method.\n",
            "\n",
            "The actual answer provides a clear explanation of the linearization process, including the use of the Taylor series expansion, the transformation of the head-loss equations into a linear system, and the iterative process of updating flows until convergence. It emphasizes the significance of solving the entire network in one global solve per iteration, which is a crucial aspect of the method.\n",
            "\n",
            "The predicted answer also covers many of these points in detail. It explains the head-loss equations, the linearization process, and how this leads to a system of equations that can be solved simultaneously. It outlines the steps involved in the method, including initialization, linearization, solving, and updating flows. However, while it does mention the decoupling of flow rates and head losses, it could be more explicit about how this decoupling facilitates the simultaneous solution of the entire network.\n",
            "\n",
            "Overall, the predicted answer captures most of the essential elements of the actual answer, but it lacks some clarity and emphasis on the iterative nature and the significance of the global solve. Therefore, it does not fully cover all elements of a complete answer.\n",
            "\n",
            "Given this analysis, I would assign a score of 4, as the predicted answer contains most elements of a complete answer but misses some nuances and clarity present in the actual answer.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: How does linearizing the head-loss equation in the Linear Theory (Simultaneous Pipe) method allow the entire network to be solved in a single system of equations per iteration?, Actual answer: Linearizing the head-loss equation entails approximating the nonlinear relationship (e.g., Darcy-Weisbach or Hazen-Williams) by evaluating its gradient at a known flow and using a linear slope around that point. This transforms the network equations into a linear system that can be solved simultaneously for all pipes in one step. After solving flows for the iteration, the head-loss slopes are updated based on the new flows, and the process repeats until convergence. Because all pipes and demands are included in the linear system, the method can update flows in the entire network in one global solve per iteration., Predicted answer: In the Linear Theory (Simultaneous Pipe) method, linearizing the head-loss equation is a crucial step that enables the entire network to be solved in a single system of equations per iteration. Here's how it works:\n",
            "\n",
            "1. **Head-loss equation**: The head-loss equation in a pipe network is typically given by the Darcy-Weisbach equation or the Hazen-Williams equation. These equations relate the head loss (h_f) in a pipe to the flow rate (Q), pipe diameter (D), length (L), and friction factor (f).\n",
            "2. **Linearization**: To linearize the head-loss equation, we can use a Taylor series expansion around a reference point (Q_ref, h_f_ref). This expansion approximates the head-loss equation as a linear function of the flow rate (Q) around the reference point.\n",
            "3. **Linearized head-loss equation**: The linearized head-loss equation can be written as:\n",
            "\n",
            "h_f ≈ h_f_ref + ∂h_f/∂Q \\* (Q - Q_ref)\n",
            "\n",
            "where ∂h_f/∂Q is the partial derivative of head loss with respect to flow rate, evaluated at the reference point.\n",
            "\n",
            "4. **System of equations**: By linearizing the head-loss equation for each pipe in the network, we can create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be written in matrix form as:\n",
            "\n",
            "A \\* Q = B\n",
            "\n",
            "where A is a matrix of coefficients, Q is a vector of flow rates, and B is a vector of head losses.\n",
            "\n",
            "5. **Single system of equations per iteration**: By linearizing the head-loss equation for each pipe in the network, we can create a single system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be solved using standard linear algebra techniques, such as Gaussian elimination or LU decomposition.\n",
            "\n",
            "The key insight here is that the linearized head-loss equation allows us to decouple the flow rates (Q) in each pipe from the head losses (h_f) in each pipe. This decoupling enables us to solve the entire network in a single system of equations per iteration, rather than having to solve a separate system of equations for each pipe.\n",
            "\n",
            "In practice, the Linear Theory (Simultaneous Pipe) method involves the following steps:\n",
            "\n",
            "1. Initialize the flow rates (Q) in each pipe.\n",
            "2. Linearize the head-loss equation for each pipe using the Taylor series expansion.\n",
            "3. Create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe.\n",
            "4. Solve the system of equations using standard linear algebra techniques.\n",
            "5. Update the flow rates (Q) in each pipe based on the solution to the system of equations.\n",
            "6. Repeat steps 2-5 until convergence is achieved.\n",
            "\n",
            "The Linear Theory (Simultaneous Pipe) method is a powerful tool for solving pipe network problems, and its ability to linearize the head-loss equation and solve the entire network in a single system of equations per iteration is a key feature of its success.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about the linearization of the head-loss equation in the context of the Linear Theory (Simultaneous Pipe) method. \n",
            "\n",
            "The actual answer provides a clear explanation of the linearization process, its mathematical basis, and how it facilitates solving the entire network in a single system of equations. It emphasizes the iterative nature of the method and the importance of updating flows until convergence.\n",
            "\n",
            "The predicted answer also covers the key points, including the head-loss equations, the linearization process using Taylor series, and the formation of a system of equations. It explains how this allows for a single system of equations to be solved per iteration and outlines the steps involved in the method.\n",
            "\n",
            "However, the predicted answer is somewhat verbose and includes detailed mathematical expressions and steps that, while relevant, may not be necessary for a concise understanding of the main concept. This could be seen as introducing some irrelevant information, particularly for an audience already familiar with the topic.\n",
            "\n",
            "Overall, the predicted answer does answer the user's question and provides relevant information, but it contains more detail than necessary, which could detract from its overall relevance.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: How does linearizing the head-loss equation in the Linear Theory (Simultaneous Pipe) method allow the entire network to be solved in a single system of equations per iteration?, Actual answer: Linearizing the head-loss equation entails approximating the nonlinear relationship (e.g., Darcy-Weisbach or Hazen-Williams) by evaluating its gradient at a known flow and using a linear slope around that point. This transforms the network equations into a linear system that can be solved simultaneously for all pipes in one step. After solving flows for the iteration, the head-loss slopes are updated based on the new flows, and the process repeats until convergence. Because all pipes and demands are included in the linear system, the method can update flows in the entire network in one global solve per iteration., Predicted answer: In the Linear Theory (Simultaneous Pipe) method, linearizing the head-loss equation is a crucial step that enables the entire network to be solved in a single system of equations per iteration. Here's how it works:\n",
            "\n",
            "1. **Head-loss equation**: The head-loss equation in a pipe network is typically given by the Darcy-Weisbach equation or the Hazen-Williams equation. These equations relate the head loss (h_f) in a pipe to the flow rate (Q), pipe diameter (D), length (L), and friction factor (f).\n",
            "2. **Linearization**: To linearize the head-loss equation, we can use a Taylor series expansion around a reference point (Q_ref, h_f_ref). This expansion approximates the head-loss equation as a linear function of the flow rate (Q) around the reference point.\n",
            "3. **Linearized head-loss equation**: The linearized head-loss equation can be written as:\n",
            "\n",
            "h_f ≈ h_f_ref + ∂h_f/∂Q \\* (Q - Q_ref)\n",
            "\n",
            "where ∂h_f/∂Q is the partial derivative of head loss with respect to flow rate, evaluated at the reference point.\n",
            "\n",
            "4. **System of equations**: By linearizing the head-loss equation for each pipe in the network, we can create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be written in matrix form as:\n",
            "\n",
            "A \\* Q = B\n",
            "\n",
            "where A is a matrix of coefficients, Q is a vector of flow rates, and B is a vector of head losses.\n",
            "\n",
            "5. **Single system of equations per iteration**: By linearizing the head-loss equation for each pipe in the network, we can create a single system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be solved using standard linear algebra techniques, such as Gaussian elimination or LU decomposition.\n",
            "\n",
            "The key insight here is that the linearized head-loss equation allows us to decouple the flow rates (Q) in each pipe from the head losses (h_f) in each pipe. This decoupling enables us to solve the entire network in a single system of equations per iteration, rather than having to solve a separate system of equations for each pipe.\n",
            "\n",
            "In practice, the Linear Theory (Simultaneous Pipe) method involves the following steps:\n",
            "\n",
            "1. Initialize the flow rates (Q) in each pipe.\n",
            "2. Linearize the head-loss equation for each pipe using the Taylor series expansion.\n",
            "3. Create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe.\n",
            "4. Solve the system of equations using standard linear algebra techniques.\n",
            "5. Update the flow rates (Q) in each pipe based on the solution to the system of equations.\n",
            "6. Repeat steps 2-5 until convergence is achieved.\n",
            "\n",
            "The Linear Theory (Simultaneous Pipe) method is a powerful tool for solving pipe network problems, and its ability to linearize the head-loss equation and solve the entire network in a single system of equations per iteration is a key feature of its success.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information and the overall length of the response. \n",
            "\n",
            "The actual answer succinctly explains the process of linearizing the head-loss equation and how it allows for the simultaneous solution of the entire network. It focuses on the essential points without unnecessary elaboration.\n",
            "\n",
            "In contrast, the predicted answer provides a detailed breakdown of the process, including definitions, equations, and a step-by-step explanation. While this thoroughness may be beneficial for clarity, it introduces a significant amount of extra information that may not be necessary to directly answer the question. The inclusion of the Taylor series expansion, matrix formulation, and specific algebraic techniques, while relevant, adds to the length and complexity of the response.\n",
            "\n",
            "Given these observations, the predicted answer includes a lot of extra information and uses flowery language, which detracts from its conciseness. Therefore, I would assign a score of 3 for the predicted response.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: How does linearizing the head-loss equation in the Linear Theory (Simultaneous Pipe) method allow the entire network to be solved in a single system of equations per iteration?, Actual answer: Linearizing the head-loss equation entails approximating the nonlinear relationship (e.g., Darcy-Weisbach or Hazen-Williams) by evaluating its gradient at a known flow and using a linear slope around that point. This transforms the network equations into a linear system that can be solved simultaneously for all pipes in one step. After solving flows for the iteration, the head-loss slopes are updated based on the new flows, and the process repeats until convergence. Because all pipes and demands are included in the linear system, the method can update flows in the entire network in one global solve per iteration., Predicted answer: In the Linear Theory (Simultaneous Pipe) method, linearizing the head-loss equation is a crucial step that enables the entire network to be solved in a single system of equations per iteration. Here's how it works:\n",
            "\n",
            "1. **Head-loss equation**: The head-loss equation in a pipe network is typically given by the Darcy-Weisbach equation or the Hazen-Williams equation. These equations relate the head loss (h_f) in a pipe to the flow rate (Q), pipe diameter (D), length (L), and friction factor (f).\n",
            "2. **Linearization**: To linearize the head-loss equation, we can use a Taylor series expansion around a reference point (Q_ref, h_f_ref). This expansion approximates the head-loss equation as a linear function of the flow rate (Q) around the reference point.\n",
            "3. **Linearized head-loss equation**: The linearized head-loss equation can be written as:\n",
            "\n",
            "h_f ≈ h_f_ref + ∂h_f/∂Q \\* (Q - Q_ref)\n",
            "\n",
            "where ∂h_f/∂Q is the partial derivative of head loss with respect to flow rate, evaluated at the reference point.\n",
            "\n",
            "4. **System of equations**: By linearizing the head-loss equation for each pipe in the network, we can create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be written in matrix form as:\n",
            "\n",
            "A \\* Q = B\n",
            "\n",
            "where A is a matrix of coefficients, Q is a vector of flow rates, and B is a vector of head losses.\n",
            "\n",
            "5. **Single system of equations per iteration**: By linearizing the head-loss equation for each pipe in the network, we can create a single system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be solved using standard linear algebra techniques, such as Gaussian elimination or LU decomposition.\n",
            "\n",
            "The key insight here is that the linearized head-loss equation allows us to decouple the flow rates (Q) in each pipe from the head losses (h_f) in each pipe. This decoupling enables us to solve the entire network in a single system of equations per iteration, rather than having to solve a separate system of equations for each pipe.\n",
            "\n",
            "In practice, the Linear Theory (Simultaneous Pipe) method involves the following steps:\n",
            "\n",
            "1. Initialize the flow rates (Q) in each pipe.\n",
            "2. Linearize the head-loss equation for each pipe using the Taylor series expansion.\n",
            "3. Create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe.\n",
            "4. Solve the system of equations using standard linear algebra techniques.\n",
            "5. Update the flow rates (Q) in each pipe based on the solution to the system of equations.\n",
            "6. Repeat steps 2-5 until convergence is achieved.\n",
            "\n",
            "The Linear Theory (Simultaneous Pipe) method is a powerful tool for solving pipe network problems, and its ability to linearize the head-loss equation and solve the entire network in a single system of equations per iteration is a key feature of its success.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response captures the essence of the actual answer while also conveying confidence in its correctness. \n",
            "\n",
            "The actual answer provides a clear and concise explanation of the linearization process, detailing how it transforms the nonlinear head-loss equations into a linear system that can be solved simultaneously. It emphasizes the iterative nature of the method and the importance of updating flows based on new calculations. The explanation is structured logically, making it easy to follow.\n",
            "\n",
            "The predicted answer also covers the key points of the actual answer, including the use of the Taylor series for linearization, the formulation of a system of equations, and the iterative process involved in solving the network. It breaks down the explanation into steps, which can enhance clarity. However, while it is thorough, the predicted answer is somewhat verbose and could be seen as repetitive in certain areas, particularly in reiterating the creation of a single system of equations.\n",
            "\n",
            "In terms of confidence, the predicted answer demonstrates a strong understanding of the topic and conveys assurance in the explanation of the linearization process and its implications for solving the network. It does not express doubt or uncertainty, and it effectively communicates the method's significance.\n",
            "\n",
            "Given these considerations, I would assign a score of 5 to the predicted answer, as it confidently asserts the correctness of the explanation and aligns closely with the actual answer's content and intent.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 5}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: How does linearizing the head-loss equation in the Linear Theory (Simultaneous Pipe) method allow the entire network to be solved in a single system of equations per iteration?, Actual answer: Linearizing the head-loss equation entails approximating the nonlinear relationship (e.g., Darcy-Weisbach or Hazen-Williams) by evaluating its gradient at a known flow and using a linear slope around that point. This transforms the network equations into a linear system that can be solved simultaneously for all pipes in one step. After solving flows for the iteration, the head-loss slopes are updated based on the new flows, and the process repeats until convergence. Because all pipes and demands are included in the linear system, the method can update flows in the entire network in one global solve per iteration., Predicted answer: In the Linear Theory (Simultaneous Pipe) method, linearizing the head-loss equation is a crucial step that enables the entire network to be solved in a single system of equations per iteration. Here's how it works:\n",
            "\n",
            "1. **Head-loss equation**: The head-loss equation in a pipe network is typically given by the Darcy-Weisbach equation or the Hazen-Williams equation. These equations relate the head loss (h_f) in a pipe to the flow rate (Q), pipe diameter (D), length (L), and friction factor (f).\n",
            "2. **Linearization**: To linearize the head-loss equation, we can use a Taylor series expansion around a reference point (Q_ref, h_f_ref). This expansion approximates the head-loss equation as a linear function of the flow rate (Q) around the reference point.\n",
            "3. **Linearized head-loss equation**: The linearized head-loss equation can be written as:\n",
            "\n",
            "h_f ≈ h_f_ref + ∂h_f/∂Q \\* (Q - Q_ref)\n",
            "\n",
            "where ∂h_f/∂Q is the partial derivative of head loss with respect to flow rate, evaluated at the reference point.\n",
            "\n",
            "4. **System of equations**: By linearizing the head-loss equation for each pipe in the network, we can create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be written in matrix form as:\n",
            "\n",
            "A \\* Q = B\n",
            "\n",
            "where A is a matrix of coefficients, Q is a vector of flow rates, and B is a vector of head losses.\n",
            "\n",
            "5. **Single system of equations per iteration**: By linearizing the head-loss equation for each pipe in the network, we can create a single system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be solved using standard linear algebra techniques, such as Gaussian elimination or LU decomposition.\n",
            "\n",
            "The key insight here is that the linearized head-loss equation allows us to decouple the flow rates (Q) in each pipe from the head losses (h_f) in each pipe. This decoupling enables us to solve the entire network in a single system of equations per iteration, rather than having to solve a separate system of equations for each pipe.\n",
            "\n",
            "In practice, the Linear Theory (Simultaneous Pipe) method involves the following steps:\n",
            "\n",
            "1. Initialize the flow rates (Q) in each pipe.\n",
            "2. Linearize the head-loss equation for each pipe using the Taylor series expansion.\n",
            "3. Create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe.\n",
            "4. Solve the system of equations using standard linear algebra techniques.\n",
            "5. Update the flow rates (Q) in each pipe based on the solution to the system of equations.\n",
            "6. Repeat steps 2-5 until convergence is achieved.\n",
            "\n",
            "The Linear Theory (Simultaneous Pipe) method is a powerful tool for solving pipe network problems, and its ability to linearize the head-loss equation and solve the entire network in a single system of equations per iteration is a key feature of its success.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to assess the factual accuracy and completeness of the information provided in both responses. \n",
            "\n",
            "The actual answer correctly describes the process of linearizing the head-loss equation, emphasizing the use of a Taylor series expansion to approximate the nonlinear relationship of head loss with flow rate. It explains how this linearization allows for the creation of a single system of equations that can be solved simultaneously for the entire network, updating flows iteratively until convergence is achieved. \n",
            "\n",
            "The predicted answer also provides a detailed explanation of the linearization process, including the use of the Taylor series and the formulation of the system of equations in matrix form. It outlines the steps involved in the Linear Theory (Simultaneous Pipe) method, which aligns well with the actual answer. \n",
            "\n",
            "However, while the predicted answer is comprehensive and mostly accurate, it does contain some redundancy in explaining the creation of the system of equations and the decoupling of flow rates and head losses. This could lead to slight confusion, but it does not fundamentally alter the factual content. \n",
            "\n",
            "Overall, both answers convey the essential concepts accurately, but the predicted answer is slightly more verbose and repetitive. Given that it contains mostly factual information with slight redundancies, I would assign a score of 4.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 5, 'factuality_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "28it [14:36, 32.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mUser message:Question: How does linearizing the head-loss equation in the Linear Theory (Simultaneous Pipe) method allow the entire network to be solved in a single system of equations per iteration?, Actual answer: Linearizing the head-loss equation entails approximating the nonlinear relationship (e.g., Darcy-Weisbach or Hazen-Williams) by evaluating its gradient at a known flow and using a linear slope around that point. This transforms the network equations into a linear system that can be solved simultaneously for all pipes in one step. After solving flows for the iteration, the head-loss slopes are updated based on the new flows, and the process repeats until convergence. Because all pipes and demands are included in the linear system, the method can update flows in the entire network in one global solve per iteration., Predicted answer: In the Linear Theory (Simultaneous Pipe) method, linearizing the head-loss equation is a crucial step that enables the entire network to be solved in a single system of equations per iteration. Here's how it works:\n",
            "\n",
            "1. **Head-loss equation**: The head-loss equation in a pipe network is typically given by the Darcy-Weisbach equation or the Hazen-Williams equation. These equations relate the head loss (h_f) in a pipe to the flow rate (Q), pipe diameter (D), length (L), and friction factor (f).\n",
            "2. **Linearization**: To linearize the head-loss equation, we can use a Taylor series expansion around a reference point (Q_ref, h_f_ref). This expansion approximates the head-loss equation as a linear function of the flow rate (Q) around the reference point.\n",
            "3. **Linearized head-loss equation**: The linearized head-loss equation can be written as:\n",
            "\n",
            "h_f ≈ h_f_ref + ∂h_f/∂Q \\* (Q - Q_ref)\n",
            "\n",
            "where ∂h_f/∂Q is the partial derivative of head loss with respect to flow rate, evaluated at the reference point.\n",
            "\n",
            "4. **System of equations**: By linearizing the head-loss equation for each pipe in the network, we can create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be written in matrix form as:\n",
            "\n",
            "A \\* Q = B\n",
            "\n",
            "where A is a matrix of coefficients, Q is a vector of flow rates, and B is a vector of head losses.\n",
            "\n",
            "5. **Single system of equations per iteration**: By linearizing the head-loss equation for each pipe in the network, we can create a single system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe. This system of equations can be solved using standard linear algebra techniques, such as Gaussian elimination or LU decomposition.\n",
            "\n",
            "The key insight here is that the linearized head-loss equation allows us to decouple the flow rates (Q) in each pipe from the head losses (h_f) in each pipe. This decoupling enables us to solve the entire network in a single system of equations per iteration, rather than having to solve a separate system of equations for each pipe.\n",
            "\n",
            "In practice, the Linear Theory (Simultaneous Pipe) method involves the following steps:\n",
            "\n",
            "1. Initialize the flow rates (Q) in each pipe.\n",
            "2. Linearize the head-loss equation for each pipe using the Taylor series expansion.\n",
            "3. Create a system of equations that relates the flow rates (Q) in each pipe to the head losses (h_f) in each pipe.\n",
            "4. Solve the system of equations using standard linear algebra techniques.\n",
            "5. Update the flow rates (Q) in each pipe based on the solution to the system of equations.\n",
            "6. Repeat steps 2-5 until convergence is achieved.\n",
            "\n",
            "The Linear Theory (Simultaneous Pipe) method is a powerful tool for solving pipe network problems, and its ability to linearize the head-loss equation and solve the entire network in a single system of equations per iteration is a key feature of its success.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and clarity of the information presented in both responses. The actual answer provides a concise explanation of the linearization process, its implications for solving the network, and the iterative nature of the method. It emphasizes the transformation of the nonlinear relationships into a linear system, which is crucial for simultaneous solving.\n",
            "\n",
            "The predicted answer also covers the necessary steps and details about linearization, including the use of Taylor series and the formation of a system of equations. It explains how the linearized equations allow for a single system to be solved per iteration, which aligns well with the actual answer. However, the predicted answer is somewhat verbose and includes repetitive elements, particularly in explaining the creation of the system of equations.\n",
            "\n",
            "Overall, the predicted answer accurately conveys the essential concepts and processes involved in the Linear Theory (Simultaneous Pipe) method, demonstrating a clear understanding of the topic. It does not misinterpret the information and provides a logical flow of reasoning. Therefore, it can be considered correct, albeit with some unnecessary elaboration.\n",
            "\n",
            "Given this analysis, I would assign the predicted answer a score of 5, as it is correct and effectively communicates the necessary information.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 5, 'factuality_descr': 4, 'judgement_descr': 5}\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "29it [14:42, 25.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No output from LLM\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: Why is calculation of partial derivatives (the Jacobian) critical in Newton-Raphson solvers for water networks?, Actual answer: The Jacobian quantifies how each unknown (flow or head) affects the network equations. In Newton-Raphson solvers, the iterative update to each variable depends on these partial derivatives, enabling the solver to predict how changing a node’s head or a pipe’s flow will impact the entire system. Without an accurate Jacobian, the solver cannot reliably determine the direction or magnitude of each correction step, leading to slower or unstable convergence., Predicted answer: The calculation of partial derivatives, also known as the Jacobian matrix, is critical in Newton-Raphson solvers for water networks for several reasons:\n",
            "\n",
            "1. **Convergence and Stability**: The Newton-Raphson method relies on the Jacobian matrix to determine the direction of the next iteration. If the Jacobian matrix is not accurately calculated, the method may not converge or may even diverge. In water networks, small errors in the Jacobian can lead to large errors in the solution, which can have significant consequences, such as pipe over-pressurization or under-pressurization.\n",
            "2. **Sensitivity Analysis**: The Jacobian matrix provides a measure of the sensitivity of the system to changes in the variables. In water networks, understanding the sensitivity of the system to changes in demand, pipe roughness, or other parameters is crucial for designing and operating the network efficiently.\n",
            "3. **Non-Linearity**: Water networks are inherently non-linear systems, meaning that small changes in the variables can lead to large changes in the solution. The Jacobian matrix helps to capture these non-linear relationships, allowing the Newton-Raphson method to converge to the correct solution.\n",
            "4. **Pipe Flow Equations**: The pipe flow equations, such as the Darcy-Weisbach equation or the Colebrook-White equation, are non-linear and involve complex relationships between variables such as flow rate, head loss, and pipe diameter. The Jacobian matrix helps to capture these complex relationships, allowing the Newton-Raphson method to solve the pipe flow equations accurately.\n",
            "5. **Network Topology**: Water networks have a complex topology, with multiple pipes, nodes, and loops. The Jacobian matrix helps to capture the interactions between these components, allowing the Newton-Raphson method to solve the network equations accurately.\n",
            "\n",
            "To calculate the Jacobian matrix for a water network, engineers typically use numerical methods, such as finite differences or automatic differentiation. These methods involve approximating the partial derivatives of the system equations with respect to the variables, which are then used to construct the Jacobian matrix.\n",
            "\n",
            "In summary, the calculation of the Jacobian matrix is critical in Newton-Raphson solvers for water networks because it provides a measure of the sensitivity of the system to changes in the variables, captures the non-linear relationships between variables, and helps to ensure convergence and stability of the method.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to assess how well the predicted response addresses the key points made in the actual answer regarding the importance of the Jacobian in Newton-Raphson solvers for water networks.\n",
            "\n",
            "The actual answer emphasizes the following critical aspects:\n",
            "1. The Jacobian quantifies the relationship between unknowns and network equations.\n",
            "2. It is essential for predicting the impact of changes in variables on the system.\n",
            "3. An accurate Jacobian is necessary for reliable convergence of the solver.\n",
            "4. Inaccuracies can lead to slower or unstable convergence.\n",
            "\n",
            "The predicted answer covers several important points:\n",
            "1. It discusses convergence and stability, highlighting the importance of an accurately calculated Jacobian.\n",
            "2. It mentions sensitivity analysis, which aligns with the idea of understanding how changes affect the system.\n",
            "3. It addresses non-linearity in water networks and the role of the Jacobian in capturing these relationships.\n",
            "4. It includes specific references to pipe flow equations and network topology, which are relevant to the context.\n",
            "\n",
            "However, while the predicted answer is comprehensive and covers many elements, it does not explicitly mention the direct relationship between the Jacobian and the network equations as stated in the actual answer. It also lacks a concise summary of the consequences of not having an accurate Jacobian, which is a critical point in the actual answer.\n",
            "\n",
            "Overall, the predicted answer includes most of the elements necessary for a complete response but misses some specific connections and implications that are present in the actual answer. Therefore, I would rate the completeness of the predicted answer as a 4.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: Why is calculation of partial derivatives (the Jacobian) critical in Newton-Raphson solvers for water networks?, Actual answer: The Jacobian quantifies how each unknown (flow or head) affects the network equations. In Newton-Raphson solvers, the iterative update to each variable depends on these partial derivatives, enabling the solver to predict how changing a node’s head or a pipe’s flow will impact the entire system. Without an accurate Jacobian, the solver cannot reliably determine the direction or magnitude of each correction step, leading to slower or unstable convergence., Predicted answer: The calculation of partial derivatives, also known as the Jacobian matrix, is critical in Newton-Raphson solvers for water networks for several reasons:\n",
            "\n",
            "1. **Convergence and Stability**: The Newton-Raphson method relies on the Jacobian matrix to determine the direction of the next iteration. If the Jacobian matrix is not accurately calculated, the method may not converge or may even diverge. In water networks, small errors in the Jacobian can lead to large errors in the solution, which can have significant consequences, such as pipe over-pressurization or under-pressurization.\n",
            "2. **Sensitivity Analysis**: The Jacobian matrix provides a measure of the sensitivity of the system to changes in the variables. In water networks, understanding the sensitivity of the system to changes in demand, pipe roughness, or other parameters is crucial for designing and operating the network efficiently.\n",
            "3. **Non-Linearity**: Water networks are inherently non-linear systems, meaning that small changes in the variables can lead to large changes in the solution. The Jacobian matrix helps to capture these non-linear relationships, allowing the Newton-Raphson method to converge to the correct solution.\n",
            "4. **Pipe Flow Equations**: The pipe flow equations, such as the Darcy-Weisbach equation or the Colebrook-White equation, are non-linear and involve complex relationships between variables such as flow rate, head loss, and pipe diameter. The Jacobian matrix helps to capture these complex relationships, allowing the Newton-Raphson method to solve the pipe flow equations accurately.\n",
            "5. **Network Topology**: Water networks have a complex topology, with multiple pipes, nodes, and loops. The Jacobian matrix helps to capture the interactions between these components, allowing the Newton-Raphson method to solve the network equations accurately.\n",
            "\n",
            "To calculate the Jacobian matrix for a water network, engineers typically use numerical methods, such as finite differences or automatic differentiation. These methods involve approximating the partial derivatives of the system equations with respect to the variables, which are then used to construct the Jacobian matrix.\n",
            "\n",
            "In summary, the calculation of the Jacobian matrix is critical in Newton-Raphson solvers for water networks because it provides a measure of the sensitivity of the system to changes in the variables, captures the non-linear relationships between variables, and helps to ensure convergence and stability of the method.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about the importance of calculating partial derivatives (the Jacobian) in Newton-Raphson solvers for water networks.\n",
            "\n",
            "The actual answer succinctly explains the role of the Jacobian in the context of the Newton-Raphson method, emphasizing its importance for predicting the effects of changes in the network and ensuring reliable convergence. It focuses on the direct implications of the Jacobian's accuracy for the solver's performance.\n",
            "\n",
            "The predicted answer, while comprehensive and detailed, includes several points that, while relevant to the topic, may not directly address the core of the user's question. For instance, it discusses convergence and stability, sensitivity analysis, non-linearity, pipe flow equations, and network topology in detail. While these aspects are related to the Jacobian's role, they introduce a broader context that may not be necessary for answering the specific question about why the Jacobian is critical.\n",
            "\n",
            "The predicted answer does provide relevant information, but it also contains a significant amount of detail that could be considered extraneous to the user's original question. This leads to a situation where the response is informative but somewhat diluted by the inclusion of additional concepts that are not strictly necessary for understanding the Jacobian's critical role.\n",
            "\n",
            "Given this analysis, I would assign a score of 3 to the predicted answer. It answers the user's question but contains more irrelevant information than relevant information.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: Why is calculation of partial derivatives (the Jacobian) critical in Newton-Raphson solvers for water networks?, Actual answer: The Jacobian quantifies how each unknown (flow or head) affects the network equations. In Newton-Raphson solvers, the iterative update to each variable depends on these partial derivatives, enabling the solver to predict how changing a node’s head or a pipe’s flow will impact the entire system. Without an accurate Jacobian, the solver cannot reliably determine the direction or magnitude of each correction step, leading to slower or unstable convergence., Predicted answer: The calculation of partial derivatives, also known as the Jacobian matrix, is critical in Newton-Raphson solvers for water networks for several reasons:\n",
            "\n",
            "1. **Convergence and Stability**: The Newton-Raphson method relies on the Jacobian matrix to determine the direction of the next iteration. If the Jacobian matrix is not accurately calculated, the method may not converge or may even diverge. In water networks, small errors in the Jacobian can lead to large errors in the solution, which can have significant consequences, such as pipe over-pressurization or under-pressurization.\n",
            "2. **Sensitivity Analysis**: The Jacobian matrix provides a measure of the sensitivity of the system to changes in the variables. In water networks, understanding the sensitivity of the system to changes in demand, pipe roughness, or other parameters is crucial for designing and operating the network efficiently.\n",
            "3. **Non-Linearity**: Water networks are inherently non-linear systems, meaning that small changes in the variables can lead to large changes in the solution. The Jacobian matrix helps to capture these non-linear relationships, allowing the Newton-Raphson method to converge to the correct solution.\n",
            "4. **Pipe Flow Equations**: The pipe flow equations, such as the Darcy-Weisbach equation or the Colebrook-White equation, are non-linear and involve complex relationships between variables such as flow rate, head loss, and pipe diameter. The Jacobian matrix helps to capture these complex relationships, allowing the Newton-Raphson method to solve the pipe flow equations accurately.\n",
            "5. **Network Topology**: Water networks have a complex topology, with multiple pipes, nodes, and loops. The Jacobian matrix helps to capture the interactions between these components, allowing the Newton-Raphson method to solve the network equations accurately.\n",
            "\n",
            "To calculate the Jacobian matrix for a water network, engineers typically use numerical methods, such as finite differences or automatic differentiation. These methods involve approximating the partial derivatives of the system equations with respect to the variables, which are then used to construct the Jacobian matrix.\n",
            "\n",
            "In summary, the calculation of the Jacobian matrix is critical in Newton-Raphson solvers for water networks because it provides a measure of the sensitivity of the system to changes in the variables, captures the non-linear relationships between variables, and helps to ensure convergence and stability of the method.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information provided in the predicted response. \n",
            "\n",
            "The actual answer is succinct and directly addresses the importance of the Jacobian in the context of the Newton-Raphson method for water networks. It focuses on the essential points: the role of the Jacobian in determining the impact of changes in variables, the necessity for accurate calculations to ensure convergence, and the consequences of inaccuracies.\n",
            "\n",
            "In contrast, the predicted answer is significantly longer and includes multiple points that, while relevant, introduce a lot of extra information. It elaborates on aspects such as convergence and stability, sensitivity analysis, non-linearity, pipe flow equations, and network topology in a detailed manner. This level of detail, while informative, diverges from the core question and adds unnecessary complexity.\n",
            "\n",
            "Given this analysis, the predicted answer includes a lot of extra information and uses flowery language, which detracts from its conciseness.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: Why is calculation of partial derivatives (the Jacobian) critical in Newton-Raphson solvers for water networks?, Actual answer: The Jacobian quantifies how each unknown (flow or head) affects the network equations. In Newton-Raphson solvers, the iterative update to each variable depends on these partial derivatives, enabling the solver to predict how changing a node’s head or a pipe’s flow will impact the entire system. Without an accurate Jacobian, the solver cannot reliably determine the direction or magnitude of each correction step, leading to slower or unstable convergence., Predicted answer: The calculation of partial derivatives, also known as the Jacobian matrix, is critical in Newton-Raphson solvers for water networks for several reasons:\n",
            "\n",
            "1. **Convergence and Stability**: The Newton-Raphson method relies on the Jacobian matrix to determine the direction of the next iteration. If the Jacobian matrix is not accurately calculated, the method may not converge or may even diverge. In water networks, small errors in the Jacobian can lead to large errors in the solution, which can have significant consequences, such as pipe over-pressurization or under-pressurization.\n",
            "2. **Sensitivity Analysis**: The Jacobian matrix provides a measure of the sensitivity of the system to changes in the variables. In water networks, understanding the sensitivity of the system to changes in demand, pipe roughness, or other parameters is crucial for designing and operating the network efficiently.\n",
            "3. **Non-Linearity**: Water networks are inherently non-linear systems, meaning that small changes in the variables can lead to large changes in the solution. The Jacobian matrix helps to capture these non-linear relationships, allowing the Newton-Raphson method to converge to the correct solution.\n",
            "4. **Pipe Flow Equations**: The pipe flow equations, such as the Darcy-Weisbach equation or the Colebrook-White equation, are non-linear and involve complex relationships between variables such as flow rate, head loss, and pipe diameter. The Jacobian matrix helps to capture these complex relationships, allowing the Newton-Raphson method to solve the pipe flow equations accurately.\n",
            "5. **Network Topology**: Water networks have a complex topology, with multiple pipes, nodes, and loops. The Jacobian matrix helps to capture the interactions between these components, allowing the Newton-Raphson method to solve the network equations accurately.\n",
            "\n",
            "To calculate the Jacobian matrix for a water network, engineers typically use numerical methods, such as finite differences or automatic differentiation. These methods involve approximating the partial derivatives of the system equations with respect to the variables, which are then used to construct the Jacobian matrix.\n",
            "\n",
            "In summary, the calculation of the Jacobian matrix is critical in Newton-Raphson solvers for water networks because it provides a measure of the sensitivity of the system to changes in the variables, captures the non-linear relationships between variables, and helps to ensure convergence and stability of the method.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response captures the critical aspects of the Jacobian's role in the Newton-Raphson method for water networks. \n",
            "\n",
            "The actual answer succinctly explains that the Jacobian quantifies the relationship between unknowns and network equations, emphasizing its importance for reliable updates in the iterative process. It highlights the consequences of an inaccurate Jacobian, such as slower or unstable convergence.\n",
            "\n",
            "The predicted answer, while longer and more detailed, covers several important points: it discusses convergence and stability, sensitivity analysis, non-linearity, pipe flow equations, and network topology. Each of these points is relevant and adds depth to the understanding of why the Jacobian is critical. However, the predicted answer could be seen as somewhat verbose and may introduce unnecessary complexity without directly addressing the core reason for the Jacobian's importance as clearly as the actual answer does.\n",
            "\n",
            "In terms of confidence, the predicted answer demonstrates a strong understanding of the topic and provides a comprehensive overview, which suggests a high level of assurance in its correctness. However, the potential for confusion due to its length and complexity might slightly detract from its clarity.\n",
            "\n",
            "Given these considerations, I would assign a score of 4 to the predicted answer, indicating moderate agreement with the actual answer while acknowledging some uncertainty due to its complexity.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: Why is calculation of partial derivatives (the Jacobian) critical in Newton-Raphson solvers for water networks?, Actual answer: The Jacobian quantifies how each unknown (flow or head) affects the network equations. In Newton-Raphson solvers, the iterative update to each variable depends on these partial derivatives, enabling the solver to predict how changing a node’s head or a pipe’s flow will impact the entire system. Without an accurate Jacobian, the solver cannot reliably determine the direction or magnitude of each correction step, leading to slower or unstable convergence., Predicted answer: The calculation of partial derivatives, also known as the Jacobian matrix, is critical in Newton-Raphson solvers for water networks for several reasons:\n",
            "\n",
            "1. **Convergence and Stability**: The Newton-Raphson method relies on the Jacobian matrix to determine the direction of the next iteration. If the Jacobian matrix is not accurately calculated, the method may not converge or may even diverge. In water networks, small errors in the Jacobian can lead to large errors in the solution, which can have significant consequences, such as pipe over-pressurization or under-pressurization.\n",
            "2. **Sensitivity Analysis**: The Jacobian matrix provides a measure of the sensitivity of the system to changes in the variables. In water networks, understanding the sensitivity of the system to changes in demand, pipe roughness, or other parameters is crucial for designing and operating the network efficiently.\n",
            "3. **Non-Linearity**: Water networks are inherently non-linear systems, meaning that small changes in the variables can lead to large changes in the solution. The Jacobian matrix helps to capture these non-linear relationships, allowing the Newton-Raphson method to converge to the correct solution.\n",
            "4. **Pipe Flow Equations**: The pipe flow equations, such as the Darcy-Weisbach equation or the Colebrook-White equation, are non-linear and involve complex relationships between variables such as flow rate, head loss, and pipe diameter. The Jacobian matrix helps to capture these complex relationships, allowing the Newton-Raphson method to solve the pipe flow equations accurately.\n",
            "5. **Network Topology**: Water networks have a complex topology, with multiple pipes, nodes, and loops. The Jacobian matrix helps to capture the interactions between these components, allowing the Newton-Raphson method to solve the network equations accurately.\n",
            "\n",
            "To calculate the Jacobian matrix for a water network, engineers typically use numerical methods, such as finite differences or automatic differentiation. These methods involve approximating the partial derivatives of the system equations with respect to the variables, which are then used to construct the Jacobian matrix.\n",
            "\n",
            "In summary, the calculation of the Jacobian matrix is critical in Newton-Raphson solvers for water networks because it provides a measure of the sensitivity of the system to changes in the variables, captures the non-linear relationships between variables, and helps to ensure convergence and stability of the method.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to assess the factual accuracy and relevance of the information presented in both responses. \n",
            "\n",
            "The actual answer succinctly explains the role of the Jacobian in the Newton-Raphson method, emphasizing its importance for convergence, stability, and the impact of changes in the network. It highlights that without an accurate Jacobian, the solver may struggle with convergence, which is a critical point.\n",
            "\n",
            "The predicted answer expands on this by providing multiple reasons why the Jacobian is essential, including aspects of convergence, sensitivity analysis, non-linearity, pipe flow equations, and network topology. Each of these points is relevant and factually correct, as they align with the principles of how the Jacobian functions in the context of water networks and the Newton-Raphson method.\n",
            "\n",
            "However, while the predicted answer is comprehensive and informative, it does not deviate from the factual basis established in the actual answer. It provides additional context and examples that enhance understanding without introducing any hallucinations or inaccuracies.\n",
            "\n",
            "Given this analysis, the predicted answer is largely factual and aligns well with the actual answer, with only slight variations in detail and depth. Therefore, I would assign a score of 5, indicating that the response only includes factual information.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 5}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "30it [15:25, 30.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mUser message:Question: Why is calculation of partial derivatives (the Jacobian) critical in Newton-Raphson solvers for water networks?, Actual answer: The Jacobian quantifies how each unknown (flow or head) affects the network equations. In Newton-Raphson solvers, the iterative update to each variable depends on these partial derivatives, enabling the solver to predict how changing a node’s head or a pipe’s flow will impact the entire system. Without an accurate Jacobian, the solver cannot reliably determine the direction or magnitude of each correction step, leading to slower or unstable convergence., Predicted answer: The calculation of partial derivatives, also known as the Jacobian matrix, is critical in Newton-Raphson solvers for water networks for several reasons:\n",
            "\n",
            "1. **Convergence and Stability**: The Newton-Raphson method relies on the Jacobian matrix to determine the direction of the next iteration. If the Jacobian matrix is not accurately calculated, the method may not converge or may even diverge. In water networks, small errors in the Jacobian can lead to large errors in the solution, which can have significant consequences, such as pipe over-pressurization or under-pressurization.\n",
            "2. **Sensitivity Analysis**: The Jacobian matrix provides a measure of the sensitivity of the system to changes in the variables. In water networks, understanding the sensitivity of the system to changes in demand, pipe roughness, or other parameters is crucial for designing and operating the network efficiently.\n",
            "3. **Non-Linearity**: Water networks are inherently non-linear systems, meaning that small changes in the variables can lead to large changes in the solution. The Jacobian matrix helps to capture these non-linear relationships, allowing the Newton-Raphson method to converge to the correct solution.\n",
            "4. **Pipe Flow Equations**: The pipe flow equations, such as the Darcy-Weisbach equation or the Colebrook-White equation, are non-linear and involve complex relationships between variables such as flow rate, head loss, and pipe diameter. The Jacobian matrix helps to capture these complex relationships, allowing the Newton-Raphson method to solve the pipe flow equations accurately.\n",
            "5. **Network Topology**: Water networks have a complex topology, with multiple pipes, nodes, and loops. The Jacobian matrix helps to capture the interactions between these components, allowing the Newton-Raphson method to solve the network equations accurately.\n",
            "\n",
            "To calculate the Jacobian matrix for a water network, engineers typically use numerical methods, such as finite differences or automatic differentiation. These methods involve approximating the partial derivatives of the system equations with respect to the variables, which are then used to construct the Jacobian matrix.\n",
            "\n",
            "In summary, the calculation of the Jacobian matrix is critical in Newton-Raphson solvers for water networks because it provides a measure of the sensitivity of the system to changes in the variables, captures the non-linear relationships between variables, and helps to ensure convergence and stability of the method.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and clarity of the information presented in both responses. The actual answer succinctly explains the role of the Jacobian in the Newton-Raphson method, emphasizing its importance for convergence, stability, and the impact of changes in the network. It also highlights the consequences of inaccuracies in the Jacobian.\n",
            "\n",
            "The predicted answer, while lengthy, covers several relevant points, including convergence and stability, sensitivity analysis, non-linearity, pipe flow equations, and network topology. It provides a comprehensive overview of why the Jacobian is critical in this context. However, it could be seen as somewhat verbose and may introduce unnecessary complexity without directly addressing the core reasons as clearly as the actual answer.\n",
            "\n",
            "In terms of judgment, the predicted answer does not misinterpret the information and correctly identifies the importance of the Jacobian. It does not confidently claim any hallucinations as truth, nor does it express uncertainty. Instead, it provides a detailed explanation that aligns well with the actual answer, albeit with more elaboration.\n",
            "\n",
            "Given these considerations, I would assign a score of 5 to the predicted answer, as it is correct and provides a thorough understanding of the topic.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 3, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 5, 'judgement_descr': 5}\n",
            "\n",
            "\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: What aspects of the Newton-Raphson technique generally lead to faster convergence compared to loop-based iterative methods?, Actual answer: Newton-Raphson methods solve all governing equations simultaneously by using partial derivatives (the Jacobian) that link changes in flows or heads to changes in hydraulic equations. This approach allows the solver to make a more direct beeline toward the solution, whereas loop-based methods adjust flows one loop at a time. By incorporating global information into each iteration, Newton-Raphson typically reaches high accuracy in fewer iterations, especially for large or complex systems., Predicted answer: The Newton-Raphson technique generally leads to faster convergence compared to loop-based iterative methods due to the following aspects:\n",
            "\n",
            "1. **Quadratic Convergence**: The Newton-Raphson method exhibits quadratic convergence, meaning that the number of correct digits in the solution approximately doubles with each iteration. This is in contrast to linear convergence, which is typical of loop-based iterative methods, where the number of correct digits increases linearly with each iteration.\n",
            "\n",
            "2. **Use of Derivatives**: The Newton-Raphson method uses the first and second derivatives of the function, which provides a more accurate estimate of the solution at each iteration. This is because the derivative of the function provides information about the rate of change of the function, and the second derivative provides information about the curvature of the function.\n",
            "\n",
            "3. **Local Convergence**: The Newton-Raphson method converges locally, meaning that it converges to a solution that is close to the initial guess. This is in contrast to loop-based iterative methods, which may converge to a solution that is far from the initial guess.\n",
            "\n",
            "4. **Reduced Number of Iterations**: The Newton-Raphson method typically requires fewer iterations to converge to a solution compared to loop-based iterative methods. This is because the Newton-Raphson method uses a more accurate estimate of the solution at each iteration, which reduces the number of iterations required to converge.\n",
            "\n",
            "5. **Robustness to Initial Guess**: The Newton-Raphson method is relatively robust to the choice of initial guess, meaning that it can converge to a solution even if the initial guess is not close to the actual solution. This is in contrast to loop-based iterative methods, which may not converge to a solution if the initial guess is not close to the actual solution.\n",
            "\n",
            "Overall, the Newton-Raphson technique leads to faster convergence compared to loop-based iterative methods due to its quadratic convergence, use of derivatives, local convergence, reduced number of iterations, and robustness to initial guess.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the completeness of the predicted answer compared to the actual answer, we need to analyze the key elements present in both responses.\n",
            "\n",
            "The actual answer emphasizes the following points:\n",
            "1. Simultaneous solution of governing equations using the Jacobian.\n",
            "2. Direct approach towards the solution compared to loop-based methods.\n",
            "3. Incorporation of global information leading to high accuracy in fewer iterations, especially in large or complex systems.\n",
            "\n",
            "The predicted answer, on the other hand, covers several aspects:\n",
            "1. Quadratic convergence and its implications.\n",
            "2. Use of derivatives for more accurate estimates.\n",
            "3. Local convergence characteristics.\n",
            "4. Reduced number of iterations required.\n",
            "5. Robustness to initial guesses.\n",
            "\n",
            "While the predicted answer is detailed and covers many important aspects of the Newton-Raphson method, it does not mention the simultaneous solving of governing equations or the use of the Jacobian, which are critical to understanding why the method is more effective in certain contexts, particularly in complex systems. Additionally, it lacks the emphasis on the global information aspect that the actual answer highlights.\n",
            "\n",
            "Overall, the predicted answer includes many relevant points but misses some key elements that would provide a more complete understanding of the advantages of the Newton-Raphson technique over loop-based methods.\n",
            "\n",
            "Given this analysis, I would assign a score of 4, as the predicted answer covers most elements of a complete answer but lacks some critical details.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: What aspects of the Newton-Raphson technique generally lead to faster convergence compared to loop-based iterative methods?, Actual answer: Newton-Raphson methods solve all governing equations simultaneously by using partial derivatives (the Jacobian) that link changes in flows or heads to changes in hydraulic equations. This approach allows the solver to make a more direct beeline toward the solution, whereas loop-based methods adjust flows one loop at a time. By incorporating global information into each iteration, Newton-Raphson typically reaches high accuracy in fewer iterations, especially for large or complex systems., Predicted answer: The Newton-Raphson technique generally leads to faster convergence compared to loop-based iterative methods due to the following aspects:\n",
            "\n",
            "1. **Quadratic Convergence**: The Newton-Raphson method exhibits quadratic convergence, meaning that the number of correct digits in the solution approximately doubles with each iteration. This is in contrast to linear convergence, which is typical of loop-based iterative methods, where the number of correct digits increases linearly with each iteration.\n",
            "\n",
            "2. **Use of Derivatives**: The Newton-Raphson method uses the first and second derivatives of the function, which provides a more accurate estimate of the solution at each iteration. This is because the derivative of the function provides information about the rate of change of the function, and the second derivative provides information about the curvature of the function.\n",
            "\n",
            "3. **Local Convergence**: The Newton-Raphson method converges locally, meaning that it converges to a solution that is close to the initial guess. This is in contrast to loop-based iterative methods, which may converge to a solution that is far from the initial guess.\n",
            "\n",
            "4. **Reduced Number of Iterations**: The Newton-Raphson method typically requires fewer iterations to converge to a solution compared to loop-based iterative methods. This is because the Newton-Raphson method uses a more accurate estimate of the solution at each iteration, which reduces the number of iterations required to converge.\n",
            "\n",
            "5. **Robustness to Initial Guess**: The Newton-Raphson method is relatively robust to the choice of initial guess, meaning that it can converge to a solution even if the initial guess is not close to the actual solution. This is in contrast to loop-based iterative methods, which may not converge to a solution if the initial guess is not close to the actual solution.\n",
            "\n",
            "Overall, the Newton-Raphson technique leads to faster convergence compared to loop-based iterative methods due to its quadratic convergence, use of derivatives, local convergence, reduced number of iterations, and robustness to initial guess.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about the aspects of the Newton-Raphson technique that contribute to its faster convergence compared to loop-based iterative methods.\n",
            "\n",
            "The predicted answer provides a detailed breakdown of several key aspects of the Newton-Raphson method, including quadratic convergence, the use of derivatives, local convergence, reduced number of iterations, and robustness to initial guesses. Each of these points is relevant to the question and explains why the Newton-Raphson method is generally faster in terms of convergence.\n",
            "\n",
            "In contrast, the actual answer also emphasizes the simultaneous solving of governing equations using the Jacobian, which is a critical aspect of the Newton-Raphson method that enhances its efficiency. While the predicted answer does not explicitly mention the Jacobian or the simultaneous nature of the solution process, it does cover other relevant points that contribute to understanding the faster convergence.\n",
            "\n",
            "Overall, the predicted answer is comprehensive and directly addresses the question, with only minor deviations in focus compared to the actual answer. It does not contain irrelevant information and remains on topic throughout.\n",
            "\n",
            "Given this analysis, I would assign a score of 5 to the predicted answer, as it answers the user's question and contains no irrelevant information.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 5}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: What aspects of the Newton-Raphson technique generally lead to faster convergence compared to loop-based iterative methods?, Actual answer: Newton-Raphson methods solve all governing equations simultaneously by using partial derivatives (the Jacobian) that link changes in flows or heads to changes in hydraulic equations. This approach allows the solver to make a more direct beeline toward the solution, whereas loop-based methods adjust flows one loop at a time. By incorporating global information into each iteration, Newton-Raphson typically reaches high accuracy in fewer iterations, especially for large or complex systems., Predicted answer: The Newton-Raphson technique generally leads to faster convergence compared to loop-based iterative methods due to the following aspects:\n",
            "\n",
            "1. **Quadratic Convergence**: The Newton-Raphson method exhibits quadratic convergence, meaning that the number of correct digits in the solution approximately doubles with each iteration. This is in contrast to linear convergence, which is typical of loop-based iterative methods, where the number of correct digits increases linearly with each iteration.\n",
            "\n",
            "2. **Use of Derivatives**: The Newton-Raphson method uses the first and second derivatives of the function, which provides a more accurate estimate of the solution at each iteration. This is because the derivative of the function provides information about the rate of change of the function, and the second derivative provides information about the curvature of the function.\n",
            "\n",
            "3. **Local Convergence**: The Newton-Raphson method converges locally, meaning that it converges to a solution that is close to the initial guess. This is in contrast to loop-based iterative methods, which may converge to a solution that is far from the initial guess.\n",
            "\n",
            "4. **Reduced Number of Iterations**: The Newton-Raphson method typically requires fewer iterations to converge to a solution compared to loop-based iterative methods. This is because the Newton-Raphson method uses a more accurate estimate of the solution at each iteration, which reduces the number of iterations required to converge.\n",
            "\n",
            "5. **Robustness to Initial Guess**: The Newton-Raphson method is relatively robust to the choice of initial guess, meaning that it can converge to a solution even if the initial guess is not close to the actual solution. This is in contrast to loop-based iterative methods, which may not converge to a solution if the initial guess is not close to the actual solution.\n",
            "\n",
            "Overall, the Newton-Raphson technique leads to faster convergence compared to loop-based iterative methods due to its quadratic convergence, use of derivatives, local convergence, reduced number of iterations, and robustness to initial guess.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information provided in the predicted response. The actual answer succinctly explains the key aspects of the Newton-Raphson method that contribute to its faster convergence, focusing on the simultaneous solution of governing equations and the use of the Jacobian.\n",
            "\n",
            "In contrast, the predicted answer elaborates on multiple aspects, including quadratic convergence, the use of derivatives, local convergence, reduced iterations, and robustness to initial guesses. While these points are relevant, the predicted response is significantly longer and includes detailed explanations that may not be necessary for a concise answer. \n",
            "\n",
            "The actual answer effectively communicates the main idea without excessive detail, while the predicted answer, although informative, contains a lot of extra information and could be considered flowery in its language. \n",
            "\n",
            "Given this analysis, I would assign a score of 3 to the predicted response for including a lot of extra information or using flowery language.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 5, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: What aspects of the Newton-Raphson technique generally lead to faster convergence compared to loop-based iterative methods?, Actual answer: Newton-Raphson methods solve all governing equations simultaneously by using partial derivatives (the Jacobian) that link changes in flows or heads to changes in hydraulic equations. This approach allows the solver to make a more direct beeline toward the solution, whereas loop-based methods adjust flows one loop at a time. By incorporating global information into each iteration, Newton-Raphson typically reaches high accuracy in fewer iterations, especially for large or complex systems., Predicted answer: The Newton-Raphson technique generally leads to faster convergence compared to loop-based iterative methods due to the following aspects:\n",
            "\n",
            "1. **Quadratic Convergence**: The Newton-Raphson method exhibits quadratic convergence, meaning that the number of correct digits in the solution approximately doubles with each iteration. This is in contrast to linear convergence, which is typical of loop-based iterative methods, where the number of correct digits increases linearly with each iteration.\n",
            "\n",
            "2. **Use of Derivatives**: The Newton-Raphson method uses the first and second derivatives of the function, which provides a more accurate estimate of the solution at each iteration. This is because the derivative of the function provides information about the rate of change of the function, and the second derivative provides information about the curvature of the function.\n",
            "\n",
            "3. **Local Convergence**: The Newton-Raphson method converges locally, meaning that it converges to a solution that is close to the initial guess. This is in contrast to loop-based iterative methods, which may converge to a solution that is far from the initial guess.\n",
            "\n",
            "4. **Reduced Number of Iterations**: The Newton-Raphson method typically requires fewer iterations to converge to a solution compared to loop-based iterative methods. This is because the Newton-Raphson method uses a more accurate estimate of the solution at each iteration, which reduces the number of iterations required to converge.\n",
            "\n",
            "5. **Robustness to Initial Guess**: The Newton-Raphson method is relatively robust to the choice of initial guess, meaning that it can converge to a solution even if the initial guess is not close to the actual solution. This is in contrast to loop-based iterative methods, which may not converge to a solution if the initial guess is not close to the actual solution.\n",
            "\n",
            "Overall, the Newton-Raphson technique leads to faster convergence compared to loop-based iterative methods due to its quadratic convergence, use of derivatives, local convergence, reduced number of iterations, and robustness to initial guess.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the confidence conveyed in both responses regarding the aspects of the Newton-Raphson technique that lead to faster convergence compared to loop-based iterative methods.\n",
            "\n",
            "The actual answer succinctly highlights the key reasons for the faster convergence of the Newton-Raphson method, emphasizing the simultaneous solution of governing equations using the Jacobian, which allows for a more direct approach to finding the solution. It also notes the efficiency in reaching high accuracy in fewer iterations, particularly in complex systems.\n",
            "\n",
            "The predicted answer, on the other hand, provides a detailed breakdown of several aspects that contribute to the faster convergence of the Newton-Raphson method. It discusses quadratic convergence, the use of derivatives, local convergence, reduced iterations, and robustness to initial guesses. This comprehensive approach demonstrates a strong understanding of the method's advantages.\n",
            "\n",
            "In terms of confidence, the predicted answer presents its points with clarity and thoroughness, suggesting a high level of assurance in the correctness of the information provided. It does not express any doubt or uncertainty, and it aligns well with the actual answer's key points, albeit with more elaboration.\n",
            "\n",
            "Given this analysis, I would assign a score of 5 to the predicted answer, as it confidently asserts the correctness of the information and provides a well-rounded explanation.\n",
            "\n",
            "FINAL SCORE: 5\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 5, 'conciseness_descr': 3, 'confidence_descr': 5}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: What aspects of the Newton-Raphson technique generally lead to faster convergence compared to loop-based iterative methods?, Actual answer: Newton-Raphson methods solve all governing equations simultaneously by using partial derivatives (the Jacobian) that link changes in flows or heads to changes in hydraulic equations. This approach allows the solver to make a more direct beeline toward the solution, whereas loop-based methods adjust flows one loop at a time. By incorporating global information into each iteration, Newton-Raphson typically reaches high accuracy in fewer iterations, especially for large or complex systems., Predicted answer: The Newton-Raphson technique generally leads to faster convergence compared to loop-based iterative methods due to the following aspects:\n",
            "\n",
            "1. **Quadratic Convergence**: The Newton-Raphson method exhibits quadratic convergence, meaning that the number of correct digits in the solution approximately doubles with each iteration. This is in contrast to linear convergence, which is typical of loop-based iterative methods, where the number of correct digits increases linearly with each iteration.\n",
            "\n",
            "2. **Use of Derivatives**: The Newton-Raphson method uses the first and second derivatives of the function, which provides a more accurate estimate of the solution at each iteration. This is because the derivative of the function provides information about the rate of change of the function, and the second derivative provides information about the curvature of the function.\n",
            "\n",
            "3. **Local Convergence**: The Newton-Raphson method converges locally, meaning that it converges to a solution that is close to the initial guess. This is in contrast to loop-based iterative methods, which may converge to a solution that is far from the initial guess.\n",
            "\n",
            "4. **Reduced Number of Iterations**: The Newton-Raphson method typically requires fewer iterations to converge to a solution compared to loop-based iterative methods. This is because the Newton-Raphson method uses a more accurate estimate of the solution at each iteration, which reduces the number of iterations required to converge.\n",
            "\n",
            "5. **Robustness to Initial Guess**: The Newton-Raphson method is relatively robust to the choice of initial guess, meaning that it can converge to a solution even if the initial guess is not close to the actual solution. This is in contrast to loop-based iterative methods, which may not converge to a solution if the initial guess is not close to the actual solution.\n",
            "\n",
            "Overall, the Newton-Raphson technique leads to faster convergence compared to loop-based iterative methods due to its quadratic convergence, use of derivatives, local convergence, reduced number of iterations, and robustness to initial guess.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the factual accuracy of the points made in the predicted response. \n",
            "\n",
            "1. **Quadratic Convergence**: The predicted answer correctly identifies that the Newton-Raphson method exhibits quadratic convergence, which is a key aspect that contributes to its faster convergence compared to linear convergence in loop-based methods. This aligns well with the actual answer.\n",
            "\n",
            "2. **Use of Derivatives**: The mention of first and second derivatives in the predicted answer is accurate. The actual answer emphasizes the use of partial derivatives (the Jacobian), which is a specific application of derivatives in the context of hydraulic equations. The predicted answer's explanation is somewhat broader but still factual.\n",
            "\n",
            "3. **Local Convergence**: The predicted answer states that the Newton-Raphson method converges locally, which is a valid point. However, the actual answer focuses more on the simultaneous solution of governing equations, which is a critical aspect of the method's efficiency. The predicted answer does not fully capture this nuance.\n",
            "\n",
            "4. **Reduced Number of Iterations**: This point is also valid in the predicted answer, as it correctly states that the Newton-Raphson method typically requires fewer iterations. This is consistent with the actual answer's emphasis on high accuracy in fewer iterations.\n",
            "\n",
            "5. **Robustness to Initial Guess**: The predicted answer's claim about the robustness of the Newton-Raphson method to initial guesses is somewhat misleading. While it is true that the method can converge from a wider range of initial guesses compared to some methods, it is not universally robust, especially in cases where the initial guess is far from the actual solution. The actual answer does not mention this aspect, which could lead to a misunderstanding.\n",
            "\n",
            "Overall, the predicted answer contains a mix of accurate information and some oversimplifications or inaccuracies, particularly regarding the robustness of the method. It does not fully capture the essence of the actual answer, which emphasizes the simultaneous solving of equations and the use of the Jacobian.\n",
            "\n",
            "Considering these points, I would assign a score of 4, as the predicted answer includes mostly factual information with slight hallucinations or inaccuracies.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 5, 'conciseness_descr': 3, 'confidence_descr': 5, 'factuality_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "31it [16:12, 34.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mUser message:Question: What aspects of the Newton-Raphson technique generally lead to faster convergence compared to loop-based iterative methods?, Actual answer: Newton-Raphson methods solve all governing equations simultaneously by using partial derivatives (the Jacobian) that link changes in flows or heads to changes in hydraulic equations. This approach allows the solver to make a more direct beeline toward the solution, whereas loop-based methods adjust flows one loop at a time. By incorporating global information into each iteration, Newton-Raphson typically reaches high accuracy in fewer iterations, especially for large or complex systems., Predicted answer: The Newton-Raphson technique generally leads to faster convergence compared to loop-based iterative methods due to the following aspects:\n",
            "\n",
            "1. **Quadratic Convergence**: The Newton-Raphson method exhibits quadratic convergence, meaning that the number of correct digits in the solution approximately doubles with each iteration. This is in contrast to linear convergence, which is typical of loop-based iterative methods, where the number of correct digits increases linearly with each iteration.\n",
            "\n",
            "2. **Use of Derivatives**: The Newton-Raphson method uses the first and second derivatives of the function, which provides a more accurate estimate of the solution at each iteration. This is because the derivative of the function provides information about the rate of change of the function, and the second derivative provides information about the curvature of the function.\n",
            "\n",
            "3. **Local Convergence**: The Newton-Raphson method converges locally, meaning that it converges to a solution that is close to the initial guess. This is in contrast to loop-based iterative methods, which may converge to a solution that is far from the initial guess.\n",
            "\n",
            "4. **Reduced Number of Iterations**: The Newton-Raphson method typically requires fewer iterations to converge to a solution compared to loop-based iterative methods. This is because the Newton-Raphson method uses a more accurate estimate of the solution at each iteration, which reduces the number of iterations required to converge.\n",
            "\n",
            "5. **Robustness to Initial Guess**: The Newton-Raphson method is relatively robust to the choice of initial guess, meaning that it can converge to a solution even if the initial guess is not close to the actual solution. This is in contrast to loop-based iterative methods, which may not converge to a solution if the initial guess is not close to the actual solution.\n",
            "\n",
            "Overall, the Newton-Raphson technique leads to faster convergence compared to loop-based iterative methods due to its quadratic convergence, use of derivatives, local convergence, reduced number of iterations, and robustness to initial guess.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and clarity of the information presented. The actual answer emphasizes the simultaneous solution of governing equations using the Jacobian, which allows for a more direct approach to finding the solution. It highlights the importance of global information in achieving faster convergence, particularly in complex systems.\n",
            "\n",
            "The predicted answer, while providing a detailed breakdown of the aspects contributing to faster convergence, introduces some inaccuracies and misinterpretations. For instance, it mentions \"local convergence\" and \"robustness to initial guess,\" which are not the primary reasons for the faster convergence of the Newton-Raphson method compared to loop-based methods. The focus on derivatives is relevant, but the explanation could be more aligned with the actual answer's emphasis on the Jacobian and simultaneous equation solving.\n",
            "\n",
            "Overall, the predicted answer does not fully capture the essence of the actual answer and introduces some confusion regarding the convergence characteristics. However, it does present the information in a structured manner and acknowledges the advantages of the Newton-Raphson method.\n",
            "\n",
            "Given these considerations, I would assign a score of 3 to the predicted answer, as it shows some understanding of the topic but also contains inaccuracies and misinterpretations.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 5, 'conciseness_descr': 3, 'confidence_descr': 5, 'factuality_descr': 4, 'judgement_descr': 3}\n",
            "\n",
            "\n",
            "No output from LLM\n",
            "Evaluating based on: completeness_descr\n",
            "\u001b[32mUser message:Question: How are flow corrections applied around each loop in the Hardy Cross method, and why must flow continuity be maintained at every junction?, Actual answer: In the Hardy Cross method, one first selects individual loops in the network and makes an initial guess of the flow in each pipe. Then, each loop is corrected iteratively: the head loss around the loop is summed, and a flow correction is applied to reduce the total head-loss error to zero. This correction is added (or subtracted) to the assumed flow in every pipe forming that loop. Flow continuity must be maintained at every junction to ensure that all flow entering a node is accounted for by either leaving through connecting pipes or satisfying demand. If continuity is not enforced, the model would not reflect true network behavior, causing errors to propagate in subsequent iterations., Predicted answer: In the Hardy Cross method, flow corrections are applied around each loop to satisfy the continuity equation at each junction. Here's a step-by-step explanation of how flow corrections are applied and why flow continuity must be maintained at every junction:\n",
            "\n",
            "**Flow Corrections around a Loop:**\n",
            "\n",
            "1.  **Select a Loop:** Choose a loop in the network, which is a path that starts and ends at the same node (junction).\n",
            "2.  **Calculate the Net Head Loss:** Calculate the net head loss (ΔH) for the loop by summing the head losses (h\\_f) for each pipe in the loop. The head loss for each pipe can be calculated using the Darcy-Weisbach equation or the Hazen-Williams equation.\n",
            "3.  **Calculate the Net Flow:** Calculate the net flow (Q\\_net) for the loop by summing the flows (Q) for each pipe in the loop. The flow for each pipe can be calculated using the Manning equation or the Darcy-Weisbach equation.\n",
            "4.  **Calculate the Flow Correction:** Calculate the flow correction (ΔQ) for the loop by dividing the net head loss (ΔH) by the net flow (Q\\_net). The flow correction represents the change in flow that is needed to balance the loop.\n",
            "5.  **Apply the Flow Correction:** Apply the flow correction (ΔQ) to each pipe in the loop by adding or subtracting the correction from the original flow (Q) for each pipe.\n",
            "\n",
            "**Maintaining Flow Continuity at Every Junction:**\n",
            "\n",
            "Flow continuity must be maintained at every junction because the sum of the flows entering a junction must equal the sum of the flows leaving the junction. This is based on the principle of conservation of mass, which states that mass cannot be created or destroyed in a closed system.\n",
            "\n",
            "In the Hardy Cross method, flow continuity is maintained at every junction by ensuring that the sum of the flows entering a junction equals the sum of the flows leaving the junction. This is achieved by applying flow corrections around each loop in the network, as described above.\n",
            "\n",
            "**Why Flow Continuity is Important:**\n",
            "\n",
            "Maintaining flow continuity at every junction is essential for several reasons:\n",
            "\n",
            "1.  **Accurate Flow Calculations:** Flow continuity ensures that the flows calculated using the Hardy Cross method are accurate and reliable.\n",
            "2.  **Conservation of Mass:** Flow continuity ensures that the principle of conservation of mass is satisfied, which is a fundamental principle in physics and engineering.\n",
            "3.  **Stable Network Operation:** Flow continuity helps to ensure that the network operates stably and efficiently, with no excessive pressure drops or flow surges.\n",
            "\n",
            "In summary, flow corrections are applied around each loop in the Hardy Cross method to satisfy the continuity equation at each junction. Maintaining flow continuity at every junction is essential for accurate flow calculations, conservation of mass, and stable network operation.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the completeness of the information provided in both responses. The actual answer succinctly outlines the process of applying flow corrections in the Hardy Cross method, including the iterative nature of the corrections and the importance of maintaining flow continuity at junctions. It emphasizes the need for flow continuity to reflect true network behavior and prevent errors in subsequent iterations.\n",
            "\n",
            "The predicted answer, while detailed and structured, covers most of the necessary elements. It explains the steps involved in applying flow corrections, including selecting a loop, calculating head loss, net flow, and applying corrections. It also addresses the importance of maintaining flow continuity and provides reasons for its necessity, such as accurate flow calculations and conservation of mass.\n",
            "\n",
            "However, the predicted answer lacks some nuances present in the actual answer, such as the iterative nature of the corrections and the potential consequences of not enforcing flow continuity. While it does provide a comprehensive overview, it does not fully capture the iterative aspect and the propagation of errors, which are critical to understanding the Hardy Cross method.\n",
            "\n",
            "Given this analysis, the predicted answer includes most elements of a complete answer but misses some key details that would elevate it to a full score. Therefore, I would assign a score of 4.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: relevance_descr\n",
            "\u001b[32mUser message:Question: How are flow corrections applied around each loop in the Hardy Cross method, and why must flow continuity be maintained at every junction?, Actual answer: In the Hardy Cross method, one first selects individual loops in the network and makes an initial guess of the flow in each pipe. Then, each loop is corrected iteratively: the head loss around the loop is summed, and a flow correction is applied to reduce the total head-loss error to zero. This correction is added (or subtracted) to the assumed flow in every pipe forming that loop. Flow continuity must be maintained at every junction to ensure that all flow entering a node is accounted for by either leaving through connecting pipes or satisfying demand. If continuity is not enforced, the model would not reflect true network behavior, causing errors to propagate in subsequent iterations., Predicted answer: In the Hardy Cross method, flow corrections are applied around each loop to satisfy the continuity equation at each junction. Here's a step-by-step explanation of how flow corrections are applied and why flow continuity must be maintained at every junction:\n",
            "\n",
            "**Flow Corrections around a Loop:**\n",
            "\n",
            "1.  **Select a Loop:** Choose a loop in the network, which is a path that starts and ends at the same node (junction).\n",
            "2.  **Calculate the Net Head Loss:** Calculate the net head loss (ΔH) for the loop by summing the head losses (h\\_f) for each pipe in the loop. The head loss for each pipe can be calculated using the Darcy-Weisbach equation or the Hazen-Williams equation.\n",
            "3.  **Calculate the Net Flow:** Calculate the net flow (Q\\_net) for the loop by summing the flows (Q) for each pipe in the loop. The flow for each pipe can be calculated using the Manning equation or the Darcy-Weisbach equation.\n",
            "4.  **Calculate the Flow Correction:** Calculate the flow correction (ΔQ) for the loop by dividing the net head loss (ΔH) by the net flow (Q\\_net). The flow correction represents the change in flow that is needed to balance the loop.\n",
            "5.  **Apply the Flow Correction:** Apply the flow correction (ΔQ) to each pipe in the loop by adding or subtracting the correction from the original flow (Q) for each pipe.\n",
            "\n",
            "**Maintaining Flow Continuity at Every Junction:**\n",
            "\n",
            "Flow continuity must be maintained at every junction because the sum of the flows entering a junction must equal the sum of the flows leaving the junction. This is based on the principle of conservation of mass, which states that mass cannot be created or destroyed in a closed system.\n",
            "\n",
            "In the Hardy Cross method, flow continuity is maintained at every junction by ensuring that the sum of the flows entering a junction equals the sum of the flows leaving the junction. This is achieved by applying flow corrections around each loop in the network, as described above.\n",
            "\n",
            "**Why Flow Continuity is Important:**\n",
            "\n",
            "Maintaining flow continuity at every junction is essential for several reasons:\n",
            "\n",
            "1.  **Accurate Flow Calculations:** Flow continuity ensures that the flows calculated using the Hardy Cross method are accurate and reliable.\n",
            "2.  **Conservation of Mass:** Flow continuity ensures that the principle of conservation of mass is satisfied, which is a fundamental principle in physics and engineering.\n",
            "3.  **Stable Network Operation:** Flow continuity helps to ensure that the network operates stably and efficiently, with no excessive pressure drops or flow surges.\n",
            "\n",
            "In summary, flow corrections are applied around each loop in the Hardy Cross method to satisfy the continuity equation at each junction. Maintaining flow continuity at every junction is essential for accurate flow calculations, conservation of mass, and stable network operation.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider how well the predicted response addresses the user's question about the application of flow corrections in the Hardy Cross method and the importance of maintaining flow continuity at junctions.\n",
            "\n",
            "The predicted answer provides a detailed step-by-step explanation of how flow corrections are applied around each loop, including the selection of loops, calculation of head loss, net flow, flow correction, and application of that correction. This aligns well with the actual answer, which also describes the iterative process of correcting flow in loops to achieve zero head-loss error.\n",
            "\n",
            "Furthermore, the predicted answer explains the necessity of maintaining flow continuity at every junction, emphasizing the conservation of mass and the implications for accurate flow calculations and stable network operation. This is consistent with the actual answer's reasoning.\n",
            "\n",
            "However, while the predicted answer is comprehensive, it includes some additional details about equations (like the Darcy-Weisbach and Hazen-Williams equations) that, while relevant, may not be strictly necessary for answering the question directly. This could be seen as slightly deviating from the core focus of the question.\n",
            "\n",
            "Overall, the predicted answer is relevant and informative, but it contains more information than strictly necessary, which could detract from its overall relevance.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: conciseness_descr\n",
            "\u001b[32mUser message:Question: How are flow corrections applied around each loop in the Hardy Cross method, and why must flow continuity be maintained at every junction?, Actual answer: In the Hardy Cross method, one first selects individual loops in the network and makes an initial guess of the flow in each pipe. Then, each loop is corrected iteratively: the head loss around the loop is summed, and a flow correction is applied to reduce the total head-loss error to zero. This correction is added (or subtracted) to the assumed flow in every pipe forming that loop. Flow continuity must be maintained at every junction to ensure that all flow entering a node is accounted for by either leaving through connecting pipes or satisfying demand. If continuity is not enforced, the model would not reflect true network behavior, causing errors to propagate in subsequent iterations., Predicted answer: In the Hardy Cross method, flow corrections are applied around each loop to satisfy the continuity equation at each junction. Here's a step-by-step explanation of how flow corrections are applied and why flow continuity must be maintained at every junction:\n",
            "\n",
            "**Flow Corrections around a Loop:**\n",
            "\n",
            "1.  **Select a Loop:** Choose a loop in the network, which is a path that starts and ends at the same node (junction).\n",
            "2.  **Calculate the Net Head Loss:** Calculate the net head loss (ΔH) for the loop by summing the head losses (h\\_f) for each pipe in the loop. The head loss for each pipe can be calculated using the Darcy-Weisbach equation or the Hazen-Williams equation.\n",
            "3.  **Calculate the Net Flow:** Calculate the net flow (Q\\_net) for the loop by summing the flows (Q) for each pipe in the loop. The flow for each pipe can be calculated using the Manning equation or the Darcy-Weisbach equation.\n",
            "4.  **Calculate the Flow Correction:** Calculate the flow correction (ΔQ) for the loop by dividing the net head loss (ΔH) by the net flow (Q\\_net). The flow correction represents the change in flow that is needed to balance the loop.\n",
            "5.  **Apply the Flow Correction:** Apply the flow correction (ΔQ) to each pipe in the loop by adding or subtracting the correction from the original flow (Q) for each pipe.\n",
            "\n",
            "**Maintaining Flow Continuity at Every Junction:**\n",
            "\n",
            "Flow continuity must be maintained at every junction because the sum of the flows entering a junction must equal the sum of the flows leaving the junction. This is based on the principle of conservation of mass, which states that mass cannot be created or destroyed in a closed system.\n",
            "\n",
            "In the Hardy Cross method, flow continuity is maintained at every junction by ensuring that the sum of the flows entering a junction equals the sum of the flows leaving the junction. This is achieved by applying flow corrections around each loop in the network, as described above.\n",
            "\n",
            "**Why Flow Continuity is Important:**\n",
            "\n",
            "Maintaining flow continuity at every junction is essential for several reasons:\n",
            "\n",
            "1.  **Accurate Flow Calculations:** Flow continuity ensures that the flows calculated using the Hardy Cross method are accurate and reliable.\n",
            "2.  **Conservation of Mass:** Flow continuity ensures that the principle of conservation of mass is satisfied, which is a fundamental principle in physics and engineering.\n",
            "3.  **Stable Network Operation:** Flow continuity helps to ensure that the network operates stably and efficiently, with no excessive pressure drops or flow surges.\n",
            "\n",
            "In summary, flow corrections are applied around each loop in the Hardy Cross method to satisfy the continuity equation at each junction. Maintaining flow continuity at every junction is essential for accurate flow calculations, conservation of mass, and stable network operation.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the conciseness of the predicted answer compared to the actual answer, we need to consider the amount of extra information provided in the predicted response. \n",
            "\n",
            "The actual answer succinctly explains the process of applying flow corrections in the Hardy Cross method and emphasizes the importance of maintaining flow continuity at junctions. It does this without unnecessary elaboration, focusing on the essential points.\n",
            "\n",
            "In contrast, the predicted answer provides a detailed step-by-step breakdown of the flow correction process, including specific equations and additional explanations about the importance of flow continuity. While this information is relevant, it introduces a significant amount of extra detail that may not be necessary for a concise response to the original question.\n",
            "\n",
            "The predicted answer could be considered verbose due to its extensive elaboration on each step and the inclusion of multiple reasons for maintaining flow continuity, which could have been summarized more effectively.\n",
            "\n",
            "Given these observations, I would assign the predicted response a score of 3, as it includes a lot of extra information and uses flowery language, making it less concise than the actual answer.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3}\n",
            "\n",
            "\n",
            "Evaluating based on: confidence_descr\n",
            "\u001b[32mUser message:Question: How are flow corrections applied around each loop in the Hardy Cross method, and why must flow continuity be maintained at every junction?, Actual answer: In the Hardy Cross method, one first selects individual loops in the network and makes an initial guess of the flow in each pipe. Then, each loop is corrected iteratively: the head loss around the loop is summed, and a flow correction is applied to reduce the total head-loss error to zero. This correction is added (or subtracted) to the assumed flow in every pipe forming that loop. Flow continuity must be maintained at every junction to ensure that all flow entering a node is accounted for by either leaving through connecting pipes or satisfying demand. If continuity is not enforced, the model would not reflect true network behavior, causing errors to propagate in subsequent iterations., Predicted answer: In the Hardy Cross method, flow corrections are applied around each loop to satisfy the continuity equation at each junction. Here's a step-by-step explanation of how flow corrections are applied and why flow continuity must be maintained at every junction:\n",
            "\n",
            "**Flow Corrections around a Loop:**\n",
            "\n",
            "1.  **Select a Loop:** Choose a loop in the network, which is a path that starts and ends at the same node (junction).\n",
            "2.  **Calculate the Net Head Loss:** Calculate the net head loss (ΔH) for the loop by summing the head losses (h\\_f) for each pipe in the loop. The head loss for each pipe can be calculated using the Darcy-Weisbach equation or the Hazen-Williams equation.\n",
            "3.  **Calculate the Net Flow:** Calculate the net flow (Q\\_net) for the loop by summing the flows (Q) for each pipe in the loop. The flow for each pipe can be calculated using the Manning equation or the Darcy-Weisbach equation.\n",
            "4.  **Calculate the Flow Correction:** Calculate the flow correction (ΔQ) for the loop by dividing the net head loss (ΔH) by the net flow (Q\\_net). The flow correction represents the change in flow that is needed to balance the loop.\n",
            "5.  **Apply the Flow Correction:** Apply the flow correction (ΔQ) to each pipe in the loop by adding or subtracting the correction from the original flow (Q) for each pipe.\n",
            "\n",
            "**Maintaining Flow Continuity at Every Junction:**\n",
            "\n",
            "Flow continuity must be maintained at every junction because the sum of the flows entering a junction must equal the sum of the flows leaving the junction. This is based on the principle of conservation of mass, which states that mass cannot be created or destroyed in a closed system.\n",
            "\n",
            "In the Hardy Cross method, flow continuity is maintained at every junction by ensuring that the sum of the flows entering a junction equals the sum of the flows leaving the junction. This is achieved by applying flow corrections around each loop in the network, as described above.\n",
            "\n",
            "**Why Flow Continuity is Important:**\n",
            "\n",
            "Maintaining flow continuity at every junction is essential for several reasons:\n",
            "\n",
            "1.  **Accurate Flow Calculations:** Flow continuity ensures that the flows calculated using the Hardy Cross method are accurate and reliable.\n",
            "2.  **Conservation of Mass:** Flow continuity ensures that the principle of conservation of mass is satisfied, which is a fundamental principle in physics and engineering.\n",
            "3.  **Stable Network Operation:** Flow continuity helps to ensure that the network operates stably and efficiently, with no excessive pressure drops or flow surges.\n",
            "\n",
            "In summary, flow corrections are applied around each loop in the Hardy Cross method to satisfy the continuity equation at each junction. Maintaining flow continuity at every junction is essential for accurate flow calculations, conservation of mass, and stable network operation.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the clarity, completeness, and confidence conveyed in both responses. \n",
            "\n",
            "The actual answer provides a concise overview of the Hardy Cross method, detailing the iterative process of applying flow corrections around loops and emphasizing the importance of maintaining flow continuity at junctions. It effectively explains the rationale behind these processes, linking them to the behavior of the network and potential errors that could arise if continuity is not enforced.\n",
            "\n",
            "The predicted answer, while also detailed and structured, introduces additional steps and equations that may not be necessary for a general understanding of the Hardy Cross method. It explains the process of selecting a loop, calculating head loss, net flow, and flow corrections in a step-by-step manner. However, it does not clearly convey the iterative nature of the corrections or the potential consequences of failing to maintain flow continuity as effectively as the actual answer does.\n",
            "\n",
            "In terms of confidence, the predicted answer does provide a systematic approach and appears confident in its explanation. However, it lacks the same level of assurance and succinctness found in the actual answer, which directly addresses the importance of flow continuity and its implications for network behavior.\n",
            "\n",
            "Given these considerations, I would assign the predicted answer a score of 4, indicating moderate agreement with the actual answer but acknowledging some uncertainty due to its complexity and less direct articulation of key points.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: factuality_descr\n",
            "\u001b[32mUser message:Question: How are flow corrections applied around each loop in the Hardy Cross method, and why must flow continuity be maintained at every junction?, Actual answer: In the Hardy Cross method, one first selects individual loops in the network and makes an initial guess of the flow in each pipe. Then, each loop is corrected iteratively: the head loss around the loop is summed, and a flow correction is applied to reduce the total head-loss error to zero. This correction is added (or subtracted) to the assumed flow in every pipe forming that loop. Flow continuity must be maintained at every junction to ensure that all flow entering a node is accounted for by either leaving through connecting pipes or satisfying demand. If continuity is not enforced, the model would not reflect true network behavior, causing errors to propagate in subsequent iterations., Predicted answer: In the Hardy Cross method, flow corrections are applied around each loop to satisfy the continuity equation at each junction. Here's a step-by-step explanation of how flow corrections are applied and why flow continuity must be maintained at every junction:\n",
            "\n",
            "**Flow Corrections around a Loop:**\n",
            "\n",
            "1.  **Select a Loop:** Choose a loop in the network, which is a path that starts and ends at the same node (junction).\n",
            "2.  **Calculate the Net Head Loss:** Calculate the net head loss (ΔH) for the loop by summing the head losses (h\\_f) for each pipe in the loop. The head loss for each pipe can be calculated using the Darcy-Weisbach equation or the Hazen-Williams equation.\n",
            "3.  **Calculate the Net Flow:** Calculate the net flow (Q\\_net) for the loop by summing the flows (Q) for each pipe in the loop. The flow for each pipe can be calculated using the Manning equation or the Darcy-Weisbach equation.\n",
            "4.  **Calculate the Flow Correction:** Calculate the flow correction (ΔQ) for the loop by dividing the net head loss (ΔH) by the net flow (Q\\_net). The flow correction represents the change in flow that is needed to balance the loop.\n",
            "5.  **Apply the Flow Correction:** Apply the flow correction (ΔQ) to each pipe in the loop by adding or subtracting the correction from the original flow (Q) for each pipe.\n",
            "\n",
            "**Maintaining Flow Continuity at Every Junction:**\n",
            "\n",
            "Flow continuity must be maintained at every junction because the sum of the flows entering a junction must equal the sum of the flows leaving the junction. This is based on the principle of conservation of mass, which states that mass cannot be created or destroyed in a closed system.\n",
            "\n",
            "In the Hardy Cross method, flow continuity is maintained at every junction by ensuring that the sum of the flows entering a junction equals the sum of the flows leaving the junction. This is achieved by applying flow corrections around each loop in the network, as described above.\n",
            "\n",
            "**Why Flow Continuity is Important:**\n",
            "\n",
            "Maintaining flow continuity at every junction is essential for several reasons:\n",
            "\n",
            "1.  **Accurate Flow Calculations:** Flow continuity ensures that the flows calculated using the Hardy Cross method are accurate and reliable.\n",
            "2.  **Conservation of Mass:** Flow continuity ensures that the principle of conservation of mass is satisfied, which is a fundamental principle in physics and engineering.\n",
            "3.  **Stable Network Operation:** Flow continuity helps to ensure that the network operates stably and efficiently, with no excessive pressure drops or flow surges.\n",
            "\n",
            "In summary, flow corrections are applied around each loop in the Hardy Cross method to satisfy the continuity equation at each junction. Maintaining flow continuity at every junction is essential for accurate flow calculations, conservation of mass, and stable network operation.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to assess the factual accuracy and completeness of the information provided in both responses. \n",
            "\n",
            "The actual answer describes the Hardy Cross method accurately, detailing the iterative process of selecting loops, calculating head loss, and applying flow corrections. It emphasizes the importance of maintaining flow continuity at junctions to reflect true network behavior and prevent errors in subsequent iterations.\n",
            "\n",
            "The predicted answer also provides a detailed step-by-step explanation of how flow corrections are applied around each loop, including the selection of loops, calculation of head loss, net flow, flow correction, and application of the correction. It correctly states the necessity of maintaining flow continuity at junctions and explains the reasons for this requirement, such as accurate flow calculations and conservation of mass.\n",
            "\n",
            "However, the predicted answer introduces some unnecessary complexity by mentioning specific equations (Darcy-Weisbach, Hazen-Williams, and Manning) without clearly linking them to the context of the Hardy Cross method. While these equations are relevant in fluid mechanics, their inclusion may distract from the core explanation of the Hardy Cross method itself.\n",
            "\n",
            "Overall, the predicted answer contains mostly factual information with slight deviations in focus and unnecessary details. It does not fundamentally misrepresent the Hardy Cross method or the importance of flow continuity.\n",
            "\n",
            "Given this analysis, I would assign the predicted answer a score of 4, as it includes mostly factual information with slight hallucinations in terms of relevance and clarity.\n",
            "\n",
            "FINAL SCORE: 4\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4}\n",
            "\n",
            "\n",
            "Evaluating based on: judgement_descr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [17:05, 31.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mUser message:Question: How are flow corrections applied around each loop in the Hardy Cross method, and why must flow continuity be maintained at every junction?, Actual answer: In the Hardy Cross method, one first selects individual loops in the network and makes an initial guess of the flow in each pipe. Then, each loop is corrected iteratively: the head loss around the loop is summed, and a flow correction is applied to reduce the total head-loss error to zero. This correction is added (or subtracted) to the assumed flow in every pipe forming that loop. Flow continuity must be maintained at every junction to ensure that all flow entering a node is accounted for by either leaving through connecting pipes or satisfying demand. If continuity is not enforced, the model would not reflect true network behavior, causing errors to propagate in subsequent iterations., Predicted answer: In the Hardy Cross method, flow corrections are applied around each loop to satisfy the continuity equation at each junction. Here's a step-by-step explanation of how flow corrections are applied and why flow continuity must be maintained at every junction:\n",
            "\n",
            "**Flow Corrections around a Loop:**\n",
            "\n",
            "1.  **Select a Loop:** Choose a loop in the network, which is a path that starts and ends at the same node (junction).\n",
            "2.  **Calculate the Net Head Loss:** Calculate the net head loss (ΔH) for the loop by summing the head losses (h\\_f) for each pipe in the loop. The head loss for each pipe can be calculated using the Darcy-Weisbach equation or the Hazen-Williams equation.\n",
            "3.  **Calculate the Net Flow:** Calculate the net flow (Q\\_net) for the loop by summing the flows (Q) for each pipe in the loop. The flow for each pipe can be calculated using the Manning equation or the Darcy-Weisbach equation.\n",
            "4.  **Calculate the Flow Correction:** Calculate the flow correction (ΔQ) for the loop by dividing the net head loss (ΔH) by the net flow (Q\\_net). The flow correction represents the change in flow that is needed to balance the loop.\n",
            "5.  **Apply the Flow Correction:** Apply the flow correction (ΔQ) to each pipe in the loop by adding or subtracting the correction from the original flow (Q) for each pipe.\n",
            "\n",
            "**Maintaining Flow Continuity at Every Junction:**\n",
            "\n",
            "Flow continuity must be maintained at every junction because the sum of the flows entering a junction must equal the sum of the flows leaving the junction. This is based on the principle of conservation of mass, which states that mass cannot be created or destroyed in a closed system.\n",
            "\n",
            "In the Hardy Cross method, flow continuity is maintained at every junction by ensuring that the sum of the flows entering a junction equals the sum of the flows leaving the junction. This is achieved by applying flow corrections around each loop in the network, as described above.\n",
            "\n",
            "**Why Flow Continuity is Important:**\n",
            "\n",
            "Maintaining flow continuity at every junction is essential for several reasons:\n",
            "\n",
            "1.  **Accurate Flow Calculations:** Flow continuity ensures that the flows calculated using the Hardy Cross method are accurate and reliable.\n",
            "2.  **Conservation of Mass:** Flow continuity ensures that the principle of conservation of mass is satisfied, which is a fundamental principle in physics and engineering.\n",
            "3.  **Stable Network Operation:** Flow continuity helps to ensure that the network operates stably and efficiently, with no excessive pressure drops or flow surges.\n",
            "\n",
            "In summary, flow corrections are applied around each loop in the Hardy Cross method to satisfy the continuity equation at each junction. Maintaining flow continuity at every junction is essential for accurate flow calculations, conservation of mass, and stable network operation.\u001b[0m\n",
            "\u001b[31mAI message:To evaluate the predicted answer against the actual answer, we need to consider the accuracy and clarity of the information presented in both responses. \n",
            "\n",
            "The actual answer provides a concise overview of the Hardy Cross method, detailing the iterative process of applying flow corrections around loops and emphasizing the importance of maintaining flow continuity at junctions. It correctly identifies the need for flow corrections to ensure that the total head-loss error is reduced to zero and explains the implications of not maintaining flow continuity.\n",
            "\n",
            "The predicted answer, while lengthy and detailed, does contain some inaccuracies and misinterpretations. For instance, it suggests that the flow correction is calculated by dividing the net head loss by the net flow, which is not a standard approach in the Hardy Cross method. The flow correction is typically based on the head loss and the flow in the loop, but the method of calculation as described in the predicted answer is misleading. Additionally, while it correctly states the importance of flow continuity, it does not clearly articulate how the corrections are applied in relation to the head loss and flow in the loop.\n",
            "\n",
            "Overall, the predicted answer shows a lack of clarity and introduces potential confusion regarding the calculation of flow corrections. It does not confidently assert a correct understanding of the Hardy Cross method, nor does it fully align with the actual answer's explanation.\n",
            "\n",
            "Given these considerations, I would assign the predicted answer a score of 3, as it shows uncertainty and misinterpretation of the information, but does attempt to explain the process.\n",
            "\n",
            "FINAL SCORE: 3\u001b[0m\n",
            "Scores: {'completeness_descr': 4, 'relevance_descr': 4, 'conciseness_descr': 3, 'confidence_descr': 4, 'factuality_descr': 4, 'judgement_descr': 3}\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [18:06, 32.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time for evaluation: 1089.2825152873993\n",
            "Error: No metric value found!\n",
            "result['run'].outputs['output'] is None True\n",
            "not result['evaluation_results']['results'] False\n",
            "Error: No metric value found!\n",
            "result['run'].outputs['output'] is None True\n",
            "not result['evaluation_results']['results'] False\n",
            "Error: No metric value found!\n",
            "result['run'].outputs['output'] is None True\n",
            "not result['evaluation_results']['results'] False\n",
            "Error: No metric value found!\n",
            "result['run'].outputs['output'] is None True\n",
            "not result['evaluation_results']['results'] False\n",
            "Error: No metric value found!\n",
            "result['run'].outputs['output'] is None True\n",
            "not result['evaluation_results']['results'] False\n",
            "Error: No metric value found!\n",
            "result['run'].outputs['output'] is None True\n",
            "not result['evaluation_results']['results'] False\n",
            "Error: No metric value found!\n",
            "result['run'].outputs['output'] is None True\n",
            "not result['evaluation_results']['results'] False\n",
            "Error: No metric value found!\n",
            "result['run'].outputs['output'] is None True\n",
            "not result['evaluation_results']['results'] False\n",
            "\u001b[31mMissing value for metric 'completeness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What are the trade-offs of using DMAs in water distribution networks?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'completeness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What is compartmentalization in water distribution networks, and how does it differ from skeletonization?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'completeness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What are the main techniques for skeletonizing a water distribution network?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'completeness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Why is the starting solution less critical in gradient-based solvers than in loop-based methods, and how do some solvers use zero-flow initial guesses?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'completeness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: In which ways can the sequential loop-balancing nature of Hardy Cross become a bottleneck as networks grow in size and complexity?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'completeness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Which algorithm does EPANET use for analyzing steady-state flows, and what makes it widely regarded as a robust and efficient solver?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'completeness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: In Newton-Raphson frameworks, how does solving for node heads all at once differ from solving for loop flow corrections all at once?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'completeness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Which factors influence the choice of initial flow guesses in the Hardy Cross approach, and how can poor choices affect convergence?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'relevance' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What are the trade-offs of using DMAs in water distribution networks?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'relevance' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What is compartmentalization in water distribution networks, and how does it differ from skeletonization?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'relevance' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What are the main techniques for skeletonizing a water distribution network?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'relevance' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Why is the starting solution less critical in gradient-based solvers than in loop-based methods, and how do some solvers use zero-flow initial guesses?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'relevance' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: In which ways can the sequential loop-balancing nature of Hardy Cross become a bottleneck as networks grow in size and complexity?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'relevance' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Which algorithm does EPANET use for analyzing steady-state flows, and what makes it widely regarded as a robust and efficient solver?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'relevance' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: In Newton-Raphson frameworks, how does solving for node heads all at once differ from solving for loop flow corrections all at once?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'relevance' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Which factors influence the choice of initial flow guesses in the Hardy Cross approach, and how can poor choices affect convergence?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'conciseness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What are the trade-offs of using DMAs in water distribution networks?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'conciseness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What is compartmentalization in water distribution networks, and how does it differ from skeletonization?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'conciseness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What are the main techniques for skeletonizing a water distribution network?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'conciseness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Why is the starting solution less critical in gradient-based solvers than in loop-based methods, and how do some solvers use zero-flow initial guesses?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'conciseness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: In which ways can the sequential loop-balancing nature of Hardy Cross become a bottleneck as networks grow in size and complexity?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'conciseness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Which algorithm does EPANET use for analyzing steady-state flows, and what makes it widely regarded as a robust and efficient solver?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'conciseness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: In Newton-Raphson frameworks, how does solving for node heads all at once differ from solving for loop flow corrections all at once?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'conciseness' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Which factors influence the choice of initial flow guesses in the Hardy Cross approach, and how can poor choices affect convergence?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'confidence' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What are the trade-offs of using DMAs in water distribution networks?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'confidence' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What is compartmentalization in water distribution networks, and how does it differ from skeletonization?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'confidence' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What are the main techniques for skeletonizing a water distribution network?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'confidence' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Why is the starting solution less critical in gradient-based solvers than in loop-based methods, and how do some solvers use zero-flow initial guesses?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'confidence' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: In which ways can the sequential loop-balancing nature of Hardy Cross become a bottleneck as networks grow in size and complexity?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'confidence' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Which algorithm does EPANET use for analyzing steady-state flows, and what makes it widely regarded as a robust and efficient solver?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'confidence' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: In Newton-Raphson frameworks, how does solving for node heads all at once differ from solving for loop flow corrections all at once?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'confidence' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Which factors influence the choice of initial flow guesses in the Hardy Cross approach, and how can poor choices affect convergence?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'factuality' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What are the trade-offs of using DMAs in water distribution networks?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'factuality' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What is compartmentalization in water distribution networks, and how does it differ from skeletonization?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'factuality' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What are the main techniques for skeletonizing a water distribution network?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'factuality' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Why is the starting solution less critical in gradient-based solvers than in loop-based methods, and how do some solvers use zero-flow initial guesses?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'factuality' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: In which ways can the sequential loop-balancing nature of Hardy Cross become a bottleneck as networks grow in size and complexity?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'factuality' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Which algorithm does EPANET use for analyzing steady-state flows, and what makes it widely regarded as a robust and efficient solver?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'factuality' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: In Newton-Raphson frameworks, how does solving for node heads all at once differ from solving for loop flow corrections all at once?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'factuality' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Which factors influence the choice of initial flow guesses in the Hardy Cross approach, and how can poor choices affect convergence?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'judgement' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What are the trade-offs of using DMAs in water distribution networks?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'judgement' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What is compartmentalization in water distribution networks, and how does it differ from skeletonization?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'judgement' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: What are the main techniques for skeletonizing a water distribution network?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'judgement' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Why is the starting solution less critical in gradient-based solvers than in loop-based methods, and how do some solvers use zero-flow initial guesses?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'judgement' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: In which ways can the sequential loop-balancing nature of Hardy Cross become a bottleneck as networks grow in size and complexity?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'judgement' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Which algorithm does EPANET use for analyzing steady-state flows, and what makes it widely regarded as a robust and efficient solver?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'judgement' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: In Newton-Raphson frameworks, how does solving for node heads all at once differ from solving for loop flow corrections all at once?\u001b[0m\n",
            "\u001b[31mMissing value for metric 'judgement' in resample 1\u001b[0m\n",
            "\u001b[32mQuestion: Which factors influence the choice of initial flow guesses in the Hardy Cross approach, and how can poor choices affect convergence?\u001b[0m\n",
            "\u001b[31mERROR: Found missing values in 8 rows out of 33\u001b[0m\n",
            "\u001b[33m0 value in row 2, column metric_completeness_1 should be replaced with mean 4.04\u001b[0m\n",
            "\u001b[33m0 value in row 4, column metric_completeness_1 should be replaced with mean 4.04\u001b[0m\n",
            "\u001b[33m0 value in row 11, column metric_completeness_1 should be replaced with mean 4.04\u001b[0m\n",
            "\u001b[33m0 value in row 17, column metric_completeness_1 should be replaced with mean 4.04\u001b[0m\n",
            "\u001b[33m0 value in row 21, column metric_completeness_1 should be replaced with mean 4.04\u001b[0m\n",
            "\u001b[33m0 value in row 23, column metric_completeness_1 should be replaced with mean 4.04\u001b[0m\n",
            "\u001b[33m0 value in row 28, column metric_completeness_1 should be replaced with mean 4.04\u001b[0m\n",
            "\u001b[33m0 value in row 31, column metric_completeness_1 should be replaced with mean 4.04\u001b[0m\n",
            "\u001b[33m0 value in row 2, column metric_relevance_1 should be replaced with mean 3.32\u001b[0m\n",
            "\u001b[33m0 value in row 4, column metric_relevance_1 should be replaced with mean 3.32\u001b[0m\n",
            "\u001b[33m0 value in row 11, column metric_relevance_1 should be replaced with mean 3.32\u001b[0m\n",
            "\u001b[33m0 value in row 17, column metric_relevance_1 should be replaced with mean 3.32\u001b[0m\n",
            "\u001b[33m0 value in row 21, column metric_relevance_1 should be replaced with mean 3.32\u001b[0m\n",
            "\u001b[33m0 value in row 23, column metric_relevance_1 should be replaced with mean 3.32\u001b[0m\n",
            "\u001b[33m0 value in row 28, column metric_relevance_1 should be replaced with mean 3.32\u001b[0m\n",
            "\u001b[33m0 value in row 31, column metric_relevance_1 should be replaced with mean 3.32\u001b[0m\n",
            "\u001b[33m0 value in row 2, column metric_conciseness_1 should be replaced with mean 2.96\u001b[0m\n",
            "\u001b[33m0 value in row 4, column metric_conciseness_1 should be replaced with mean 2.96\u001b[0m\n",
            "\u001b[33m0 value in row 11, column metric_conciseness_1 should be replaced with mean 2.96\u001b[0m\n",
            "\u001b[33m0 value in row 17, column metric_conciseness_1 should be replaced with mean 2.96\u001b[0m\n",
            "\u001b[33m0 value in row 21, column metric_conciseness_1 should be replaced with mean 2.96\u001b[0m\n",
            "\u001b[33m0 value in row 23, column metric_conciseness_1 should be replaced with mean 2.96\u001b[0m\n",
            "\u001b[33m0 value in row 28, column metric_conciseness_1 should be replaced with mean 2.96\u001b[0m\n",
            "\u001b[33m0 value in row 31, column metric_conciseness_1 should be replaced with mean 2.96\u001b[0m\n",
            "\u001b[33m0 value in row 2, column metric_confidence_1 should be replaced with mean 3.76\u001b[0m\n",
            "\u001b[33m0 value in row 4, column metric_confidence_1 should be replaced with mean 3.76\u001b[0m\n",
            "\u001b[33m0 value in row 11, column metric_confidence_1 should be replaced with mean 3.76\u001b[0m\n",
            "\u001b[33m0 value in row 17, column metric_confidence_1 should be replaced with mean 3.76\u001b[0m\n",
            "\u001b[33m0 value in row 21, column metric_confidence_1 should be replaced with mean 3.76\u001b[0m\n",
            "\u001b[33m0 value in row 23, column metric_confidence_1 should be replaced with mean 3.76\u001b[0m\n",
            "\u001b[33m0 value in row 28, column metric_confidence_1 should be replaced with mean 3.76\u001b[0m\n",
            "\u001b[33m0 value in row 31, column metric_confidence_1 should be replaced with mean 3.76\u001b[0m\n",
            "\u001b[33m0 value in row 2, column metric_factuality_1 should be replaced with mean 3.68\u001b[0m\n",
            "\u001b[33m0 value in row 4, column metric_factuality_1 should be replaced with mean 3.68\u001b[0m\n",
            "\u001b[33m0 value in row 11, column metric_factuality_1 should be replaced with mean 3.68\u001b[0m\n",
            "\u001b[33m0 value in row 17, column metric_factuality_1 should be replaced with mean 3.68\u001b[0m\n",
            "\u001b[33m0 value in row 21, column metric_factuality_1 should be replaced with mean 3.68\u001b[0m\n",
            "\u001b[33m0 value in row 23, column metric_factuality_1 should be replaced with mean 3.68\u001b[0m\n",
            "\u001b[33m0 value in row 28, column metric_factuality_1 should be replaced with mean 3.68\u001b[0m\n",
            "\u001b[33m0 value in row 31, column metric_factuality_1 should be replaced with mean 3.68\u001b[0m\n",
            "\u001b[33m0 value in row 2, column metric_judgement_1 should be replaced with mean 3.56\u001b[0m\n",
            "\u001b[33m0 value in row 4, column metric_judgement_1 should be replaced with mean 3.56\u001b[0m\n",
            "\u001b[33m0 value in row 11, column metric_judgement_1 should be replaced with mean 3.56\u001b[0m\n",
            "\u001b[33m0 value in row 17, column metric_judgement_1 should be replaced with mean 3.56\u001b[0m\n",
            "\u001b[33m0 value in row 21, column metric_judgement_1 should be replaced with mean 3.56\u001b[0m\n",
            "\u001b[33m0 value in row 23, column metric_judgement_1 should be replaced with mean 3.56\u001b[0m\n",
            "\u001b[33m0 value in row 28, column metric_judgement_1 should be replaced with mean 3.56\u001b[0m\n",
            "\u001b[33m0 value in row 31, column metric_judgement_1 should be replaced with mean 3.56\u001b[0m\n",
            "\n",
            "Zero values replaced per row:\n",
            "Row/question 2: 6 replacements\n",
            "Row/question 4: 6 replacements\n",
            "Row/question 11: 6 replacements\n",
            "Row/question 17: 6 replacements\n",
            "Row/question 21: 6 replacements\n",
            "Row/question 23: 6 replacements\n",
            "Row/question 28: 6 replacements\n",
            "Row/question 31: 6 replacements\n",
            "\n",
            "Zero values replaced per column:\n",
            "Column/metric metric_completeness_1: 8 replacements\n",
            "Column/metric metric_conciseness_1: 8 replacements\n",
            "Column/metric metric_confidence_1: 8 replacements\n",
            "Column/metric metric_factuality_1: 8 replacements\n",
            "Column/metric metric_judgement_1: 8 replacements\n",
            "Column/metric metric_relevance_1: 8 replacements\n",
            "\n",
            "Summary Statistics over run 0:\n",
            "--------------------------------------------------\n",
            "completeness:\n",
            "  mean: 3.06\n",
            "  std_error: 0.32\n",
            "  ci_low: 2.43\n",
            "  ci_high: 3.69\n",
            "--------------------------------------------------\n",
            "relevance:\n",
            "  mean: 2.52\n",
            "  std_error: 0.28\n",
            "  ci_low: 1.97\n",
            "  ci_high: 3.06\n",
            "--------------------------------------------------\n",
            "conciseness:\n",
            "  mean: 2.24\n",
            "  std_error: 0.23\n",
            "  ci_low: 1.80\n",
            "  ci_high: 2.69\n",
            "--------------------------------------------------\n",
            "confidence:\n",
            "  mean: 2.85\n",
            "  std_error: 0.31\n",
            "  ci_low: 2.23\n",
            "  ci_high: 3.46\n",
            "--------------------------------------------------\n",
            "factuality:\n",
            "  mean: 2.79\n",
            "  std_error: 0.29\n",
            "  ci_low: 2.21\n",
            "  ci_high: 3.36\n",
            "--------------------------------------------------\n",
            "judgement:\n",
            "  mean: 2.70\n",
            "  std_error: 0.31\n",
            "  ci_low: 2.09\n",
            "  ci_high: 3.30\n",
            "--------------------------------------------------\n",
            "Model meta-llama/Meta-Llama-3.1-8B-Instruct saved\n",
            "Models saved so far: ['meta-llama/Meta-Llama-3.1-8B-Instruct']\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Main execution loop (move code below inside this function)\n",
        "# def main():\n",
        "all_models_stats, all_runs_model_metrics = load_model_stats(judge_model) #Try to load already saved data (if some models have already been evaluated), otherwise initialize empty dicts\n",
        "\n",
        "for model_id in models:\n",
        "    global model_name, model, tokenizer, pipeline, generate_max_tokens\n",
        "    model, tokenizer, pipeline = get_model(model_id)\n",
        "    model_name = model_id #Since model_name defined as global variable\n",
        "    \n",
        "    try: #Sometimes some errors with the evaluation\n",
        "        evaluation_all_resamples, dataset_langsmith = perform_evaluation(model_id, judge_model, n_resamples, example_inputs, factor_evaluator, langsmith_api_key)\n",
        "        chunk_size = len(example_inputs) #Number of questions\n",
        "        results_df, list_of_questions = process_evaluation_results(langsmith_api_key, dataset_langsmith)\n",
        "        \n",
        "        all_resamples_metrics = [] #Keep track of all metrics over all resamples and all questions\n",
        "        #There will be n_resamples lists, each with num_questions sublists (each having num_metrics sublists) (so num_questions*num_metrics elements in those in total)\n",
        "        #Each question will have 6 metric values like this: [EvaluationResult(key='completeness', score=4, value='To evaluate the ....\n",
        "        all_runs_metric_scores = [] #This will be appended to the input that plots metrics at the end. \n",
        "        #The format of it is [{metric1_descr_run1: [q1_score, q2_score, ...], metric2_descr_run1: [q1_score, q2_score, ...], ...}, \n",
        "        #                     {metric1_descr_run2: [q1_score, q2_score, ...], metric2_descr_run2: [q1_score, q2_score, ...], ...},\n",
        "        #                     ...num_runs]\n",
        "        \n",
        "        # Process each resample\n",
        "        for resample_idx in range(n_resamples):\n",
        "            start_idx = resample_idx * chunk_size #start index of current resample (chunk size is the number of questions of each resample)\n",
        "            #Resample_results saved above in the process_metrics function\n",
        "            resample_results = evaluation_all_resamples[start_idx:start_idx + chunk_size] #Get results of a particular resample\n",
        "            assert len(resample_results)==chunk_size, f\"Number of resample results not matching num_questions. Got {len(resample_results)} resample results but expected {chunk_size}\"\n",
        "\n",
        "            predicted_answers = [x['run'].outputs['output'] for x in resample_results] #None if error\n",
        "            assert len(predicted_answers)==chunk_size, f\"Number of predicted answers not matching num_questions. Got {len(predicted_answers)} predicted answers but expected {chunk_size}\"\n",
        "\n",
        "            # with open('predicted_answers_'+str(resample_idx)+'_'+str(model_name.split('/')[1])+'.txt', 'w') as f:\n",
        "            #     f.write(str(predicted_answers))\n",
        "\n",
        "            #Add predicted answers to df\n",
        "            results_df[f'predicted_answer_{resample_idx+1}'] = predicted_answers\n",
        "\n",
        "            individual_run_metric_scores, metrics, results_df = process_metrics(\n",
        "                    resample_results, \n",
        "                    list_of_metrics, \n",
        "                    list_of_questions,\n",
        "                    resample_idx,\n",
        "                    results_df,\n",
        "                    model_name\n",
        "                )           \n",
        "\n",
        "            # Handle zero values\n",
        "            zero_rows_columns = handle_zero_values(results_df, n_resamples, list_of_metrics)\n",
        "            if zero_rows_columns:\n",
        "                unique_zero_rows_columns = len(set([x for sublist in list(zero_rows_columns.values()) for x in sublist]))\n",
        "                print(colored(f\"ERROR: Found missing values in {unique_zero_rows_columns} rows out of {len(results_df)}\", 'red'))\n",
        "                process_zero_values(results_df, zero_rows_columns, list_of_metrics, model_name) #Replace 0s with mean of non-zero values     \n",
        "            \n",
        "            #In each iteration we append the metrics (6 in total) of one resample for all questions - n at the end, one for each resample\n",
        "            #If there is an error, the metrics will be 0 (there will be n_errors*num_metrics less 'EvaluationResult' objects in that case)\n",
        "            all_resamples_metrics.append(metrics)\n",
        "\n",
        "            #Has n_resamples lists, each with num_metrics sublists (each sublist has scores over all questions of one metric) \n",
        "            all_runs_metric_scores.append(individual_run_metric_scores)\n",
        "        \n",
        "        assert len(all_runs_metric_scores)==n_resamples, f\"Number of all_runs_metric_scores not matching num_resamples. \\\n",
        "            Got {len(all_runs_metric_scores)} all_runs_metric_scores but expected {n_resamples}\"\n",
        "        \n",
        "        for i in range(n_resamples):\n",
        "            assert len(all_runs_metric_scores[i])==len(list_of_metrics), f\"Number of all_runs_metric_scores[{i}] not matching num_metrics. \\\n",
        "                Got {len(all_runs_metric_scores[i])} all_runs_metric_scores[{i}] but expected {len(list_of_metrics)}\"\n",
        "\n",
        "        with open('all_runs_metric_scores_main_'+str(model_name.split('/')[1])+'.txt', 'w') as f:\n",
        "            f.write(str(all_runs_metric_scores))\n",
        "\n",
        "        with open('all_resamples_metrics_main_'+str(model_name.split('/')[1])+'.txt', 'w') as f:\n",
        "            f.write(str(all_resamples_metrics))\n",
        "\n",
        "        assert len(all_resamples_metrics)==n_resamples, f\"Number of all_resamples_metrics not matching num_resamples. \\\n",
        "            Got {len(all_resamples_metrics)} all_resamples_metrics but expected {n_resamples}\"\n",
        "        \n",
        "        for i in range(n_resamples): #Each one will have num_questions elements, each with num_metrics sublists (or 0 if error)\n",
        "            assert len(all_resamples_metrics[i])==len(list_of_questions), f\"Number of all_resamples_metrics[{i}] not matching num_questions. \\\n",
        "                Got {len(all_resamples_metrics[i])} all_resamples_metrics[{i}] but expected {len(list_of_questions)}\" #Each all_ressamples_metrics[i] should have num_questions elements\n",
        "\n",
        "        # Calculate statistics\n",
        "        metric_stats_resampling = calculate_metric_statistics(\n",
        "            all_runs_metric_scores, \n",
        "            list_of_metrics, \n",
        "            len(list_of_questions),\n",
        "            model_name\n",
        "        )\n",
        "        \n",
        "        # Save initial results\n",
        "        save_results(results_df, judge_model, model_id, \"before\")\n",
        "        \n",
        "        # # Handle zero values\n",
        "        # zero_rows_columns = handle_zero_values(results_df, n_resamples, list_of_metrics)\n",
        "        # if zero_rows_columns:\n",
        "        #     unique_zero_rows_columns = len(set([x for sublist in list(zero_rows_columns.values()) for x in sublist]))\n",
        "        #     print(colored(f\"ERROR: Found missing values in {unique_zero_rows_columns} rows out of {len(results_df)}\", 'red'))\n",
        "        #     process_zero_values(results_df, zero_rows_columns, list_of_metrics, model_name) #Replace 0s with mean of non-zero values\n",
        "        \n",
        "        # Reorganize metrics - Has num_metrics keys, each with num_questions*num_resamples values (as a list)\n",
        "        metric_scores_all_resamples = reorganize_evaluation_metrics(all_resamples_metrics, list_of_metrics, model_name, list_of_questions, n_resamples)\n",
        "\n",
        "        with open('metric_scores_all_resamples_final_main_'+str(model_name.split('/')[1])+'.txt', 'w') as f:\n",
        "            f.write(str(metric_scores_all_resamples))\n",
        "\n",
        "        assert len(metric_scores_all_resamples)==len(list_of_metrics), f\"Number of metric_scores_all_resamples not matching num_metrics. \\\n",
        "            Got {len(metric_scores_all_resamples)} metric_scores_all_resamples but expected {len(list_of_metrics)}\"\n",
        "        \n",
        "        for i in range(len(list_of_metrics)):\n",
        "            name_of_metric=list_of_metrics[i].replace('_descr','')\n",
        "            assert len(metric_scores_all_resamples[name_of_metric])==len(list_of_questions)*n_resamples, f\"Number of metric_scores_all_resamples[{name_of_metric}] not matching \\\n",
        "                num_questions*num_resamples. Got {len(metric_scores_all_resamples[name_of_metric])} metric_scores_all_resamples[{name_of_metric}] but \\\n",
        "                expected {len(list_of_questions)*n_resamples}\"\n",
        "\n",
        "        metric_names = list(metric_scores_all_resamples.keys()) #Final list of metrics for plotting\n",
        "        \n",
        "        # Verify metric names\n",
        "        metrics_names_loop = [metric.replace('_descr','') for metric in list_of_metrics]\n",
        "        assert metrics_names_loop == metric_names, \"Metric names mismatch\"\n",
        "        \n",
        "        # Save results\n",
        "        all_runs_model_metrics[model_id] = all_runs_metric_scores #Used in plotting metrics\n",
        "        #Dictionary in format {model_id:[{metric_1_run_1:[values], metric_2_run_1:[values], ...}, {metric_1_run_2:[values]....}]\n",
        "\n",
        "        all_models_stats[model_id] = plot_figures_metrics(\n",
        "            all_runs_model_metrics,\n",
        "            metric_names,\n",
        "            model_id,\n",
        "            judge_model\n",
        "        ) #Stats like mean, std, etc. per metric and per run over all questions\n",
        "        \n",
        "        # Save to files\n",
        "        with open(f'stats_{judge_model.split(\"/\")[1]}.json', 'w') as f:\n",
        "            json.dump(all_models_stats, f, indent=4)\n",
        "        with open(f'all_runs_model_metrics_{judge_model.split(\"/\")[1]}.json', 'w') as f:\n",
        "            json.dump(all_runs_model_metrics, f, indent=4)\n",
        "\n",
        "        print(\"Model\",model_id,\"saved\")\n",
        "        print(\"Models saved so far:\",list(all_models_stats.keys()))\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(\"An error occurred in evaluating model\",model_id)\n",
        "        print(\"Error Details:\", e)\n",
        "        traceback.print_exc()\n",
        "    \n",
        "    finally:\n",
        "        # Clear VRAM\n",
        "        del model, tokenizer, pipeline\n",
        "        torch.cuda.empty_cache()\n",
        "        print('-'*100)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Statistical comparison between models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_model_performances(all_runs_model_metrics): #all_models_stats, \n",
        "    \"\"\"\n",
        "    Performs statistical comparison between models using paired differences, standard errors,\n",
        "    and Pearson correlation coefficients following section 4.2 methodology.\n",
        "    \n",
        "    Args:\n",
        "        all_models_stats (dict): Dictionary containing statistics for each model\n",
        "        all_runs_model_metrics (dict): Dictionary containing raw metrics for each model/run/question\n",
        "        \n",
        "    Returns:\n",
        "        dict: Dictionary containing pairwise comparison results\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from scipy import stats\n",
        "    import itertools\n",
        "    \n",
        "    # Get all model pairs for comparison\n",
        "    models = list(all_runs_model_metrics.keys())\n",
        "    model_pairs = list(itertools.combinations(models, 2))\n",
        "    \n",
        "    # Store results\n",
        "    comparison_results = {}\n",
        "    \n",
        "    for model1, model2 in model_pairs:\n",
        "        comparison_key = f\"{model1.split('/')[-1]}_vs_{model2.split('/')[-1]}\"\n",
        "        comparison_results[comparison_key] = {}\n",
        "        \n",
        "        # Get metrics (removing '_descr' suffix)\n",
        "        metrics = [metric.replace('_descr', '') for metric in list(all_runs_model_metrics[model1][0].keys())]\n",
        "        \n",
        "        # Create file for this model comparison\n",
        "        variance_results_text = f\"\\n=== Variance Analysis Results for {comparison_key} ===\\n\"\n",
        "        \n",
        "        for metric in metrics:\n",
        "            # Calculate differences and correlations for each resample\n",
        "            resample_differences = []\n",
        "            resample_ses = []\n",
        "            correlations = []\n",
        "            model1_variances = []  # Initialize list\n",
        "            model2_variances = []  # Initialize list\n",
        "            \n",
        "            # Iterate through resamples - Same number for both models\n",
        "            for resample_idx in range(len(all_runs_model_metrics[model1])):\n",
        "                # Get scores for both models for this resample\n",
        "                scores1 = all_runs_model_metrics[model1][resample_idx][f'{metric}_descr']\n",
        "                scores2 = all_runs_model_metrics[model2][resample_idx][f'{metric}_descr']\n",
        "                \n",
        "                # Calculate differences for each question\n",
        "                question_differences = np.array(scores1) - np.array(scores2)\n",
        "                \n",
        "                # Calculate mean difference for this resample\n",
        "                mean_diff = np.mean(question_differences) #Same as the formula in the paper since mean(a-b)=mean(a)-mean(b)\n",
        "                \n",
        "                # Calculate standard error for this resample - Paired analysis (section 4.2)\n",
        "                n = len(question_differences)\n",
        "                se = np.sqrt(np.sum((question_differences - mean_diff)**2) / (n * (n-1))) if n > 1 else np.nan\n",
        "\n",
        "                # # Calculate standard errors for each model - Unpaired analysis (section 4.1)\n",
        "                # n = len(scores1)\n",
        "                # sea = np.sqrt(np.sum((scores1 - np.mean(scores1))**2) / (n * (n - 1))) if n > 1 else np.nan\n",
        "                # seb = np.sqrt(np.sum((scores2 - np.mean(scores2))**2) / (n * (n - 1))) if n > 1 else np.nan\n",
        "\n",
        "                # # Calculate the combined standard error as sqrt(sea^2 + seb^2)\n",
        "                # se = np.sqrt(sea**2 + seb**2)\n",
        "\n",
        "                # Calculate variances for each model\n",
        "                var1 = np.var(scores1, ddof=1)  # Using ddof=1 for sample variance\n",
        "                var2 = np.var(scores2, ddof=1)\n",
        "                model1_variances.append(var1)\n",
        "                model2_variances.append(var2)\n",
        "                \n",
        "                # Calculate Pearson correlation\n",
        "                correlation, _ = stats.pearsonr(scores1, scores2)\n",
        "                \n",
        "                resample_differences.append(mean_diff)\n",
        "                resample_ses.append(se)\n",
        "                correlations.append(correlation)\n",
        "            \n",
        "            # Convert to numpy arrays\n",
        "            resample_differences = np.array(resample_differences)\n",
        "            resample_ses = np.array(resample_ses)\n",
        "            correlations = np.array(correlations)\n",
        "            model1_variances = np.array(model1_variances)\n",
        "            model2_variances = np.array(model2_variances)\n",
        "            print(\"resample_differences\",resample_differences)\n",
        "            print(\"resample_ses\",resample_ses)\n",
        "            print(\"correlations\",correlations)\n",
        "            print(f\"Model 1 variances: {model1_variances}\")\n",
        "            print(f\"Model 2 variances: {model2_variances}\")\n",
        "          \n",
        "            # Calculate overall mean difference over all resamples\n",
        "            overall_mean_diff = np.mean(resample_differences)\n",
        "            print(\"overall_mean_diff\",overall_mean_diff)\n",
        "            \n",
        "            #We want an aggregated SE across all resamples for the same questions (same paired differences)\n",
        "            #This approach accounts for the fact that each resampling provides a different estimate of the variance of the same underlying distribution, \n",
        "            # and averaging these estimates gives a better representation of the overall uncertainty.\n",
        "\n",
        "            # Calculate pooled standard error across resamples\n",
        "            R = len(resample_differences)\n",
        "            pooled_se = np.sqrt(np.sum(resample_ses**2) / (R**2))\n",
        "            print(\"pooled_se\",pooled_se)\n",
        "            \n",
        "            # # If the resampling results are independent estimates of variance (i.e., combining uncertainty estimates from independent sources), the combined variance is\n",
        "            # # the sum of all individual variances, and the combined standard error is given below (goal to capture total variability)\n",
        "            # # Calculate the overall combined SE across all resamples\n",
        "            # combined_se = np.sqrt(np.nansum(np.array(resample_ses)**2))\n",
        "\n",
        "            # Calculate overall variance reduction across all resamples\n",
        "            n = len(scores1)\n",
        "            \n",
        "            # Calculate mean variances across resamples\n",
        "            mean_var1 = np.mean(model1_variances)  # Var(sA)\n",
        "            mean_var2 = np.mean(model2_variances)  # Var(sB)\n",
        "            \n",
        "            # Calculate mean correlation across resamples\n",
        "            mean_correlation = np.mean(correlations)\n",
        "            \n",
        "            # Calculate covariance between model scores\n",
        "            mean_cov = mean_correlation * np.sqrt(mean_var1 * mean_var2)  # Cov(sA, sB)\n",
        "            \n",
        "            # Calculate variance for unpaired case: Var(μA-B,unpaired) = (Var(sA) + Var(sB))/n\n",
        "            var_unpaired = (mean_var1 + mean_var2) / n\n",
        "            \n",
        "            # Calculate variance for paired case: Var(μA-B,paired) = (Var(sA) + Var(sB) - 2Cov(sA,sB))/n\n",
        "            var_paired = (mean_var1 + mean_var2 - 2 * mean_cov) / n\n",
        "            \n",
        "            # The reduction in variance is: Var(μA-B,unpaired) - Var(μA-B,paired) = 2Cov(xA,xB)/n\n",
        "            variance_reduction = 2 * mean_cov / n  # This should equal var_unpaired - var_paired\n",
        "            \n",
        "            # Calculate percentage reduction in variance\n",
        "            percent_reduction = (variance_reduction / var_unpaired) * 100 if var_unpaired != 0 else 0\n",
        "\n",
        "            # Add results for this metric to the text\n",
        "            variance_results_text += f\"\\nMetric: {metric}\\n\"\n",
        "            variance_results_text += f\"Mean Model 1 variance (Var(sA)): {mean_var1:.6f}\\n\"\n",
        "            variance_results_text += f\"Mean Model 2 variance (Var(sB)): {mean_var2:.6f}\\n\"\n",
        "            variance_results_text += f\"Mean covariance (Cov(sA,sB)): {mean_cov:.6f}\\n\"\n",
        "            variance_results_text += f\"Unpaired variance: {var_unpaired:.6f}\\n\"\n",
        "            variance_results_text += f\"Paired variance: {var_paired:.6f}\\n\"\n",
        "            variance_results_text += f\"Variance reduction (2Cov(xA,xB)/n): {variance_reduction:.6f}\\n\"\n",
        "            variance_results_text += f\"Percent reduction: {percent_reduction:.1f}%\\n\"\n",
        "\n",
        "            # # Calculate t-statistic and p-value\n",
        "            # t_stat = overall_mean_diff / pooled_se if pooled_se != 0 else np.nan\n",
        "            # df = R - 1  # degrees of freedom\n",
        "            # p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df)) if not np.isnan(t_stat) else np.nan\n",
        "            \n",
        "            # # Calculate confidence interval\n",
        "            # t_crit = stats.t.ppf(0.975, df)  # 95% CI\n",
        "            # ci_margin = t_crit * pooled_se\n",
        "\n",
        "            # Calculate z-statistic and CI using standard normal distribution\n",
        "            z_stat = overall_mean_diff / pooled_se if pooled_se != 0 else np.nan\n",
        "            \n",
        "            # Calculate confidence interval using 1.96 for 95% CI\n",
        "            ci_margin = 1.96 * pooled_se\n",
        "            \n",
        "            # Calculate p-value using standard normal distribution\n",
        "            #For a two-tailed test p = 2 × (1 − Φ(|z|)), where Φ(z) is the cumulative distribution function (CDF) of the standard normal distribution.\n",
        "            p_value = 2 * (1 - stats.norm.cdf(abs(z_stat))) if not np.isnan(z_stat) else np.nan\n",
        "            \n",
        "            # # Calculate average Pearson correlation - not accurate when correlations close to 1 or -1, variances differences across resamples, sample size is small.\n",
        "            # avg_correlation = np.mean(correlations)\n",
        "\n",
        "            #Apply Fisher z-transformation\n",
        "            z_values = [0.5 * np.log((1 + r) / (1 - r)) for r in correlations]\n",
        "\n",
        "            # Compute the mean Fisher z-value\n",
        "            z_mean = np.mean(z_values)\n",
        "\n",
        "            #Back-transform to Pearson correlation scale\n",
        "            overall_correlation = (np.exp(2 * z_mean) - 1) / (np.exp(2 * z_mean) + 1)\n",
        "            \n",
        "            # Store results\n",
        "            comparison_results[comparison_key][metric] = {\n",
        "                \"mean_difference\": overall_mean_diff,\n",
        "                \"pooled_standard_error\": pooled_se,\n",
        "                \"ci_low\": overall_mean_diff - ci_margin,\n",
        "                \"ci_high\": overall_mean_diff + ci_margin,\n",
        "                # \"t_statistic\": t_stat,\n",
        "                \"z_statistic\": z_stat,\n",
        "                \"p_value\": p_value,\n",
        "                \"significant\": p_value < 0.05 if not np.isnan(p_value) else None,\n",
        "                \"better_model\": model1.split('/')[-1] if overall_mean_diff > 0 else model2.split('/')[-1],\n",
        "                \"pearson_correlation\": overall_correlation\n",
        "            }\n",
        "        \n",
        "        # Write all metrics results for this model comparison to a single file\n",
        "        with open(f'variance_results_{comparison_key}.txt', 'w') as f:\n",
        "            variance_results_text += f\"Overall Variance Reduction Analysis:\\n\"\n",
        "            f.write(variance_results_text)\n",
        "    \n",
        "    return comparison_results\n",
        "\n",
        "comparison_results = compare_model_performances(all_runs_model_metrics) #all_models_stats\n",
        "\n",
        "# Save results to file\n",
        "with open('comparison_results.json', 'w') as f:\n",
        "    # Convert numpy types to native Python types for JSON serialization\n",
        "    def convert_to_serializable(obj):\n",
        "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
        "            np.int16, np.int32, np.int64, np.uint8,\n",
        "            np.uint16, np.uint32, np.uint64)):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, (np.bool_)):\n",
        "            return bool(obj)\n",
        "        elif isinstance(obj, (np.ndarray,)):\n",
        "            return obj.tolist()\n",
        "        elif obj is None:\n",
        "            return None\n",
        "        return obj\n",
        "    \n",
        "    serializable_results = json.loads(\n",
        "        json.dumps(comparison_results, default=convert_to_serializable)\n",
        "    )\n",
        "    json.dump(serializable_results, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 15000x12000 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot comparison results\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Extract metrics and models from comparison_results\n",
        "metrics = [metric.replace('_descr', '') for metric in list_of_metrics]\n",
        "model_pairs = list(comparison_results.keys())\n",
        "\n",
        "# Create figure with subplots for each metric\n",
        "fig, axes = plt.subplots(2, 3, figsize=(25, 20), dpi=600)  # Increased DPI for higher resolution\n",
        "fig.suptitle('Model Comparison Results by Metric', fontsize=16, y=1.05)\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    ax = axes[i]\n",
        "    \n",
        "    # Extract data for this metric\n",
        "    means = []\n",
        "    cis = []\n",
        "    labels = []\n",
        "    \n",
        "    for pair in model_pairs:\n",
        "        metric_data = comparison_results[pair][metric]\n",
        "        means.append(metric_data['mean_difference'])\n",
        "        # ci_margin = metric_data['ci_margin']\n",
        "        cis.append([metric_data['ci_low'], \n",
        "                   metric_data['ci_high']])\n",
        "        labels.append(pair)\n",
        "\n",
        "    # Create bar plot\n",
        "    bars = ax.bar(range(len(means)), means)\n",
        "    \n",
        "    # Add error bars for confidence intervals\n",
        "    ax.errorbar(range(len(means)), means, \n",
        "               yerr=[[m - ci[0] for m, ci in zip(means, cis)],\n",
        "                     [ci[1] - m for m, ci in zip(means, cis)]],\n",
        "               fmt='none', color='black', capsize=5)\n",
        "    \n",
        "    # Add horizontal line at y=0\n",
        "    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "    \n",
        "    # Customize plot\n",
        "    ax.set_title(f'{metric.capitalize()}')\n",
        "    ax.set_xticks(range(len(means)))\n",
        "    ax.set_xticklabels(labels, rotation=90) # Changed to vertical labels\n",
        "    ax.set_ylabel('Mean Difference')\n",
        "    \n",
        "    # Color bars based on statistical significance\n",
        "    for j, bar in enumerate(bars):\n",
        "        if comparison_results[model_pairs[j]][metric]['p_value'] < 0.05:\n",
        "            bar.set_color('darkred')\n",
        "        else:\n",
        "            bar.set_color('lightgray')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot before showing with high resolution\n",
        "plt.savefig('model_comparisons.png', bbox_inches='tight', dpi=600)  # Increased DPI for higher resolution\n",
        "\n",
        "# Show plot after saving\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create Tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Metric | Model | Baseline | Model - Baseline | 95% Conf. Interval | Correlation |\n",
            "|--------|--------|-----------|-----------------|-------------------|-------------|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def create_comparison_table(comparison_results, metrics):\n",
        "    \"\"\"\n",
        "    Creates a formatted table from comparison results.\n",
        "    \n",
        "    Args:\n",
        "        comparison_results (dict): The comparison results dictionary\n",
        "        metrics (list): List of metrics to include\n",
        "        \n",
        "    Returns:\n",
        "        str: Formatted markdown table\n",
        "    \"\"\"\n",
        "    # Table header\n",
        "    table = \"| Metric | Model | Baseline | Model - Baseline | 95% Conf. Interval | Correlation |\\n\"\n",
        "    table += \"|--------|--------|-----------|-----------------|-------------------|-------------|\\n\"\n",
        "    \n",
        "    # Add rows for each comparison and metric\n",
        "    for pair in comparison_results:\n",
        "        model1, model2 = pair.split('_vs_')\n",
        "        for metric in metrics:\n",
        "            results = comparison_results[pair][metric]\n",
        "            \n",
        "            row = f\"| {metric} | {model1} | {model2} | \"\n",
        "            row += f\"{results['mean_difference']:.1%} | \"\n",
        "            row += f\"({results['ci_low']:.1%}, {results['ci_high']:.1%}) | \"\n",
        "            row += f\"{results['pearson_correlation']:.2f} |\\n\"\n",
        "            \n",
        "            table += row\n",
        "            \n",
        "    return table\n",
        "\n",
        "# Create and print the table\n",
        "metrics = [m.replace('_descr', '') for m in list_of_metrics]\n",
        "comparison_table = create_comparison_table(comparison_results, metrics)\n",
        "print(comparison_table)\n",
        "\n",
        "# Save table to file\n",
        "with open('comparison_table.txt', 'w') as f:\n",
        "    f.write(comparison_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Power Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Required samples per model for statistical power: 1000\n"
          ]
        }
      ],
      "source": [
        "from statsmodels.stats.power import TTestIndPower\n",
        "\n",
        "def perform_power_analysis(effect_size=0.5, alpha=0.05, power=0.8):\n",
        "    \"\"\"\n",
        "    Perform power analysis to determine required sample size.\n",
        "    \n",
        "    Args:\n",
        "        effect_size (float): Expected effect size (Cohen's d)\n",
        "        alpha (float): Significance level\n",
        "        power (float): Desired statistical power\n",
        "        \n",
        "    Returns:\n",
        "        int: Required sample size per group\n",
        "    \"\"\"\n",
        "    analysis = TTestIndPower()\n",
        "    sample_size = analysis.solve_power(\n",
        "        effect_size=effect_size,\n",
        "        alpha=alpha,\n",
        "        power=power,\n",
        "        alternative='two-sided'\n",
        "    )\n",
        "    return int(np.ceil(sample_size))\n",
        "\n",
        "# First, determine required sample size\n",
        "required_samples = perform_power_analysis(effect_size=0.1254, alpha=0.05, power=0.8)  #These parameters result in a sample size of 1000\n",
        "print(f\"Required samples per model for statistical power: {required_samples}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For real-time inference (below implementation only for meta-llama/Meta-Llama-3.1-8B-Instruct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# import torch\n",
        "# # del pipeline #Otherwise too much memory is used\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_name,device_map='auto')\n",
        "\n",
        "# #Example of real-time response generation\n",
        "# messages=[{\"role\": \"user\", \"content\": \"What is the chemical formula of water?\"}]\n",
        "\n",
        "# inputs_tokenized = tokenizer.apply_chat_template(\n",
        "#     messages,\n",
        "#     tokenize=True,\n",
        "#     add_generation_prompt=True,\n",
        "#     return_tensors=\"pt\",\n",
        "#     return_dict=True,\n",
        "# ).to(\"cuda\")\n",
        "\n",
        "# input_ids = inputs_tokenized['input_ids']\n",
        "\n",
        "# # Generate tokens one by one\n",
        "# max_length = 256\n",
        "# output_ids = input_ids\n",
        "# for _ in range(256):\n",
        "#     outputs = model.generate(\n",
        "#         output_ids,\n",
        "#         max_new_tokens=1,\n",
        "#         do_sample=True,\n",
        "#         top_k=50,\n",
        "#         pad_token_id=tokenizer.eos_token_id\n",
        "#     )\n",
        "#     new_token_id = outputs[0, -1].item()\n",
        "#     if new_token_id == tokenizer.eos_token_id:\n",
        "#         break\n",
        "#     output_ids = torch.cat([output_ids, outputs[:, -1:]], dim=1)\n",
        "#     new_token = tokenizer.decode(new_token_id, skip_special_tokens=True)\n",
        "#     print(new_token, end=\"\", flush=True)\n",
        "\n",
        "# print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Other evaluators from Langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://docs.smith.langchain.com/old/evaluation/faq/evaluator-implementations\n",
        "# https://docs.smith.langchain.com/old/evaluation/quickstart\n",
        "\n",
        "# from langsmith.evaluation import LangChainStringEvaluator\n",
        "\n",
        "# eval_llm = ChatOpenAI(model_name=judge_model.split('/')[1], api_key=openai_api_key, temperature=0.0, seed=42)\n",
        "\n",
        "# #Evaluators\n",
        "# qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\": eval_llm}) #LLM just gives 'correct' or 'incorrect' based on reference answer\n",
        "# context_qa_evaluator = LangChainStringEvaluator(\"context_qa\", config={\"llm\": eval_llm}) #Also uses reference context of example outputs to do the above\n",
        "# cot_qa_evaluator = LangChainStringEvaluator(\"cot_qa\", config={\"llm\": eval_llm}) #Same as above but with chain of thought 'reasoning'\n",
        "\n",
        "#Prompts Used internally:\n",
        "\n",
        "# 1) context_qa_evaluator: You are a teacher grading a quiz.\n",
        "# You are given a question, the context the question is about, and the student's answer. You are asked to score the student's answer as either CORRECT or INCORRECT, \n",
        "# based on the context.\n",
        "\n",
        "# Example Format:\n",
        "# QUESTION: question here\n",
        "# CONTEXT: context the question is about here\n",
        "# STUDENT ANSWER: student's answer here\n",
        "# GRADE: CORRECT or INCORRECT here\n",
        "\n",
        "# Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. \n",
        "# It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \n",
        "\n",
        "\n",
        "# 2) cot_qa_evaluator: You are a teacher grading a quiz.\n",
        "# You are given a question, the context the question is about, and the student's answer. You are asked to score the student's answer as either CORRECT or INCORRECT, \n",
        "# based on the context.\n",
        "# Write out in a step by step manner your reasoning to be sure that your conclusion is correct. Avoid simply stating the correct answer at the outset.\n",
        "\n",
        "# Example Format:\n",
        "# QUESTION: question here\n",
        "# CONTEXT: context the question is about here\n",
        "# STUDENT ANSWER: student's answer here\n",
        "# EXPLANATION: step by step reasoning here\n",
        "# GRADE: CORRECT or INCORRECT here\n",
        "\n",
        "# Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer.\n",
        "#  It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \n",
        "\n",
        "\n",
        "# 3) qa_evaluator: You are a teacher grading a quiz.\n",
        "# You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\n",
        "\n",
        "# Example Format:\n",
        "# QUESTION: question here\n",
        "# STUDENT ANSWER: student's answer here\n",
        "# TRUE ANSWER: true answer here\n",
        "# GRADE: CORRECT or INCORRECT here\n",
        "\n",
        "# Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer.\n",
        "#  It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, use custom prompts as shown below (and set {\"prompt\": PROMPT} as additional argument inside the config above)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from langchain_core.prompts.prompt import PromptTemplate\n",
        "\n",
        "# _PROMPT_TEMPLATE = \"\"\"You are an expert professor specialized in chemical engineering answers to questions.\n",
        "# You are grading the following question:\n",
        "# {query}\n",
        "# Here is the real answer:\n",
        "# {answer}\n",
        "# You are grading the following predicted answer:\n",
        "# {result}\n",
        "# Respond with CORRECT or INCORRECT:\n",
        "# \"\"\"\n",
        "\n",
        "# PROMPT = PromptTemplate(\n",
        "#     input_variables=[\"query\", \"result\", \"answer\"], template=_PROMPT_TEMPLATE\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notes: Non-reproducible results, even when seed set (https://platform.openai.com/docs/api-reference/chat/create#chat-create-seed), temperature=0 (top_p should not change when we changed temperature - smaller values result in more constrained and focused response - https://medium.com/@rasithbm/chatopenai-parameters-83bef49f6384)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "test_code_execution",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04b9c5f781e34806b9756d9e3e553a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cacd8a8bd03b4d0d83d266fe85e8ee65",
              "IPY_MODEL_abf8eb8102384433a59628820355d272",
              "IPY_MODEL_be7aa2993d57460c9d4f23c090e42c36"
            ],
            "layout": "IPY_MODEL_75aa3a3eb1b8420f9f26d404505e46cc"
          }
        },
        "0adc7382479c412f9c9230a17b56ea42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c13fc64f2e143b29105ec10e444b779": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ace1e934716404a9340bce56cb1a3cf",
            "placeholder": "​",
            "style": "IPY_MODEL_e3db7de6fcc04e6ba738f7ae78cef24d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1bd3eb0157a3477f907dae0c8fdbbec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24713d9c124b41488af127cfd3d1321e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331036e81d104ab49c44bcbde2d873f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ec4c77240854f3ebab46e0b7d307f74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ace1e934716404a9340bce56cb1a3cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9db2c468cf4dc598a80da6a548d034": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d9d371e98fc45329cf381bc36a290ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_331036e81d104ab49c44bcbde2d873f7",
            "placeholder": "​",
            "style": "IPY_MODEL_1bd3eb0157a3477f907dae0c8fdbbec4",
            "value": ""
          }
        },
        "6e84ac6346d8450d9814b9f1a647164c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75aa3a3eb1b8420f9f26d404505e46cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87311a42fde0441fb2e88a0655a95f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c13fc64f2e143b29105ec10e444b779",
              "IPY_MODEL_a2ac8fac33444da794be1f25a9c0d702",
              "IPY_MODEL_c0e527b08dd942a684246e2db22ed22d"
            ],
            "layout": "IPY_MODEL_cf7de095d0514bbf937d0632c777a232"
          }
        },
        "9253c9636a6c4e20b215ff11c928be07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "981e94324ba64b548259b1f1d297a564": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24713d9c124b41488af127cfd3d1321e",
            "placeholder": "​",
            "style": "IPY_MODEL_0adc7382479c412f9c9230a17b56ea42",
            "value": " 9/? [00:06&lt;00:00,  6.70s/it]"
          }
        },
        "98971ab8fe5c411f9c8c4c77753a745f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8bc61359ce44954bd235566d9ada2d7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f628c84495494694a62ca9c181ec63ba",
            "value": 1
          }
        },
        "9b527616d5a647d88a33b14ee2712211": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d9d371e98fc45329cf381bc36a290ae",
              "IPY_MODEL_98971ab8fe5c411f9c8c4c77753a745f",
              "IPY_MODEL_981e94324ba64b548259b1f1d297a564"
            ],
            "layout": "IPY_MODEL_c1ffb867972444579481d5408abcdba9"
          }
        },
        "a2ac8fac33444da794be1f25a9c0d702": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ec4c77240854f3ebab46e0b7d307f74",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdcfaa70f8c14dfcb0528b0cc0573db3",
            "value": 2
          }
        },
        "abf8eb8102384433a59628820355d272": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca6d3c439b254aa793c5d39304170849",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fac87e8a3a044de994d726896d479de3",
            "value": 1
          }
        },
        "b68644c249c04e059c924e1165a01370": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be7aa2993d57460c9d4f23c090e42c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6defd5c41f94c0ebda4080bb09c19c3",
            "placeholder": "​",
            "style": "IPY_MODEL_6e84ac6346d8450d9814b9f1a647164c",
            "value": " 9/? [01:10&lt;00:00,  5.27s/it]"
          }
        },
        "c0e527b08dd942a684246e2db22ed22d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed1e9eb6e6bc4452b3d12aecffb6cc2a",
            "placeholder": "​",
            "style": "IPY_MODEL_9253c9636a6c4e20b215ff11c928be07",
            "value": " 2/2 [00:18&lt;00:00,  8.66s/it]"
          }
        },
        "c1ffb867972444579481d5408abcdba9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca6d3c439b254aa793c5d39304170849": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cacd8a8bd03b4d0d83d266fe85e8ee65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b68644c249c04e059c924e1165a01370",
            "placeholder": "​",
            "style": "IPY_MODEL_5c9db2c468cf4dc598a80da6a548d034",
            "value": ""
          }
        },
        "cf7de095d0514bbf937d0632c777a232": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3db7de6fcc04e6ba738f7ae78cef24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8bc61359ce44954bd235566d9ada2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ed1e9eb6e6bc4452b3d12aecffb6cc2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f628c84495494694a62ca9c181ec63ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6defd5c41f94c0ebda4080bb09c19c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac87e8a3a044de994d726896d479de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdcfaa70f8c14dfcb0528b0cc0573db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
