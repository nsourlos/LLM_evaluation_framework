{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4671e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import runpod #pip install runpod\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "import pyperclip #pip install pyperclip==1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8ecaa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(os.path.join(os.path.dirname(os.getcwd()), \"env\"))  # Load env file from parent directory\n",
    "runpod.api_key = os.getenv('RUNPOD_API_KEY') #Load API key from environment variable\n",
    "files_path = os.path.join(os.path.dirname(os.getcwd())) #Path of the files to copy to the pod\n",
    "save_path = os.path.join(os.path.dirname(os.getcwd()), \"LLM_outputs\") #Path of the files to copy to the pod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654f897",
   "metadata": {},
   "source": [
    "Create Pod - Had to modify the files to take 'start_jupyter' as input, as stated in [this](https://github.com/runpod/runpod-python/pull/328/commits/071484c10438f546666667c7a2f38ad143beb435) issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "078ceb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pod - https://github.com/runpod/runpod-python/blob/main/runpod/api/ctl_commands.py\n",
    "pod = runpod.create_pod(name=\"testnew\", #Set a name for the pod\n",
    "                        image_name=\"runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel-ubuntu22.04\", #Set the image to use\n",
    "                        gpu_type_id=\"NVIDIA A40\", #runpod.get_gpus() for all gpu types #\"NVIDIA A40\",\"NVIDIA RTX A4500\", \"NVIDIA GeForce RTX 3080\"\n",
    "                        cloud_type=\"COMMUNITY\", #\"ALL\", \"COMMUNITY\", \"SECURE\"\n",
    "                        support_public_ip=True, #This is the default\n",
    "                        # country_code=\"FR\", #Data should remain within the EU\n",
    "                        container_disk_in_gb=100, #Set the disk size of the container\n",
    "                        volume_in_gb=200, #Set the volume size of the pod\n",
    "                        ports=\"8888/http,22/tcp\", #Set the ports to expose\n",
    "                        volume_mount_path=\"/workspace\", #Set the volume mount path - Should modified below if changed here\n",
    "                        start_jupyter=True, #Start the Jupyter notebook - Not exist in official documentation, found through issues.\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05552319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all my pods\n",
    "pods = runpod.get_pods()\n",
    "pods #Confirm the pod was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b80520",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(90) #Wait for the pod to be ready and get the http url\n",
    "exposed_pod = runpod.get_pods()[0]\n",
    "exposed_pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f87e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_number=int(exposed_pod['ports'].split(',')[1].split('/')[0]) # Extract 22 from '8888/http,22/tcp'\n",
    "\n",
    "ip, public_port = [port for port in exposed_pod['runtime']['ports'] if port['privatePort'] == port_number][0]['ip'], \\\n",
    "                    [port for port in exposed_pod['runtime']['ports'] if port['privatePort'] == port_number][0]['publicPort']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c8791d",
   "metadata": {},
   "source": [
    "Connect via SSH to the Pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcdc99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First connect via SSH to accept the host key\n",
    "ssh_command = f\"ssh -p {public_port} -i ~/.ssh/id_ed25519 -o StrictHostKeyChecking=accept-new root@{ip} exit\"\n",
    "subprocess.run(ssh_command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a2a29",
   "metadata": {},
   "source": [
    "Copy files from local PC to the Pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadbec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = files_path.replace('\\\\', '/')\n",
    "# Copy all files in source directory\n",
    "scp_command = f\"scp -P {public_port} -i ~/.ssh/id_ed25519 {source_dir}/* root@{ip}:/workspace/\"\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(scp_command, shell=True, check=True, capture_output=True, text=True)\n",
    "    print(\"Successfully copied all files.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error copying files: {e.stderr}\")\n",
    "\n",
    "# Copy llm_evaluation_framework folder recursively \n",
    "scp_framework_command = f\"scp -r -P {public_port} -i ~/.ssh/id_ed25519 {source_dir}/llm_evaluation_framework root@{ip}:/workspace/\"\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(scp_framework_command, shell=True, check=True, capture_output=True, text=True)\n",
    "    print(\"Successfully copied llm_evaluation_framework folder.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error copying llm_evaluation_framework folder: {e.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b932f8e",
   "metadata": {},
   "source": [
    "Create environment and install dependencies inside the Pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSH command to connect and execute multiple commands - Takes ~16mins to complete\n",
    "ssh_commands = [\n",
    "    \"python -m venv /workspace/myenv\",\n",
    "    \"source /workspace/myenv/bin/activate\", \n",
    "    \"cd /workspace\",\n",
    "    \"pip install --upgrade ipykernel\",\n",
    "    \"python -m ipykernel install --name myenv --user --display-name 'Python (myenv)'\",\n",
    "    \"pip install -r requirements_rag.txt && pip install flash-attn==2.6.3\", #requirements.txt copied in the previous step\n",
    "    \"pip install autoawq==0.2.8\", #Not compatible with colpali transformers version\n",
    "    \"pip install triton==3.2.0\", \n",
    "    \"pip install transformers==4.49.0\",\n",
    "    \"pip install langchain-google-genai==2.1.3\",\n",
    "\n",
    "    # #Use below for Visual RAG with colpali - Also copy pdf and img folder with imgs from pdf - deactivate above autoawq and transformers installation\n",
    "    # \"pip install cohere==5.15.0\",\n",
    "    # \"pip install --upgrade byaldi\",\n",
    "    # \"apt-get update\",\n",
    "    # \"apt-get install -y poppler-utils\",  # not working in macOS\n",
    "    # \"pip install -q pdf2image transformers==4.51.3 qwen-vl-utils\",  # needed to get Qwen - git+https://github.com/huggingface/transformers.git\n",
    "    # \"pip uninstall flash-attn -y\",\n",
    "    # \"pip install ninja\",\n",
    "    # \"pip install packaging\",\n",
    "    # \"git clone https://github.com/Dao-AILab/flash-attention\",\n",
    "    # \"cd flash-attention\",\n",
    "    # \"pip install .\",\n",
    "    # \"pip uninstall torch torchvision -y\",\n",
    "    # \"pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\",\n",
    "    # \"pip install ipywidgets\",\n",
    "    # \"cd ..\",\n",
    "]\n",
    "\n",
    "# Join commands with semicolons for sequential execution\n",
    "command_string = \"; \".join(ssh_commands)\n",
    "ssh_command = f\"\"\"ssh root@{ip} -p {public_port} -i ~/.ssh/id_ed25519 \"{command_string}\" \"\"\"\n",
    "\n",
    "# Execute the SSH command with live output streaming\n",
    "process = subprocess.Popen(ssh_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "# Stream output in real-time\n",
    "while True:\n",
    "    output = process.stdout.readline()\n",
    "    if output == '' and process.poll() is not None:\n",
    "        break\n",
    "    if output:\n",
    "        print(output.strip())\n",
    "\n",
    "# Print any errors after completion\n",
    "if process.returncode != 0:\n",
    "    print(\"Error executing commands:\")\n",
    "    print(process.stderr.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c40ee71",
   "metadata": {},
   "source": [
    "Install environment and dependencies for executing code to evaluate water networks questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c941da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new virtual environment for testing\n",
    "venv_name = \"test_LLM\"\n",
    "command_install = f\"ssh root@{ip} -p {public_port} -i ~/.ssh/id_ed25519 \\\"python -m venv /workspace/{venv_name}\\\"\"\n",
    "print(\"Creating test environment...\")\n",
    "\n",
    "try:\n",
    "    # Execute the command and capture the output\n",
    "    result_install = subprocess.check_output(command_install, shell=True, stderr=subprocess.STDOUT, text=True)\n",
    "    print(\"Venv installation:\", result_install)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    result_install = f\"Error in installation: {e.output}\"\n",
    "    print(result_install)\n",
    "\n",
    "# Activate the virtual environment and install requirements\n",
    "activate_cmd = f\"source /workspace/{venv_name}/bin/activate\"\n",
    "requirements_file = \"requirements_code_execution.txt\"\n",
    "\n",
    "try:\n",
    "    install_cmd = f\"bash -c '{activate_cmd} && pip install -r /workspace/{requirements_file}'\"\n",
    "    ssh_command = f\"ssh root@{ip} -p {public_port} -i ~/.ssh/id_ed25519 \\\"{install_cmd}\\\"\"\n",
    "    \n",
    "    # Execute the SSH command with live output streaming\n",
    "    process = subprocess.Popen(ssh_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    \n",
    "    # Stream output in real-time\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "    \n",
    "    # Check for errors\n",
    "    if process.returncode != 0:\n",
    "        print(\"Error installing requirements:\")\n",
    "        print(process.stderr.read())\n",
    "    else:\n",
    "        print(f\"Successfully installed requirements in {venv_name} environment \\n\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error in requirements installation: {str(e)} \\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Install WNTR and other required packages\n",
    "try:\n",
    "    install_cmd = f\"bash -c '{activate_cmd} && pip install --upgrade pip setuptools wheel && pip install --upgrade --force-reinstall numpy && pip install --upgrade --force-reinstall wntr'\"\n",
    "    ssh_command = f\"ssh root@{ip} -p {public_port} -i ~/.ssh/id_ed25519 \\\"{install_cmd}\\\"\"\n",
    "    \n",
    "    # Execute the SSH command with live output streaming\n",
    "    process = subprocess.Popen(ssh_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    \n",
    "    # Stream output in real-time\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "    \n",
    "    # Check for errors\n",
    "    if process.returncode != 0:\n",
    "        print(\"Error installing WNTR:\")\n",
    "        print(process.stderr.read())\n",
    "    else:\n",
    "        print(\"Successfully installed WNTR and dependencies \\n\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error in WNTR installation: {str(e)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de21e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Jupyter password from env variables\n",
    "jupyter_password = [env.split('=')[1] for env in exposed_pod['env'] if env.startswith('JUPYTER_PASSWORD')][0]\n",
    "jupyter_port = exposed_pod['ports'].split(\"/\")[0]  # Extract 8888 from \"8888/http,22/tcp\"\n",
    "jupyter_url = \"https://\" + exposed_pod['id'] + \"-\" + jupyter_port +\".proxy.runpod.net/?token=\" + jupyter_password\n",
    "jupyter_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c749b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy the above variable to the clipboard - Best time to run until here should be 3.5mins\n",
    "pyperclip.copy(jupyter_url)\n",
    "print(\"Jupyter URL copied to clipboard!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0edefb2",
   "metadata": {},
   "source": [
    "Copy files from Pod to local PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy output files from remote to local\n",
    "file_patterns = [\"*.xlsx*\", \"*.png\", \"*.json\", \"*.txt\"]  # File patterns to copy\n",
    "local_dest = save_path\n",
    "\n",
    "# Ensure local destination directory exists\n",
    "os.makedirs(local_dest, exist_ok=True)\n",
    "\n",
    "# Copy each file pattern\n",
    "for pattern in file_patterns:\n",
    "    # Construct scp command to copy files from remote to local\n",
    "    scp_command = f\"scp -P {public_port} -i ~/.ssh/id_ed25519 root@{ip}:/workspace/{pattern} {local_dest}\"\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(scp_command, shell=True, check=True, capture_output=True, text=True)\n",
    "        print(f\"Successfully copied {pattern} files to {local_dest}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error copying {pattern} files: {e.stderr}\")\n",
    "\n",
    "# Copy llm_evaluation_framework folder\n",
    "scp_command = f\"scp -r -P {public_port} -i ~/.ssh/id_ed25519 root@{ip}:/workspace/llm_evaluation_framework {local_dest}\"\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(scp_command, shell=True, check=True, capture_output=True, text=True)\n",
    "    print(f\"Successfully copied llm_evaluation_framework folder to {local_dest}\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error copying llm_evaluation_framework folder: {e.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2295c730",
   "metadata": {},
   "source": [
    "Terminate the Pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7a28e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runpod.terminate_pod(pods[0]['id'])\n",
    "# runpod.get_pods()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRACO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
